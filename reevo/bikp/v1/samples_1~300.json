[
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 1,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (randomly among top 20% or solutions with low weight utilization)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios to identify items with high potential to improve both objectives\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: swap items based on combined ratio and randomness\n    for i in sorted_indices:\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Additional random swaps to explore neighborhood\n    for _ in range(5):\n        i = random.choice(sorted_indices)\n        if base_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.882099645621616,
            2.2329690754413605
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (randomly among top 20% or solutions with low weight utilization)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios to identify items with high potential to improve both objectives\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: swap items based on combined ratio and randomness\n    for i in sorted_indices:\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Additional random swaps to explore neighborhood\n    for _ in range(5):\n        i = random.choice(sorted_indices)\n        if base_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 1,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (randomly among top 20% or solutions with low weight utilization)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios to identify items with high potential to improve both objectives\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: swap items based on combined ratio and randomness\n    for i in sorted_indices:\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Additional random swaps to explore neighborhood\n    for _ in range(5):\n        i = random.choice(sorted_indices)\n        if base_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.882099645621616,
            2.2329690754413605
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (randomly among top 20% or solutions with low weight utilization)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios to identify items with high potential to improve both objectives\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: swap items based on combined ratio and randomness\n    for i in sorted_indices:\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Additional random swaps to explore neighborhood\n    for _ in range(5):\n        i = random.choice(sorted_indices)\n        if base_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 1,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (randomly among top 20% or solutions with low weight utilization)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios to identify items with high potential to improve both objectives\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: swap items based on combined ratio and randomness\n    for i in sorted_indices:\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Additional random swaps to explore neighborhood\n    for _ in range(5):\n        i = random.choice(sorted_indices)\n        if base_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.882099645621616,
            2.2329690754413605
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (randomly among top 20% or solutions with low weight utilization)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios to identify items with high potential to improve both objectives\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: swap items based on combined ratio and randomness\n    for i in sorted_indices:\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Additional random swaps to explore neighborhood\n    for _ in range(5):\n        i = random.choice(sorted_indices)\n        if base_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 2,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (those with lower values but room for improvement)\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with lower values but higher potential for improvement\n            potential = (np.sum(value1_lst * sol) + np.sum(value2_lst * sol)) * (1 + remaining_capacity / capacity)\n            candidates.append((sol, potential))\n\n    if not candidates:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select the solution with the highest potential\n        base_solution = max(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    for _ in range(min(3, n_items)):  # Limit the number of flips to avoid excessive changes\n        # Calculate value-to-weight ratios for both objectives\n        ratio1 = value1_lst / (weight_lst + 1e-6)\n        ratio2 = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = ratio1 + ratio2  # Combine both objectives\n\n        # Select items to flip based on combined ratio and randomness\n        flip_prob = combined_ratio / np.sum(combined_ratio)\n        flip_indices = np.random.choice(n_items, size=min(3, n_items), p=flip_prob, replace=False)\n\n        for idx in flip_indices:\n            # Try flipping the item\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                # Check if adding the item would exceed capacity\n                if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.39218266838656207,
            2.4569281339645386
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (those with lower values but room for improvement)\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with lower values but higher potential for improvement\n            potential = (np.sum(value1_lst * sol) + np.sum(value2_lst * sol)) * (1 + remaining_capacity / capacity)\n            candidates.append((sol, potential))\n\n    if not candidates:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select the solution with the highest potential\n        base_solution = max(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    for _ in range(min(3, n_items)):  # Limit the number of flips to avoid excessive changes\n        # Calculate value-to-weight ratios for both objectives\n        ratio1 = value1_lst / (weight_lst + 1e-6)\n        ratio2 = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = ratio1 + ratio2  # Combine both objectives\n\n        # Select items to flip based on combined ratio and randomness\n        flip_prob = combined_ratio / np.sum(combined_ratio)\n        flip_indices = np.random.choice(n_items, size=min(3, n_items), p=flip_prob, replace=False)\n\n        for idx in flip_indices:\n            # Try flipping the item\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                # Check if adding the item would exceed capacity\n                if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 3,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., top 20% by combined value)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = np.random.randint(0, max(1, len(sorted_archive) // 5))\n    base_solution = sorted_archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps with value-based greedy selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Perform random swaps with a bias toward higher-value items\n    for _ in range(min(5, num_items // 2)):  # Limit swaps to avoid excessive computation\n        # Select a random item to flip\n        item_idx = np.random.randint(0, num_items)\n\n        # Calculate potential change in weight and values\n        delta_weight = weight_lst[item_idx] if base_solution[item_idx] == 0 else -weight_lst[item_idx]\n        delta_value1 = value1_lst[item_idx] if base_solution[item_idx] == 0 else -value1_lst[item_idx]\n        delta_value2 = value2_lst[item_idx] if base_solution[item_idx] == 0 else -value2_lst[item_idx]\n\n        # Check feasibility and apply swap if beneficial\n        if (current_weight + delta_weight <= capacity) or (base_solution[item_idx] == 1):\n            # Prefer flipping out items with low value or flipping in items with high value\n            if (base_solution[item_idx] == 1 and (delta_value1 < 0 or delta_value2 < 0)) or \\\n               (base_solution[item_idx] == 0 and (delta_value1 > 0 or delta_value2 > 0)):\n                new_solution[item_idx] = 1 - new_solution[item_idx]\n                current_weight += delta_weight\n\n    # Additional greedy step: add high-value items not in the solution\n    remaining_weight = capacity - current_weight\n    for item_idx in np.argsort(-(value1_lst + value2_lst)):  # Sort by combined value\n        if new_solution[item_idx] == 0 and weight_lst[item_idx] <= remaining_weight:\n            new_solution[item_idx] = 1\n            remaining_weight -= weight_lst[item_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3509471775768592,
            4.939451605081558
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., top 20% by combined value)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = np.random.randint(0, max(1, len(sorted_archive) // 5))\n    base_solution = sorted_archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps with value-based greedy selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Perform random swaps with a bias toward higher-value items\n    for _ in range(min(5, num_items // 2)):  # Limit swaps to avoid excessive computation\n        # Select a random item to flip\n        item_idx = np.random.randint(0, num_items)\n\n        # Calculate potential change in weight and values\n        delta_weight = weight_lst[item_idx] if base_solution[item_idx] == 0 else -weight_lst[item_idx]\n        delta_value1 = value1_lst[item_idx] if base_solution[item_idx] == 0 else -value1_lst[item_idx]\n        delta_value2 = value2_lst[item_idx] if base_solution[item_idx] == 0 else -value2_lst[item_idx]\n\n        # Check feasibility and apply swap if beneficial\n        if (current_weight + delta_weight <= capacity) or (base_solution[item_idx] == 1):\n            # Prefer flipping out items with low value or flipping in items with high value\n            if (base_solution[item_idx] == 1 and (delta_value1 < 0 or delta_value2 < 0)) or \\\n               (base_solution[item_idx] == 0 and (delta_value1 > 0 or delta_value2 > 0)):\n                new_solution[item_idx] = 1 - new_solution[item_idx]\n                current_weight += delta_weight\n\n    # Additional greedy step: add high-value items not in the solution\n    remaining_weight = capacity - current_weight\n    for item_idx in np.argsort(-(value1_lst + value2_lst)):  # Sort by combined value\n        if new_solution[item_idx] == 0 and weight_lst[item_idx] <= remaining_weight:\n            new_solution[item_idx] = 1\n            remaining_weight -= weight_lst[item_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 4,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (with high potential for improvement)\n    # Criteria: Solutions with high objective values but still have room for improvement\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_k = min(5, len(sorted_archive))\n    candidates = sorted_archive[:top_k]\n\n    # Select a random candidate from top performers\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search\n    # First, perform random swaps to diversify\n    num_swaps = random.randint(1, min(3, len(new_solution)))\n    for _ in range(num_swaps):\n        # Select two distinct items\n        i, j = random.sample(range(len(new_solution)), 2)\n\n        # Try swapping them\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        # Check feasibility\n        current_weight = np.sum(weight_lst[temp_solution == 1])\n        if current_weight <= capacity:\n            new_solution = temp_solution\n\n    # Then perform greedy improvement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            current_weight = np.sum(weight_lst[temp_solution == 1])\n            if current_weight <= capacity:\n                # Calculate marginal utility\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                # Accept if it improves at least one objective\n                if marginal1 > 0 or marginal2 > 0:\n                    new_solution = temp_solution\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            current_weight = np.sum(weight_lst[temp_solution == 1])\n            if current_weight <= capacity:\n                # Calculate marginal utility\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                # Accept if it improves at least one objective\n                if marginal1 > 0 or marginal2 > 0:\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.5099531377488545,
            9.932463586330414
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (with high potential for improvement)\n    # Criteria: Solutions with high objective values but still have room for improvement\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_k = min(5, len(sorted_archive))\n    candidates = sorted_archive[:top_k]\n\n    # Select a random candidate from top performers\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search\n    # First, perform random swaps to diversify\n    num_swaps = random.randint(1, min(3, len(new_solution)))\n    for _ in range(num_swaps):\n        # Select two distinct items\n        i, j = random.sample(range(len(new_solution)), 2)\n\n        # Try swapping them\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        # Check feasibility\n        current_weight = np.sum(weight_lst[temp_solution == 1])\n        if current_weight <= capacity:\n            new_solution = temp_solution\n\n    # Then perform greedy improvement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            current_weight = np.sum(weight_lst[temp_solution == 1])\n            if current_weight <= capacity:\n                # Calculate marginal utility\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                # Accept if it improves at least one objective\n                if marginal1 > 0 or marginal2 > 0:\n                    new_solution = temp_solution\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            current_weight = np.sum(weight_lst[temp_solution == 1])\n            if current_weight <= capacity:\n                # Calculate marginal utility\n                marginal1 = value1_lst[i]\n                marginal2 = value2_lst[i]\n                # Accept if it improves at least one objective\n                if marginal1 > 0 or marginal2 > 0:\n                    new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 5,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution by flipping a few bits\n    perturbation_size = min(3, len(base_solution))\n    flip_indices = np.random.choice(len(base_solution), size=perturbation_size, replace=False)\n    new_solution = base_solution.copy()\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess items if needed\n    excess_weight = np.sum(weight_lst * new_solution) - capacity\n    if excess_weight > 0:\n        # Remove items randomly until feasible\n        while excess_weight > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Add item if it improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[item]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[item]\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n\n            if (new_value1 > current_value1) and (new_value2 > current_value2):\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.40763878303261836,
            1.7192518413066864
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution by flipping a few bits\n    perturbation_size = min(3, len(base_solution))\n    flip_indices = np.random.choice(len(base_solution), size=perturbation_size, replace=False)\n    new_solution = base_solution.copy()\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess items if needed\n    excess_weight = np.sum(weight_lst * new_solution) - capacity\n    if excess_weight > 0:\n        # Remove items randomly until feasible\n        while excess_weight > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Add item if it improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[item]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[item]\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n\n            if (new_value1 > current_value1) and (new_value2 > current_value2):\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 5,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution by flipping a few bits\n    perturbation_size = min(3, len(base_solution))\n    flip_indices = np.random.choice(len(base_solution), size=perturbation_size, replace=False)\n    new_solution = base_solution.copy()\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess items if needed\n    excess_weight = np.sum(weight_lst * new_solution) - capacity\n    if excess_weight > 0:\n        # Remove items randomly until feasible\n        while excess_weight > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Add item if it improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[item]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[item]\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n\n            if (new_value1 > current_value1) and (new_value2 > current_value2):\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.40763878303261836,
            1.7192518413066864
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution by flipping a few bits\n    perturbation_size = min(3, len(base_solution))\n    flip_indices = np.random.choice(len(base_solution), size=perturbation_size, replace=False)\n    new_solution = base_solution.copy()\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess items if needed\n    excess_weight = np.sum(weight_lst * new_solution) - capacity\n    if excess_weight > 0:\n        # Remove items randomly until feasible\n        while excess_weight > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Add item if it improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[item]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[item]\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n\n            if (new_value1 > current_value1) and (new_value2 > current_value2):\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 6,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal for both objectives)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        potential = (capacity - total_weight) / capacity  # Higher potential if more room for improvement\n        candidates.append((sol, obj, potential))\n\n    # Sort candidates by potential and pick one randomly from the top 30%\n    candidates.sort(key=lambda x: -x[2])\n    selected = random.choice(candidates[:max(1, len(candidates) // 3)])[0]\n    base_solution = selected.copy()\n\n    # Hybrid local search: Random flip with greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (1-3 items)\n    flip_indices = random.sample(range(len(new_solution)), random.randint(1, min(3, len(new_solution))))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility and improve solution greedily\n    total_weight = np.sum(new_solution * weight_lst)\n    while total_weight > capacity:\n        # Remove the heaviest item in the knapsack\n        in_knapsack = np.where(new_solution == 1)[0]\n        if len(in_knapsack) == 0:\n            break  # No items left to remove\n        heaviest = in_knapsack[np.argmax(weight_lst[in_knapsack])]\n        new_solution[heaviest] = 0\n        total_weight -= weight_lst[heaviest]\n\n    # Step 3: Greedy improvement - add items that improve both objectives\n    out_of_knapsack = np.where(new_solution == 0)[0]\n    np.random.shuffle(out_of_knapsack)  # Randomize order for diversity\n\n    for idx in out_of_knapsack:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Calculate improvement in both objectives\n            improvement1 = value1_lst[idx]\n            improvement2 = value2_lst[idx]\n\n            # Add if it improves at least one objective\n            if improvement1 > 0 or improvement2 > 0:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.35478066151428506,
            5.244090288877487
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal for both objectives)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        potential = (capacity - total_weight) / capacity  # Higher potential if more room for improvement\n        candidates.append((sol, obj, potential))\n\n    # Sort candidates by potential and pick one randomly from the top 30%\n    candidates.sort(key=lambda x: -x[2])\n    selected = random.choice(candidates[:max(1, len(candidates) // 3)])[0]\n    base_solution = selected.copy()\n\n    # Hybrid local search: Random flip with greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (1-3 items)\n    flip_indices = random.sample(range(len(new_solution)), random.randint(1, min(3, len(new_solution))))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility and improve solution greedily\n    total_weight = np.sum(new_solution * weight_lst)\n    while total_weight > capacity:\n        # Remove the heaviest item in the knapsack\n        in_knapsack = np.where(new_solution == 1)[0]\n        if len(in_knapsack) == 0:\n            break  # No items left to remove\n        heaviest = in_knapsack[np.argmax(weight_lst[in_knapsack])]\n        new_solution[heaviest] = 0\n        total_weight -= weight_lst[heaviest]\n\n    # Step 3: Greedy improvement - add items that improve both objectives\n    out_of_knapsack = np.where(new_solution == 0)[0]\n    np.random.shuffle(out_of_knapsack)  # Randomize order for diversity\n\n    for idx in out_of_knapsack:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Calculate improvement in both objectives\n            improvement1 = value1_lst[idx]\n            improvement2 = value2_lst[idx]\n\n            # Add if it improves at least one objective\n            if improvement1 > 0 or improvement2 > 0:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 7,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Select solution with highest density\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed)\n    # We prioritize items with high value-to-weight ratios in either objective\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Highest to lowest\n\n    # Try to flip items in order of combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                break\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # If no single flip worked, try a more sophisticated move\n    if np.array_equal(new_solution, base_solution):\n        # Try swapping two items: one in the knapsack and one out\n        in_knapsack = np.where(new_solution == 1)[0]\n        out_knapsack = np.where(new_solution == 0)[0]\n\n        for in_idx in in_knapsack:\n            for out_idx in out_knapsack:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    # Perform the swap\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9068510391491447,
            1.131665199995041
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Select solution with highest density\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed)\n    # We prioritize items with high value-to-weight ratios in either objective\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Highest to lowest\n\n    # Try to flip items in order of combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                break\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # If no single flip worked, try a more sophisticated move\n    if np.array_equal(new_solution, base_solution):\n        # Try swapping two items: one in the knapsack and one out\n        in_knapsack = np.where(new_solution == 1)[0]\n        out_knapsack = np.where(new_solution == 0)[0]\n\n        for in_idx in in_knapsack:\n            for out_idx in out_knapsack:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    # Perform the swap\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    return new_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 7,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Select solution with highest density\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed)\n    # We prioritize items with high value-to-weight ratios in either objective\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Highest to lowest\n\n    # Try to flip items in order of combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                break\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # If no single flip worked, try a more sophisticated move\n    if np.array_equal(new_solution, base_solution):\n        # Try swapping two items: one in the knapsack and one out\n        in_knapsack = np.where(new_solution == 1)[0]\n        out_knapsack = np.where(new_solution == 0)[0]\n\n        for in_idx in in_knapsack:\n            for out_idx in out_knapsack:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    # Perform the swap\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9068510391491447,
            1.131665199995041
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Select solution with highest density\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed)\n    # We prioritize items with high value-to-weight ratios in either objective\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Highest to lowest\n\n    # Try to flip items in order of combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                break\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # If no single flip worked, try a more sophisticated move\n    if np.array_equal(new_solution, base_solution):\n        # Try swapping two items: one in the knapsack and one out\n        in_knapsack = np.where(new_solution == 1)[0]\n        out_knapsack = np.where(new_solution == 0)[0]\n\n        for in_idx in in_knapsack:\n            for out_idx in out_knapsack:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    # Perform the swap\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    return new_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 7,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Select solution with highest density\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed)\n    # We prioritize items with high value-to-weight ratios in either objective\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Highest to lowest\n\n    # Try to flip items in order of combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                break\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # If no single flip worked, try a more sophisticated move\n    if np.array_equal(new_solution, base_solution):\n        # Try swapping two items: one in the knapsack and one out\n        in_knapsack = np.where(new_solution == 1)[0]\n        out_knapsack = np.where(new_solution == 0)[0]\n\n        for in_idx in in_knapsack:\n            for out_idx in out_knapsack:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    # Perform the swap\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9068510391491447,
            1.131665199995041
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Select solution with highest density\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed)\n    # We prioritize items with high value-to-weight ratios in either objective\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = value1_ratio + value2_ratio\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Highest to lowest\n\n    # Try to flip items in order of combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                break\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # If no single flip worked, try a more sophisticated move\n    if np.array_equal(new_solution, base_solution):\n        # Try swapping two items: one in the knapsack and one out\n        in_knapsack = np.where(new_solution == 1)[0]\n        out_knapsack = np.where(new_solution == 0)[0]\n\n        for in_idx in in_knapsack:\n            for out_idx in out_knapsack:\n                if (current_weight - weight_lst[in_idx] + weight_lst[out_idx]) <= capacity:\n                    # Perform the swap\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    return new_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 8,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_solution = None\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            selected_solution = sol.copy()\n            break\n    if selected_solution is None:\n        selected_solution = archive[0][0].copy()  # Fallback to first solution if all are near capacity\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy: flip a subset of items with high marginal contribution\n    # Calculate marginal contributions for each item\n    marginal_contributions = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(marginal_contributions)[::-1]  # Sort by highest marginal contribution\n\n    # Randomly select a subset of items to flip (with higher marginal contribution more likely)\n    flip_indices = np.random.choice(sorted_indices[:min(10, len(sorted_indices))], size=np.random.randint(1, 4), replace=False)\n\n    # Flip the selected items while ensuring feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item would exceed capacity\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8328180091036862,
            3.1273639500141144
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_solution = None\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            selected_solution = sol.copy()\n            break\n    if selected_solution is None:\n        selected_solution = archive[0][0].copy()  # Fallback to first solution if all are near capacity\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy: flip a subset of items with high marginal contribution\n    # Calculate marginal contributions for each item\n    marginal_contributions = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(marginal_contributions)[::-1]  # Sort by highest marginal contribution\n\n    # Randomly select a subset of items to flip (with higher marginal contribution more likely)\n    flip_indices = np.random.choice(sorted_indices[:min(10, len(sorted_indices))], size=np.random.randint(1, 4), replace=False)\n\n    # Flip the selected items while ensuring feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item would exceed capacity\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 9,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions that are not too close to the archive's boundary in either objective\n    objectives = np.array([obj for _, obj in archive])\n    min_obj1, max_obj1 = np.min(objectives[:, 0]), np.max(objectives[:, 0])\n    min_obj2, max_obj2 = np.min(objectives[:, 1]), np.max(objectives[:, 1])\n\n    # Calculate the \"promise score\" for each solution: balance between improvement potential and diversity\n    promise_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        obj1, obj2 = obj\n        # Prefer solutions that are not extreme in either objective\n        obj1_norm = (obj1 - min_obj1) / (max_obj1 - min_obj1 + 1e-10) if max_obj1 > min_obj1 else 0.5\n        obj2_norm = (obj2 - min_obj2) / (max_obj2 - min_obj2 + 1e-10) if max_obj2 > min_obj2 else 0.5\n        diversity_score = 1 - abs(obj1_norm - obj2_norm)  # Prefer balanced solutions\n        improvement_potential = (obj1_norm + obj2_norm) / 2  # Prefer higher objective values\n        promise_scores.append(diversity_score * improvement_potential)\n\n    # Select the solution with the highest promise score\n    selected_idx = np.argmax(promise_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor using hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a small number of random bits\n    num_items = len(base_solution)\n    num_flips = min(3, num_items)  # Limit the number of flips to avoid excessive changes\n    flip_indices = np.random.choice(num_items, size=num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_indices)\n        for idx in excess_indices:\n            new_solution[idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight <= capacity:\n                break\n\n    # Step 3: Greedy improvement step\n    # Try to add or remove items to improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_items = np.where(new_solution == 1)[0]\n\n    # Calculate current total weight and objectives\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    total_value1 = np.sum(value1_lst[new_solution == 1])\n    total_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to add items that improve both objectives\n    for idx in remaining_items:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Calculate the marginal gain in both objectives\n            gain1 = value1_lst[idx]\n            gain2 = value2_lst[idx]\n            # If both gains are positive, add the item\n            if gain1 > 0 and gain2 > 0:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                total_value1 += gain1\n                total_value2 += gain2\n\n    # Try to remove items that hurt both objectives\n    for idx in current_items:\n        # Calculate the marginal loss in both objectives\n        loss1 = value1_lst[idx]\n        loss2 = value2_lst[idx]\n        # If both losses are positive, consider removing the item\n        if loss1 > 0 and loss2 > 0:\n            # Check if removing this item would still keep the solution feasible\n            # (This is redundant here since we're removing, but kept for completeness)\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n            total_value1 -= loss1\n            total_value2 -= loss2\n\n    return new_solution\n\n",
        "score": [
            -0.8299145690372003,
            1.858940064907074
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions that are not too close to the archive's boundary in either objective\n    objectives = np.array([obj for _, obj in archive])\n    min_obj1, max_obj1 = np.min(objectives[:, 0]), np.max(objectives[:, 0])\n    min_obj2, max_obj2 = np.min(objectives[:, 1]), np.max(objectives[:, 1])\n\n    # Calculate the \"promise score\" for each solution: balance between improvement potential and diversity\n    promise_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        obj1, obj2 = obj\n        # Prefer solutions that are not extreme in either objective\n        obj1_norm = (obj1 - min_obj1) / (max_obj1 - min_obj1 + 1e-10) if max_obj1 > min_obj1 else 0.5\n        obj2_norm = (obj2 - min_obj2) / (max_obj2 - min_obj2 + 1e-10) if max_obj2 > min_obj2 else 0.5\n        diversity_score = 1 - abs(obj1_norm - obj2_norm)  # Prefer balanced solutions\n        improvement_potential = (obj1_norm + obj2_norm) / 2  # Prefer higher objective values\n        promise_scores.append(diversity_score * improvement_potential)\n\n    # Select the solution with the highest promise score\n    selected_idx = np.argmax(promise_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor using hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a small number of random bits\n    num_items = len(base_solution)\n    num_flips = min(3, num_items)  # Limit the number of flips to avoid excessive changes\n    flip_indices = np.random.choice(num_items, size=num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_indices)\n        for idx in excess_indices:\n            new_solution[idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight <= capacity:\n                break\n\n    # Step 3: Greedy improvement step\n    # Try to add or remove items to improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_items = np.where(new_solution == 1)[0]\n\n    # Calculate current total weight and objectives\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    total_value1 = np.sum(value1_lst[new_solution == 1])\n    total_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to add items that improve both objectives\n    for idx in remaining_items:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Calculate the marginal gain in both objectives\n            gain1 = value1_lst[idx]\n            gain2 = value2_lst[idx]\n            # If both gains are positive, add the item\n            if gain1 > 0 and gain2 > 0:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                total_value1 += gain1\n                total_value2 += gain2\n\n    # Try to remove items that hurt both objectives\n    for idx in current_items:\n        # Calculate the marginal loss in both objectives\n        loss1 = value1_lst[idx]\n        loss2 = value2_lst[idx]\n        # If both losses are positive, consider removing the item\n        if loss1 > 0 and loss2 > 0:\n            # Check if removing this item would still keep the solution feasible\n            # (This is redundant here since we're removing, but kept for completeness)\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n            total_value1 -= loss1\n            total_value2 -= loss2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 10,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    # Sort solutions by their dominance and potential for improvement\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    candidates = archive_sorted[:max(1, len(archive) // 2)]\n\n    # Randomly select a candidate solution\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random flip with bias towards items with high marginal gain\n    # 2. If feasible, perform a more aggressive flip\n    # 3. If not feasible, perform a repair operation\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n    combined_gains = marginal_gains1 + marginal_gains2\n\n    # Identify items to consider for flip\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Bias selection towards items with high marginal gain\n        probs = combined_gains[candidate_indices]\n        probs = probs / (np.sum(probs) + 1e-6)\n        selected_idx = np.random.choice(candidate_indices, p=probs)\n\n        # Attempt to add the selected item\n        if current_weight + weight_lst[selected_idx] <= capacity:\n            new_solution[selected_idx] = 1\n            current_weight += weight_lst[selected_idx]\n        else:\n            # If not feasible, try to remove a low-value item\n            candidate_remove = np.where(new_solution == 1)[0]\n            if len(candidate_remove) > 0:\n                # Remove the item with lowest combined marginal gain\n                remove_idx = candidate_remove[np.argmin(combined_gains[candidate_remove])]\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    # Additional local search: flip a random pair of items\n    if np.sum(new_solution) > 1:\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) >= 2:\n            i, j = random.sample(list(items_in), 2)\n            # Check if swapping these items maintains feasibility\n            if (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Final check for feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If still infeasible, perform a greedy repair\n        items_in = np.where(new_solution == 1)[0]\n        current_weight = np.sum(weight_lst[items_in])\n        while current_weight > capacity and len(items_in) > 0:\n            # Remove the item with lowest marginal gain\n            remove_idx = items_in[np.argmin(combined_gains[items_in])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            items_in = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.6914068614920231,
            1.1293281316757202
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    # Sort solutions by their dominance and potential for improvement\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    candidates = archive_sorted[:max(1, len(archive) // 2)]\n\n    # Randomly select a candidate solution\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random flip with bias towards items with high marginal gain\n    # 2. If feasible, perform a more aggressive flip\n    # 3. If not feasible, perform a repair operation\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n    combined_gains = marginal_gains1 + marginal_gains2\n\n    # Identify items to consider for flip\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Bias selection towards items with high marginal gain\n        probs = combined_gains[candidate_indices]\n        probs = probs / (np.sum(probs) + 1e-6)\n        selected_idx = np.random.choice(candidate_indices, p=probs)\n\n        # Attempt to add the selected item\n        if current_weight + weight_lst[selected_idx] <= capacity:\n            new_solution[selected_idx] = 1\n            current_weight += weight_lst[selected_idx]\n        else:\n            # If not feasible, try to remove a low-value item\n            candidate_remove = np.where(new_solution == 1)[0]\n            if len(candidate_remove) > 0:\n                # Remove the item with lowest combined marginal gain\n                remove_idx = candidate_remove[np.argmin(combined_gains[candidate_remove])]\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    # Additional local search: flip a random pair of items\n    if np.sum(new_solution) > 1:\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) >= 2:\n            i, j = random.sample(list(items_in), 2)\n            # Check if swapping these items maintains feasibility\n            if (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Final check for feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If still infeasible, perform a greedy repair\n        items_in = np.where(new_solution == 1)[0]\n        current_weight = np.sum(weight_lst[items_in])\n        while current_weight > capacity and len(items_in) > 0:\n            # Remove the item with lowest marginal gain\n            remove_idx = items_in[np.argmin(combined_gains[items_in])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            items_in = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 10,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    # Sort solutions by their dominance and potential for improvement\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    candidates = archive_sorted[:max(1, len(archive) // 2)]\n\n    # Randomly select a candidate solution\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random flip with bias towards items with high marginal gain\n    # 2. If feasible, perform a more aggressive flip\n    # 3. If not feasible, perform a repair operation\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n    combined_gains = marginal_gains1 + marginal_gains2\n\n    # Identify items to consider for flip\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Bias selection towards items with high marginal gain\n        probs = combined_gains[candidate_indices]\n        probs = probs / (np.sum(probs) + 1e-6)\n        selected_idx = np.random.choice(candidate_indices, p=probs)\n\n        # Attempt to add the selected item\n        if current_weight + weight_lst[selected_idx] <= capacity:\n            new_solution[selected_idx] = 1\n            current_weight += weight_lst[selected_idx]\n        else:\n            # If not feasible, try to remove a low-value item\n            candidate_remove = np.where(new_solution == 1)[0]\n            if len(candidate_remove) > 0:\n                # Remove the item with lowest combined marginal gain\n                remove_idx = candidate_remove[np.argmin(combined_gains[candidate_remove])]\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    # Additional local search: flip a random pair of items\n    if np.sum(new_solution) > 1:\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) >= 2:\n            i, j = random.sample(list(items_in), 2)\n            # Check if swapping these items maintains feasibility\n            if (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Final check for feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If still infeasible, perform a greedy repair\n        items_in = np.where(new_solution == 1)[0]\n        current_weight = np.sum(weight_lst[items_in])\n        while current_weight > capacity and len(items_in) > 0:\n            # Remove the item with lowest marginal gain\n            remove_idx = items_in[np.argmin(combined_gains[items_in])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            items_in = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.6914068614920231,
            1.1293281316757202
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    # Sort solutions by their dominance and potential for improvement\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    candidates = archive_sorted[:max(1, len(archive) // 2)]\n\n    # Randomly select a candidate solution\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random flip with bias towards items with high marginal gain\n    # 2. If feasible, perform a more aggressive flip\n    # 3. If not feasible, perform a repair operation\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst / (weight_lst + 1e-6)\n    marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n    combined_gains = marginal_gains1 + marginal_gains2\n\n    # Identify items to consider for flip\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Bias selection towards items with high marginal gain\n        probs = combined_gains[candidate_indices]\n        probs = probs / (np.sum(probs) + 1e-6)\n        selected_idx = np.random.choice(candidate_indices, p=probs)\n\n        # Attempt to add the selected item\n        if current_weight + weight_lst[selected_idx] <= capacity:\n            new_solution[selected_idx] = 1\n            current_weight += weight_lst[selected_idx]\n        else:\n            # If not feasible, try to remove a low-value item\n            candidate_remove = np.where(new_solution == 1)[0]\n            if len(candidate_remove) > 0:\n                # Remove the item with lowest combined marginal gain\n                remove_idx = candidate_remove[np.argmin(combined_gains[candidate_remove])]\n                new_solution[remove_idx] = 0\n                current_weight -= weight_lst[remove_idx]\n\n    # Additional local search: flip a random pair of items\n    if np.sum(new_solution) > 1:\n        items_in = np.where(new_solution == 1)[0]\n        if len(items_in) >= 2:\n            i, j = random.sample(list(items_in), 2)\n            # Check if swapping these items maintains feasibility\n            if (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Final check for feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If still infeasible, perform a greedy repair\n        items_in = np.where(new_solution == 1)[0]\n        current_weight = np.sum(weight_lst[items_in])\n        while current_weight > capacity and len(items_in) > 0:\n            # Remove the item with lowest marginal gain\n            remove_idx = items_in[np.argmin(combined_gains[items_in])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            items_in = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 11,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (i.e., not too close to capacity)\n    # and have a good balance between the two objectives\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        # Avoid solutions that are too close to capacity (risk of infeasibility)\n        if total_weight < 0.9 * capacity:\n            # Prefer solutions with a balanced objective trade-off\n            balance_score = abs(v1 - v2) / (v1 + v2 + 1e-6)  # Avoid division by zero\n            candidates.append((sol, balance_score))\n\n    if not candidates:\n        # Fallback: randomly select a solution if no good candidates are found\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the best balance score (lowest imbalance)\n        base_solution = min(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Use value-to-weight ratio to prioritize flipping items that improve both objectives\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        # Calculate the effect of flipping this item\n        if new_solution[idx] == 1:\n            # If item is currently included, try to exclude it (if it doesn't violate capacity)\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If item is currently excluded, try to include it (if it fits within capacity)\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                # Prioritize items with high value-to-weight ratio for both objectives\n                v1_ratio = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n                v2_ratio = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n                if random.random() < 0.7 * (v1_ratio + v2_ratio):  # Higher probability for better items\n                    new_solution[idx] = 1\n\n    # Additional diversification: randomly flip one more item to escape local optima\n    if n_items > 0:\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.39551619241751346,
            1.6321773827075958
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (i.e., not too close to capacity)\n    # and have a good balance between the two objectives\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        # Avoid solutions that are too close to capacity (risk of infeasibility)\n        if total_weight < 0.9 * capacity:\n            # Prefer solutions with a balanced objective trade-off\n            balance_score = abs(v1 - v2) / (v1 + v2 + 1e-6)  # Avoid division by zero\n            candidates.append((sol, balance_score))\n\n    if not candidates:\n        # Fallback: randomly select a solution if no good candidates are found\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the best balance score (lowest imbalance)\n        base_solution = min(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Use value-to-weight ratio to prioritize flipping items that improve both objectives\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        # Calculate the effect of flipping this item\n        if new_solution[idx] == 1:\n            # If item is currently included, try to exclude it (if it doesn't violate capacity)\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If item is currently excluded, try to include it (if it fits within capacity)\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                # Prioritize items with high value-to-weight ratio for both objectives\n                v1_ratio = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n                v2_ratio = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n                if random.random() < 0.7 * (v1_ratio + v2_ratio):  # Higher probability for better items\n                    new_solution[idx] = 1\n\n    # Additional diversification: randomly flip one more item to escape local optima\n    if n_items > 0:\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 12,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the Pareto front\n    # or solutions that have not been explored much (e.g., based on crowding distance or other metrics)\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_items = len(new_solution)\n    swap_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random swaps\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        while excess > 0 and len(excess_items) > 0:\n            idx = random.choice(excess_items)\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    # 2. Greedily add items that improve at least one objective\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 3. Objective-specific perturbation: Flip items that are critical for one objective but not the other\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            # If the item is not critical for either objective, consider removing it\n            if value1_lst[idx] == 0 and value2_lst[idx] == 0:\n                new_solution[idx] = 0\n            # If the item is critical for one objective but not the other, consider flipping it\n            elif (value1_lst[idx] > 0 and value2_lst[idx] == 0) or (value1_lst[idx] == 0 and value2_lst[idx] > 0):\n                if random.random() < 0.3:  # 30% chance to flip\n                    new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.4331252376509562,
            1.5719508528709412
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the Pareto front\n    # or solutions that have not been explored much (e.g., based on crowding distance or other metrics)\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_items = len(new_solution)\n    swap_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random swaps\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        while excess > 0 and len(excess_items) > 0:\n            idx = random.choice(excess_items)\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    # 2. Greedily add items that improve at least one objective\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 3. Objective-specific perturbation: Flip items that are critical for one objective but not the other\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            # If the item is not critical for either objective, consider removing it\n            if value1_lst[idx] == 0 and value2_lst[idx] == 0:\n                new_solution[idx] = 0\n            # If the item is critical for one objective but not the other, consider flipping it\n            elif (value1_lst[idx] > 0 and value2_lst[idx] == 0) or (value1_lst[idx] == 0 and value2_lst[idx] > 0):\n                if random.random() < 0.3:  # 30% chance to flip\n                    new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 13,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with probability proportional to its non-dominated rank\n    # (simplified: higher objective values are more likely to be selected)\n    objectives = np.array([obj for _, obj in archive])\n    total_values = objectives.sum(axis=0)\n    probs = objectives / total_values\n    probs = probs.sum(axis=1) / probs.sum()\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a small number of bits\n    num_flips = max(1, int(np.sqrt(len(new_solution))))\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Greedy improvement: add items with highest marginal value-to-weight ratio\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate marginal value-to-weight ratios for both objectives\n        marginal_value1 = value1_lst[remaining_items] / weight_lst[remaining_items]\n        marginal_value2 = value2_lst[remaining_items] / weight_lst[remaining_items]\n\n        # Combine the two objectives using a weighted sum\n        combined_ratio = marginal_value1 + marginal_value2\n        best_item_idx = remaining_items[np.argmax(combined_ratio)]\n\n        # Add the best item if it fits\n        if current_weight + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3695223894143629,
            1.138188511133194
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with probability proportional to its non-dominated rank\n    # (simplified: higher objective values are more likely to be selected)\n    objectives = np.array([obj for _, obj in archive])\n    total_values = objectives.sum(axis=0)\n    probs = objectives / total_values\n    probs = probs.sum(axis=1) / probs.sum()\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a small number of bits\n    num_flips = max(1, int(np.sqrt(len(new_solution))))\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if current_weight <= capacity:\n                break\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Greedy improvement: add items with highest marginal value-to-weight ratio\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate marginal value-to-weight ratios for both objectives\n        marginal_value1 = value1_lst[remaining_items] / weight_lst[remaining_items]\n        marginal_value2 = value2_lst[remaining_items] / weight_lst[remaining_items]\n\n        # Combine the two objectives using a weighted sum\n        combined_ratio = marginal_value1 + marginal_value2\n        best_item_idx = remaining_items[np.argmax(combined_ratio)]\n\n        # Add the best item if it fits\n        if current_weight + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 14,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a base solution with probability proportional to its potential improvement\n    # Potential improvement is estimated by the sum of value-to-weight ratios of excluded items\n    potentials = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        excluded_items = np.where(sol == 0)[0]\n        if len(excluded_items) == 0:\n            potentials.append(0.0)\n            continue\n        # Calculate the average value-to-weight ratio of excluded items\n        excluded_value1 = value1_lst[excluded_items]\n        excluded_value2 = value2_lst[excluded_items]\n        excluded_weights = weight_lst[excluded_items]\n        # Use a weighted sum of the two objectives to estimate potential\n        potential = np.mean((excluded_value1 + excluded_value2) / (excluded_weights + 1e-6))\n        potentials.append(potential)\n\n    if all(p == 0 for p in potentials):\n        # If all solutions have no potential, randomly select one\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Normalize potentials to form a probability distribution\n        max_potential = max(potentials)\n        min_potential = min(potentials)\n        if max_potential == min_potential:\n            probs = [1.0 / len(potentials) for _ in potentials]\n        else:\n            normalized_potentials = [(p - min_potential) / (max_potential - min_potential) for p in potentials]\n            probs = [p / sum(normalized_potentials) for p in normalized_potentials]\n        base_solution = random.choices([sol for sol, _ in archive], weights=probs, k=1)[0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with a bias towards high value-to-weight ratio)\n    # 2. Ensure feasibility by removing items if capacity is exceeded\n    # 3. If no items can be added, perform a targeted flip of a low value-to-weight ratio item\n\n    # Step 1: Randomly flip a subset of items\n    flip_candidates = np.where(new_solution == 0)[0]\n    if len(flip_candidates) > 0:\n        # Calculate value-to-weight ratios for flip candidates\n        flip_ratios = (value1_lst[flip_candidates] + value2_lst[flip_candidates]) / (weight_lst[flip_candidates] + 1e-6)\n        # Select items to flip with probability proportional to their ratio\n        flip_probs = flip_ratios / np.sum(flip_ratios)\n        num_flips = min(len(flip_candidates), max(1, int(np.random.normal(loc=3, scale=1))))  # Random number of flips\n        flip_indices = np.random.choice(flip_candidates, size=num_flips, p=flip_probs, replace=False)\n        new_solution[flip_indices] = 1\n\n    # Check feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Step 2: Remove items to restore feasibility\n        excess_weight = new_weight - capacity\n        # Calculate value-to-weight ratios for included items\n        included_items = np.where(new_solution == 1)[0]\n        included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        # Sort items by ratio in ascending order (remove least valuable first)\n        sorted_indices = np.argsort(included_ratios)\n        removed_weight = 0\n        for idx in sorted_indices:\n            if removed_weight >= excess_weight:\n                break\n            item_idx = included_items[idx]\n            if new_solution[item_idx] == 1:\n                new_solution[item_idx] = 0\n                removed_weight += weight_lst[item_idx]\n\n    # Step 3: If no items can be added, perform a targeted flip\n    if np.sum(new_solution) == np.sum(base_solution):\n        # Find the item with the lowest value-to-weight ratio in the solution\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_item = included_items[np.argmin(included_ratios)]\n            new_solution[worst_item] = 0\n            # Try to add the best excluded item that fits\n            excluded_items = np.where(new_solution == 0)[0]\n            if len(excluded_items) > 0:\n                excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n                best_item = excluded_items[np.argmax(excluded_ratios)]\n                if weight_lst[best_item] <= capacity - np.sum(weight_lst * new_solution):\n                    new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3009550891908461,
            9.273122400045395
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a base solution with probability proportional to its potential improvement\n    # Potential improvement is estimated by the sum of value-to-weight ratios of excluded items\n    potentials = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        excluded_items = np.where(sol == 0)[0]\n        if len(excluded_items) == 0:\n            potentials.append(0.0)\n            continue\n        # Calculate the average value-to-weight ratio of excluded items\n        excluded_value1 = value1_lst[excluded_items]\n        excluded_value2 = value2_lst[excluded_items]\n        excluded_weights = weight_lst[excluded_items]\n        # Use a weighted sum of the two objectives to estimate potential\n        potential = np.mean((excluded_value1 + excluded_value2) / (excluded_weights + 1e-6))\n        potentials.append(potential)\n\n    if all(p == 0 for p in potentials):\n        # If all solutions have no potential, randomly select one\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Normalize potentials to form a probability distribution\n        max_potential = max(potentials)\n        min_potential = min(potentials)\n        if max_potential == min_potential:\n            probs = [1.0 / len(potentials) for _ in potentials]\n        else:\n            normalized_potentials = [(p - min_potential) / (max_potential - min_potential) for p in potentials]\n            probs = [p / sum(normalized_potentials) for p in normalized_potentials]\n        base_solution = random.choices([sol for sol, _ in archive], weights=probs, k=1)[0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with a bias towards high value-to-weight ratio)\n    # 2. Ensure feasibility by removing items if capacity is exceeded\n    # 3. If no items can be added, perform a targeted flip of a low value-to-weight ratio item\n\n    # Step 1: Randomly flip a subset of items\n    flip_candidates = np.where(new_solution == 0)[0]\n    if len(flip_candidates) > 0:\n        # Calculate value-to-weight ratios for flip candidates\n        flip_ratios = (value1_lst[flip_candidates] + value2_lst[flip_candidates]) / (weight_lst[flip_candidates] + 1e-6)\n        # Select items to flip with probability proportional to their ratio\n        flip_probs = flip_ratios / np.sum(flip_ratios)\n        num_flips = min(len(flip_candidates), max(1, int(np.random.normal(loc=3, scale=1))))  # Random number of flips\n        flip_indices = np.random.choice(flip_candidates, size=num_flips, p=flip_probs, replace=False)\n        new_solution[flip_indices] = 1\n\n    # Check feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Step 2: Remove items to restore feasibility\n        excess_weight = new_weight - capacity\n        # Calculate value-to-weight ratios for included items\n        included_items = np.where(new_solution == 1)[0]\n        included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        # Sort items by ratio in ascending order (remove least valuable first)\n        sorted_indices = np.argsort(included_ratios)\n        removed_weight = 0\n        for idx in sorted_indices:\n            if removed_weight >= excess_weight:\n                break\n            item_idx = included_items[idx]\n            if new_solution[item_idx] == 1:\n                new_solution[item_idx] = 0\n                removed_weight += weight_lst[item_idx]\n\n    # Step 3: If no items can be added, perform a targeted flip\n    if np.sum(new_solution) == np.sum(base_solution):\n        # Find the item with the lowest value-to-weight ratio in the solution\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            included_ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n            worst_item = included_items[np.argmin(included_ratios)]\n            new_solution[worst_item] = 0\n            # Try to add the best excluded item that fits\n            excluded_items = np.where(new_solution == 0)[0]\n            if len(excluded_items) > 0:\n                excluded_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / (weight_lst[excluded_items] + 1e-6)\n                best_item = excluded_items[np.argmax(excluded_ratios)]\n                if weight_lst[best_item] <= capacity - np.sum(weight_lst * new_solution):\n                    new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 15,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.dot(sol, weight_lst)\n        if total_weight < capacity * 0.9:  # Prefer solutions that are not too close to full capacity\n            candidates.append(sol)\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]  # Fallback to all solutions if none meet the condition\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random perturbation + value-based improvement\n    # Step 1: Randomly flip a subset of items to introduce diversity\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility by removing items that exceed capacity\n    total_weight = np.dot(new_solution, weight_lst)\n    if total_weight > capacity:\n        # Sort items by their marginal value density (value1 + value2) / weight\n        marginal_value = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(marginal_value)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight = np.dot(new_solution, weight_lst)\n                if total_weight <= capacity:\n                    break\n\n    # Step 3: Value-based improvement: add items with highest marginal value density if possible\n    marginal_value = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(marginal_value)[::-1]  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (total_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3328276721911487,
            2.406480759382248
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.dot(sol, weight_lst)\n        if total_weight < capacity * 0.9:  # Prefer solutions that are not too close to full capacity\n            candidates.append(sol)\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]  # Fallback to all solutions if none meet the condition\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random perturbation + value-based improvement\n    # Step 1: Randomly flip a subset of items to introduce diversity\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility by removing items that exceed capacity\n    total_weight = np.dot(new_solution, weight_lst)\n    if total_weight > capacity:\n        # Sort items by their marginal value density (value1 + value2) / weight\n        marginal_value = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(marginal_value)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight = np.dot(new_solution, weight_lst)\n                if total_weight <= capacity:\n                    break\n\n    # Step 3: Value-based improvement: add items with highest marginal value density if possible\n    marginal_value = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(marginal_value)[::-1]  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (total_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 16,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution: prioritize those with high total value and low weight\n    archive_with_metrics = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst[sol == 1])\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        archive_with_metrics.append((sol, val1 + val2, total_weight))\n\n    if not archive_with_metrics:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by (val1 + val2) descending, then by weight ascending\n    archive_with_metrics.sort(key=lambda x: (-x[1], x[2]))\n\n    # Select top 20% or at least 1 solution\n    top_n = max(1, len(archive_with_metrics) // 5)\n    selected = random.choice(archive_with_metrics[:top_n])\n    base_solution = selected[0].copy()\n\n    # Hybrid local search: random swap + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap k items (k is small to preserve structure)\n    k = min(3, len(new_solution) // 2)\n    indices = np.random.choice(len(new_solution), size=k, replace=False)\n    new_solution[indices] = 1 - new_solution[indices]\n\n    # Ensure feasibility after random swap\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) == 0:\n                break  # No items left to remove\n            idx = np.random.choice(candidates)\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for idx in remaining_items:\n        if weight_lst[idx] <= capacity - np.sum(weight_lst[new_solution == 1]):\n            # Check if adding this item improves both objectives\n            current_val1 = np.sum(value1_lst[new_solution == 1])\n            current_val2 = np.sum(value2_lst[new_solution == 1])\n            new_val1 = current_val1 + value1_lst[idx]\n            new_val2 = current_val2 + value2_lst[idx]\n\n            # Only add if both values improve (or at least one improves)\n            if (new_val1 > current_val1) or (new_val2 > current_val2):\n                new_solution[idx] = 1\n                # Recheck feasibility (shouldn't be needed due to weight check above)\n                if np.sum(weight_lst[new_solution == 1]) > capacity:\n                    new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.34125636793369407,
            6.771536439657211
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution: prioritize those with high total value and low weight\n    archive_with_metrics = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst[sol == 1])\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        archive_with_metrics.append((sol, val1 + val2, total_weight))\n\n    if not archive_with_metrics:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by (val1 + val2) descending, then by weight ascending\n    archive_with_metrics.sort(key=lambda x: (-x[1], x[2]))\n\n    # Select top 20% or at least 1 solution\n    top_n = max(1, len(archive_with_metrics) // 5)\n    selected = random.choice(archive_with_metrics[:top_n])\n    base_solution = selected[0].copy()\n\n    # Hybrid local search: random swap + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap k items (k is small to preserve structure)\n    k = min(3, len(new_solution) // 2)\n    indices = np.random.choice(len(new_solution), size=k, replace=False)\n    new_solution[indices] = 1 - new_solution[indices]\n\n    # Ensure feasibility after random swap\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) == 0:\n                break  # No items left to remove\n            idx = np.random.choice(candidates)\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for idx in remaining_items:\n        if weight_lst[idx] <= capacity - np.sum(weight_lst[new_solution == 1]):\n            # Check if adding this item improves both objectives\n            current_val1 = np.sum(value1_lst[new_solution == 1])\n            current_val2 = np.sum(value2_lst[new_solution == 1])\n            new_val1 = current_val1 + value1_lst[idx]\n            new_val2 = current_val2 + value2_lst[idx]\n\n            # Only add if both values improve (or at least one improves)\n            if (new_val1 > current_val1) or (new_val2 > current_val2):\n                new_solution[idx] = 1\n                # Recheck feasibility (shouldn't be needed due to weight check above)\n                if np.sum(weight_lst[new_solution == 1]) > capacity:\n                    new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 17,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high diversity or potential for improvement\n    selected_solution = None\n    max_potential = -1\n\n    for sol, _ in archive:\n        # Calculate potential for improvement (could be based on marginal gains, diversity, etc.)\n        current_weight = np.sum(weight_lst * sol)\n        potential = capacity - current_weight  # Higher potential means more room for improvement\n\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = random.choice(archive)[0]\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with probability based on their marginal gains)\n    # 2. Apply a greedy improvement step to ensure feasibility and quality\n    n_items = len(new_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n\n    for idx in flip_indices:\n        # Flip the item and check feasibility\n        new_solution[idx] = 1 - new_solution[idx]\n        current_weight = np.sum(weight_lst * new_solution)\n\n        if current_weight > capacity:\n            # If flipping makes it infeasible, undo the flip and try another item\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Greedy improvement: try to add items with high marginal gain for either objective\n    for _ in range(3):  # Limit iterations to avoid excessive computation\n        added = False\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = np.sum(weight_lst * temp_solution)\n\n                if temp_weight <= capacity:\n                    # Calculate marginal gains for both objectives\n                    marginal_gain1 = value1_lst[i]\n                    marginal_gain2 = value2_lst[i]\n\n                    # Accept if it improves at least one objective\n                    if marginal_gain1 > 0 or marginal_gain2 > 0:\n                        new_solution = temp_solution\n                        added = True\n                        break\n\n        if not added:\n            break  # No more improvements possible\n\n    return new_solution\n\n",
        "score": [
            -0.5030065867586047,
            7.496668964624405
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high diversity or potential for improvement\n    selected_solution = None\n    max_potential = -1\n\n    for sol, _ in archive:\n        # Calculate potential for improvement (could be based on marginal gains, diversity, etc.)\n        current_weight = np.sum(weight_lst * sol)\n        potential = capacity - current_weight  # Higher potential means more room for improvement\n\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = random.choice(archive)[0]\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with probability based on their marginal gains)\n    # 2. Apply a greedy improvement step to ensure feasibility and quality\n    n_items = len(new_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n\n    for idx in flip_indices:\n        # Flip the item and check feasibility\n        new_solution[idx] = 1 - new_solution[idx]\n        current_weight = np.sum(weight_lst * new_solution)\n\n        if current_weight > capacity:\n            # If flipping makes it infeasible, undo the flip and try another item\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Greedy improvement: try to add items with high marginal gain for either objective\n    for _ in range(3):  # Limit iterations to avoid excessive computation\n        added = False\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n                temp_weight = np.sum(weight_lst * temp_solution)\n\n                if temp_weight <= capacity:\n                    # Calculate marginal gains for both objectives\n                    marginal_gain1 = value1_lst[i]\n                    marginal_gain2 = value2_lst[i]\n\n                    # Accept if it improves at least one objective\n                    if marginal_gain1 > 0 or marginal_gain2 > 0:\n                        new_solution = temp_solution\n                        added = True\n                        break\n\n        if not added:\n            break  # No more improvements possible\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 18,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    # We use a simple heuristic: select a solution with a high combined value but not already in the archive\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = np.array([obj for _, obj in archive])\n\n    # Calculate the \"potential\" of each solution (e.g., distance to the Pareto front)\n    # Here, we use a simple heuristic: the solution with the highest combined value not already in the archive\n    combined_values = archive_values[:, 0] + archive_values[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by flipping a subset of items\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item would keep the solution feasible\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Apply a greedy improvement step to balance the objectives\n    # For each flipped item, decide whether to keep it based on the marginal improvement in both objectives\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Calculate marginal value if we remove the item\n            marginal_value1 = -value1_lst[idx]\n            marginal_value2 = -value2_lst[idx]\n            # If removing improves at least one objective, keep the change\n            if marginal_value1 > 0 or marginal_value2 > 0:\n                continue\n            else:\n                new_solution[idx] = 0\n        else:\n            # Calculate marginal value if we add the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                marginal_value1 = value1_lst[idx]\n                marginal_value2 = value2_lst[idx]\n                # If adding improves at least one objective, keep the change\n                if marginal_value1 > 0 or marginal_value2 > 0:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.34521780436019667,
            2.3133773505687714
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    # We use a simple heuristic: select a solution with a high combined value but not already in the archive\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = np.array([obj for _, obj in archive])\n\n    # Calculate the \"potential\" of each solution (e.g., distance to the Pareto front)\n    # Here, we use a simple heuristic: the solution with the highest combined value not already in the archive\n    combined_values = archive_values[:, 0] + archive_values[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by flipping a subset of items\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 random items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item would keep the solution feasible\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Apply a greedy improvement step to balance the objectives\n    # For each flipped item, decide whether to keep it based on the marginal improvement in both objectives\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Calculate marginal value if we remove the item\n            marginal_value1 = -value1_lst[idx]\n            marginal_value2 = -value2_lst[idx]\n            # If removing improves at least one objective, keep the change\n            if marginal_value1 > 0 or marginal_value2 > 0:\n                continue\n            else:\n                new_solution[idx] = 0\n        else:\n            # Calculate marginal value if we add the item\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if current_weight + weight_lst[idx] <= capacity:\n                marginal_value1 = value1_lst[idx]\n                marginal_value2 = value2_lst[idx]\n                # If adding improves at least one objective, keep the change\n                if marginal_value1 > 0 or marginal_value2 > 0:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 19,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst[sol == 1]) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst[sol == 1]) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst[sol == 1]) for sol in archive_solutions]\n\n    # Calculate potential improvement (simple heuristic: solutions with lower weight and higher values)\n    potential = [(i, archive_weights[i], archive_values1[i] + archive_values2[i]) for i in range(len(archive))]\n    potential.sort(key=lambda x: (x[1], -x[2]))  # Prefer lower weight and higher total value\n\n    # Select top 30% of solutions with highest potential\n    top_indices = [x[0] for x in potential[:max(1, len(potential) // 3)]]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip some items (exploration)\n    # 2. Greedily flip items to improve both objectives (exploitation)\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Random flip (20% of items)\n    flip_indices = random.sample(range(n_items), min(n_items, max(1, n_items // 5)))\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Ensure feasibility (in case of any rounding errors)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_weights = weight_lst[excess_items]\n        sorted_excess = np.argsort(excess_weights)\n        for i in sorted_excess:\n            if excess <= 0:\n                break\n            new_solution[excess_items[i]] = 0\n            excess -= excess_weights[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8952977406207678,
            3.8233375251293182
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst[sol == 1]) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst[sol == 1]) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst[sol == 1]) for sol in archive_solutions]\n\n    # Calculate potential improvement (simple heuristic: solutions with lower weight and higher values)\n    potential = [(i, archive_weights[i], archive_values1[i] + archive_values2[i]) for i in range(len(archive))]\n    potential.sort(key=lambda x: (x[1], -x[2]))  # Prefer lower weight and higher total value\n\n    # Select top 30% of solutions with highest potential\n    top_indices = [x[0] for x in potential[:max(1, len(potential) // 3)]]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip some items (exploration)\n    # 2. Greedily flip items to improve both objectives (exploitation)\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Random flip (20% of items)\n    flip_indices = random.sample(range(n_items), min(n_items, max(1, n_items // 5)))\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Ensure feasibility (in case of any rounding errors)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_weights = weight_lst[excess_items]\n        sorted_excess = np.argsort(excess_weights)\n        for i in sorted_excess:\n            if excess <= 0:\n                break\n            new_solution[excess_items[i]] = 0\n            excess -= excess_weights[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 20,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(weight_lst[solution[0] == 1]) for solution in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: combine random flip with value-based swap\n    new_solution = base_solution.copy()\n\n    # Step 1: Random flip with feasibility check\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_idx = np.random.choice(flip_candidates)\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n\n    # Step 2: Add highest value item not in solution\n    add_candidates = np.where(new_solution == 0)[0]\n    if len(add_candidates) > 0:\n        # Consider both objectives for potential improvement\n        total_value = np.sum(value1_lst) + np.sum(value2_lst)\n        value_score = (value1_lst + value2_lst) / total_value\n        add_idx = add_candidates[np.argmax(value_score[add_candidates])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n\n    # Step 3: Random swap between objectives\n    if np.random.rand() < 0.3:  # 30% chance of swap\n        obj1_items = np.where(new_solution == 1)[0]\n        obj2_items = np.where(new_solution == 0)[0]\n        if len(obj1_items) > 0 and len(obj2_items) > 0:\n            out_idx = np.random.choice(obj1_items)\n            in_idx = np.random.choice(obj2_items)\n            if (current_weight - weight_lst[out_idx] + weight_lst[in_idx]) <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7684282617583271,
            1.6358892917633057
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(weight_lst[solution[0] == 1]) for solution in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: combine random flip with value-based swap\n    new_solution = base_solution.copy()\n\n    # Step 1: Random flip with feasibility check\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_idx = np.random.choice(flip_candidates)\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n\n    # Step 2: Add highest value item not in solution\n    add_candidates = np.where(new_solution == 0)[0]\n    if len(add_candidates) > 0:\n        # Consider both objectives for potential improvement\n        total_value = np.sum(value1_lst) + np.sum(value2_lst)\n        value_score = (value1_lst + value2_lst) / total_value\n        add_idx = add_candidates[np.argmax(value_score[add_candidates])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n\n    # Step 3: Random swap between objectives\n    if np.random.rand() < 0.3:  # 30% chance of swap\n        obj1_items = np.where(new_solution == 1)[0]\n        obj2_items = np.where(new_solution == 0)[0]\n        if len(obj1_items) > 0 and len(obj2_items) > 0:\n            out_idx = np.random.choice(obj1_items)\n            in_idx = np.random.choice(obj2_items)\n            if (current_weight - weight_lst[out_idx] + weight_lst[in_idx]) <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 21,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher potential for improvement\n    # Here, we prioritize solutions that are not already optimal in both objectives\n    candidates = []\n    for sol, (val1, val2) in archive:\n        # Check if the solution is not Pareto-optimal in the archive (simplified check)\n        is_dominated = False\n        for _, (other_val1, other_val2) in archive:\n            if (other_val1 >= val1 and other_val2 > val2) or (other_val1 > val1 and other_val2 >= val2):\n                is_dominated = True\n                break\n        if not is_dominated:\n            candidates.append((sol, val1, val2))\n\n    if not candidates:\n        # If all solutions are Pareto-optimal, randomly select one\n        base_solution, _, _ = random.choice(archive)\n    else:\n        # Select a solution with higher potential for improvement (e.g., not too close to the Pareto front)\n        # Here, we use a simple heuristic: select a solution with lower average value\n        base_solution, _, _ = min(candidates, key=lambda x: (x[1] + x[2]) / 2)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily select items to improve both objectives (exploitation)\n\n    # Step 1: Random flipping (exploration)\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items randomly\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flipping\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0 and np.sum(new_solution) > 0:\n            remove_idx = random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if weight_lst[idx] <= capacity - np.sum(weight_lst[new_solution == 1]):\n            new_solution[idx] = 1\n            # Check if the new solution dominates the base solution in both objectives\n            new_val1 = np.sum(value1_lst[new_solution == 1])\n            new_val2 = np.sum(value2_lst[new_solution == 1])\n            base_val1 = np.sum(value1_lst[base_solution == 1])\n            base_val2 = np.sum(value2_lst[base_solution == 1])\n            if (new_val1 >= base_val1 and new_val2 >= base_val2) and (new_val1 > base_val1 or new_val2 > base_val2):\n                # Keep the improvement\n                pass\n            else:\n                # Revert if no improvement\n                new_solution[idx] = 0\n\n    # Final check for feasibility\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If still infeasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.39182092148584075,
            8.691551804542542
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher potential for improvement\n    # Here, we prioritize solutions that are not already optimal in both objectives\n    candidates = []\n    for sol, (val1, val2) in archive:\n        # Check if the solution is not Pareto-optimal in the archive (simplified check)\n        is_dominated = False\n        for _, (other_val1, other_val2) in archive:\n            if (other_val1 >= val1 and other_val2 > val2) or (other_val1 > val1 and other_val2 >= val2):\n                is_dominated = True\n                break\n        if not is_dominated:\n            candidates.append((sol, val1, val2))\n\n    if not candidates:\n        # If all solutions are Pareto-optimal, randomly select one\n        base_solution, _, _ = random.choice(archive)\n    else:\n        # Select a solution with higher potential for improvement (e.g., not too close to the Pareto front)\n        # Here, we use a simple heuristic: select a solution with lower average value\n        base_solution, _, _ = min(candidates, key=lambda x: (x[1] + x[2]) / 2)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily select items to improve both objectives (exploitation)\n\n    # Step 1: Random flipping (exploration)\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items randomly\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flipping\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0 and np.sum(new_solution) > 0:\n            remove_idx = random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if weight_lst[idx] <= capacity - np.sum(weight_lst[new_solution == 1]):\n            new_solution[idx] = 1\n            # Check if the new solution dominates the base solution in both objectives\n            new_val1 = np.sum(value1_lst[new_solution == 1])\n            new_val2 = np.sum(value2_lst[new_solution == 1])\n            base_val1 = np.sum(value1_lst[base_solution == 1])\n            base_val2 = np.sum(value2_lst[base_solution == 1])\n            if (new_val1 >= base_val1 and new_val2 >= base_val2) and (new_val1 > base_val1 or new_val2 > base_val2):\n                # Keep the improvement\n                pass\n            else:\n                # Revert if no improvement\n                new_solution[idx] = 0\n\n    # Final check for feasibility\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If still infeasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 22,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (higher sum is better)\n        sorted_archive = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n        # Select from the top 30% of solutions to ensure diversity\n        selection_pool = sorted_archive[:max(1, len(sorted_archive) // 3)]\n        base_solution = random.choice(selection_pool)[0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random perturbation: flip a small number of bits (1-3) to introduce diversity\n    num_flips = random.randint(1, 3)\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedy improvement: evaluate the impact of each flip and keep the best feasible change\n    best_solution = new_solution.copy()\n    best_value = sum(value1_lst[new_solution == 1]) + sum(value2_lst[new_solution == 1])\n    total_weight = sum(weight_lst[new_solution == 1])\n\n    for idx in range(len(new_solution)):\n        # Try flipping the bit at idx\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Check feasibility\n        temp_weight = total_weight + (weight_lst[idx] if temp_solution[idx] == 1 else -weight_lst[idx])\n        if temp_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        # Calculate new value\n        temp_value = sum(value1_lst[temp_solution == 1]) + sum(value2_lst[temp_solution == 1])\n\n        # Update if better\n        if temp_value > best_value:\n            best_solution = temp_solution.copy()\n            best_value = temp_value\n            total_weight = temp_weight\n\n    # 3. Objective-specific improvement: try to improve one objective while keeping the other stable\n    # For example, try to improve value1 without significantly affecting value2\n    for idx in range(len(best_solution)):\n        if best_solution[idx] == 0:\n            # Try adding this item if it improves value1 without hurting value2 too much\n            temp_solution = best_solution.copy()\n            temp_solution[idx] = 1\n\n            temp_weight = total_weight + weight_lst[idx]\n            if temp_weight > capacity:\n                continue\n\n            temp_value1 = sum(value1_lst[temp_solution == 1])\n            temp_value2 = sum(value2_lst[temp_solution == 1])\n\n            # Accept if value1 improves and value2 doesn't decrease significantly\n            if temp_value1 > sum(value1_lst[best_solution == 1]) and temp_value2 >= 0.95 * sum(value2_lst[best_solution == 1]):\n                best_solution = temp_solution.copy()\n                total_weight = temp_weight\n\n    return best_solution\n\n",
        "score": [
            -0.3490407741666953,
            9.844122618436813
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (higher sum is better)\n        sorted_archive = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n        # Select from the top 30% of solutions to ensure diversity\n        selection_pool = sorted_archive[:max(1, len(sorted_archive) // 3)]\n        base_solution = random.choice(selection_pool)[0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random perturbation: flip a small number of bits (1-3) to introduce diversity\n    num_flips = random.randint(1, 3)\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedy improvement: evaluate the impact of each flip and keep the best feasible change\n    best_solution = new_solution.copy()\n    best_value = sum(value1_lst[new_solution == 1]) + sum(value2_lst[new_solution == 1])\n    total_weight = sum(weight_lst[new_solution == 1])\n\n    for idx in range(len(new_solution)):\n        # Try flipping the bit at idx\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Check feasibility\n        temp_weight = total_weight + (weight_lst[idx] if temp_solution[idx] == 1 else -weight_lst[idx])\n        if temp_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        # Calculate new value\n        temp_value = sum(value1_lst[temp_solution == 1]) + sum(value2_lst[temp_solution == 1])\n\n        # Update if better\n        if temp_value > best_value:\n            best_solution = temp_solution.copy()\n            best_value = temp_value\n            total_weight = temp_weight\n\n    # 3. Objective-specific improvement: try to improve one objective while keeping the other stable\n    # For example, try to improve value1 without significantly affecting value2\n    for idx in range(len(best_solution)):\n        if best_solution[idx] == 0:\n            # Try adding this item if it improves value1 without hurting value2 too much\n            temp_solution = best_solution.copy()\n            temp_solution[idx] = 1\n\n            temp_weight = total_weight + weight_lst[idx]\n            if temp_weight > capacity:\n                continue\n\n            temp_value1 = sum(value1_lst[temp_solution == 1])\n            temp_value2 = sum(value2_lst[temp_solution == 1])\n\n            # Accept if value1 improves and value2 doesn't decrease significantly\n            if temp_value1 > sum(value1_lst[best_solution == 1]) and temp_value2 >= 0.95 * sum(value2_lst[best_solution == 1]):\n                best_solution = temp_solution.copy()\n                total_weight = temp_weight\n\n    return best_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 23,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions with lower total weight (more room for improvement)\n    archive_sorted = sorted(archive, key=lambda x: np.sum(weight_lst * x[0]))\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of archive\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Random perturbation (flip some bits)\n    perturbation_size = max(1, int(n_items * 0.1))  # Flip up to 10% of items\n    flip_indices = random.sample(range(n_items), min(perturbation_size, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in_solution)\n        for idx in items_in_solution:\n            if current_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # 2. Greedy improvement step (add items with highest \"bang-for-buck\" ratio)\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate \"bang-for-buck\" ratio for each item (combining both objectives)\n        items_not_in_solution = np.where(new_solution == 0)[0]\n        if len(items_not_in_solution) > 0:\n            # Normalize values to avoid bias towards one objective\n            max_value1 = np.max(value1_lst) if np.max(value1_lst) != 0 else 1\n            max_value2 = np.max(value2_lst) if np.max(value2_lst) != 0 else 1\n            normalized_value1 = value1_lst / max_value1\n            normalized_value2 = value2_lst / max_value2\n\n            # Combined score (can be adjusted for different trade-offs)\n            scores = (normalized_value1 + normalized_value2) / (weight_lst + 1e-6)  # Avoid division by zero\n\n            # Sort items by score in descending order\n            sorted_indices = np.argsort(scores)[::-1]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_weight and new_solution[idx] == 0:\n                    new_solution[idx] = 1\n                    remaining_weight -= weight_lst[idx]\n                    if remaining_weight <= 0:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.33263914068756,
            1.3781624734401703
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions with lower total weight (more room for improvement)\n    archive_sorted = sorted(archive, key=lambda x: np.sum(weight_lst * x[0]))\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of archive\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Random perturbation (flip some bits)\n    perturbation_size = max(1, int(n_items * 0.1))  # Flip up to 10% of items\n    flip_indices = random.sample(range(n_items), min(perturbation_size, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        items_in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in_solution)\n        for idx in items_in_solution:\n            if current_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # 2. Greedy improvement step (add items with highest \"bang-for-buck\" ratio)\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate \"bang-for-buck\" ratio for each item (combining both objectives)\n        items_not_in_solution = np.where(new_solution == 0)[0]\n        if len(items_not_in_solution) > 0:\n            # Normalize values to avoid bias towards one objective\n            max_value1 = np.max(value1_lst) if np.max(value1_lst) != 0 else 1\n            max_value2 = np.max(value2_lst) if np.max(value2_lst) != 0 else 1\n            normalized_value1 = value1_lst / max_value1\n            normalized_value2 = value2_lst / max_value2\n\n            # Combined score (can be adjusted for different trade-offs)\n            scores = (normalized_value1 + normalized_value2) / (weight_lst + 1e-6)  # Avoid division by zero\n\n            # Sort items by score in descending order\n            sorted_indices = np.argsort(scores)[::-1]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_weight and new_solution[idx] == 0:\n                    new_solution[idx] = 1\n                    remaining_weight -= weight_lst[idx]\n                    if remaining_weight <= 0:\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 24,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher combined value\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to flip a random item (add or remove)\n    # 2. If the flip is feasible, accept it\n    # 3. If not, try to swap two items (one in, one out)\n    # 4. If swap is feasible, accept it\n    # 5. If neither is feasible, try a random flip again\n\n    # Attempt 1: Random flip\n    item_to_flip = random.randint(0, len(weight_lst) - 1)\n    if new_solution[item_to_flip] == 1:\n        new_weight = current_weight - weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 0\n            return new_solution\n    else:\n        new_weight = current_weight + weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 1\n            return new_solution\n\n    # If random flip didn't work, try a swap\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    if len(zero_indices) > 0 and len(one_indices) > 0:\n        item_out = random.choice(one_indices)\n        item_in = random.choice(zero_indices)\n\n        new_weight = current_weight - weight_lst[item_out] + weight_lst[item_in]\n        if new_weight <= capacity:\n            new_solution[item_out] = 0\n            new_solution[item_in] = 1\n            return new_solution\n\n    # If swap didn't work, try another random flip (with a higher chance of improvement)\n    # Calculate potential improvements for all items\n    improvements = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Potential improvement by removing item i\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n        else:\n            # Potential improvement by adding item i\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n\n        # Only consider feasible improvements\n        if current_weight + delta_weight <= capacity:\n            improvements.append((i, delta_value1, delta_value2))\n\n    if improvements:\n        # Select the item with the highest combined improvement\n        best_item, _, _ = max(improvements, key=lambda x: x[1] + x[2])\n        new_solution[best_item] = 1 - new_solution[best_item]\n        return new_solution\n\n    # If no improvements found, return the base solution\n    return base_solution\n\n",
        "score": [
            -0.2858248266534406,
            0.8610722422599792
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher combined value\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to flip a random item (add or remove)\n    # 2. If the flip is feasible, accept it\n    # 3. If not, try to swap two items (one in, one out)\n    # 4. If swap is feasible, accept it\n    # 5. If neither is feasible, try a random flip again\n\n    # Attempt 1: Random flip\n    item_to_flip = random.randint(0, len(weight_lst) - 1)\n    if new_solution[item_to_flip] == 1:\n        new_weight = current_weight - weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 0\n            return new_solution\n    else:\n        new_weight = current_weight + weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 1\n            return new_solution\n\n    # If random flip didn't work, try a swap\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    if len(zero_indices) > 0 and len(one_indices) > 0:\n        item_out = random.choice(one_indices)\n        item_in = random.choice(zero_indices)\n\n        new_weight = current_weight - weight_lst[item_out] + weight_lst[item_in]\n        if new_weight <= capacity:\n            new_solution[item_out] = 0\n            new_solution[item_in] = 1\n            return new_solution\n\n    # If swap didn't work, try another random flip (with a higher chance of improvement)\n    # Calculate potential improvements for all items\n    improvements = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Potential improvement by removing item i\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n        else:\n            # Potential improvement by adding item i\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n\n        # Only consider feasible improvements\n        if current_weight + delta_weight <= capacity:\n            improvements.append((i, delta_value1, delta_value2))\n\n    if improvements:\n        # Select the item with the highest combined improvement\n        best_item, _, _ = max(improvements, key=lambda x: x[1] + x[2])\n        new_solution[best_item] = 1 - new_solution[best_item]\n        return new_solution\n\n    # If no improvements found, return the base solution\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 24,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher combined value\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to flip a random item (add or remove)\n    # 2. If the flip is feasible, accept it\n    # 3. If not, try to swap two items (one in, one out)\n    # 4. If swap is feasible, accept it\n    # 5. If neither is feasible, try a random flip again\n\n    # Attempt 1: Random flip\n    item_to_flip = random.randint(0, len(weight_lst) - 1)\n    if new_solution[item_to_flip] == 1:\n        new_weight = current_weight - weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 0\n            return new_solution\n    else:\n        new_weight = current_weight + weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 1\n            return new_solution\n\n    # If random flip didn't work, try a swap\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    if len(zero_indices) > 0 and len(one_indices) > 0:\n        item_out = random.choice(one_indices)\n        item_in = random.choice(zero_indices)\n\n        new_weight = current_weight - weight_lst[item_out] + weight_lst[item_in]\n        if new_weight <= capacity:\n            new_solution[item_out] = 0\n            new_solution[item_in] = 1\n            return new_solution\n\n    # If swap didn't work, try another random flip (with a higher chance of improvement)\n    # Calculate potential improvements for all items\n    improvements = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Potential improvement by removing item i\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n        else:\n            # Potential improvement by adding item i\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n\n        # Only consider feasible improvements\n        if current_weight + delta_weight <= capacity:\n            improvements.append((i, delta_value1, delta_value2))\n\n    if improvements:\n        # Select the item with the highest combined improvement\n        best_item, _, _ = max(improvements, key=lambda x: x[1] + x[2])\n        new_solution[best_item] = 1 - new_solution[best_item]\n        return new_solution\n\n    # If no improvements found, return the base solution\n    return base_solution\n\n",
        "score": [
            -0.2858248266534406,
            0.8610722422599792
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher combined value\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to flip a random item (add or remove)\n    # 2. If the flip is feasible, accept it\n    # 3. If not, try to swap two items (one in, one out)\n    # 4. If swap is feasible, accept it\n    # 5. If neither is feasible, try a random flip again\n\n    # Attempt 1: Random flip\n    item_to_flip = random.randint(0, len(weight_lst) - 1)\n    if new_solution[item_to_flip] == 1:\n        new_weight = current_weight - weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 0\n            return new_solution\n    else:\n        new_weight = current_weight + weight_lst[item_to_flip]\n        if new_weight <= capacity:\n            new_solution[item_to_flip] = 1\n            return new_solution\n\n    # If random flip didn't work, try a swap\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    if len(zero_indices) > 0 and len(one_indices) > 0:\n        item_out = random.choice(one_indices)\n        item_in = random.choice(zero_indices)\n\n        new_weight = current_weight - weight_lst[item_out] + weight_lst[item_in]\n        if new_weight <= capacity:\n            new_solution[item_out] = 0\n            new_solution[item_in] = 1\n            return new_solution\n\n    # If swap didn't work, try another random flip (with a higher chance of improvement)\n    # Calculate potential improvements for all items\n    improvements = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Potential improvement by removing item i\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n        else:\n            # Potential improvement by adding item i\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n\n        # Only consider feasible improvements\n        if current_weight + delta_weight <= capacity:\n            improvements.append((i, delta_value1, delta_value2))\n\n    if improvements:\n        # Select the item with the highest combined improvement\n        best_item, _, _ = max(improvements, key=lambda x: x[1] + x[2])\n        new_solution[best_item] = 1 - new_solution[best_item]\n        return new_solution\n\n    # If no improvements found, return the base solution\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 25,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on objective diversity and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random swaps (exploration)\n    swap_indices = random.sample(range(len(base_solution)), min(3, len(base_solution)))\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        random.shuffle(excess_indices)\n        for idx in excess_indices:\n            if new_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            new_weight -= weight_lst[idx]\n\n    # Step 2: Objective-weighted flips (exploitation)\n    if random.random() < 0.7:  # 70% chance to perform this step\n        total_value1 = np.sum(value1_lst * new_solution)\n        total_value2 = np.sum(value2_lst * new_solution)\n\n        # Calculate weights for each objective\n        w1 = total_value1 / (total_value1 + total_value2 + 1e-6)\n        w2 = total_value2 / (total_value1 + total_value2 + 1e-6)\n\n        # Flip items based on their contribution to both objectives\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Score items by their potential improvement\n            scores = w1 * value1_lst[candidate_indices] + w2 * value2_lst[candidate_indices]\n            best_candidate = candidate_indices[np.argmax(scores)]\n\n            # Check if adding the item is feasible\n            if current_weight + weight_lst[best_candidate] <= capacity:\n                new_solution[best_candidate] = 1\n\n    # Step 3: Capacity-aware adjustments\n    if random.random() < 0.5:  # 50% chance to perform this step\n        # Try to add items that are underweighted\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Sort by weight-to-value ratio\n            ratios = (weight_lst[candidate_indices] / (value1_lst[candidate_indices] + value2_lst[candidate_indices] + 1e-6))\n            best_candidate = candidate_indices[np.argmin(ratios)]\n\n            # Check if adding the item is feasible\n            if current_weight + weight_lst[best_candidate] <= capacity:\n                new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.36457963436289853,
            1.0293432176113129
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on objective diversity and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random swaps (exploration)\n    swap_indices = random.sample(range(len(base_solution)), min(3, len(base_solution)))\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        random.shuffle(excess_indices)\n        for idx in excess_indices:\n            if new_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            new_weight -= weight_lst[idx]\n\n    # Step 2: Objective-weighted flips (exploitation)\n    if random.random() < 0.7:  # 70% chance to perform this step\n        total_value1 = np.sum(value1_lst * new_solution)\n        total_value2 = np.sum(value2_lst * new_solution)\n\n        # Calculate weights for each objective\n        w1 = total_value1 / (total_value1 + total_value2 + 1e-6)\n        w2 = total_value2 / (total_value1 + total_value2 + 1e-6)\n\n        # Flip items based on their contribution to both objectives\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Score items by their potential improvement\n            scores = w1 * value1_lst[candidate_indices] + w2 * value2_lst[candidate_indices]\n            best_candidate = candidate_indices[np.argmax(scores)]\n\n            # Check if adding the item is feasible\n            if current_weight + weight_lst[best_candidate] <= capacity:\n                new_solution[best_candidate] = 1\n\n    # Step 3: Capacity-aware adjustments\n    if random.random() < 0.5:  # 50% chance to perform this step\n        # Try to add items that are underweighted\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Sort by weight-to-value ratio\n            ratios = (weight_lst[candidate_indices] / (value1_lst[candidate_indices] + value2_lst[candidate_indices] + 1e-6))\n            best_candidate = candidate_indices[np.argmin(ratios)]\n\n            # Check if adding the item is feasible\n            if current_weight + weight_lst[best_candidate] <= capacity:\n                new_solution[best_candidate] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 26,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability inversely proportional to its dominance count\n    # (simulating a tournament selection based on non-dominated status)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a candidate by flipping a random bit (exploration)\n    candidate = base_solution.copy()\n    flip_pos = random.randint(0, len(candidate) - 1)\n    candidate[flip_pos] = 1 - candidate[flip_pos]\n\n    # Ensure feasibility: if flip makes solution infeasible, undo it\n    new_weight = current_weight + weight_lst[flip_pos] * (2 * candidate[flip_pos] - 1)\n    if new_weight > capacity:\n        candidate[flip_pos] = 1 - candidate[flip_pos]\n        new_weight = current_weight\n\n    # Perform a greedy improvement step: try to add/remove items that improve both objectives\n    improved = True\n    while improved:\n        improved = False\n        # Try adding items not in solution\n        for i in range(len(candidate)):\n            if candidate[i] == 0 and (new_weight + weight_lst[i]) <= capacity:\n                new_value1 = current_value1 + value1_lst[i]\n                new_value2 = current_value2 + value2_lst[i]\n                # Check if adding improves both objectives\n                if new_value1 > current_value1 and new_value2 > current_value2:\n                    candidate[i] = 1\n                    current_value1, current_value2 = new_value1, new_value2\n                    new_weight += weight_lst[i]\n                    improved = True\n                    break\n        # Try removing items in solution\n        for i in range(len(candidate)):\n            if candidate[i] == 1:\n                new_value1 = current_value1 - value1_lst[i]\n                new_value2 = current_value2 - value2_lst[i]\n                # Check if removing improves both objectives\n                if new_value1 > current_value1 and new_value2 > current_value2:\n                    candidate[i] = 0\n                    current_value1, current_value2 = new_value1, new_value2\n                    new_weight -= weight_lst[i]\n                    improved = True\n                    break\n\n    return candidate\n\n",
        "score": [
            -0.3780218459688735,
            6.306473344564438
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability inversely proportional to its dominance count\n    # (simulating a tournament selection based on non-dominated status)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a candidate by flipping a random bit (exploration)\n    candidate = base_solution.copy()\n    flip_pos = random.randint(0, len(candidate) - 1)\n    candidate[flip_pos] = 1 - candidate[flip_pos]\n\n    # Ensure feasibility: if flip makes solution infeasible, undo it\n    new_weight = current_weight + weight_lst[flip_pos] * (2 * candidate[flip_pos] - 1)\n    if new_weight > capacity:\n        candidate[flip_pos] = 1 - candidate[flip_pos]\n        new_weight = current_weight\n\n    # Perform a greedy improvement step: try to add/remove items that improve both objectives\n    improved = True\n    while improved:\n        improved = False\n        # Try adding items not in solution\n        for i in range(len(candidate)):\n            if candidate[i] == 0 and (new_weight + weight_lst[i]) <= capacity:\n                new_value1 = current_value1 + value1_lst[i]\n                new_value2 = current_value2 + value2_lst[i]\n                # Check if adding improves both objectives\n                if new_value1 > current_value1 and new_value2 > current_value2:\n                    candidate[i] = 1\n                    current_value1, current_value2 = new_value1, new_value2\n                    new_weight += weight_lst[i]\n                    improved = True\n                    break\n        # Try removing items in solution\n        for i in range(len(candidate)):\n            if candidate[i] == 1:\n                new_value1 = current_value1 - value1_lst[i]\n                new_value2 = current_value2 - value2_lst[i]\n                # Check if removing improves both objectives\n                if new_value1 > current_value1 and new_value2 > current_value2:\n                    candidate[i] = 0\n                    current_value1, current_value2 = new_value1, new_value2\n                    new_weight -= weight_lst[i]\n                    improved = True\n                    break\n\n    return candidate\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 27,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement: prioritize solutions with low weight and high value ratios\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        total_value1 = np.sum(value1_lst * sol)\n        total_value2 = np.sum(value2_lst * sol)\n        # Calculate normalized scores for both objectives\n        score1 = total_value1 / (total_weight + 1e-6)  # Avoid division by zero\n        score2 = total_value2 / (total_weight + 1e-6)\n        candidates.append((sol, score1 + score2))  # Combine scores\n\n    # Sort candidates by combined score (descending) to prioritize high-potential solutions\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search: flip a random subset of items with high value-to-weight ratio\n    new_solution = base_solution.copy()\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n\n    # Identify items not in the solution that could fit within remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    feasible_items = [i for i in available_items if weight_lst[i] <= remaining_capacity]\n\n    if feasible_items:\n        # Select top 20% of feasible items by value-to-weight ratio (combined for both objectives)\n        item_scores = []\n        for i in feasible_items:\n            score1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n            score2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            item_scores.append((i, score1 + score2))\n        item_scores.sort(key=lambda x: -x[1])\n        top_items = [x[0] for x in item_scores[:max(1, len(item_scores) // 5)]]\n\n        # Randomly flip a subset of top items to explore neighbors\n        flip_indices = random.sample(top_items, min(2, len(top_items)))\n        for i in flip_indices:\n            if new_solution[i] == 0 and (remaining_capacity - weight_lst[i]) >= 0:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Also consider flipping items already in the solution if it improves objectives\n    included_items = np.where(new_solution == 1)[0]\n    if included_items.size > 0:\n        for i in random.sample(list(included_items), min(2, len(included_items))):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove items with lowest value-to-weight ratio until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if included_items.size == 0:\n                break\n            # Find item with lowest combined value-to-weight ratio\n            min_score = float('inf')\n            min_item = -1\n            for i in included_items:\n                score1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n                score2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n                if (score1 + score2) < min_score:\n                    min_score = score1 + score2\n                    min_item = i\n            if min_item != -1:\n                new_solution[min_item] = 0\n                total_weight -= weight_lst[min_item]\n\n    return new_solution\n\n",
        "score": [
            -0.6616938974603992,
            2.855970174074173
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement: prioritize solutions with low weight and high value ratios\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        total_value1 = np.sum(value1_lst * sol)\n        total_value2 = np.sum(value2_lst * sol)\n        # Calculate normalized scores for both objectives\n        score1 = total_value1 / (total_weight + 1e-6)  # Avoid division by zero\n        score2 = total_value2 / (total_weight + 1e-6)\n        candidates.append((sol, score1 + score2))  # Combine scores\n\n    # Sort candidates by combined score (descending) to prioritize high-potential solutions\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search: flip a random subset of items with high value-to-weight ratio\n    new_solution = base_solution.copy()\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n\n    # Identify items not in the solution that could fit within remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    feasible_items = [i for i in available_items if weight_lst[i] <= remaining_capacity]\n\n    if feasible_items:\n        # Select top 20% of feasible items by value-to-weight ratio (combined for both objectives)\n        item_scores = []\n        for i in feasible_items:\n            score1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n            score2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            item_scores.append((i, score1 + score2))\n        item_scores.sort(key=lambda x: -x[1])\n        top_items = [x[0] for x in item_scores[:max(1, len(item_scores) // 5)]]\n\n        # Randomly flip a subset of top items to explore neighbors\n        flip_indices = random.sample(top_items, min(2, len(top_items)))\n        for i in flip_indices:\n            if new_solution[i] == 0 and (remaining_capacity - weight_lst[i]) >= 0:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Also consider flipping items already in the solution if it improves objectives\n    included_items = np.where(new_solution == 1)[0]\n    if included_items.size > 0:\n        for i in random.sample(list(included_items), min(2, len(included_items))):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                remaining_capacity += weight_lst[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove items with lowest value-to-weight ratio until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if included_items.size == 0:\n                break\n            # Find item with lowest combined value-to-weight ratio\n            min_score = float('inf')\n            min_item = -1\n            for i in included_items:\n                score1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n                score2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n                if (score1 + score2) < min_score:\n                    min_score = score1 + score2\n                    min_item = i\n            if min_item != -1:\n                new_solution[min_item] = 0\n                total_weight -= weight_lst[min_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 28,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with a probability weighted by its potential for improvement\n    # Solutions with higher value-to-weight ratios are more likely to be selected\n    total_values = np.array([sum(sol[1]) for sol in archive])\n    total_weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    value_to_weight_ratios = total_values / (total_weights + 1e-10)  # Avoid division by zero\n\n    # Normalize ratios to get selection probabilities\n    probabilities = value_to_weight_ratios / np.sum(value_to_weight_ratios)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # 1. Randomly flip a subset of items (diversity)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Apply value-to-weight ratio-based flips (quality)\n    # Calculate marginal value-to-weight ratios for items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        marginal_ratios = (value1_lst[not_in_solution] + value2_lst[not_in_solution]) / weight_lst[not_in_solution]\n        best_candidate_idx = not_in_solution[np.argmax(marginal_ratios)]\n\n        # Check if adding this item keeps the solution feasible\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight + weight_lst[best_candidate_idx] <= capacity:\n            new_solution[best_candidate_idx] = 1\n\n    # 3. Remove low-value items to free up capacity\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_candidate_idx = in_solution[np.argmin(marginal_ratios)]\n        new_solution[worst_candidate_idx] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(in_solution)\n        for idx in in_solution:\n            new_solution[idx] = 0\n            if np.sum(weight_lst * new_solution) <= capacity:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.37320250129341564,
            1.8185948133468628
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with a probability weighted by its potential for improvement\n    # Solutions with higher value-to-weight ratios are more likely to be selected\n    total_values = np.array([sum(sol[1]) for sol in archive])\n    total_weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    value_to_weight_ratios = total_values / (total_weights + 1e-10)  # Avoid division by zero\n\n    # Normalize ratios to get selection probabilities\n    probabilities = value_to_weight_ratios / np.sum(value_to_weight_ratios)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # 1. Randomly flip a subset of items (diversity)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Apply value-to-weight ratio-based flips (quality)\n    # Calculate marginal value-to-weight ratios for items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        marginal_ratios = (value1_lst[not_in_solution] + value2_lst[not_in_solution]) / weight_lst[not_in_solution]\n        best_candidate_idx = not_in_solution[np.argmax(marginal_ratios)]\n\n        # Check if adding this item keeps the solution feasible\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight + weight_lst[best_candidate_idx] <= capacity:\n            new_solution[best_candidate_idx] = 1\n\n    # 3. Remove low-value items to free up capacity\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_candidate_idx = in_solution[np.argmin(marginal_ratios)]\n        new_solution[worst_candidate_idx] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(in_solution)\n        for idx in in_solution:\n            new_solution[idx] = 0\n            if np.sum(weight_lst * new_solution) <= capacity:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 29,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Random item flips with weight balance\n    for _ in range(min(3, len(new_solution))):\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            # Try removing item if weight allows\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding item if weight allows\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Strategy 2: Objective-specific flips\n    if random.random() < 0.5:\n        # Focus on improving value1\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            best_item = max(candidate_items, key=lambda i: value1_lst[i] / weight_lst[i])\n            if current_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n    else:\n        # Focus on improving value2\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            best_item = max(candidate_items, key=lambda i: value2_lst[i] / weight_lst[i])\n            if current_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    # Strategy 3: Weight-balanced adjustments\n    if current_weight > 0.9 * capacity:\n        # Try to reduce weight while maintaining value\n        heavy_items = np.where(new_solution == 1)[0]\n        if len(heavy_items) > 0:\n            worst_item = min(heavy_items, key=lambda i: (value1_lst[i] + value2_lst[i]) / weight_lst[i])\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3200094267332291,
            1.7711674571037292
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Random item flips with weight balance\n    for _ in range(min(3, len(new_solution))):\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            # Try removing item if weight allows\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding item if weight allows\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Strategy 2: Objective-specific flips\n    if random.random() < 0.5:\n        # Focus on improving value1\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            best_item = max(candidate_items, key=lambda i: value1_lst[i] / weight_lst[i])\n            if current_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n    else:\n        # Focus on improving value2\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            best_item = max(candidate_items, key=lambda i: value2_lst[i] / weight_lst[i])\n            if current_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    # Strategy 3: Weight-balanced adjustments\n    if current_weight > 0.9 * capacity:\n        # Try to reduce weight while maintaining value\n        heavy_items = np.where(new_solution == 1)[0]\n        if len(heavy_items) > 0:\n            worst_item = min(heavy_items, key=lambda i: (value1_lst[i] + value2_lst[i]) / weight_lst[i])\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 30,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a high potential for improvement\n    # Candidates are solutions that are not fully packed and have room for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        if current_weight < capacity * 0.9:  # Only consider solutions with significant room\n            candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest potential for improvement\n        # Potential is estimated by the ratio of remaining capacity to total capacity\n        base_solution = max(candidates, key=lambda x: (capacity - np.sum(x * weight_lst)) / capacity)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (add/remove)\n    # 2. Apply a value-based heuristic to prioritize flips that improve both objectives\n    # 3. Ensure feasibility by checking the weight constraint\n\n    # Step 1: Randomly select items to consider flipping\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(num_items // 2, 10))  # Consider up to 10 items\n\n    # Step 2: Prioritize flips based on value-to-weight ratio for both objectives\n    for idx in flip_indices:\n        current_weight = np.sum(new_solution * weight_lst)\n        if new_solution[idx] == 1:\n            # If item is in the solution, consider removing it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate potential improvement\n                value1_improvement = value1_lst[idx]\n                value2_improvement = value2_lst[idx]\n                # Accept the flip if it improves both objectives\n                if value1_improvement > 0 and value2_improvement > 0:\n                    new_solution[idx] = 0\n        else:\n            # If item is not in the solution, consider adding it\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate potential improvement\n                value1_improvement = value1_lst[idx]\n                value2_improvement = value2_lst[idx]\n                # Accept the flip if it improves both objectives\n                if value1_improvement > 0 and value2_improvement > 0:\n                    new_solution[idx] = 1\n\n    # Step 3: If no improvements found, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.choice(flip_indices)\n        if new_solution[random_idx] == 1:\n            if np.sum(new_solution * weight_lst) - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if np.sum(new_solution * weight_lst) + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.39335983837844923,
            1.4329313039779663
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a high potential for improvement\n    # Candidates are solutions that are not fully packed and have room for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(sol * weight_lst)\n        if current_weight < capacity * 0.9:  # Only consider solutions with significant room\n            candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest potential for improvement\n        # Potential is estimated by the ratio of remaining capacity to total capacity\n        base_solution = max(candidates, key=lambda x: (capacity - np.sum(x * weight_lst)) / capacity)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (add/remove)\n    # 2. Apply a value-based heuristic to prioritize flips that improve both objectives\n    # 3. Ensure feasibility by checking the weight constraint\n\n    # Step 1: Randomly select items to consider flipping\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(num_items // 2, 10))  # Consider up to 10 items\n\n    # Step 2: Prioritize flips based on value-to-weight ratio for both objectives\n    for idx in flip_indices:\n        current_weight = np.sum(new_solution * weight_lst)\n        if new_solution[idx] == 1:\n            # If item is in the solution, consider removing it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate potential improvement\n                value1_improvement = value1_lst[idx]\n                value2_improvement = value2_lst[idx]\n                # Accept the flip if it improves both objectives\n                if value1_improvement > 0 and value2_improvement > 0:\n                    new_solution[idx] = 0\n        else:\n            # If item is not in the solution, consider adding it\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate potential improvement\n                value1_improvement = value1_lst[idx]\n                value2_improvement = value2_lst[idx]\n                # Accept the flip if it improves both objectives\n                if value1_improvement > 0 and value2_improvement > 0:\n                    new_solution[idx] = 1\n\n    # Step 3: If no improvements found, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.choice(flip_indices)\n        if new_solution[random_idx] == 1:\n            if np.sum(new_solution * weight_lst) - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if np.sum(new_solution * weight_lst) + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 31,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a high potential for improvement (e.g., non-dominated but not fully explored)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random flip followed by greedy improvement\n    # Step 1: Randomly flip a subset of items (1-3 items)\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 4), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break  # No items left, return original solution\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = current_value1 + value1_lst[item]\n            new_value2 = current_value2 + value2_lst[item]\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n                current_value1, current_value2 = new_value1, new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.3672137820591785,
            1.4043413996696472
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a high potential for improvement (e.g., non-dominated but not fully explored)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random flip followed by greedy improvement\n    # Step 1: Randomly flip a subset of items (1-3 items)\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 4), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break  # No items left, return original solution\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = current_value1 + value1_lst[item]\n            new_value2 = current_value2 + value2_lst[item]\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n                current_value1, current_value2 = new_value1, new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 32,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a base solution intelligently: prioritize solutions with high potential for improvement\n    # Here, we select solutions that are not too close to the Pareto front and have high marginal gains\n    base_solution, _ = max(archive, key=lambda x: sum(x[0] * (value1_lst + value2_lst)))\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If the item is included, check if removing it keeps the solution feasible\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If the item is excluded, check if adding it keeps the solution feasible\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # 2. Perform value-based swaps to improve both objectives\n    # Identify items that are in the solution but have low marginal value for both objectives\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Sort excluded items by their value-to-weight ratio for both objectives\n    excluded_items_sorted = sorted(excluded_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x], reverse=True)\n\n    for idx in included_items:\n        # Find the best excluded item to swap with\n        for candidate in excluded_items_sorted:\n            if (np.sum(new_solution * weight_lst) - weight_lst[idx] + weight_lst[candidate]) <= capacity:\n                # Perform the swap\n                new_solution[idx] = 0\n                new_solution[candidate] = 1\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.7581014815344823,
            6.444400310516357
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a base solution intelligently: prioritize solutions with high potential for improvement\n    # Here, we select solutions that are not too close to the Pareto front and have high marginal gains\n    base_solution, _ = max(archive, key=lambda x: sum(x[0] * (value1_lst + value2_lst)))\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If the item is included, check if removing it keeps the solution feasible\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If the item is excluded, check if adding it keeps the solution feasible\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # 2. Perform value-based swaps to improve both objectives\n    # Identify items that are in the solution but have low marginal value for both objectives\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Sort excluded items by their value-to-weight ratio for both objectives\n    excluded_items_sorted = sorted(excluded_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x], reverse=True)\n\n    for idx in included_items:\n        # Find the best excluded item to swap with\n        for candidate in excluded_items_sorted:\n            if (np.sum(new_solution * weight_lst) - weight_lst[idx] + weight_lst[candidate]) <= capacity:\n                # Perform the swap\n                new_solution[idx] = 0\n                new_solution[candidate] = 1\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 33,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Sort solutions by the sum of their objectives (prioritize solutions with higher combined value)\n    sorted_solutions = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected_solution = sorted_solutions[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply a greedy improvement step (exploitation)\n    new_solution = selected_solution.copy()\n\n    # Step 1: Random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Check if removing the item keeps the solution feasible\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    available_items = np.where(new_solution == 0)[0]\n\n    for idx in available_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            if value1_lst[idx] > 0 and value2_lst[idx] > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3424286069702049,
            2.8353962004184723
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Sort solutions by the sum of their objectives (prioritize solutions with higher combined value)\n    sorted_solutions = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected_solution = sorted_solutions[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply a greedy improvement step (exploitation)\n    new_solution = selected_solution.copy()\n\n    # Step 1: Random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Check if removing the item keeps the solution feasible\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    available_items = np.where(new_solution == 0)[0]\n\n    for idx in available_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            if value1_lst[idx] > 0 and value2_lst[idx] > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 34,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most promising solution (e.g., highest total value1 + value2)\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine randomness with a novel operator\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (with a bias towards low-weight, high-value items)\n    flip_prob = 0.3  # Probability of flipping an item\n    for i in range(len(base_solution)):\n        if np.random.rand() < flip_prob:\n            if base_solution[i] == 1:\n                # Try to remove the item if it's in the solution\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to add the item if it's not in the solution\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Apply a novel local search operator: \"Value-weighted Flip\"\n    # This operator flips items based on a weighted probability that considers both objectives and weights\n    for i in range(len(base_solution)):\n        if new_solution[i] == 1:\n            # Probability of flipping based on the ratio of value to weight\n            flip_prob = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n            if np.random.rand() < flip_prob * 0.1:  # Scale down to avoid excessive flips\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n        else:\n            # Probability of flipping based on the ratio of value to weight\n            flip_prob = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n            if np.random.rand() < flip_prob * 0.1:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3938681573017719,
            2.4956033527851105
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most promising solution (e.g., highest total value1 + value2)\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine randomness with a novel operator\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (with a bias towards low-weight, high-value items)\n    flip_prob = 0.3  # Probability of flipping an item\n    for i in range(len(base_solution)):\n        if np.random.rand() < flip_prob:\n            if base_solution[i] == 1:\n                # Try to remove the item if it's in the solution\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to add the item if it's not in the solution\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Apply a novel local search operator: \"Value-weighted Flip\"\n    # This operator flips items based on a weighted probability that considers both objectives and weights\n    for i in range(len(base_solution)):\n        if new_solution[i] == 1:\n            # Probability of flipping based on the ratio of value to weight\n            flip_prob = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n            if np.random.rand() < flip_prob * 0.1:  # Scale down to avoid excessive flips\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n        else:\n            # Probability of flipping based on the ratio of value to weight\n            flip_prob = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n            if np.random.rand() < flip_prob * 0.1:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 35,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (highest sum of normalized values)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_values = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_values.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: flip a random item with high value contribution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate value per weight ratios for both objectives\n    value1_per_weight = value1_lst / (weight_lst + 1e-10)\n    value2_per_weight = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value1_per_weight + value2_per_weight\n\n    # Candidates for flipping: items not in the solution with high combined ratio\n    candidates = np.where(new_solution == 0)[0]\n    candidate_ratios = combined_ratio[candidates]\n    if len(candidates) > 0:\n        # Select a candidate with probability proportional to its ratio\n        probs = candidate_ratios / np.sum(candidate_ratios)\n        selected_item = np.random.choice(candidates, p=probs)\n\n        # Check if adding the item would exceed capacity\n        if current_weight + weight_lst[selected_item] <= capacity:\n            new_solution[selected_item] = 1\n\n    # Also consider removing low-value items\n    if np.sum(new_solution) > 0:\n        # Calculate marginal contribution of each item in the solution\n        marginal_contribution = (value1_lst + value2_lst) * new_solution\n        # Select an item to remove with probability inversely proportional to its contribution\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            inv_probs = 1 / (marginal_contribution[items_in_solution] + 1e-10)\n            inv_probs = inv_probs / np.sum(inv_probs)\n            remove_item = np.random.choice(items_in_solution, p=inv_probs)\n            new_solution[remove_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9036531386468387,
            1.3913307189941406
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (highest sum of normalized values)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_values = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_values.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: flip a random item with high value contribution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate value per weight ratios for both objectives\n    value1_per_weight = value1_lst / (weight_lst + 1e-10)\n    value2_per_weight = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value1_per_weight + value2_per_weight\n\n    # Candidates for flipping: items not in the solution with high combined ratio\n    candidates = np.where(new_solution == 0)[0]\n    candidate_ratios = combined_ratio[candidates]\n    if len(candidates) > 0:\n        # Select a candidate with probability proportional to its ratio\n        probs = candidate_ratios / np.sum(candidate_ratios)\n        selected_item = np.random.choice(candidates, p=probs)\n\n        # Check if adding the item would exceed capacity\n        if current_weight + weight_lst[selected_item] <= capacity:\n            new_solution[selected_item] = 1\n\n    # Also consider removing low-value items\n    if np.sum(new_solution) > 0:\n        # Calculate marginal contribution of each item in the solution\n        marginal_contribution = (value1_lst + value2_lst) * new_solution\n        # Select an item to remove with probability inversely proportional to its contribution\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            inv_probs = 1 / (marginal_contribution[items_in_solution] + 1e-10)\n            inv_probs = inv_probs / np.sum(inv_probs)\n            remove_item = np.random.choice(items_in_solution, p=inv_probs)\n            new_solution[remove_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 36,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the capacity\n    current_weights = [np.sum(weight_lst * sol) for sol, _ in archive]\n    normalized_weights = [w / capacity for w in current_weights]\n    probabilities = [1 - w for w in normalized_weights]  # Higher probability for solutions with less used capacity\n    probabilities = [p / sum(probabilities) for p in probabilities]  # Normalize to probabilities\n\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip: flip a random subset of items (1-3 flips)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If infeasible, remove items randomly until feasible\n        while current_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break  # No items to remove, solution is empty\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate the \"improvement\" potential for both objectives\n            value1_gain = value1_lst[item]\n            value2_gain = value2_lst[item]\n\n            # Add the item if it improves both objectives or at least one significantly\n            if (value1_gain > 0 and value2_gain > 0) or \\\n               (value1_gain > np.mean(value1_lst) and value2_gain > np.mean(value2_lst)):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.37458188590614766,
            3.1273211538791656
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the capacity\n    current_weights = [np.sum(weight_lst * sol) for sol, _ in archive]\n    normalized_weights = [w / capacity for w in current_weights]\n    probabilities = [1 - w for w in normalized_weights]  # Higher probability for solutions with less used capacity\n    probabilities = [p / sum(probabilities) for p in probabilities]  # Normalize to probabilities\n\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip: flip a random subset of items (1-3 flips)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If infeasible, remove items randomly until feasible\n        while current_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break  # No items to remove, solution is empty\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate the \"improvement\" potential for both objectives\n            value1_gain = value1_lst[item]\n            value2_gain = value2_lst[item]\n\n            # Add the item if it improves both objectives or at least one significantly\n            if (value1_gain > 0 and value2_gain > 0) or \\\n               (value1_gain > np.mean(value1_lst) and value2_gain > np.mean(value2_lst)):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 37,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher total value\n    values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probs = values / np.sum(values)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal utility for each item (weighted sum of both objectives)\n    marginal_utility = (value1_lst + value2_lst) / weight_lst\n\n    # Identify items to consider for flipping (either included or excluded)\n    candidate_indices = np.where(marginal_utility > 0)[0]\n\n    # If no candidates, return the base solution\n    if len(candidate_indices) == 0:\n        return new_solution\n\n    # Randomly select a subset of candidates to flip\n    num_flips = min(3, len(candidate_indices))  # Limit the number of flips to 3 for efficiency\n    flip_indices = np.random.choice(candidate_indices, size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.32617507332203455,
            0.9450054168701172
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher total value\n    values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probs = values / np.sum(values)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal utility for each item (weighted sum of both objectives)\n    marginal_utility = (value1_lst + value2_lst) / weight_lst\n\n    # Identify items to consider for flipping (either included or excluded)\n    candidate_indices = np.where(marginal_utility > 0)[0]\n\n    # If no candidates, return the base solution\n    if len(candidate_indices) == 0:\n        return new_solution\n\n    # Randomly select a subset of candidates to flip\n    num_flips = min(3, len(candidate_indices))  # Limit the number of flips to 3 for efficiency\n    flip_indices = np.random.choice(candidate_indices, size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 38,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (descending)\n    selected_solution, _ = archive[0]\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip with objective-aware selection\n    for _ in range(3):  # Try 3 random flips\n        candidates = np.where(np.logical_or(\n            (current_solution == 0) & (weight_lst <= (capacity - np.sum(weight_lst * current_solution))),\n            (current_solution == 1)\n        ))[0]\n\n        if len(candidates) > 0:\n            item_idx = random.choice(candidates)\n            new_solution = current_solution.copy()\n            new_solution[item_idx] = 1 - new_solution[item_idx]\n\n            # Check feasibility\n            if np.sum(weight_lst * new_solution) <= capacity:\n                current_solution = new_solution.copy()\n\n    # 2. Objective-aware swap\n    if random.random() < 0.5:  # 50% chance to perform swap\n        # Find items that could improve both objectives\n        zero_items = np.where(current_solution == 0)[0]\n        one_items = np.where(current_solution == 1)[0]\n\n        if len(zero_items) > 0 and len(one_items) > 0:\n            # Select items with highest marginal value in either objective\n            zero_values = value1_lst[zero_items] + value2_lst[zero_items]\n            one_values = value1_lst[one_items] + value2_lst[one_items]\n\n            if np.max(zero_values) > np.max(one_values):\n                # Add best zero item\n                best_zero = zero_items[np.argmax(zero_values)]\n                new_solution = current_solution.copy()\n                new_solution[best_zero] = 1\n\n                # Remove least valuable one item if needed\n                if np.sum(weight_lst * new_solution) > capacity:\n                    one_weights = weight_lst[one_items]\n                    one_values_total = value1_lst[one_items] + value2_lst[one_items]\n                    remove_idx = one_items[np.argmin(one_values_total / one_weights)]\n                    new_solution[remove_idx] = 0\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n            else:\n                # Remove worst one item and add best zero item\n                worst_one = one_items[np.argmin(one_values)]\n                best_zero = zero_items[np.argmax(zero_values)]\n\n                new_solution = current_solution.copy()\n                new_solution[worst_one] = 0\n                new_solution[best_zero] = 1\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n\n    return current_solution\n\n",
        "score": [
            -0.3307772804090099,
            0.7096994817256927
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (descending)\n    selected_solution, _ = archive[0]\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip with objective-aware selection\n    for _ in range(3):  # Try 3 random flips\n        candidates = np.where(np.logical_or(\n            (current_solution == 0) & (weight_lst <= (capacity - np.sum(weight_lst * current_solution))),\n            (current_solution == 1)\n        ))[0]\n\n        if len(candidates) > 0:\n            item_idx = random.choice(candidates)\n            new_solution = current_solution.copy()\n            new_solution[item_idx] = 1 - new_solution[item_idx]\n\n            # Check feasibility\n            if np.sum(weight_lst * new_solution) <= capacity:\n                current_solution = new_solution.copy()\n\n    # 2. Objective-aware swap\n    if random.random() < 0.5:  # 50% chance to perform swap\n        # Find items that could improve both objectives\n        zero_items = np.where(current_solution == 0)[0]\n        one_items = np.where(current_solution == 1)[0]\n\n        if len(zero_items) > 0 and len(one_items) > 0:\n            # Select items with highest marginal value in either objective\n            zero_values = value1_lst[zero_items] + value2_lst[zero_items]\n            one_values = value1_lst[one_items] + value2_lst[one_items]\n\n            if np.max(zero_values) > np.max(one_values):\n                # Add best zero item\n                best_zero = zero_items[np.argmax(zero_values)]\n                new_solution = current_solution.copy()\n                new_solution[best_zero] = 1\n\n                # Remove least valuable one item if needed\n                if np.sum(weight_lst * new_solution) > capacity:\n                    one_weights = weight_lst[one_items]\n                    one_values_total = value1_lst[one_items] + value2_lst[one_items]\n                    remove_idx = one_items[np.argmin(one_values_total / one_weights)]\n                    new_solution[remove_idx] = 0\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n            else:\n                # Remove worst one item and add best zero item\n                worst_one = one_items[np.argmin(one_values)]\n                best_zero = zero_items[np.argmax(zero_values)]\n\n                new_solution = current_solution.copy()\n                new_solution[worst_one] = 0\n                new_solution[best_zero] = 1\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n\n    return current_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 38,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (descending)\n    selected_solution, _ = archive[0]\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip with objective-aware selection\n    for _ in range(3):  # Try 3 random flips\n        candidates = np.where(np.logical_or(\n            (current_solution == 0) & (weight_lst <= (capacity - np.sum(weight_lst * current_solution))),\n            (current_solution == 1)\n        ))[0]\n\n        if len(candidates) > 0:\n            item_idx = random.choice(candidates)\n            new_solution = current_solution.copy()\n            new_solution[item_idx] = 1 - new_solution[item_idx]\n\n            # Check feasibility\n            if np.sum(weight_lst * new_solution) <= capacity:\n                current_solution = new_solution.copy()\n\n    # 2. Objective-aware swap\n    if random.random() < 0.5:  # 50% chance to perform swap\n        # Find items that could improve both objectives\n        zero_items = np.where(current_solution == 0)[0]\n        one_items = np.where(current_solution == 1)[0]\n\n        if len(zero_items) > 0 and len(one_items) > 0:\n            # Select items with highest marginal value in either objective\n            zero_values = value1_lst[zero_items] + value2_lst[zero_items]\n            one_values = value1_lst[one_items] + value2_lst[one_items]\n\n            if np.max(zero_values) > np.max(one_values):\n                # Add best zero item\n                best_zero = zero_items[np.argmax(zero_values)]\n                new_solution = current_solution.copy()\n                new_solution[best_zero] = 1\n\n                # Remove least valuable one item if needed\n                if np.sum(weight_lst * new_solution) > capacity:\n                    one_weights = weight_lst[one_items]\n                    one_values_total = value1_lst[one_items] + value2_lst[one_items]\n                    remove_idx = one_items[np.argmin(one_values_total / one_weights)]\n                    new_solution[remove_idx] = 0\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n            else:\n                # Remove worst one item and add best zero item\n                worst_one = one_items[np.argmin(one_values)]\n                best_zero = zero_items[np.argmax(zero_values)]\n\n                new_solution = current_solution.copy()\n                new_solution[worst_one] = 0\n                new_solution[best_zero] = 1\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n\n    return current_solution\n\n",
        "score": [
            -0.3307772804090099,
            0.7096994817256927
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (descending)\n    selected_solution, _ = archive[0]\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip with objective-aware selection\n    for _ in range(3):  # Try 3 random flips\n        candidates = np.where(np.logical_or(\n            (current_solution == 0) & (weight_lst <= (capacity - np.sum(weight_lst * current_solution))),\n            (current_solution == 1)\n        ))[0]\n\n        if len(candidates) > 0:\n            item_idx = random.choice(candidates)\n            new_solution = current_solution.copy()\n            new_solution[item_idx] = 1 - new_solution[item_idx]\n\n            # Check feasibility\n            if np.sum(weight_lst * new_solution) <= capacity:\n                current_solution = new_solution.copy()\n\n    # 2. Objective-aware swap\n    if random.random() < 0.5:  # 50% chance to perform swap\n        # Find items that could improve both objectives\n        zero_items = np.where(current_solution == 0)[0]\n        one_items = np.where(current_solution == 1)[0]\n\n        if len(zero_items) > 0 and len(one_items) > 0:\n            # Select items with highest marginal value in either objective\n            zero_values = value1_lst[zero_items] + value2_lst[zero_items]\n            one_values = value1_lst[one_items] + value2_lst[one_items]\n\n            if np.max(zero_values) > np.max(one_values):\n                # Add best zero item\n                best_zero = zero_items[np.argmax(zero_values)]\n                new_solution = current_solution.copy()\n                new_solution[best_zero] = 1\n\n                # Remove least valuable one item if needed\n                if np.sum(weight_lst * new_solution) > capacity:\n                    one_weights = weight_lst[one_items]\n                    one_values_total = value1_lst[one_items] + value2_lst[one_items]\n                    remove_idx = one_items[np.argmin(one_values_total / one_weights)]\n                    new_solution[remove_idx] = 0\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n            else:\n                # Remove worst one item and add best zero item\n                worst_one = one_items[np.argmin(one_values)]\n                best_zero = zero_items[np.argmax(zero_values)]\n\n                new_solution = current_solution.copy()\n                new_solution[worst_one] = 0\n                new_solution[best_zero] = 1\n\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    current_solution = new_solution.copy()\n\n    return current_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 39,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution: prioritize those with high marginal gains\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate marginal gains for each objective\n    marginal_gains = []\n    for sol, w, v1, v2 in zip(archive_solutions, archive_weights, archive_values1, archive_values2):\n        # Marginal gain is approximated by the ratio of value to weight\n        gain1 = v1 / (w + 1e-6)  # Avoid division by zero\n        gain2 = v2 / (w + 1e-6)\n        marginal_gains.append(gain1 + gain2)  # Combined marginal gain\n\n    # Select the solution with the highest marginal gain\n    selected_idx = np.argmax(marginal_gains)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = archive_weights[selected_idx]\n\n    # Generate neighbor by flipping items with high value-to-weight ratio\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    candidate_indices = np.where(base_solution == 1)[0]  # Indices of included items\n    if len(candidate_indices) == 0:\n        candidate_indices = np.arange(n_items)  # If no items included, consider all\n\n    # Randomly select a subset of items to flip\n    flip_indices = np.random.choice(candidate_indices, size=min(3, len(candidate_indices)), replace=False)\n\n    # Calculate the effect of flipping each selected item\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to exclude it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8452594945023122,
            2.6890847086906433
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution: prioritize those with high marginal gains\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate marginal gains for each objective\n    marginal_gains = []\n    for sol, w, v1, v2 in zip(archive_solutions, archive_weights, archive_values1, archive_values2):\n        # Marginal gain is approximated by the ratio of value to weight\n        gain1 = v1 / (w + 1e-6)  # Avoid division by zero\n        gain2 = v2 / (w + 1e-6)\n        marginal_gains.append(gain1 + gain2)  # Combined marginal gain\n\n    # Select the solution with the highest marginal gain\n    selected_idx = np.argmax(marginal_gains)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = archive_weights[selected_idx]\n\n    # Generate neighbor by flipping items with high value-to-weight ratio\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    candidate_indices = np.where(base_solution == 1)[0]  # Indices of included items\n    if len(candidate_indices) == 0:\n        candidate_indices = np.arange(n_items)  # If no items included, consider all\n\n    # Randomly select a subset of items to flip\n    flip_indices = np.random.choice(candidate_indices, size=min(3, len(candidate_indices)), replace=False)\n\n    # Calculate the effect of flipping each selected item\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to exclude it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 40,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    # Prioritize solutions with high marginal gains or those with low crowding distance\n    base_solution, _ = max(archive, key=lambda x: np.sum(value1_lst[x[0] == 1]) + np.sum(value2_lst[x[0] == 1]))\n\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Identify items with high marginal contribution\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_items = np.argsort(marginal_contributions)[::-1]  # Descending order\n\n    # Apply hybrid local search: flip items with high marginal contribution first\n    for item in sorted_items:\n        if new_solution[item] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n                current_value1 -= value1_lst[item]\n                current_value2 -= value2_lst[item]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                current_value1 += value1_lst[item]\n                current_value2 += value2_lst[item]\n\n    # Apply a perturbation: flip a few random items to escape local optima\n    num_perturbations = min(3, len(new_solution))\n    perturbation_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    for idx in perturbation_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7806319382946305,
            3.428436368703842
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    # Prioritize solutions with high marginal gains or those with low crowding distance\n    base_solution, _ = max(archive, key=lambda x: np.sum(value1_lst[x[0] == 1]) + np.sum(value2_lst[x[0] == 1]))\n\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Identify items with high marginal contribution\n    marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_items = np.argsort(marginal_contributions)[::-1]  # Descending order\n\n    # Apply hybrid local search: flip items with high marginal contribution first\n    for item in sorted_items:\n        if new_solution[item] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n                current_value1 -= value1_lst[item]\n                current_value2 -= value2_lst[item]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                current_value1 += value1_lst[item]\n                current_value2 += value2_lst[item]\n\n    # Apply a perturbation: flip a few random items to escape local optima\n    num_perturbations = min(3, len(new_solution))\n    perturbation_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    for idx in perturbation_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 41,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with high marginal contribution\n    # Calculate marginal contribution for each solution in the archive\n    marginal_contributions = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        # Marginal contribution is the ratio of total value to total weight\n        marg1 = val1 / total_weight if total_weight > 0 else 0\n        marg2 = val2 / total_weight if total_weight > 0 else 0\n        marginal_contributions.append((marg1 + marg2) / 2)  # Average marginal contribution\n\n    # Select top 30% of solutions with highest marginal contribution\n    top_indices = np.argsort(marginal_contributions)[-max(1, len(archive) // 3):]\n    selected_solutions = [archive[i] for i in top_indices]\n\n    # Randomly select one of the top solutions\n    base_sol, (base_val1, base_val2) = random.choice(selected_solutions)\n    new_solution = base_sol.copy()\n\n    # Step 2: Apply hybrid local search\n    # Strategy: Random flips with objective-driven selection and marginal contribution checks\n    for _ in range(5):  # Number of local search steps\n        # Randomly select a subset of items to flip\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n\n        for idx in flip_indices:\n            # Calculate the effect of flipping this item\n            if new_solution[idx] == 1:\n                # Item is currently included, try to exclude it\n                new_weight = np.sum(weight_lst * new_solution) - weight_lst[idx]\n                if new_weight <= capacity:\n                    # Check if excluding improves both objectives\n                    new_val1 = base_val1 - value1_lst[idx]\n                    new_val2 = base_val2 - value2_lst[idx]\n                    if (new_val1 >= base_val1 and new_val2 >= base_val2) or \\\n                       (random.random() < 0.3):  # Sometimes accept worse solutions\n                        new_solution[idx] = 0\n                        base_val1, base_val2 = new_val1, new_val2\n            else:\n                # Item is currently excluded, try to include it\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[idx]\n                if new_weight <= capacity:\n                    # Check if including improves both objectives\n                    new_val1 = base_val1 + value1_lst[idx]\n                    new_val2 = base_val2 + value2_lst[idx]\n                    if (new_val1 >= base_val1 and new_val2 >= base_val2) or \\\n                       (random.random() < 0.3):  # Sometimes accept worse solutions\n                        new_solution[idx] = 1\n                        base_val1, base_val2 = new_val1, new_val2\n\n    return new_solution\n\n",
        "score": [
            -0.33357387981151876,
            3.695551097393036
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with high marginal contribution\n    # Calculate marginal contribution for each solution in the archive\n    marginal_contributions = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        # Marginal contribution is the ratio of total value to total weight\n        marg1 = val1 / total_weight if total_weight > 0 else 0\n        marg2 = val2 / total_weight if total_weight > 0 else 0\n        marginal_contributions.append((marg1 + marg2) / 2)  # Average marginal contribution\n\n    # Select top 30% of solutions with highest marginal contribution\n    top_indices = np.argsort(marginal_contributions)[-max(1, len(archive) // 3):]\n    selected_solutions = [archive[i] for i in top_indices]\n\n    # Randomly select one of the top solutions\n    base_sol, (base_val1, base_val2) = random.choice(selected_solutions)\n    new_solution = base_sol.copy()\n\n    # Step 2: Apply hybrid local search\n    # Strategy: Random flips with objective-driven selection and marginal contribution checks\n    for _ in range(5):  # Number of local search steps\n        # Randomly select a subset of items to flip\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n\n        for idx in flip_indices:\n            # Calculate the effect of flipping this item\n            if new_solution[idx] == 1:\n                # Item is currently included, try to exclude it\n                new_weight = np.sum(weight_lst * new_solution) - weight_lst[idx]\n                if new_weight <= capacity:\n                    # Check if excluding improves both objectives\n                    new_val1 = base_val1 - value1_lst[idx]\n                    new_val2 = base_val2 - value2_lst[idx]\n                    if (new_val1 >= base_val1 and new_val2 >= base_val2) or \\\n                       (random.random() < 0.3):  # Sometimes accept worse solutions\n                        new_solution[idx] = 0\n                        base_val1, base_val2 = new_val1, new_val2\n            else:\n                # Item is currently excluded, try to include it\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[idx]\n                if new_weight <= capacity:\n                    # Check if including improves both objectives\n                    new_val1 = base_val1 + value1_lst[idx]\n                    new_val2 = base_val2 + value2_lst[idx]\n                    if (new_val1 >= base_val1 and new_val2 >= base_val2) or \\\n                       (random.random() < 0.3):  # Sometimes accept worse solutions\n                        new_solution[idx] = 1\n                        base_val1, base_val2 = new_val1, new_val2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 42,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios to identify promising items\n    combined_ratio = ratio1 + ratio2\n\n    # Identify items not in the solution\n    not_included = np.where(new_solution == 0)[0]\n\n    # Prioritize items with high combined ratio\n    if len(not_included) > 0:\n        sorted_indices = np.argsort(combined_ratio[not_included])[::-1]\n        top_items = not_included[sorted_indices[:min(5, len(sorted_indices))]]\n\n        # Try to add the top items one by one\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break\n\n    # Randomly flip some items to maintain diversity\n    if len(not_included) > 0:\n        # Randomly select a subset of items to consider flipping\n        flip_candidates = np.random.choice(not_included, size=min(3, len(not_included)), replace=False)\n        for item in flip_candidates:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Randomly remove some items to create space\n    included = np.where(new_solution == 1)[0]\n    if len(included) > 0:\n        # Randomly select a subset of items to consider removing\n        remove_candidates = np.random.choice(included, size=min(2, len(included)), replace=False)\n        for item in remove_candidates:\n            if np.random.rand() < 0.3:  # 30% chance to remove\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.33297576438104715,
            6.830101758241653
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios to identify promising items\n    combined_ratio = ratio1 + ratio2\n\n    # Identify items not in the solution\n    not_included = np.where(new_solution == 0)[0]\n\n    # Prioritize items with high combined ratio\n    if len(not_included) > 0:\n        sorted_indices = np.argsort(combined_ratio[not_included])[::-1]\n        top_items = not_included[sorted_indices[:min(5, len(sorted_indices))]]\n\n        # Try to add the top items one by one\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break\n\n    # Randomly flip some items to maintain diversity\n    if len(not_included) > 0:\n        # Randomly select a subset of items to consider flipping\n        flip_candidates = np.random.choice(not_included, size=min(3, len(not_included)), replace=False)\n        for item in flip_candidates:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Randomly remove some items to create space\n    included = np.where(new_solution == 1)[0]\n    if len(included) > 0:\n        # Randomly select a subset of items to consider removing\n        remove_candidates = np.random.choice(included, size=min(2, len(included)), replace=False)\n        for item in remove_candidates:\n            if np.random.rand() < 0.3:  # 30% chance to remove\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 43,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate crowding distance as a proxy for potential improvement\n    crowding_distances = []\n    for i in range(len(archive)):\n        left = max(0, i - 1)\n        right = min(len(archive) - 1, i + 1)\n        if left == right:\n            crowding_distances.append(float('inf'))\n        else:\n            dist = (objectives[right][0] - objectives[left][0]) + (objectives[right][1] - objectives[left][1])\n            crowding_distances.append(dist)\n\n    # Select a solution with high crowding distance (potential for improvement)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = solutions[selected_idx].copy()\n    current_obj1, current_obj2 = objectives[selected_idx]\n\n    # Calculate current total weight\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Generate a neighbor solution using a hybrid approach\n    new_solution = base_solution.copy()\n\n    # Phase 1: Random flip with value-based prioritization\n    for _ in range(min(3, len(new_solution))):  # Limit the number of flips\n        # Calculate value-to-weight ratio for each item\n        v1_w_ratio = value1_lst / (weight_lst + 1e-6)\n        v2_w_ratio = value2_lst / (weight_lst + 1e-6)\n\n        # Combine ratios with randomness\n        combined_ratio = 0.6 * v1_w_ratio + 0.4 * v2_w_ratio + 0.1 * np.random.rand(len(new_solution))\n\n        # Select items to flip based on the combined ratio\n        flip_candidates = np.argsort(combined_ratio)[-5:]  # Consider top 5 items\n        if len(flip_candidates) == 0:\n            break\n\n        flip_idx = random.choice(flip_candidates)\n\n        # Try to flip the selected item\n        if new_solution[flip_idx] == 1:\n            # Try to remove it if it doesn't violate capacity\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            # Try to add it if it doesn't violate capacity\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Phase 2: Greedy improvement for the selected item\n    # Find the item with the highest marginal gain in either objective\n    marginal_gains = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Calculate gain if we remove this item\n            gain1 = -value1_lst[i]\n            gain2 = -value2_lst[i]\n        else:\n            # Calculate gain if we add this item (if feasible)\n            if current_weight + weight_lst[i] > capacity:\n                gain1 = -float('inf')\n                gain2 = -float('inf')\n            else:\n                gain1 = value1_lst[i]\n                gain2 = value2_lst[i]\n        marginal_gains.append((gain1, gain2))\n\n    # Select the item with the highest combined marginal gain\n    combined_gains = [g1 + g2 for g1, g2 in marginal_gains]\n    best_item = np.argmax(combined_gains)\n\n    # Apply the best flip if it improves at least one objective\n    if combined_gains[best_item] > 0:\n        if new_solution[best_item] == 1:\n            new_solution[best_item] = 0\n        else:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7765335069545833,
            3.6283668279647827
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate crowding distance as a proxy for potential improvement\n    crowding_distances = []\n    for i in range(len(archive)):\n        left = max(0, i - 1)\n        right = min(len(archive) - 1, i + 1)\n        if left == right:\n            crowding_distances.append(float('inf'))\n        else:\n            dist = (objectives[right][0] - objectives[left][0]) + (objectives[right][1] - objectives[left][1])\n            crowding_distances.append(dist)\n\n    # Select a solution with high crowding distance (potential for improvement)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = solutions[selected_idx].copy()\n    current_obj1, current_obj2 = objectives[selected_idx]\n\n    # Calculate current total weight\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Generate a neighbor solution using a hybrid approach\n    new_solution = base_solution.copy()\n\n    # Phase 1: Random flip with value-based prioritization\n    for _ in range(min(3, len(new_solution))):  # Limit the number of flips\n        # Calculate value-to-weight ratio for each item\n        v1_w_ratio = value1_lst / (weight_lst + 1e-6)\n        v2_w_ratio = value2_lst / (weight_lst + 1e-6)\n\n        # Combine ratios with randomness\n        combined_ratio = 0.6 * v1_w_ratio + 0.4 * v2_w_ratio + 0.1 * np.random.rand(len(new_solution))\n\n        # Select items to flip based on the combined ratio\n        flip_candidates = np.argsort(combined_ratio)[-5:]  # Consider top 5 items\n        if len(flip_candidates) == 0:\n            break\n\n        flip_idx = random.choice(flip_candidates)\n\n        # Try to flip the selected item\n        if new_solution[flip_idx] == 1:\n            # Try to remove it if it doesn't violate capacity\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            # Try to add it if it doesn't violate capacity\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Phase 2: Greedy improvement for the selected item\n    # Find the item with the highest marginal gain in either objective\n    marginal_gains = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Calculate gain if we remove this item\n            gain1 = -value1_lst[i]\n            gain2 = -value2_lst[i]\n        else:\n            # Calculate gain if we add this item (if feasible)\n            if current_weight + weight_lst[i] > capacity:\n                gain1 = -float('inf')\n                gain2 = -float('inf')\n            else:\n                gain1 = value1_lst[i]\n                gain2 = value2_lst[i]\n        marginal_gains.append((gain1, gain2))\n\n    # Select the item with the highest combined marginal gain\n    combined_gains = [g1 + g2 for g1, g2 in marginal_gains]\n    best_item = np.argmax(combined_gains)\n\n    # Apply the best flip if it improves at least one objective\n    if combined_gains[best_item] > 0:\n        if new_solution[best_item] == 1:\n            new_solution[best_item] = 0\n        else:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 44,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    selected_solution, (current_value1, current_value2) = random.choice(archive)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    n_items = len(selected_solution)\n    if n_items < 2:\n        return new_solution  # No operation possible\n\n    # Step 1: Randomly select two items to swap\n    idx1, idx2 = random.sample(range(n_items), 2)\n\n    # Check if swapping these items keeps the solution feasible\n    total_weight = np.sum(weight_lst * new_solution)\n    weight_diff = weight_lst[idx1] - weight_lst[idx2]\n\n    if total_weight + weight_diff <= capacity:\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n    else:\n        # If swap is infeasible, try a flip operation instead\n        # Select an item to flip (include if excluded, exclude if included)\n        flip_idx = random.choice(range(n_items))\n        if new_solution[flip_idx] == 1:\n            if total_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if total_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Step 2: Additional local improvement - try to add the most valuable item not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate the ratio of the sum of both objectives to weight for each remaining item\n        value_ratio1 = value1_lst[remaining_items] / weight_lst[remaining_items]\n        value_ratio2 = value2_lst[remaining_items] / weight_lst[remaining_items]\n        combined_ratio = value_ratio1 + value_ratio2\n\n        # Select the item with the highest combined value-to-weight ratio\n        best_item_idx = remaining_items[np.argmax(combined_ratio)]\n\n        # Check if adding this item keeps the solution feasible\n        if np.sum(weight_lst * new_solution) + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.30722623399855764,
            3.7418061196804047
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    selected_solution, (current_value1, current_value2) = random.choice(archive)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    n_items = len(selected_solution)\n    if n_items < 2:\n        return new_solution  # No operation possible\n\n    # Step 1: Randomly select two items to swap\n    idx1, idx2 = random.sample(range(n_items), 2)\n\n    # Check if swapping these items keeps the solution feasible\n    total_weight = np.sum(weight_lst * new_solution)\n    weight_diff = weight_lst[idx1] - weight_lst[idx2]\n\n    if total_weight + weight_diff <= capacity:\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n    else:\n        # If swap is infeasible, try a flip operation instead\n        # Select an item to flip (include if excluded, exclude if included)\n        flip_idx = random.choice(range(n_items))\n        if new_solution[flip_idx] == 1:\n            if total_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if total_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Step 2: Additional local improvement - try to add the most valuable item not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate the ratio of the sum of both objectives to weight for each remaining item\n        value_ratio1 = value1_lst[remaining_items] / weight_lst[remaining_items]\n        value_ratio2 = value2_lst[remaining_items] / weight_lst[remaining_items]\n        combined_ratio = value_ratio1 + value_ratio2\n\n        # Select the item with the highest combined value-to-weight ratio\n        best_item_idx = remaining_items[np.argmax(combined_ratio)]\n\n        # Check if adding this item keeps the solution feasible\n        if np.sum(weight_lst * new_solution) + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 45,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards solutions that are not too similar to others\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Perform a random swap (flip a random bit)\n    num_items = len(new_solution)\n    if num_items == 0:\n        return new_solution\n\n    # Randomly select an item to flip\n    item_to_flip = random.randint(0, num_items - 1)\n\n    # Check if flipping this item keeps the solution feasible\n    if new_solution[item_to_flip] == 1:\n        # If the item is included, check if removing it keeps the solution feasible\n        if np.sum(weight_lst * new_solution) - weight_lst[item_to_flip] <= capacity:\n            new_solution[item_to_flip] = 0\n        else:\n            # If not, try to find another item to swap out\n            candidates = np.where((new_solution == 1) & (weight_lst <= weight_lst[item_to_flip]))[0]\n            if len(candidates) > 0:\n                item_to_remove = random.choice(candidates)\n                new_solution[item_to_remove] = 0\n                if np.sum(weight_lst * new_solution) + weight_lst[item_to_flip] <= capacity:\n                    new_solution[item_to_flip] = 1\n    else:\n        # If the item is excluded, check if adding it keeps the solution feasible\n        if np.sum(weight_lst * new_solution) + weight_lst[item_to_flip] <= capacity:\n            new_solution[item_to_flip] = 1\n        else:\n            # If not, try to find another item to swap in\n            candidates = np.where((new_solution == 0) & (weight_lst <= weight_lst[item_to_flip]))[0]\n            if len(candidates) > 0:\n                item_to_add = random.choice(candidates)\n                new_solution[item_to_add] = 1\n                if np.sum(weight_lst * new_solution) - weight_lst[item_to_flip] <= capacity:\n                    new_solution[item_to_flip] = 0\n\n    # Perform a greedy improvement step to enhance the solution\n    # Evaluate the current solution's objectives\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Try to improve by adding items that increase both objectives\n    for i in range(num_items):\n        if new_solution[i] == 0 and (np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity):\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n            # If both objectives improve, accept the change\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_value1, current_value2 = new_value1, new_value2\n\n    # Try to improve by removing items that don't contribute to both objectives\n    for i in range(num_items):\n        if new_solution[i] == 1:\n            # Check if removing this item improves at least one objective\n            new_value1 = current_value1 - value1_lst[i]\n            new_value2 = current_value2 - value2_lst[i]\n            if (new_value1 >= current_value1 and new_value2 > current_value2) or (new_value1 > current_value1 and new_value2 >= current_value2):\n                new_solution[i] = 0\n                current_value1, current_value2 = new_value1, new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.297336090274016,
            6.725038319826126
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards solutions that are not too similar to others\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Perform a random swap (flip a random bit)\n    num_items = len(new_solution)\n    if num_items == 0:\n        return new_solution\n\n    # Randomly select an item to flip\n    item_to_flip = random.randint(0, num_items - 1)\n\n    # Check if flipping this item keeps the solution feasible\n    if new_solution[item_to_flip] == 1:\n        # If the item is included, check if removing it keeps the solution feasible\n        if np.sum(weight_lst * new_solution) - weight_lst[item_to_flip] <= capacity:\n            new_solution[item_to_flip] = 0\n        else:\n            # If not, try to find another item to swap out\n            candidates = np.where((new_solution == 1) & (weight_lst <= weight_lst[item_to_flip]))[0]\n            if len(candidates) > 0:\n                item_to_remove = random.choice(candidates)\n                new_solution[item_to_remove] = 0\n                if np.sum(weight_lst * new_solution) + weight_lst[item_to_flip] <= capacity:\n                    new_solution[item_to_flip] = 1\n    else:\n        # If the item is excluded, check if adding it keeps the solution feasible\n        if np.sum(weight_lst * new_solution) + weight_lst[item_to_flip] <= capacity:\n            new_solution[item_to_flip] = 1\n        else:\n            # If not, try to find another item to swap in\n            candidates = np.where((new_solution == 0) & (weight_lst <= weight_lst[item_to_flip]))[0]\n            if len(candidates) > 0:\n                item_to_add = random.choice(candidates)\n                new_solution[item_to_add] = 1\n                if np.sum(weight_lst * new_solution) - weight_lst[item_to_flip] <= capacity:\n                    new_solution[item_to_flip] = 0\n\n    # Perform a greedy improvement step to enhance the solution\n    # Evaluate the current solution's objectives\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Try to improve by adding items that increase both objectives\n    for i in range(num_items):\n        if new_solution[i] == 0 and (np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity):\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n            # If both objectives improve, accept the change\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_value1, current_value2 = new_value1, new_value2\n\n    # Try to improve by removing items that don't contribute to both objectives\n    for i in range(num_items):\n        if new_solution[i] == 1:\n            # Check if removing this item improves at least one objective\n            new_value1 = current_value1 - value1_lst[i]\n            new_value2 = current_value2 - value2_lst[i]\n            if (new_value1 >= current_value1 and new_value2 > current_value2) or (new_value1 > current_value1 and new_value2 >= current_value2):\n                new_solution[i] = 0\n                current_value1, current_value2 = new_value1, new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 46,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Sort archive by the sum of objectives (can be replaced with other criteria)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n\n    # Select top 20% of solutions for further consideration\n    top_k = max(1, int(len(archive_sorted) * 0.2))\n    candidates = archive_sorted[:top_k]\n\n    # Randomly select a base solution from the top candidates\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with probability based on their value)\n    num_items = len(new_solution)\n    flip_prob = (value1_lst + value2_lst) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-8)  # Avoid division by zero\n\n    # Determine how many items to flip (between 1 and 10% of items)\n    max_flips = max(1, int(num_items * 0.1))\n    num_flips = random.randint(1, max_flips)\n\n    # Select items to flip with probability proportional to their total value\n    flip_candidates = np.where(flip_prob > np.random.rand(num_items))[0]\n    if len(flip_candidates) < num_flips:\n        flip_indices = np.random.choice(num_items, num_flips, replace=False)\n    else:\n        flip_indices = np.random.choice(flip_candidates, num_flips, replace=False)\n\n    # Flip the selected items and ensure feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is currently included, remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is currently excluded, add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3659921358127065,
            1.048678457736969
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Sort archive by the sum of objectives (can be replaced with other criteria)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n\n    # Select top 20% of solutions for further consideration\n    top_k = max(1, int(len(archive_sorted) * 0.2))\n    candidates = archive_sorted[:top_k]\n\n    # Randomly select a base solution from the top candidates\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with probability based on their value)\n    num_items = len(new_solution)\n    flip_prob = (value1_lst + value2_lst) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-8)  # Avoid division by zero\n\n    # Determine how many items to flip (between 1 and 10% of items)\n    max_flips = max(1, int(num_items * 0.1))\n    num_flips = random.randint(1, max_flips)\n\n    # Select items to flip with probability proportional to their total value\n    flip_candidates = np.where(flip_prob > np.random.rand(num_items))[0]\n    if len(flip_candidates) < num_flips:\n        flip_indices = np.random.choice(num_items, num_flips, replace=False)\n    else:\n        flip_indices = np.random.choice(flip_candidates, num_flips, replace=False)\n\n    # Flip the selected items and ensure feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is currently included, remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is currently excluded, add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 47,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select promising solutions (top 30% by objective values)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    candidate_count = max(1, int(0.3 * len(sorted_archive)))\n    candidates = sorted_archive[:candidate_count]\n\n    # Intelligent random selection based on potential improvement\n    weights = [1.0 / (i + 1) for i in range(len(candidates))]  # Higher chance for better solutions\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution, _ = candidates[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search operator\n    # First, try to add items that improve both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Get items not in the solution\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each excluded item\n    improvements = []\n    for item in excluded_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Calculate relative improvement potential\n            improvement1 = value1_lst[item] / (weight_lst[item] + 1e-6)\n            improvement2 = value2_lst[item] / (weight_lst[item] + 1e-6)\n            total_improvement = improvement1 + improvement2\n            improvements.append((total_improvement, item))\n\n    if improvements:\n        # Sort by improvement potential\n        improvements.sort(reverse=True, key=lambda x: x[0])\n        best_items = [item for _, item in improvements[:min(3, len(improvements))]]\n\n        # Randomly select one of the top items to add\n        if best_items:\n            selected_item = random.choice(best_items)\n            new_solution[selected_item] = 1\n\n    # Then, try to remove items that don't contribute much to either objective\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate contribution of each included item\n        contributions = []\n        for item in included_items:\n            contribution1 = value1_lst[item] / (weight_lst[item] + 1e-6)\n            contribution2 = value2_lst[item] / (weight_lst[item] + 1e-6)\n            total_contribution = contribution1 + contribution2\n            contributions.append((total_contribution, item))\n\n        # Sort by contribution (lowest first)\n        contributions.sort(key=lambda x: x[0])\n        worst_items = [item for _, item in contributions[:min(2, len(contributions))]]\n\n        # Randomly select one of the least contributing items to remove\n        if worst_items:\n            selected_item = random.choice(worst_items)\n            new_solution[selected_item] = 0\n\n    # Ensure solution remains feasible\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        included_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(included_items) > 0:\n            item_to_remove = random.choice(included_items)\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n            included_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.8361292310124402,
            1.0512631237506866
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select promising solutions (top 30% by objective values)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    candidate_count = max(1, int(0.3 * len(sorted_archive)))\n    candidates = sorted_archive[:candidate_count]\n\n    # Intelligent random selection based on potential improvement\n    weights = [1.0 / (i + 1) for i in range(len(candidates))]  # Higher chance for better solutions\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution, _ = candidates[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search operator\n    # First, try to add items that improve both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Get items not in the solution\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate potential improvements for each excluded item\n    improvements = []\n    for item in excluded_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Calculate relative improvement potential\n            improvement1 = value1_lst[item] / (weight_lst[item] + 1e-6)\n            improvement2 = value2_lst[item] / (weight_lst[item] + 1e-6)\n            total_improvement = improvement1 + improvement2\n            improvements.append((total_improvement, item))\n\n    if improvements:\n        # Sort by improvement potential\n        improvements.sort(reverse=True, key=lambda x: x[0])\n        best_items = [item for _, item in improvements[:min(3, len(improvements))]]\n\n        # Randomly select one of the top items to add\n        if best_items:\n            selected_item = random.choice(best_items)\n            new_solution[selected_item] = 1\n\n    # Then, try to remove items that don't contribute much to either objective\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate contribution of each included item\n        contributions = []\n        for item in included_items:\n            contribution1 = value1_lst[item] / (weight_lst[item] + 1e-6)\n            contribution2 = value2_lst[item] / (weight_lst[item] + 1e-6)\n            total_contribution = contribution1 + contribution2\n            contributions.append((total_contribution, item))\n\n        # Sort by contribution (lowest first)\n        contributions.sort(key=lambda x: x[0])\n        worst_items = [item for _, item in contributions[:min(2, len(contributions))]]\n\n        # Randomly select one of the least contributing items to remove\n        if worst_items:\n            selected_item = random.choice(worst_items)\n            new_solution[selected_item] = 0\n\n    # Ensure solution remains feasible\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        included_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(included_items) > 0:\n            item_to_remove = random.choice(included_items)\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n            included_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 48,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.argmax([np.sum(sol[0] * weight_lst) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Swap items based on value density and random perturbations\n    n_items = len(base_solution)\n    if n_items <= 1:\n        return new_solution\n\n    # Calculate value densities for each objective\n    value_density1 = value1_lst / (weight_lst + 1e-6)\n    value_density2 = value2_lst / (weight_lst + 1e-6)\n\n    # Randomly select a candidate item to swap or perturb\n    candidate_idx = np.random.choice(n_items)\n\n    # Apply a hybrid strategy: swap with a high-value item or flip based on density\n    if np.random.random() < 0.5:\n        # Swap with an item of similar value density in the other objective\n        target_idx = np.argmax(value_density2 if base_solution[candidate_idx] else value_density1)\n        if target_idx != candidate_idx:\n            new_solution[candidate_idx], new_solution[target_idx] = new_solution[target_idx], new_solution[candidate_idx]\n    else:\n        # Flip the candidate item if it improves the solution\n        new_solution[candidate_idx] = 1 - new_solution[candidate_idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8857970117623628,
            1.7904706001281738
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.argmax([np.sum(sol[0] * weight_lst) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Swap items based on value density and random perturbations\n    n_items = len(base_solution)\n    if n_items <= 1:\n        return new_solution\n\n    # Calculate value densities for each objective\n    value_density1 = value1_lst / (weight_lst + 1e-6)\n    value_density2 = value2_lst / (weight_lst + 1e-6)\n\n    # Randomly select a candidate item to swap or perturb\n    candidate_idx = np.random.choice(n_items)\n\n    # Apply a hybrid strategy: swap with a high-value item or flip based on density\n    if np.random.random() < 0.5:\n        # Swap with an item of similar value density in the other objective\n        target_idx = np.argmax(value_density2 if base_solution[candidate_idx] else value_density1)\n        if target_idx != candidate_idx:\n            new_solution[candidate_idx], new_solution[target_idx] = new_solution[target_idx], new_solution[candidate_idx]\n    else:\n        # Flip the candidate item if it improves the solution\n        new_solution[candidate_idx] = 1 - new_solution[candidate_idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 49,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be swapped or toggled\n    candidate_items = np.where(new_solution == 1)[0]\n    non_selected_items = np.where(new_solution == 0)[0]\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for removal\n    if len(candidate_items) > 0:\n        num_to_remove = min(3, len(candidate_items))  # Limit to avoid excessive changes\n        items_to_remove = np.random.choice(candidate_items, size=num_to_remove, replace=False)\n        new_solution[items_to_remove] = 0\n\n    # 2. Add items that improve both objectives, prioritizing value1 and value2\n    for item in non_selected_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[item] > 0) or (value2_lst[item] > 0):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # 3. Randomly toggle one item to escape local optima\n    if len(non_selected_items) > 0:\n        item_to_toggle = np.random.choice(non_selected_items)\n        if current_weight + weight_lst[item_to_toggle] <= capacity:\n            new_solution[item_to_toggle] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9415817991464379,
            1.0063407719135284
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be swapped or toggled\n    candidate_items = np.where(new_solution == 1)[0]\n    non_selected_items = np.where(new_solution == 0)[0]\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for removal\n    if len(candidate_items) > 0:\n        num_to_remove = min(3, len(candidate_items))  # Limit to avoid excessive changes\n        items_to_remove = np.random.choice(candidate_items, size=num_to_remove, replace=False)\n        new_solution[items_to_remove] = 0\n\n    # 2. Add items that improve both objectives, prioritizing value1 and value2\n    for item in non_selected_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[item] > 0) or (value2_lst[item] > 0):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # 3. Randomly toggle one item to escape local optima\n    if len(non_selected_items) > 0:\n        item_to_toggle = np.random.choice(non_selected_items)\n        if current_weight + weight_lst[item_to_toggle] <= capacity:\n            new_solution[item_to_toggle] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 49,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be swapped or toggled\n    candidate_items = np.where(new_solution == 1)[0]\n    non_selected_items = np.where(new_solution == 0)[0]\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for removal\n    if len(candidate_items) > 0:\n        num_to_remove = min(3, len(candidate_items))  # Limit to avoid excessive changes\n        items_to_remove = np.random.choice(candidate_items, size=num_to_remove, replace=False)\n        new_solution[items_to_remove] = 0\n\n    # 2. Add items that improve both objectives, prioritizing value1 and value2\n    for item in non_selected_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[item] > 0) or (value2_lst[item] > 0):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # 3. Randomly toggle one item to escape local optima\n    if len(non_selected_items) > 0:\n        item_to_toggle = np.random.choice(non_selected_items)\n        if current_weight + weight_lst[item_to_toggle] <= capacity:\n            new_solution[item_to_toggle] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9415817991464379,
            1.0063407719135284
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be swapped or toggled\n    candidate_items = np.where(new_solution == 1)[0]\n    non_selected_items = np.where(new_solution == 0)[0]\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for removal\n    if len(candidate_items) > 0:\n        num_to_remove = min(3, len(candidate_items))  # Limit to avoid excessive changes\n        items_to_remove = np.random.choice(candidate_items, size=num_to_remove, replace=False)\n        new_solution[items_to_remove] = 0\n\n    # 2. Add items that improve both objectives, prioritizing value1 and value2\n    for item in non_selected_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[item] > 0) or (value2_lst[item] > 0):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # 3. Randomly toggle one item to escape local optima\n    if len(non_selected_items) > 0:\n        item_to_toggle = np.random.choice(non_selected_items)\n        if current_weight + weight_lst[item_to_toggle] <= capacity:\n            new_solution[item_to_toggle] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 50,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with a bias towards solutions that are not fully packed\n    solution, _ = random.choice(archive)\n    new_solution = solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine the number of items to swap (between 1 and min(10, number of items))\n    num_swaps = min(10, len(new_solution))\n    swap_indices = random.sample(range(len(new_solution)), num_swaps)\n\n    # Perform the swaps\n    for idx in swap_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Apply a greedy improvement step to enhance the solution\n    # Iterate over all items and consider adding or removing them if it improves the solution\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Check if removing this item improves both objectives\n            if (current_weight - weight_lst[idx] <= capacity and\n                np.sum(value1_lst * (new_solution - np.eye(len(new_solution), dtype=int)[idx])) >= current_value1 and\n                np.sum(value2_lst * (new_solution - np.eye(len(new_solution), dtype=int)[idx])) >= current_value2):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Check if adding this item improves both objectives\n            if (current_weight + weight_lst[idx] <= capacity and\n                current_value1 + value1_lst[idx] >= current_value1 and\n                current_value2 + value2_lst[idx] >= current_value2):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.42711688324198327,
            9.719111502170563
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with a bias towards solutions that are not fully packed\n    solution, _ = random.choice(archive)\n    new_solution = solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine the number of items to swap (between 1 and min(10, number of items))\n    num_swaps = min(10, len(new_solution))\n    swap_indices = random.sample(range(len(new_solution)), num_swaps)\n\n    # Perform the swaps\n    for idx in swap_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Apply a greedy improvement step to enhance the solution\n    # Iterate over all items and consider adding or removing them if it improves the solution\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Check if removing this item improves both objectives\n            if (current_weight - weight_lst[idx] <= capacity and\n                np.sum(value1_lst * (new_solution - np.eye(len(new_solution), dtype=int)[idx])) >= current_value1 and\n                np.sum(value2_lst * (new_solution - np.eye(len(new_solution), dtype=int)[idx])) >= current_value2):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Check if adding this item improves both objectives\n            if (current_weight + weight_lst[idx] <= capacity and\n                current_value1 + value1_lst[idx] >= current_value1 and\n                current_value2 + value2_lst[idx] >= current_value2):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 51,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on its objective values (prioritize solutions with higher combined values)\n    archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: value-based swap with randomness\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly select a subset of items to consider for swapping\n    swap_candidates = random.sample(range(n_items), min(10, n_items))\n\n    for i in swap_candidates:\n        if base_solution[i] == 1:\n            # If item is included, try to exclude it if it's not critical\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            # If item is excluded, try to include it if it fits\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Value-based swap to improve both objectives\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal contributions for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Sort items by combined marginal value (descending)\n    sorted_items = np.argsort(-combined_marginal)\n\n    for i in sorted_items:\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.675519583489937,
            1.6478182673454285
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on its objective values (prioritize solutions with higher combined values)\n    archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: value-based swap with randomness\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly select a subset of items to consider for swapping\n    swap_candidates = random.sample(range(n_items), min(10, n_items))\n\n    for i in swap_candidates:\n        if base_solution[i] == 1:\n            # If item is included, try to exclude it if it's not critical\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            # If item is excluded, try to include it if it fits\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Value-based swap to improve both objectives\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal contributions for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Sort items by combined marginal value (descending)\n    sorted_items = np.argsort(-combined_marginal)\n\n    for i in sorted_items:\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 52,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability proportional to its potential for improvement\n    # Potential is estimated by the ratio of non-dominated neighbors (simplified proxy)\n    potentials = []\n    for sol, _ in archive:\n        # Count how many items could be flipped without violating capacity\n        current_weight = np.sum(sol * weight_lst)\n        flip_candidates = []\n        for i in range(len(sol)):\n            if sol[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    flip_candidates.append(i)\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    flip_candidates.append(i)\n        potentials.append(len(flip_candidates))\n\n    if not potentials:\n        return archive[0][0].copy()\n\n    # Select solution with highest potential for improvement\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random swaps with objective-aware flips\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # First, perform random swaps to escape local optima\n    n_swaps = min(3, len(new_solution) // 2)\n    for _ in range(n_swaps):\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check if swap is feasible\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                if current_weight + weight_lst[i] - weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight + weight_lst[i] - weight_lst[j]\n\n    # Then perform objective-aware flips\n    n_flips = min(5, len(new_solution))\n    for _ in range(n_flips):\n        # Calculate marginal contributions for each objective\n        marginal1 = value1_lst - (2 * new_solution - 1) * value1_lst\n        marginal2 = value2_lst - (2 * new_solution - 1) * value2_lst\n\n        # Normalize to combine objectives\n        norm_marginal = marginal1 / (np.max(marginal1) + 1e-6) + marginal2 / (np.max(marginal2) + 1e-6)\n\n        # Select items to flip with highest combined marginal benefit\n        candidate_items = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    candidate_items.append((i, norm_marginal[i]))\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    candidate_items.append((i, norm_marginal[i]))\n\n        if candidate_items:\n            candidate_items.sort(key=lambda x: -x[1])\n            best_item = candidate_items[0][0]\n            new_solution[best_item] = 1 - new_solution[best_item]\n            current_weight += (2 * new_solution[best_item] - 1) * weight_lst[best_item]\n\n    return new_solution\n\n",
        "score": [
            -0.33303050710731696,
            6.682441771030426
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability proportional to its potential for improvement\n    # Potential is estimated by the ratio of non-dominated neighbors (simplified proxy)\n    potentials = []\n    for sol, _ in archive:\n        # Count how many items could be flipped without violating capacity\n        current_weight = np.sum(sol * weight_lst)\n        flip_candidates = []\n        for i in range(len(sol)):\n            if sol[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    flip_candidates.append(i)\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    flip_candidates.append(i)\n        potentials.append(len(flip_candidates))\n\n    if not potentials:\n        return archive[0][0].copy()\n\n    # Select solution with highest potential for improvement\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random swaps with objective-aware flips\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # First, perform random swaps to escape local optima\n    n_swaps = min(3, len(new_solution) // 2)\n    for _ in range(n_swaps):\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check if swap is feasible\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                if current_weight + weight_lst[i] - weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight + weight_lst[i] - weight_lst[j]\n\n    # Then perform objective-aware flips\n    n_flips = min(5, len(new_solution))\n    for _ in range(n_flips):\n        # Calculate marginal contributions for each objective\n        marginal1 = value1_lst - (2 * new_solution - 1) * value1_lst\n        marginal2 = value2_lst - (2 * new_solution - 1) * value2_lst\n\n        # Normalize to combine objectives\n        norm_marginal = marginal1 / (np.max(marginal1) + 1e-6) + marginal2 / (np.max(marginal2) + 1e-6)\n\n        # Select items to flip with highest combined marginal benefit\n        candidate_items = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    candidate_items.append((i, norm_marginal[i]))\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    candidate_items.append((i, norm_marginal[i]))\n\n        if candidate_items:\n            candidate_items.sort(key=lambda x: -x[1])\n            best_item = candidate_items[0][0]\n            new_solution[best_item] = 1 - new_solution[best_item]\n            current_weight += (2 * new_solution[best_item] - 1) * weight_lst[best_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 53,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability proportional to its objective values (normalized)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = objectives / (np.max(objectives, axis=0) + 1e-10)  # Avoid division by zero\n    combined_scores = normalized_objectives[:, 0] + normalized_objectives[:, 1]\n    probabilities = combined_scores / np.sum(combined_scores)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (exploration)\n    # 2. Apply value-weighted flips to the remaining items (exploitation)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # For each flip candidate, decide whether to flip based on value and weight impact\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, consider removing it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not included, consider adding it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional exploitation: flip items with highest value-to-weight ratio\n    if random.random() < 0.5:  # 50% chance to apply this step\n        value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(value_ratio)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3130150361783619,
            1.625151515007019
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability proportional to its objective values (normalized)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = objectives / (np.max(objectives, axis=0) + 1e-10)  # Avoid division by zero\n    combined_scores = normalized_objectives[:, 0] + normalized_objectives[:, 1]\n    probabilities = combined_scores / np.sum(combined_scores)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (exploration)\n    # 2. Apply value-weighted flips to the remaining items (exploitation)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # For each flip candidate, decide whether to flip based on value and weight impact\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, consider removing it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not included, consider adding it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional exploitation: flip items with highest value-to-weight ratio\n    if random.random() < 0.5:  # 50% chance to apply this step\n        value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(value_ratio)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 54,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with high potential for improvement\n    # Here, we use a simple strategy: select a solution with high combined value or low weight utilization\n    base_solution, _ = max(archive, key=lambda x: sum(x[0] * value1_lst) + sum(x[0] * value2_lst) - 0.5 * sum(x[0] * weight_lst))\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their marginal gains)\n    # 2. Apply a greedy improvement step for the most promising flips\n\n    # Step 1: Random flip with marginal gain consideration\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to consider flipping each item\n            if new_solution[i] == 1:\n                # Potential to remove\n                if current_weight - weight_lst[i] <= capacity:\n                    # Accept removal if it doesn't violate capacity\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Potential to add\n                if current_weight + weight_lst[i] <= capacity:\n                    # Calculate marginal gains for both objectives\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n\n                    # Accept addition if it improves at least one objective\n                    if marginal1 > 0 or marginal2 > 0:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Step 2: Greedy improvement for the most promising flips\n    # Calculate marginal gains for all possible flips\n    marginal_gains = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Marginal gain if removed (negative)\n            gain1 = -value1_lst[i]\n            gain2 = -value2_lst[i]\n            weight_change = -weight_lst[i]\n        else:\n            # Marginal gain if added (positive)\n            gain1 = value1_lst[i]\n            gain2 = value2_lst[i]\n            weight_change = weight_lst[i]\n\n        # Only consider flips that maintain feasibility\n        if current_weight + weight_change <= capacity:\n            marginal_gains.append((i, gain1, gain2, weight_change))\n\n    # Sort by combined marginal gain (normalized)\n    marginal_gains.sort(key=lambda x: (x[1] + x[2]) / (abs(x[1]) + abs(x[2]) + 1e-6), reverse=True)\n\n    # Apply the top 2 flips (if they exist)\n    for i, gain1, gain2, weight_change in marginal_gains[:2]:\n        new_solution[i] = 1 - new_solution[i]\n        current_weight += weight_change\n\n    return new_solution\n\n",
        "score": [
            -0.40691895480359513,
            4.468956559896469
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with high potential for improvement\n    # Here, we use a simple strategy: select a solution with high combined value or low weight utilization\n    base_solution, _ = max(archive, key=lambda x: sum(x[0] * value1_lst) + sum(x[0] * value2_lst) - 0.5 * sum(x[0] * weight_lst))\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their marginal gains)\n    # 2. Apply a greedy improvement step for the most promising flips\n\n    # Step 1: Random flip with marginal gain consideration\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to consider flipping each item\n            if new_solution[i] == 1:\n                # Potential to remove\n                if current_weight - weight_lst[i] <= capacity:\n                    # Accept removal if it doesn't violate capacity\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Potential to add\n                if current_weight + weight_lst[i] <= capacity:\n                    # Calculate marginal gains for both objectives\n                    marginal1 = value1_lst[i]\n                    marginal2 = value2_lst[i]\n\n                    # Accept addition if it improves at least one objective\n                    if marginal1 > 0 or marginal2 > 0:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Step 2: Greedy improvement for the most promising flips\n    # Calculate marginal gains for all possible flips\n    marginal_gains = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Marginal gain if removed (negative)\n            gain1 = -value1_lst[i]\n            gain2 = -value2_lst[i]\n            weight_change = -weight_lst[i]\n        else:\n            # Marginal gain if added (positive)\n            gain1 = value1_lst[i]\n            gain2 = value2_lst[i]\n            weight_change = weight_lst[i]\n\n        # Only consider flips that maintain feasibility\n        if current_weight + weight_change <= capacity:\n            marginal_gains.append((i, gain1, gain2, weight_change))\n\n    # Sort by combined marginal gain (normalized)\n    marginal_gains.sort(key=lambda x: (x[1] + x[2]) / (abs(x[1]) + abs(x[2]) + 1e-6), reverse=True)\n\n    # Apply the top 2 flips (if they exist)\n    for i, gain1, gain2, weight_change in marginal_gains[:2]:\n        new_solution[i] = 1 - new_solution[i]\n        current_weight += weight_change\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 55,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on a combination of objective values and solution density\n    selected_idx = np.argmax([(obj1 + obj2) * (np.sum(sol) / len(sol)) for sol, (obj1, obj2) in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation - flip a small number of random items\n    num_flips = max(1, int(0.1 * len(base_solution)))  # Flip 10% of items (minimum 1)\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 0:\n            # Try to add the item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        else:\n            # Remove the item\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    available_indices = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n    if len(available_indices) > 0:\n        # Calculate the combined improvement potential (normalized)\n        improvement_potential = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n        best_candidate = available_indices[np.argmax(improvement_potential[available_indices])]\n\n        # Add the best candidate if it fits\n        if current_weight + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.32027702017601134,
            1.0349768102169037
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on a combination of objective values and solution density\n    selected_idx = np.argmax([(obj1 + obj2) * (np.sum(sol) / len(sol)) for sol, (obj1, obj2) in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation - flip a small number of random items\n    num_flips = max(1, int(0.1 * len(base_solution)))  # Flip 10% of items (minimum 1)\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 0:\n            # Try to add the item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        else:\n            # Remove the item\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    available_indices = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n    if len(available_indices) > 0:\n        # Calculate the combined improvement potential (normalized)\n        improvement_potential = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n        best_candidate = available_indices[np.argmax(improvement_potential[available_indices])]\n\n        # Add the best candidate if it fits\n        if current_weight + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 56,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising base solution with a bias towards high-value items\n    # Sort solutions by the sum of their normalized objectives\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst) + 1e-6), reverse=True)\n    # Select top 30% of solutions with some randomness\n    top_k = max(1, int(0.3 * len(archive_sorted)))\n    selected_solutions = random.sample(archive_sorted[:top_k], k=min(3, top_k))\n    base_solution, _ = random.choice(selected_solutions)\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2.1: Randomly select a subset of items to consider for flipping\n    n_items = len(weight_lst)\n    n_flips = min(3, n_items)  # Number of items to potentially flip\n    flip_indices = random.sample(range(n_items), n_flips)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Consider removing the item if it's in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Consider adding the item if it's not in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                # Add with probability based on value density (value/weight)\n                value_density1 = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n                value_density2 = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n                combined_density = value_density1 + value_density2\n                if random.random() < combined_density / (np.mean(value1_lst + value2_lst) / np.mean(weight_lst) + 1e-6):\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 2.2: Perform a value-based local improvement\n    # Identify items that could improve either objective when added\n    for idx in range(n_items):\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item would improve either objective\n            current_value1 = np.sum(value1_lst[new_solution == 1])\n            current_value2 = np.sum(value2_lst[new_solution == 1])\n            if (value1_lst[idx] > 0 and value1_lst[idx] > np.mean(value1_lst[new_solution == 1])) or \\\n               (value2_lst[idx] > 0 and value2_lst[idx] > np.mean(value2_lst[new_solution == 1])):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3067141341009033,
            8.677921772003174
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising base solution with a bias towards high-value items\n    # Sort solutions by the sum of their normalized objectives\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst) + 1e-6), reverse=True)\n    # Select top 30% of solutions with some randomness\n    top_k = max(1, int(0.3 * len(archive_sorted)))\n    selected_solutions = random.sample(archive_sorted[:top_k], k=min(3, top_k))\n    base_solution, _ = random.choice(selected_solutions)\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2.1: Randomly select a subset of items to consider for flipping\n    n_items = len(weight_lst)\n    n_flips = min(3, n_items)  # Number of items to potentially flip\n    flip_indices = random.sample(range(n_items), n_flips)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Consider removing the item if it's in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Consider adding the item if it's not in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                # Add with probability based on value density (value/weight)\n                value_density1 = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n                value_density2 = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n                combined_density = value_density1 + value_density2\n                if random.random() < combined_density / (np.mean(value1_lst + value2_lst) / np.mean(weight_lst) + 1e-6):\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Step 2.2: Perform a value-based local improvement\n    # Identify items that could improve either objective when added\n    for idx in range(n_items):\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item would improve either objective\n            current_value1 = np.sum(value1_lst[new_solution == 1])\n            current_value2 = np.sum(value2_lst[new_solution == 1])\n            if (value1_lst[idx] > 0 and value1_lst[idx] > np.mean(value1_lst[new_solution == 1])) or \\\n               (value2_lst[idx] > 0 and value2_lst[idx] > np.mean(value2_lst[new_solution == 1])):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 57,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest sum of normalized objectives to prioritize diverse exploration\n    normalized_archive = []\n    max_value1 = max(obj[0] for _, obj in archive) if archive else 1.0\n    max_value2 = max(obj[1] for _, obj in archive) if archive else 1.0\n\n    for sol, obj in archive:\n        normalized_obj = (obj[0] / max_value1 if max_value1 > 0 else 0,\n                          obj[1] / max_value2 if max_value2 > 0 else 0)\n        normalized_archive.append((sol, normalized_obj))\n\n    # Sort by the sum of normalized objectives (prioritize solutions with higher combined values)\n    normalized_archive.sort(key=lambda x: sum(x[1]), reverse=True)\n\n    # Select the top 3 solutions and choose one randomly for exploration\n    top_solutions = [sol for sol, _ in normalized_archive[:min(3, len(normalized_archive))]]\n    base_solution = random.choice(top_solutions).copy()\n\n    # Hybrid local search: flip a random subset of items (1-3 items) and perform a greedy repair if needed\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), random.randint(1, min(3, n_items)))\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedy repair: remove items with the lowest ratio of (sum of normalized values) / weight until feasible\n        while total_weight > capacity:\n            # Calculate the ratio of normalized values to weight for each included item\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n\n            ratios = []\n            for idx in included_items:\n                normalized_value = (value1_lst[idx] / max_value1 + value2_lst[idx] / max_value2) / 2\n                ratio = normalized_value / weight_lst[idx] if weight_lst[idx] > 0 else float('inf')\n                ratios.append((idx, ratio))\n\n            # Remove the item with the smallest ratio\n            ratios.sort(key=lambda x: x[1])\n            remove_idx = ratios[0][0]\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.31079930130085476,
            3.2147114872932434
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest sum of normalized objectives to prioritize diverse exploration\n    normalized_archive = []\n    max_value1 = max(obj[0] for _, obj in archive) if archive else 1.0\n    max_value2 = max(obj[1] for _, obj in archive) if archive else 1.0\n\n    for sol, obj in archive:\n        normalized_obj = (obj[0] / max_value1 if max_value1 > 0 else 0,\n                          obj[1] / max_value2 if max_value2 > 0 else 0)\n        normalized_archive.append((sol, normalized_obj))\n\n    # Sort by the sum of normalized objectives (prioritize solutions with higher combined values)\n    normalized_archive.sort(key=lambda x: sum(x[1]), reverse=True)\n\n    # Select the top 3 solutions and choose one randomly for exploration\n    top_solutions = [sol for sol, _ in normalized_archive[:min(3, len(normalized_archive))]]\n    base_solution = random.choice(top_solutions).copy()\n\n    # Hybrid local search: flip a random subset of items (1-3 items) and perform a greedy repair if needed\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), random.randint(1, min(3, n_items)))\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedy repair: remove items with the lowest ratio of (sum of normalized values) / weight until feasible\n        while total_weight > capacity:\n            # Calculate the ratio of normalized values to weight for each included item\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n\n            ratios = []\n            for idx in included_items:\n                normalized_value = (value1_lst[idx] / max_value1 + value2_lst[idx] / max_value2) / 2\n                ratio = normalized_value / weight_lst[idx] if weight_lst[idx] > 0 else float('inf')\n                ratios.append((idx, ratio))\n\n            # Remove the item with the smallest ratio\n            ratios.sort(key=lambda x: x[1])\n            remove_idx = ratios[0][0]\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 58,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with higher value diversity\n    if len(archive) > 1:\n        # Calculate diversity scores (difference between objectives)\n        diversity_scores = [abs(obj[0] - obj[1]) for _, obj in archive]\n        total_diversity = sum(diversity_scores)\n        probabilities = [score / total_diversity for score in diversity_scores]\n        selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps + greedy improvement\n    n_items = len(base_solution)\n    if n_items == 0:\n        return new_solution\n\n    # Random swap phase (exploration)\n    swap_attempts = min(5, n_items // 2)  # Limit swap attempts\n    for _ in range(swap_attempts):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Check feasibility\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]  # Revert if infeasible\n\n    # Greedy improvement phase (exploitation)\n    current_weight = np.dot(new_solution, weight_lst)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n\n            if temp_weight <= capacity:\n                # Check if removal improves both objectives\n                delta_v1 = -value1_lst[i]\n                delta_v2 = -value2_lst[i]\n\n                # If both objectives improve, keep the change\n                if delta_v1 > 0 and delta_v2 > 0:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n\n            if temp_weight <= capacity:\n                # Check if addition improves at least one objective\n                delta_v1 = value1_lst[i]\n                delta_v2 = value2_lst[i]\n\n                # If either objective improves, keep the change\n                if delta_v1 > 0 or delta_v2 > 0:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3499578181164494,
            4.709136664867401
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with higher value diversity\n    if len(archive) > 1:\n        # Calculate diversity scores (difference between objectives)\n        diversity_scores = [abs(obj[0] - obj[1]) for _, obj in archive]\n        total_diversity = sum(diversity_scores)\n        probabilities = [score / total_diversity for score in diversity_scores]\n        selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps + greedy improvement\n    n_items = len(base_solution)\n    if n_items == 0:\n        return new_solution\n\n    # Random swap phase (exploration)\n    swap_attempts = min(5, n_items // 2)  # Limit swap attempts\n    for _ in range(swap_attempts):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Check feasibility\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]  # Revert if infeasible\n\n    # Greedy improvement phase (exploitation)\n    current_weight = np.dot(new_solution, weight_lst)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n\n            if temp_weight <= capacity:\n                # Check if removal improves both objectives\n                delta_v1 = -value1_lst[i]\n                delta_v2 = -value2_lst[i]\n\n                # If both objectives improve, keep the change\n                if delta_v1 > 0 and delta_v2 > 0:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n\n            if temp_weight <= capacity:\n                # Check if addition improves at least one objective\n                delta_v1 = value1_lst[i]\n                delta_v2 = value2_lst[i]\n\n                # If either objective improves, keep the change\n                if delta_v1 > 0 or delta_v2 > 0:\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 59,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with probability proportional to its potential for improvement\n    # Here, we use a simple heuristic: solutions with lower total weight are more likely to be selected\n    weights = [1 / (np.sum(weight_lst[s[0]]) + 1e-6) for s in archive]  # Avoid division by zero\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a neighbor by flipping a random subset of items\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If removing the item keeps the solution feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If adding the item keeps the solution feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a greedy local search to further improve the solution\n    # Evaluate the marginal contribution of each item not in the solution\n    for idx in range(num_items):\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Calculate the marginal contribution (weighted sum of value1 and value2)\n            marginal_value = value1_lst[idx] + value2_lst[idx]\n            # Add the item if it improves both objectives\n            if marginal_value > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3594865187087677,
            4.743970543146133
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with probability proportional to its potential for improvement\n    # Here, we use a simple heuristic: solutions with lower total weight are more likely to be selected\n    weights = [1 / (np.sum(weight_lst[s[0]]) + 1e-6) for s in archive]  # Avoid division by zero\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a neighbor by flipping a random subset of items\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If removing the item keeps the solution feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If adding the item keeps the solution feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a greedy local search to further improve the solution\n    # Evaluate the marginal contribution of each item not in the solution\n    for idx in range(num_items):\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Calculate the marginal contribution (weighted sum of value1 and value2)\n            marginal_value = value1_lst[idx] + value2_lst[idx]\n            # Add the item if it improves both objectives\n            if marginal_value > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 60,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We prioritize solutions that are not too close to the Pareto front in either objective\n    # and have a reasonable number of items that could be flipped\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        available_weight = capacity - current_weight\n        # Potential items that can be added (not in solution and fit weight constraint)\n        potential_add = (sol == 0) & (weight_lst <= available_weight)\n        # Items that can be removed (in solution)\n        potential_remove = (sol == 1)\n\n        # Calculate \"improvement potential\" - combination of value density and flexibility\n        add_value_density = np.sum(value1_lst * potential_add) + np.sum(value2_lst * potential_add)\n        remove_value_density = np.sum(value1_lst * potential_remove) + np.sum(value2_lst * potential_remove)\n        improvement_potential = add_value_density + remove_value_density\n\n        candidates.append((sol, improvement_potential, current_weight))\n\n    # Sort by improvement potential (descending) and select top 3 candidates\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = [x[0] for x in candidates[:min(3, len(candidates))]]\n\n    if not top_candidates:\n        return archive[0][0].copy()\n\n    base_solution = random.choice(top_candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search operator\n    # 1. First try to add items that are not in the solution\n    # 2. If no addition is possible, try to remove items\n    # 3. If neither is possible, perform a swap operation\n\n    # Get current weight and available capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - current_weight\n\n    # Potential items to add (not in solution and fit weight constraint)\n    potential_add = (new_solution == 0) & (weight_lst <= available_weight)\n\n    if np.any(potential_add):\n        # Select items to add based on combined value density\n        value_density = (value1_lst + value2_lst) * potential_add\n        if np.sum(value_density) > 0:\n            # Normalize to create a probability distribution\n            prob = value_density / np.sum(value_density)\n            # Select one item to add with probability proportional to value density\n            items_to_add = np.random.choice(np.arange(len(weight_lst)), p=prob)\n            new_solution[items_to_add] = 1\n            return new_solution\n\n    # If no addition possible, try to remove items\n    potential_remove = (new_solution == 1)\n    if np.any(potential_remove):\n        # Select items to remove based on combined value density\n        value_density = (value1_lst + value2_lst) * potential_remove\n        if np.sum(value_density) > 0:\n            # Normalize to create a probability distribution\n            prob = value_density / np.sum(value_density)\n            # Select one item to remove with probability proportional to value density\n            items_to_remove = np.random.choice(np.arange(len(weight_lst)), p=prob)\n            new_solution[items_to_remove] = 0\n            return new_solution\n\n    # If neither addition nor removal is possible, perform a swap operation\n    # Find items that can be swapped (remove one, add another)\n    # We look for pairs where adding the new item and removing the old one keeps us feasible\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Try to find an item to swap with\n            for j in range(len(weight_lst)):\n                if new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        # Perform the swap\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        return new_solution\n\n    # If no swap is possible, return the original solution\n    return base_solution\n\n",
        "score": [
            -0.8762586237474567,
            5.029189825057983
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We prioritize solutions that are not too close to the Pareto front in either objective\n    # and have a reasonable number of items that could be flipped\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        available_weight = capacity - current_weight\n        # Potential items that can be added (not in solution and fit weight constraint)\n        potential_add = (sol == 0) & (weight_lst <= available_weight)\n        # Items that can be removed (in solution)\n        potential_remove = (sol == 1)\n\n        # Calculate \"improvement potential\" - combination of value density and flexibility\n        add_value_density = np.sum(value1_lst * potential_add) + np.sum(value2_lst * potential_add)\n        remove_value_density = np.sum(value1_lst * potential_remove) + np.sum(value2_lst * potential_remove)\n        improvement_potential = add_value_density + remove_value_density\n\n        candidates.append((sol, improvement_potential, current_weight))\n\n    # Sort by improvement potential (descending) and select top 3 candidates\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = [x[0] for x in candidates[:min(3, len(candidates))]]\n\n    if not top_candidates:\n        return archive[0][0].copy()\n\n    base_solution = random.choice(top_candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search operator\n    # 1. First try to add items that are not in the solution\n    # 2. If no addition is possible, try to remove items\n    # 3. If neither is possible, perform a swap operation\n\n    # Get current weight and available capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - current_weight\n\n    # Potential items to add (not in solution and fit weight constraint)\n    potential_add = (new_solution == 0) & (weight_lst <= available_weight)\n\n    if np.any(potential_add):\n        # Select items to add based on combined value density\n        value_density = (value1_lst + value2_lst) * potential_add\n        if np.sum(value_density) > 0:\n            # Normalize to create a probability distribution\n            prob = value_density / np.sum(value_density)\n            # Select one item to add with probability proportional to value density\n            items_to_add = np.random.choice(np.arange(len(weight_lst)), p=prob)\n            new_solution[items_to_add] = 1\n            return new_solution\n\n    # If no addition possible, try to remove items\n    potential_remove = (new_solution == 1)\n    if np.any(potential_remove):\n        # Select items to remove based on combined value density\n        value_density = (value1_lst + value2_lst) * potential_remove\n        if np.sum(value_density) > 0:\n            # Normalize to create a probability distribution\n            prob = value_density / np.sum(value_density)\n            # Select one item to remove with probability proportional to value density\n            items_to_remove = np.random.choice(np.arange(len(weight_lst)), p=prob)\n            new_solution[items_to_remove] = 0\n            return new_solution\n\n    # If neither addition nor removal is possible, perform a swap operation\n    # Find items that can be swapped (remove one, add another)\n    # We look for pairs where adding the new item and removing the old one keeps us feasible\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Try to find an item to swap with\n            for j in range(len(weight_lst)):\n                if new_solution[j] == 0:\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        # Perform the swap\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        return new_solution\n\n    # If no swap is possible, return the original solution\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 61,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with intelligent randomness based on potential improvement\n    base_solution, _ = random.choices(\n        archive,\n        weights=[1.0 / (1.0 + i) for i in range(len(archive))],  # Prefer earlier solutions\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swap and partial re-optimization\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Random item swap with feasibility check\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] == new_solution[j]:\n            # If both items are the same (both 0 or both 1), we need to change one\n            if new_solution[i] == 1:\n                if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    new_solution[i], new_solution[j] = 0, 1\n            else:\n                if weight_lst[j] <= remaining_capacity:\n                    new_solution[i], new_solution[j] = 1, 0\n        else:\n            # If items are different, we can swap them if feasible\n            delta_weight = weight_lst[j] - weight_lst[i]\n            if delta_weight <= remaining_capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Partial re-optimization for one objective\n    if random.random() < 0.5:  # 50% chance to re-optimize\n        objective_to_optimize = random.choice(['value1', 'value2'])\n        if objective_to_optimize == 'value1':\n            # Greedy addition for value1\n            for item in np.where(new_solution == 0)[0]:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n        else:\n            # Greedy addition for value2\n            for item in np.where(new_solution == 0)[0]:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break\n            item_to_remove = random.choice(items_in_solution)\n            new_solution[item_to_remove] = 0\n            excess -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.36327069977095244,
            1.6991173028945923
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with intelligent randomness based on potential improvement\n    base_solution, _ = random.choices(\n        archive,\n        weights=[1.0 / (1.0 + i) for i in range(len(archive))],  # Prefer earlier solutions\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swap and partial re-optimization\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Step 1: Random item swap with feasibility check\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] == new_solution[j]:\n            # If both items are the same (both 0 or both 1), we need to change one\n            if new_solution[i] == 1:\n                if weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    new_solution[i], new_solution[j] = 0, 1\n            else:\n                if weight_lst[j] <= remaining_capacity:\n                    new_solution[i], new_solution[j] = 1, 0\n        else:\n            # If items are different, we can swap them if feasible\n            delta_weight = weight_lst[j] - weight_lst[i]\n            if delta_weight <= remaining_capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Partial re-optimization for one objective\n    if random.random() < 0.5:  # 50% chance to re-optimize\n        objective_to_optimize = random.choice(['value1', 'value2'])\n        if objective_to_optimize == 'value1':\n            # Greedy addition for value1\n            for item in np.where(new_solution == 0)[0]:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n        else:\n            # Greedy addition for value2\n            for item in np.where(new_solution == 0)[0]:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break\n            item_to_remove = random.choice(items_in_solution)\n            new_solution[item_to_remove] = 0\n            excess -= weight_lst[item_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 62,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential\n    # Sort solutions by the sum of normalized objectives (to balance both)\n    normalized_archive = []\n    max_val1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_val2 = max(obj[1] for _, obj in archive) if archive else 1\n\n    for sol, obj in archive:\n        norm_val1 = obj[0] / max_val1 if max_val1 > 0 else 0\n        norm_val2 = obj[1] / max_val2 if max_val2 > 0 else 0\n        normalized_archive.append((sol, obj, norm_val1 + norm_val2))\n\n    # Select top 20% of solutions with highest potential\n    top_percentile = max(1, len(normalized_archive) // 5)\n    top_solutions = sorted(normalized_archive, key=lambda x: -x[2])[:top_percentile]\n\n    if not top_solutions:\n        selected_sol = archive[0][0]\n    else:\n        # Randomly select from top solutions with probability proportional to their potential\n        probabilities = [x[2] for x in top_solutions]\n        sum_probs = sum(probabilities)\n        if sum_probs == 0:\n            selected_sol = random.choice(top_solutions)[0]\n        else:\n            selected_sol = random.choices(\n                [x[0] for x in top_solutions],\n                weights=[x[2] for x in top_solutions],\n                k=1\n            )[0]\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = selected_sol.copy()\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Operator 1: Randomly flip items with high marginal contribution\n    # Calculate marginal contribution for each item\n    marginal_contrib = np.zeros_like(weight_lst)\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0:\n            marginal_contrib[i] = value1_lst[i] + value2_lst[i]\n        else:\n            marginal_contrib[i] = -(value1_lst[i] + value2_lst[i])\n\n    # Sort items by marginal contribution\n    sorted_indices = np.argsort(-marginal_contrib)\n\n    # Try to add/remove top items that improve both objectives\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:  # Try adding\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n        else:  # Try removing\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    # Operator 2: Randomly swap some items if beneficial\n    # Identify items with negative marginal contribution\n    negative_contrib = sorted_indices[marginal_contrib[sorted_indices] < 0]\n\n    # Try to swap negative items with positive ones\n    for neg_idx in negative_contrib:\n        if new_solution[neg_idx] == 0:\n            continue\n\n        # Find best item to swap with (positive contribution and fits capacity)\n        best_swap = -1\n        best_contrib = -float('inf')\n        for pos_idx in sorted_indices[:len(sorted_indices)//2]:  # Check top half\n            if new_solution[pos_idx] == 1:\n                continue\n\n            # Check if swap is feasible\n            new_total = total_weight - weight_lst[neg_idx] + weight_lst[pos_idx]\n            if new_total <= capacity and (value1_lst[pos_idx] + value2_lst[pos_idx]) > best_contrib:\n                best_swap = pos_idx\n                best_contrib = value1_lst[pos_idx] + value2_lst[pos_idx]\n\n        if best_swap != -1:\n            new_solution[neg_idx] = 0\n            new_solution[best_swap] = 1\n            total_weight = total_weight - weight_lst[neg_idx] + weight_lst[best_swap]\n\n    return new_solution\n\n",
        "score": [
            -0.8663701846581395,
            1.7331799566745758
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential\n    # Sort solutions by the sum of normalized objectives (to balance both)\n    normalized_archive = []\n    max_val1 = max(obj[0] for _, obj in archive) if archive else 1\n    max_val2 = max(obj[1] for _, obj in archive) if archive else 1\n\n    for sol, obj in archive:\n        norm_val1 = obj[0] / max_val1 if max_val1 > 0 else 0\n        norm_val2 = obj[1] / max_val2 if max_val2 > 0 else 0\n        normalized_archive.append((sol, obj, norm_val1 + norm_val2))\n\n    # Select top 20% of solutions with highest potential\n    top_percentile = max(1, len(normalized_archive) // 5)\n    top_solutions = sorted(normalized_archive, key=lambda x: -x[2])[:top_percentile]\n\n    if not top_solutions:\n        selected_sol = archive[0][0]\n    else:\n        # Randomly select from top solutions with probability proportional to their potential\n        probabilities = [x[2] for x in top_solutions]\n        sum_probs = sum(probabilities)\n        if sum_probs == 0:\n            selected_sol = random.choice(top_solutions)[0]\n        else:\n            selected_sol = random.choices(\n                [x[0] for x in top_solutions],\n                weights=[x[2] for x in top_solutions],\n                k=1\n            )[0]\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = selected_sol.copy()\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Operator 1: Randomly flip items with high marginal contribution\n    # Calculate marginal contribution for each item\n    marginal_contrib = np.zeros_like(weight_lst)\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0:\n            marginal_contrib[i] = value1_lst[i] + value2_lst[i]\n        else:\n            marginal_contrib[i] = -(value1_lst[i] + value2_lst[i])\n\n    # Sort items by marginal contribution\n    sorted_indices = np.argsort(-marginal_contrib)\n\n    # Try to add/remove top items that improve both objectives\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:  # Try adding\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n        else:  # Try removing\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    # Operator 2: Randomly swap some items if beneficial\n    # Identify items with negative marginal contribution\n    negative_contrib = sorted_indices[marginal_contrib[sorted_indices] < 0]\n\n    # Try to swap negative items with positive ones\n    for neg_idx in negative_contrib:\n        if new_solution[neg_idx] == 0:\n            continue\n\n        # Find best item to swap with (positive contribution and fits capacity)\n        best_swap = -1\n        best_contrib = -float('inf')\n        for pos_idx in sorted_indices[:len(sorted_indices)//2]:  # Check top half\n            if new_solution[pos_idx] == 1:\n                continue\n\n            # Check if swap is feasible\n            new_total = total_weight - weight_lst[neg_idx] + weight_lst[pos_idx]\n            if new_total <= capacity and (value1_lst[pos_idx] + value2_lst[pos_idx]) > best_contrib:\n                best_swap = pos_idx\n                best_contrib = value1_lst[pos_idx] + value2_lst[pos_idx]\n\n        if best_swap != -1:\n            new_solution[neg_idx] = 0\n            new_solution[best_swap] = 1\n            total_weight = total_weight - weight_lst[neg_idx] + weight_lst[best_swap]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 63,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_solution = random.choice(archive)[0].copy()\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Identify items that can be flipped (either included or excluded without violating capacity)\n    flip_candidates = []\n    for i in range(len(selected_solution)):\n        if selected_solution[i] == 1:\n            # If item is included, check if excluding it keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # If item is excluded, check if including it keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    if not flip_candidates:\n        # If no flips are possible, return the solution as is (or apply a different strategy)\n        return selected_solution\n\n    # Randomly select a subset of flip candidates to flip\n    num_flips = min(3, len(flip_candidates))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    # Create a new solution by flipping the selected items\n    new_solution = selected_solution.copy()\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Greedy improvement step: try to add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_weight:\n            # Check if adding this item improves both objectives\n            if (value1_lst[i] > 0 and value2_lst[i] > 0):\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4075051331531041,
            8.286293625831604
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_solution = random.choice(archive)[0].copy()\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Identify items that can be flipped (either included or excluded without violating capacity)\n    flip_candidates = []\n    for i in range(len(selected_solution)):\n        if selected_solution[i] == 1:\n            # If item is included, check if excluding it keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # If item is excluded, check if including it keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    if not flip_candidates:\n        # If no flips are possible, return the solution as is (or apply a different strategy)\n        return selected_solution\n\n    # Randomly select a subset of flip candidates to flip\n    num_flips = min(3, len(flip_candidates))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    # Create a new solution by flipping the selected items\n    new_solution = selected_solution.copy()\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Greedy improvement step: try to add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_weight:\n            # Check if adding this item improves both objectives\n            if (value1_lst[i] > 0 and value2_lst[i] > 0):\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 64,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher potential for improvement\n    # Here, we prioritize solutions with higher total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    base_solution = archive_sorted[0][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Hybrid local search: combine random swaps with a value-to-weight ratio heuristic\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly select a subset of items to consider for swapping\n    swap_candidates = np.random.choice(n_items, size=min(10, n_items), replace=False)\n\n    # Step 2: For each candidate, decide to include/exclude based on a hybrid heuristic\n    for i in swap_candidates:\n        if new_solution[i] == 1:\n            # If item is included, decide to exclude it if it has low value-to-weight ratio\n            value_ratio1 = value1_lst[i] / weight_lst[i]\n            value_ratio2 = value2_lst[i] / weight_lst[i]\n            if np.random.rand() < 0.5 and (value_ratio1 < 1.0 or value_ratio2 < 1.0):\n                new_solution[i] = 0\n        else:\n            # If item is excluded, decide to include it if it fits and has high value-to-weight ratio\n            if current_weight + weight_lst[i] <= capacity:\n                value_ratio1 = value1_lst[i] / weight_lst[i]\n                value_ratio2 = value2_lst[i] / weight_lst[i]\n                if np.random.rand() < 0.7 and (value_ratio1 > 1.0 or value_ratio2 > 1.0):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 3: Ensure feasibility by removing items if weight exceeds capacity\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        # Remove items with lowest value-to-weight ratio until feasible\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            break\n        # Calculate value-to-weight ratios for included items\n        ratios = (value1_lst[candidate_indices] + value2_lst[candidate_indices]) / weight_lst[candidate_indices]\n        # Remove the item with the lowest ratio\n        remove_idx = candidate_indices[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.48277754112307975,
            6.421171635389328
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher potential for improvement\n    # Here, we prioritize solutions with higher total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    base_solution = archive_sorted[0][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Hybrid local search: combine random swaps with a value-to-weight ratio heuristic\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly select a subset of items to consider for swapping\n    swap_candidates = np.random.choice(n_items, size=min(10, n_items), replace=False)\n\n    # Step 2: For each candidate, decide to include/exclude based on a hybrid heuristic\n    for i in swap_candidates:\n        if new_solution[i] == 1:\n            # If item is included, decide to exclude it if it has low value-to-weight ratio\n            value_ratio1 = value1_lst[i] / weight_lst[i]\n            value_ratio2 = value2_lst[i] / weight_lst[i]\n            if np.random.rand() < 0.5 and (value_ratio1 < 1.0 or value_ratio2 < 1.0):\n                new_solution[i] = 0\n        else:\n            # If item is excluded, decide to include it if it fits and has high value-to-weight ratio\n            if current_weight + weight_lst[i] <= capacity:\n                value_ratio1 = value1_lst[i] / weight_lst[i]\n                value_ratio2 = value2_lst[i] / weight_lst[i]\n                if np.random.rand() < 0.7 and (value_ratio1 > 1.0 or value_ratio2 > 1.0):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 3: Ensure feasibility by removing items if weight exceeds capacity\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_weight = np.sum(new_solution * weight_lst) - capacity\n        # Remove items with lowest value-to-weight ratio until feasible\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            break\n        # Calculate value-to-weight ratios for included items\n        ratios = (value1_lst[candidate_indices] + value2_lst[candidate_indices]) / weight_lst[candidate_indices]\n        # Remove the item with the lowest ratio\n        remove_idx = candidate_indices[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 65,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty.\")\n\n    # Select a promising solution: prioritize solutions with high objective values\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = np.random.choice(min(5, len(archive_sorted)), 1)[0]  # Randomly select from top 5 solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search operator: flip items based on a combination of objectives and weights\n    new_solution = base_solution.copy()\n    for _ in range(3):  # Perform up to 3 flips\n        # Calculate flip scores: prioritize items that improve both objectives or reduce weight\n        flip_scores = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Score for removing item: reduce weight, maintain values\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    score = (current_value1 - value1_lst[i]) + (current_value2 - value2_lst[i]) - 0.1 * (current_weight - new_weight)\n                    flip_scores.append((score, i, 0))  # 0 indicates removal\n            else:\n                # Score for adding item: add weight, improve values\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    score = (current_value1 + value1_lst[i]) + (current_value2 + value2_lst[i]) - 0.1 * (new_weight - current_weight)\n                    flip_scores.append((score, i, 1))  # 1 indicates addition\n\n        if not flip_scores:\n            break\n\n        # Select the best flip (highest score)\n        best_score, best_i, action = max(flip_scores, key=lambda x: x[0])\n        if action == 1:\n            new_solution[best_i] = 1\n            current_weight += weight_lst[best_i]\n            current_value1 += value1_lst[best_i]\n            current_value2 += value2_lst[best_i]\n        else:\n            new_solution[best_i] = 0\n            current_weight -= weight_lst[best_i]\n            current_value1 -= value1_lst[best_i]\n            current_value2 -= value2_lst[best_i]\n\n    return new_solution\n\n",
        "score": [
            -0.2838077046486932,
            2.795367479324341
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty.\")\n\n    # Select a promising solution: prioritize solutions with high objective values\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = np.random.choice(min(5, len(archive_sorted)), 1)[0]  # Randomly select from top 5 solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search operator: flip items based on a combination of objectives and weights\n    new_solution = base_solution.copy()\n    for _ in range(3):  # Perform up to 3 flips\n        # Calculate flip scores: prioritize items that improve both objectives or reduce weight\n        flip_scores = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Score for removing item: reduce weight, maintain values\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    score = (current_value1 - value1_lst[i]) + (current_value2 - value2_lst[i]) - 0.1 * (current_weight - new_weight)\n                    flip_scores.append((score, i, 0))  # 0 indicates removal\n            else:\n                # Score for adding item: add weight, improve values\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    score = (current_value1 + value1_lst[i]) + (current_value2 + value2_lst[i]) - 0.1 * (new_weight - current_weight)\n                    flip_scores.append((score, i, 1))  # 1 indicates addition\n\n        if not flip_scores:\n            break\n\n        # Select the best flip (highest score)\n        best_score, best_i, action = max(flip_scores, key=lambda x: x[0])\n        if action == 1:\n            new_solution[best_i] = 1\n            current_weight += weight_lst[best_i]\n            current_value1 += value1_lst[best_i]\n            current_value2 += value2_lst[best_i]\n        else:\n            new_solution[best_i] = 0\n            current_weight -= weight_lst[best_i]\n            current_value1 -= value1_lst[best_i]\n            current_value2 -= value2_lst[best_i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 66,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    # Here, we use a simple heuristic: select a solution that is not dominated by others in the archive\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] > obj[0] and other_obj[1] >= obj[1]) or (other_obj[0] >= obj[0] and other_obj[1] > obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        # If no non-dominated solutions, select the first one\n        base_solution, _ = archive[0]\n    else:\n        # Select a random non-dominated solution\n        base_solution, _ = non_dominated[np.random.choice(len(non_dominated))]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a bit (add/remove an item) if feasible\n    # 2. If not feasible, swap the item with another for higher value\n    for _ in range(10):  # Try up to 10 times to find a feasible neighbor\n        # Random flip\n        idx = np.random.randint(0, n_items)\n        new_val = 1 - new_solution[idx]\n        current_weight = np.sum(weight_lst[new_solution == 1])\n\n        if new_val == 1:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                break\n        else:\n            new_solution[idx] = 0\n            break\n\n    # If no feasible flip found, perform a value-based swap\n    if np.array_equal(new_solution, base_solution):\n        # Find items that can be swapped for higher value\n        for i in range(n_items):\n            if new_solution[i] == 1:\n                for j in range(n_items):\n                    if new_solution[j] == 0:\n                        delta_weight = weight_lst[j] - weight_lst[i]\n                        if np.sum(weight_lst[new_solution == 1]) + delta_weight <= capacity:\n                            new_solution[i] = 0\n                            new_solution[j] = 1\n                            break\n                else:\n                    continue\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.32087882086013336,
            1.232432097196579
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    # Here, we use a simple heuristic: select a solution that is not dominated by others in the archive\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] > obj[0] and other_obj[1] >= obj[1]) or (other_obj[0] >= obj[0] and other_obj[1] > obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        # If no non-dominated solutions, select the first one\n        base_solution, _ = archive[0]\n    else:\n        # Select a random non-dominated solution\n        base_solution, _ = non_dominated[np.random.choice(len(non_dominated))]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a bit (add/remove an item) if feasible\n    # 2. If not feasible, swap the item with another for higher value\n    for _ in range(10):  # Try up to 10 times to find a feasible neighbor\n        # Random flip\n        idx = np.random.randint(0, n_items)\n        new_val = 1 - new_solution[idx]\n        current_weight = np.sum(weight_lst[new_solution == 1])\n\n        if new_val == 1:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                break\n        else:\n            new_solution[idx] = 0\n            break\n\n    # If no feasible flip found, perform a value-based swap\n    if np.array_equal(new_solution, base_solution):\n        # Find items that can be swapped for higher value\n        for i in range(n_items):\n            if new_solution[i] == 1:\n                for j in range(n_items):\n                    if new_solution[j] == 0:\n                        delta_weight = weight_lst[j] - weight_lst[i]\n                        if np.sum(weight_lst[new_solution == 1]) + delta_weight <= capacity:\n                            new_solution[i] = 0\n                            new_solution[j] = 1\n                            break\n                else:\n                    continue\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 67,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [s[0] for s in archive]\n    archive_objectives = [s[1] for s in archive]\n\n    # Compute crowding distances to identify less crowded solutions (more potential for improvement)\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):  # For both objectives\n        sorted_indices = np.argsort([obj[i] for obj in archive_objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (archive_objectives[sorted_indices[j+1]][i] - archive_objectives[sorted_indices[j-1]][i])\n\n    # Select a solution with the smallest crowding distance (less crowded, more potential)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly swap a subset of items (exploration)\n    swap_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random swaps\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break  # No items to remove, return base solution\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(new_solution * weight_lst)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try adding items that improve at least one objective\n    for i in range(n_items):\n        if new_solution[i] == 0 and (total_weight + weight_lst[i]) <= capacity:\n            # Check if adding the item improves at least one objective\n            current_obj1 = np.sum(new_solution * value1_lst)\n            current_obj2 = np.sum(new_solution * value2_lst)\n            new_obj1 = current_obj1 + value1_lst[i]\n            new_obj2 = current_obj2 + value2_lst[i]\n\n            # If adding the item improves at least one objective, keep it\n            if (new_obj1 > current_obj1) or (new_obj2 > current_obj2):\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4946202589697779,
            1.7866436839103699
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [s[0] for s in archive]\n    archive_objectives = [s[1] for s in archive]\n\n    # Compute crowding distances to identify less crowded solutions (more potential for improvement)\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):  # For both objectives\n        sorted_indices = np.argsort([obj[i] for obj in archive_objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (archive_objectives[sorted_indices[j+1]][i] - archive_objectives[sorted_indices[j-1]][i])\n\n    # Select a solution with the smallest crowding distance (less crowded, more potential)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly swap a subset of items (exploration)\n    swap_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random swaps\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break  # No items to remove, return base solution\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(new_solution * weight_lst)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try adding items that improve at least one objective\n    for i in range(n_items):\n        if new_solution[i] == 0 and (total_weight + weight_lst[i]) <= capacity:\n            # Check if adding the item improves at least one objective\n            current_obj1 = np.sum(new_solution * value1_lst)\n            current_obj2 = np.sum(new_solution * value2_lst)\n            new_obj1 = current_obj1 + value1_lst[i]\n            new_obj2 = current_obj2 + value2_lst[i]\n\n            # If adding the item improves at least one objective, keep it\n            if (new_obj1 > current_obj1) or (new_obj2 > current_obj2):\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 68,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate value-to-weight ratios for all items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Hybrid local search: combine random swaps with ratio-based selection\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Perform multiple random swaps with a bias towards high-value-to-weight items\n    for _ in range(min(5, n_items // 2)):  # Limit the number of swaps\n        # Select two items to swap\n        i = random.randint(0, n_items - 1)\n        j = random.randint(0, n_items - 1)\n\n        # Calculate potential weight change\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 and new_solution[j] == 0 else \\\n                      (weight_lst[i] - weight_lst[j]) if new_solution[i] == 0 and new_solution[j] == 1 else 0\n\n        # Check feasibility\n        if abs(delta_weight) == 0:\n            continue  # No change in weight\n\n        new_weight = current_weight + delta_weight\n        if new_weight <= capacity:\n            # Accept the swap with probability based on value improvement\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                value1_improvement = value1_lst[j] - value1_lst[i]\n                value2_improvement = value2_lst[j] - value2_lst[i]\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                value1_improvement = value1_lst[i] - value1_lst[j]\n                value2_improvement = value2_lst[i] - value2_lst[j]\n            else:\n                continue  # No swap\n\n            # Accept if both objectives improve, or at least one improves significantly\n            if (value1_improvement > 0 and value2_improvement > 0) or \\\n               (value1_improvement > 0 or value2_improvement > 0):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight = new_weight\n\n    # Additional improvement: try to add high-value items that fit\n    remaining_weight = capacity - current_weight\n    if remaining_weight > 0:\n        # Sort items by combined value-to-weight ratio\n        combined_ratio = value1_ratio + value2_ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n                if remaining_weight <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.34661141467891826,
            4.537593394517899
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate value-to-weight ratios for all items\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Hybrid local search: combine random swaps with ratio-based selection\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Perform multiple random swaps with a bias towards high-value-to-weight items\n    for _ in range(min(5, n_items // 2)):  # Limit the number of swaps\n        # Select two items to swap\n        i = random.randint(0, n_items - 1)\n        j = random.randint(0, n_items - 1)\n\n        # Calculate potential weight change\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 and new_solution[j] == 0 else \\\n                      (weight_lst[i] - weight_lst[j]) if new_solution[i] == 0 and new_solution[j] == 1 else 0\n\n        # Check feasibility\n        if abs(delta_weight) == 0:\n            continue  # No change in weight\n\n        new_weight = current_weight + delta_weight\n        if new_weight <= capacity:\n            # Accept the swap with probability based on value improvement\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                value1_improvement = value1_lst[j] - value1_lst[i]\n                value2_improvement = value2_lst[j] - value2_lst[i]\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                value1_improvement = value1_lst[i] - value1_lst[j]\n                value2_improvement = value2_lst[i] - value2_lst[j]\n            else:\n                continue  # No swap\n\n            # Accept if both objectives improve, or at least one improves significantly\n            if (value1_improvement > 0 and value2_improvement > 0) or \\\n               (value1_improvement > 0 or value2_improvement > 0):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight = new_weight\n\n    # Additional improvement: try to add high-value items that fit\n    remaining_weight = capacity - current_weight\n    if remaining_weight > 0:\n        # Sort items by combined value-to-weight ratio\n        combined_ratio = value1_ratio + value2_ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n                if remaining_weight <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 69,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with the highest combined value (sum of both objectives)\n    archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Randomly perturb the solution (flip a few items)\n    num_items = len(weight_lst)\n    perturb_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the lowest combined value-to-weight ratio until feasible\n        while current_weight > capacity:\n            # Calculate value-to-weight ratios for items in the solution\n            ratios = (value1_lst + value2_lst) / weight_lst\n            selected_indices = np.where(new_solution == 1)[0]\n            if len(selected_indices) == 0:\n                break  # No items left to remove\n            # Remove the item with the lowest ratio\n            remove_idx = selected_indices[np.argmin(ratios[selected_indices])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement: add items not in the solution that improve both objectives\n    remaining_indices = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_indices)  # Randomize order for exploration\n    for idx in remaining_indices:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = archive_sorted[0][1][0] + value1_lst[idx]\n            new_value2 = archive_sorted[0][1][1] + value2_lst[idx]\n            if new_value1 > archive_sorted[0][1][0] and new_value2 > archive_sorted[0][1][1]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.322502755224237,
            5.602845519781113
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with the highest combined value (sum of both objectives)\n    archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Randomly perturb the solution (flip a few items)\n    num_items = len(weight_lst)\n    perturb_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the lowest combined value-to-weight ratio until feasible\n        while current_weight > capacity:\n            # Calculate value-to-weight ratios for items in the solution\n            ratios = (value1_lst + value2_lst) / weight_lst\n            selected_indices = np.where(new_solution == 1)[0]\n            if len(selected_indices) == 0:\n                break  # No items left to remove\n            # Remove the item with the lowest ratio\n            remove_idx = selected_indices[np.argmin(ratios[selected_indices])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement: add items not in the solution that improve both objectives\n    remaining_indices = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_indices)  # Randomize order for exploration\n    for idx in remaining_indices:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = archive_sorted[0][1][0] + value1_lst[idx]\n            new_value2 = archive_sorted[0][1][1] + value2_lst[idx]\n            if new_value1 > archive_sorted[0][1][0] and new_value2 > archive_sorted[0][1][1]:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 70,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: sum(x[0] * value1_lst) + sum(x[0] * value2_lst))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Identify items that can be flipped without exceeding capacity\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append((i, -1))  # -1 indicates removal\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append((i, 1))  # 1 indicates addition\n\n    if not flip_candidates:\n        return new_solution  # No feasible flips possible\n\n    # Select a flip candidate based on value density (weighted sum of value1 and value2 per unit weight)\n    value_density = []\n    for i, flip_type in flip_candidates:\n        if flip_type == 1:\n            value_density.append((i, (value1_lst[i] + value2_lst[i]) / weight_lst[i], flip_type))\n        else:\n            value_density.append((i, -(value1_lst[i] + value2_lst[i]) / weight_lst[i], flip_type))\n\n    # Sort by value density (descending for additions, ascending for removals)\n    value_density.sort(key=lambda x: x[1], reverse=True)\n\n    # Randomly select among top 30% candidates to introduce diversity\n    top_candidates = value_density[:max(1, len(value_density) // 3)]\n    if not top_candidates:\n        return new_solution\n\n    selected_i, _, flip_type = random.choice(top_candidates)\n    new_solution[selected_i] = flip_type\n\n    # Perform a secondary flip if possible to improve both objectives\n    current_weight = np.dot(new_solution, weight_lst)\n    secondary_flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                secondary_flip_candidates.append((i, -1))\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                secondary_flip_candidates.append((i, 1))\n\n    if secondary_flip_candidates:\n        # Select the secondary flip with the highest marginal gain in both objectives\n        best_secondary = None\n        best_score = -float('inf')\n        for i, flip_type in secondary_flip_candidates:\n            if flip_type == 1:\n                score = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            else:\n                score = -(value1_lst[i] + value2_lst[i]) / weight_lst[i]\n\n            if score > best_score:\n                best_score = score\n                best_secondary = (i, flip_type)\n\n        if best_secondary:\n            new_solution[best_secondary[0]] = best_secondary[1]\n\n    return new_solution\n\n",
        "score": [
            -0.8697845116683428,
            8.221726655960083
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: sum(x[0] * value1_lst) + sum(x[0] * value2_lst))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Identify items that can be flipped without exceeding capacity\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append((i, -1))  # -1 indicates removal\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append((i, 1))  # 1 indicates addition\n\n    if not flip_candidates:\n        return new_solution  # No feasible flips possible\n\n    # Select a flip candidate based on value density (weighted sum of value1 and value2 per unit weight)\n    value_density = []\n    for i, flip_type in flip_candidates:\n        if flip_type == 1:\n            value_density.append((i, (value1_lst[i] + value2_lst[i]) / weight_lst[i], flip_type))\n        else:\n            value_density.append((i, -(value1_lst[i] + value2_lst[i]) / weight_lst[i], flip_type))\n\n    # Sort by value density (descending for additions, ascending for removals)\n    value_density.sort(key=lambda x: x[1], reverse=True)\n\n    # Randomly select among top 30% candidates to introduce diversity\n    top_candidates = value_density[:max(1, len(value_density) // 3)]\n    if not top_candidates:\n        return new_solution\n\n    selected_i, _, flip_type = random.choice(top_candidates)\n    new_solution[selected_i] = flip_type\n\n    # Perform a secondary flip if possible to improve both objectives\n    current_weight = np.dot(new_solution, weight_lst)\n    secondary_flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                secondary_flip_candidates.append((i, -1))\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                secondary_flip_candidates.append((i, 1))\n\n    if secondary_flip_candidates:\n        # Select the secondary flip with the highest marginal gain in both objectives\n        best_secondary = None\n        best_score = -float('inf')\n        for i, flip_type in secondary_flip_candidates:\n            if flip_type == 1:\n                score = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            else:\n                score = -(value1_lst[i] + value2_lst[i]) / weight_lst[i]\n\n            if score > best_score:\n                best_score = score\n                best_secondary = (i, flip_type)\n\n        if best_secondary:\n            new_solution[best_secondary[0]] = best_secondary[1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 71,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Calculate crowding distance or other metrics to select diverse solutions\n        # Here, we randomly select a solution with a bias towards higher value solutions\n        weights = np.array([obj[0] + obj[1] for _, obj in archive])\n        weights = weights / np.sum(weights)  # Normalize to form a probability distribution\n        selected_idx = np.random.choice(len(archive), p=weights)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    current_value1 = np.sum(base_solution * value1_lst)\n    current_value2 = np.sum(base_solution * value2_lst)\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n\n    # Random flip with a bias towards improving both objectives\n    for i in range(len(base_solution)):\n        if random.random() < 0.3:  # 30% chance to flip each item\n            if base_solution[i] == 1:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n                    current_value1 -= value1_lst[i]\n                    current_value2 -= value2_lst[i]\n            else:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n                    current_value1 += value1_lst[i]\n                    current_value2 += value2_lst[i]\n\n    # Step 3: Greedy improvement step\n    # Evaluate all possible single-item swaps to find the best improvement\n    best_solution = new_solution.copy()\n    best_value1 = current_value1\n    best_value2 = current_value2\n\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                temp_value1 = current_value1 - value1_lst[i]\n                temp_value2 = current_value2 - value2_lst[i]\n                # Check if this improves both objectives\n                if (temp_value1 > best_value1 and temp_value2 >= best_value2) or \\\n                   (temp_value1 >= best_value1 and temp_value2 > best_value2):\n                    best_value1 = temp_value1\n                    best_value2 = temp_value2\n                    best_solution = new_solution.copy()\n                    best_solution[i] = 0\n        else:\n            # Try adding item i\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                temp_value1 = current_value1 + value1_lst[i]\n                temp_value2 = current_value2 + value2_lst[i]\n                # Check if this improves both objectives\n                if (temp_value1 > best_value1 and temp_value2 >= best_value2) or \\\n                   (temp_value1 >= best_value1 and temp_value2 > best_value2):\n                    best_value1 = temp_value1\n                    best_value2 = temp_value2\n                    best_solution = new_solution.copy()\n                    best_solution[i] = 1\n\n    return best_solution\n\n",
        "score": [
            -0.3254606258982887,
            1.84140944480896
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Calculate crowding distance or other metrics to select diverse solutions\n        # Here, we randomly select a solution with a bias towards higher value solutions\n        weights = np.array([obj[0] + obj[1] for _, obj in archive])\n        weights = weights / np.sum(weights)  # Normalize to form a probability distribution\n        selected_idx = np.random.choice(len(archive), p=weights)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    current_value1 = np.sum(base_solution * value1_lst)\n    current_value2 = np.sum(base_solution * value2_lst)\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n\n    # Random flip with a bias towards improving both objectives\n    for i in range(len(base_solution)):\n        if random.random() < 0.3:  # 30% chance to flip each item\n            if base_solution[i] == 1:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n                    current_value1 -= value1_lst[i]\n                    current_value2 -= value2_lst[i]\n            else:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n                    current_value1 += value1_lst[i]\n                    current_value2 += value2_lst[i]\n\n    # Step 3: Greedy improvement step\n    # Evaluate all possible single-item swaps to find the best improvement\n    best_solution = new_solution.copy()\n    best_value1 = current_value1\n    best_value2 = current_value2\n\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                temp_value1 = current_value1 - value1_lst[i]\n                temp_value2 = current_value2 - value2_lst[i]\n                # Check if this improves both objectives\n                if (temp_value1 > best_value1 and temp_value2 >= best_value2) or \\\n                   (temp_value1 >= best_value1 and temp_value2 > best_value2):\n                    best_value1 = temp_value1\n                    best_value2 = temp_value2\n                    best_solution = new_solution.copy()\n                    best_solution[i] = 0\n        else:\n            # Try adding item i\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                temp_value1 = current_value1 + value1_lst[i]\n                temp_value2 = current_value2 + value2_lst[i]\n                # Check if this improves both objectives\n                if (temp_value1 > best_value1 and temp_value2 >= best_value2) or \\\n                   (temp_value1 >= best_value1 and temp_value2 > best_value2):\n                    best_value1 = temp_value1\n                    best_value2 = temp_value2\n                    best_solution = new_solution.copy()\n                    best_solution[i] = 1\n\n    return best_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 72,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Here, we prioritize solutions that are not on the extreme fronts and have a balance between the two objectives\n    def potential_score(solution, objective):\n        total_weight = np.sum(weight_lst * solution)\n        # Solutions with moderate weight and central objective values are more promising\n        return (1 - abs(0.5 - (objective[0] / np.max(value1_lst)))) + (1 - abs(0.5 - (objective[1] / np.max(value2_lst))))\n\n    scored_solutions = [(potential_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: -x[0])  # Sort by potential score descending\n\n    # Select top 20% of solutions with highest potential\n    top_k = max(1, len(scored_solutions) // 5)\n    candidates = [sol for score, sol in scored_solutions[:top_k]]\n\n    if not candidates:\n        candidates = [sol for _, sol in scored_solutions]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip, swap, and guided perturbation\n    operation = random.choice(['flip', 'swap', 'guided'])\n\n    if operation == 'flip':\n        # Flip a random item (0 to 1 or 1 to 0) while maintaining feasibility\n        flip_pos = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_pos] == 1:\n            # If removing, check if weight is reduced below capacity\n            new_solution[flip_pos] = 0\n        else:\n            # If adding, check if weight is within capacity\n            if np.sum(weight_lst * new_solution) + weight_lst[flip_pos] <= capacity:\n                new_solution[flip_pos] = 1\n    elif operation == 'swap':\n        # Swap two random items while maintaining feasibility\n        pos1, pos2 = random.sample(range(len(new_solution)), 2)\n        if new_solution[pos1] != new_solution[pos2]:\n            # Swap only if it doesn't violate capacity\n            new_weight = np.sum(weight_lst * new_solution)\n            if (new_solution[pos1] == 1 and new_solution[pos2] == 0):\n                if new_weight - weight_lst[pos1] + weight_lst[pos2] <= capacity:\n                    new_solution[pos1], new_solution[pos2] = new_solution[pos2], new_solution[pos1]\n            elif (new_solution[pos1] == 0 and new_solution[pos2] == 1):\n                if new_weight + weight_lst[pos1] - weight_lst[pos2] <= capacity:\n                    new_solution[pos1], new_solution[pos2] = new_solution[pos2], new_solution[pos1]\n    elif operation == 'guided':\n        # Guided perturbation: add or remove items that improve both objectives\n        # Calculate marginal gains for each item\n        current_weight = np.sum(weight_lst * new_solution)\n        marginal_gains = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # For included items, consider removing if it doesn't hurt objectives too much\n                marginal_gain = (value1_lst[i], value2_lst[i])\n                marginal_gains.append((-1, i, marginal_gain))  # Negative to indicate removal\n            else:\n                # For excluded items, consider adding if it fits and improves objectives\n                if current_weight + weight_lst[i] <= capacity:\n                    marginal_gain = (value1_lst[i], value2_lst[i])\n                    marginal_gains.append((1, i, marginal_gain))\n\n        if marginal_gains:\n            # Sort by combined marginal gain (lexicographic order)\n            marginal_gains.sort(key=lambda x: (-x[2][0], -x[2][1]))\n            # Apply the best marginal gain operation\n            action, pos, _ = marginal_gains[0]\n            new_solution[pos] = action\n\n    return new_solution\n\n",
        "score": [
            -0.7407615187333136,
            2.414480745792389
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Here, we prioritize solutions that are not on the extreme fronts and have a balance between the two objectives\n    def potential_score(solution, objective):\n        total_weight = np.sum(weight_lst * solution)\n        # Solutions with moderate weight and central objective values are more promising\n        return (1 - abs(0.5 - (objective[0] / np.max(value1_lst)))) + (1 - abs(0.5 - (objective[1] / np.max(value2_lst))))\n\n    scored_solutions = [(potential_score(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(key=lambda x: -x[0])  # Sort by potential score descending\n\n    # Select top 20% of solutions with highest potential\n    top_k = max(1, len(scored_solutions) // 5)\n    candidates = [sol for score, sol in scored_solutions[:top_k]]\n\n    if not candidates:\n        candidates = [sol for _, sol in scored_solutions]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip, swap, and guided perturbation\n    operation = random.choice(['flip', 'swap', 'guided'])\n\n    if operation == 'flip':\n        # Flip a random item (0 to 1 or 1 to 0) while maintaining feasibility\n        flip_pos = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_pos] == 1:\n            # If removing, check if weight is reduced below capacity\n            new_solution[flip_pos] = 0\n        else:\n            # If adding, check if weight is within capacity\n            if np.sum(weight_lst * new_solution) + weight_lst[flip_pos] <= capacity:\n                new_solution[flip_pos] = 1\n    elif operation == 'swap':\n        # Swap two random items while maintaining feasibility\n        pos1, pos2 = random.sample(range(len(new_solution)), 2)\n        if new_solution[pos1] != new_solution[pos2]:\n            # Swap only if it doesn't violate capacity\n            new_weight = np.sum(weight_lst * new_solution)\n            if (new_solution[pos1] == 1 and new_solution[pos2] == 0):\n                if new_weight - weight_lst[pos1] + weight_lst[pos2] <= capacity:\n                    new_solution[pos1], new_solution[pos2] = new_solution[pos2], new_solution[pos1]\n            elif (new_solution[pos1] == 0 and new_solution[pos2] == 1):\n                if new_weight + weight_lst[pos1] - weight_lst[pos2] <= capacity:\n                    new_solution[pos1], new_solution[pos2] = new_solution[pos2], new_solution[pos1]\n    elif operation == 'guided':\n        # Guided perturbation: add or remove items that improve both objectives\n        # Calculate marginal gains for each item\n        current_weight = np.sum(weight_lst * new_solution)\n        marginal_gains = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # For included items, consider removing if it doesn't hurt objectives too much\n                marginal_gain = (value1_lst[i], value2_lst[i])\n                marginal_gains.append((-1, i, marginal_gain))  # Negative to indicate removal\n            else:\n                # For excluded items, consider adding if it fits and improves objectives\n                if current_weight + weight_lst[i] <= capacity:\n                    marginal_gain = (value1_lst[i], value2_lst[i])\n                    marginal_gains.append((1, i, marginal_gain))\n\n        if marginal_gains:\n            # Sort by combined marginal gain (lexicographic order)\n            marginal_gains.sort(key=lambda x: (-x[2][0], -x[2][1]))\n            # Apply the best marginal gain operation\n            action, pos, _ = marginal_gains[0]\n            new_solution[pos] = action\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 73,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a base solution with a bias towards solutions with higher potential\n    # Calculate potential as the sum of (value1 + value2) for items not in the solution\n    potentials = []\n    for sol, _ in archive:\n        remaining_items = ~sol.astype(bool)\n        potential = np.sum(value1_lst[remaining_items] + value2_lst[remaining_items])\n        potentials.append(potential)\n\n    # Normalize potentials to form a probability distribution\n    total_potential = sum(potentials)\n    if total_potential == 0:\n        probs = [1.0 / len(archive)] * len(archive)\n    else:\n        probs = [p / total_potential for p in potentials]\n\n    # Select a base solution with probability proportional to its potential\n    selected_idx = random.choices(range(len(archive)), weights=probs, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Random Swaps (exploration)\n    if random.random() < 0.5:\n        swap_indices = random.sample(range(n_items), min(3, n_items))\n        for idx in swap_indices:\n            new_solution[idx] = 1 - new_solution[idx]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst[new_solution.astype(bool)])\n        if current_weight > capacity:\n            # Remove excess items randomly\n            excess_weight = current_weight - capacity\n            excess_items = np.where(new_solution)[0]\n            while excess_weight > 0 and len(excess_items) > 0:\n                remove_idx = random.choice(excess_items)\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n                excess_items = np.where(new_solution)[0]\n\n    # Strategy 2: Targeted Flips (exploitation)\n    else:\n        # Calculate marginal gains for each item\n        current_weight = np.sum(weight_lst[new_solution.astype(bool)])\n        marginal_gains = []\n        for i in range(n_items):\n            if new_solution[i] == 1:\n                # Calculate gain if removed\n                gain = -(value1_lst[i] + value2_lst[i])\n                marginal_gains.append((gain, i, -1))  # Negative gain for removal\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    # Calculate gain if added\n                    gain = value1_lst[i] + value2_lst[i]\n                    marginal_gains.append((gain, i, 1))  # Positive gain for addition\n                else:\n                    marginal_gains.append((-np.inf, i, 0))  # No action if infeasible\n\n        # Sort by marginal gain (descending)\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n        # Apply top 2 marginal changes\n        for _, idx, action in marginal_gains[:2]:\n            if action != 0:\n                new_solution[idx] = action\n\n    return new_solution\n\n",
        "score": [
            -0.3467422164075707,
            1.5465415716171265
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a base solution with a bias towards solutions with higher potential\n    # Calculate potential as the sum of (value1 + value2) for items not in the solution\n    potentials = []\n    for sol, _ in archive:\n        remaining_items = ~sol.astype(bool)\n        potential = np.sum(value1_lst[remaining_items] + value2_lst[remaining_items])\n        potentials.append(potential)\n\n    # Normalize potentials to form a probability distribution\n    total_potential = sum(potentials)\n    if total_potential == 0:\n        probs = [1.0 / len(archive)] * len(archive)\n    else:\n        probs = [p / total_potential for p in potentials]\n\n    # Select a base solution with probability proportional to its potential\n    selected_idx = random.choices(range(len(archive)), weights=probs, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Random Swaps (exploration)\n    if random.random() < 0.5:\n        swap_indices = random.sample(range(n_items), min(3, n_items))\n        for idx in swap_indices:\n            new_solution[idx] = 1 - new_solution[idx]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst[new_solution.astype(bool)])\n        if current_weight > capacity:\n            # Remove excess items randomly\n            excess_weight = current_weight - capacity\n            excess_items = np.where(new_solution)[0]\n            while excess_weight > 0 and len(excess_items) > 0:\n                remove_idx = random.choice(excess_items)\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n                excess_items = np.where(new_solution)[0]\n\n    # Strategy 2: Targeted Flips (exploitation)\n    else:\n        # Calculate marginal gains for each item\n        current_weight = np.sum(weight_lst[new_solution.astype(bool)])\n        marginal_gains = []\n        for i in range(n_items):\n            if new_solution[i] == 1:\n                # Calculate gain if removed\n                gain = -(value1_lst[i] + value2_lst[i])\n                marginal_gains.append((gain, i, -1))  # Negative gain for removal\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    # Calculate gain if added\n                    gain = value1_lst[i] + value2_lst[i]\n                    marginal_gains.append((gain, i, 1))  # Positive gain for addition\n                else:\n                    marginal_gains.append((-np.inf, i, 0))  # No action if infeasible\n\n        # Sort by marginal gain (descending)\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n        # Apply top 2 marginal changes\n        for _, idx, action in marginal_gains[:2]:\n            if action != 0:\n                new_solution[idx] = action\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 74,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution from the archive based on a combination of randomness and potential\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (1 + i) for i in range(len(archive))])[0]\n    base_solution, objectives = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-based selection\n    num_items = len(weight_lst)\n    for _ in range(min(5, num_items // 2)):  # Limit the number of swaps to avoid excessive computation\n        # Randomly select two items to swap\n        i, j = random.sample(range(num_items), 2)\n\n        # Calculate the change in weight and values if we swap i and j\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n        delta_value1 = (value1_lst[j] - value1_lst[i]) if new_solution[i] == 1 else (value1_lst[i] - value1_lst[j])\n        delta_value2 = (value2_lst[j] - value2_lst[i]) if new_solution[i] == 1 else (value2_lst[i] - value2_lst[j])\n\n        # Check if the swap is feasible and beneficial\n        if (current_weight + delta_weight <= capacity) and (delta_value1 > 0 or delta_value2 > 0):\n            # Perform the swap\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n            current_value1 += delta_value1\n            current_value2 += delta_value2\n\n    return new_solution\n\n",
        "score": [
            -0.4955010597136908,
            1.4853004813194275
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution from the archive based on a combination of randomness and potential\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (1 + i) for i in range(len(archive))])[0]\n    base_solution, objectives = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Hybrid local search: random swaps with value-based selection\n    num_items = len(weight_lst)\n    for _ in range(min(5, num_items // 2)):  # Limit the number of swaps to avoid excessive computation\n        # Randomly select two items to swap\n        i, j = random.sample(range(num_items), 2)\n\n        # Calculate the change in weight and values if we swap i and j\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n        delta_value1 = (value1_lst[j] - value1_lst[i]) if new_solution[i] == 1 else (value1_lst[i] - value1_lst[j])\n        delta_value2 = (value2_lst[j] - value2_lst[i]) if new_solution[i] == 1 else (value2_lst[i] - value2_lst[j])\n\n        # Check if the swap is feasible and beneficial\n        if (current_weight + delta_weight <= capacity) and (delta_value1 > 0 or delta_value2 > 0):\n            # Perform the swap\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n            current_value1 += delta_value1\n            current_value2 += delta_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 75,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with intelligent randomness (prioritize solutions near the Pareto front)\n    base_solution, _ = max(archive, key=lambda x: sum(x[0]) / len(x[0]))  # Select a solution with higher density of items\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flip and greedy improvement\n    # Step 1: Randomly flip a subset of items (20% of the items)\n    flip_indices = np.random.choice(len(new_solution), size=max(1, int(0.2 * len(new_solution))), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility: if total weight exceeds capacity, remove items with lowest marginal value\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Calculate marginal value for each item (value1 + value2)\n        marginal_value = (value1_lst + value2_lst) * new_solution\n        # Sort items by marginal value in ascending order\n        sorted_indices = np.argsort(marginal_value)\n        # Remove items until weight is within capacity\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Step 2: Greedily add items that improve at least one objective\n    remaining_capacity = capacity - np.sum(new_solution * weight_lst)\n    if remaining_capacity > 0:\n        # Calculate effective value for each item (normalized by weight)\n        effective_value1 = value1_lst / (weight_lst + 1e-6)\n        effective_value2 = value2_lst / (weight_lst + 1e-6)\n        # Sort items by effective value (sum of both objectives)\n        sorted_indices = np.argsort(-(effective_value1 + effective_value2))\n        # Add items until capacity is reached\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3712210514107908,
            2.0273654460906982
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with intelligent randomness (prioritize solutions near the Pareto front)\n    base_solution, _ = max(archive, key=lambda x: sum(x[0]) / len(x[0]))  # Select a solution with higher density of items\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flip and greedy improvement\n    # Step 1: Randomly flip a subset of items (20% of the items)\n    flip_indices = np.random.choice(len(new_solution), size=max(1, int(0.2 * len(new_solution))), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility: if total weight exceeds capacity, remove items with lowest marginal value\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Calculate marginal value for each item (value1 + value2)\n        marginal_value = (value1_lst + value2_lst) * new_solution\n        # Sort items by marginal value in ascending order\n        sorted_indices = np.argsort(marginal_value)\n        # Remove items until weight is within capacity\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Step 2: Greedily add items that improve at least one objective\n    remaining_capacity = capacity - np.sum(new_solution * weight_lst)\n    if remaining_capacity > 0:\n        # Calculate effective value for each item (normalized by weight)\n        effective_value1 = value1_lst / (weight_lst + 1e-6)\n        effective_value2 = value2_lst / (weight_lst + 1e-6)\n        # Sort items by effective value (sum of both objectives)\n        sorted_indices = np.argsort(-(effective_value1 + effective_value2))\n        # Add items until capacity is reached\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 76,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on marginal utility and diversity\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[1 / (1 + np.sum(archive[i][0]) * np.sum(weight_lst)) for i in range(len(archive))],\n        k=1\n    )[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swap and random flip with feasibility check\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for swap/flip\n    subset_size = min(10, n_items)\n    candidate_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    for i in candidate_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = new_weight\n\n    # Additional random flip to escape local optima\n    if random.random() < 0.3:\n        flip_idx = random.choice(candidate_indices)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4857486356439095,
            0.9259708821773529
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on marginal utility and diversity\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[1 / (1 + np.sum(archive[i][0]) * np.sum(weight_lst)) for i in range(len(archive))],\n        k=1\n    )[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swap and random flip with feasibility check\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for swap/flip\n    subset_size = min(10, n_items)\n    candidate_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    for i in candidate_indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = new_weight\n\n    # Additional random flip to escape local optima\n    if random.random() < 0.3:\n        flip_idx = random.choice(candidate_indices)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 77,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on the sum of normalized objectives\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Limit iterations to prevent excessive computation\n        # Option 1: Random flip with feasibility check\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n        # Option 2: Value-to-weight ratio-based selection (for one objective)\n        if random.random() < 0.3:  # 30% chance to try this\n            ratio = value1_lst / (weight_lst + 1e-10)\n            candidate_idx = np.argmax(ratio * (1 - new_solution))  # Consider only items not in solution\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n        # Option 3: Novel objective-aware swap (for both objectives)\n        if random.random() < 0.5:  # 50% chance to try this\n            in_items = np.where(new_solution == 1)[0]\n            out_items = np.where(new_solution == 0)[0]\n\n            if len(in_items) > 0 and len(out_items) > 0:\n                in_idx = random.choice(in_items)\n                out_idx = random.choice(out_items)\n\n                # Calculate potential new weight\n                new_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n\n                if new_weight <= capacity:\n                    # Calculate potential improvement in both objectives\n                    delta1 = value1_lst[out_idx] - value1_lst[in_idx]\n                    delta2 = value2_lst[out_idx] - value2_lst[in_idx]\n\n                    # Only accept if at least one objective improves\n                    if delta1 > 0 or delta2 > 0:\n                        new_solution[in_idx] = 0\n                        new_solution[out_idx] = 1\n                        current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.32940472514315106,
            1.4752126336097717
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on the sum of normalized objectives\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Limit iterations to prevent excessive computation\n        # Option 1: Random flip with feasibility check\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n        # Option 2: Value-to-weight ratio-based selection (for one objective)\n        if random.random() < 0.3:  # 30% chance to try this\n            ratio = value1_lst / (weight_lst + 1e-10)\n            candidate_idx = np.argmax(ratio * (1 - new_solution))  # Consider only items not in solution\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                current_weight += weight_lst[candidate_idx]\n\n        # Option 3: Novel objective-aware swap (for both objectives)\n        if random.random() < 0.5:  # 50% chance to try this\n            in_items = np.where(new_solution == 1)[0]\n            out_items = np.where(new_solution == 0)[0]\n\n            if len(in_items) > 0 and len(out_items) > 0:\n                in_idx = random.choice(in_items)\n                out_idx = random.choice(out_items)\n\n                # Calculate potential new weight\n                new_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n\n                if new_weight <= capacity:\n                    # Calculate potential improvement in both objectives\n                    delta1 = value1_lst[out_idx] - value1_lst[in_idx]\n                    delta2 = value2_lst[out_idx] - value2_lst[in_idx]\n\n                    # Only accept if at least one objective improves\n                    if delta1 > 0 or delta2 > 0:\n                        new_solution[in_idx] = 0\n                        new_solution[out_idx] = 1\n                        current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 78,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with a bias towards higher value-to-weight ratios\n    def selection_prob(solution):\n        total_weight = np.sum(weight_lst[solution == 1])\n        if total_weight == 0:\n            return 0.0\n        total_value1 = np.sum(value1_lst[solution == 1])\n        total_value2 = np.sum(value2_lst[solution == 1])\n        # Normalize by capacity to get a ratio\n        ratio1 = total_value1 / total_weight\n        ratio2 = total_value2 / total_weight\n        return (ratio1 + ratio2) / 2  # Combined metric\n\n    # Weighted random selection\n    weights = [selection_prob(sol[0]) for sol in archive]\n    if all(w == 0 for w in weights):\n        weights = [1.0 for _ in weights]  # Fallback to uniform if all zero\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly select a subset of items to consider for swapping\n    n_items = len(new_solution)\n    swap_candidates = random.sample(range(n_items), min(5, n_items))  # Consider up to 5 items\n\n    for i in swap_candidates:\n        # 2. For each candidate, decide whether to flip it based on value-to-weight ratio and current state\n        current_state = new_solution[i]\n        total_weight = np.sum(weight_lst[new_solution == 1])\n\n        if current_state == 1:\n            # If item is included, consider removing it if it's low-value or over capacity\n            if (value1_lst[i] + value2_lst[i]) < (np.mean(value1_lst) + np.mean(value2_lst)) or \\\n               (total_weight + weight_lst[i] > capacity):\n                new_solution[i] = 0\n        else:\n            # If item is excluded, consider adding it if it improves both objectives\n            if (total_weight + weight_lst[i] <= capacity) and \\\n               (value1_lst[i] > np.mean(value1_lst) or value2_lst[i] > np.mean(value2_lst)):\n                new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.40791811017045987,
            5.4770268201828
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with a bias towards higher value-to-weight ratios\n    def selection_prob(solution):\n        total_weight = np.sum(weight_lst[solution == 1])\n        if total_weight == 0:\n            return 0.0\n        total_value1 = np.sum(value1_lst[solution == 1])\n        total_value2 = np.sum(value2_lst[solution == 1])\n        # Normalize by capacity to get a ratio\n        ratio1 = total_value1 / total_weight\n        ratio2 = total_value2 / total_weight\n        return (ratio1 + ratio2) / 2  # Combined metric\n\n    # Weighted random selection\n    weights = [selection_prob(sol[0]) for sol in archive]\n    if all(w == 0 for w in weights):\n        weights = [1.0 for _ in weights]  # Fallback to uniform if all zero\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly select a subset of items to consider for swapping\n    n_items = len(new_solution)\n    swap_candidates = random.sample(range(n_items), min(5, n_items))  # Consider up to 5 items\n\n    for i in swap_candidates:\n        # 2. For each candidate, decide whether to flip it based on value-to-weight ratio and current state\n        current_state = new_solution[i]\n        total_weight = np.sum(weight_lst[new_solution == 1])\n\n        if current_state == 1:\n            # If item is included, consider removing it if it's low-value or over capacity\n            if (value1_lst[i] + value2_lst[i]) < (np.mean(value1_lst) + np.mean(value2_lst)) or \\\n               (total_weight + weight_lst[i] > capacity):\n                new_solution[i] = 0\n        else:\n            # If item is excluded, consider adding it if it improves both objectives\n            if (total_weight + weight_lst[i] <= capacity) and \\\n               (value1_lst[i] > np.mean(value1_lst) or value2_lst[i] > np.mean(value2_lst)):\n                new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 79,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to a random solution if all are infeasible\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    # Here, we select a solution that is not too crowded in the objective space (simplified heuristic)\n    base_solution = max(candidates, key=lambda x: np.sum(value1_lst * x) + np.sum(value2_lst * x))\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_items = len(new_solution)\n    swap_indices = random.sample(range(n_items), min(3, n_items))  # Swap up to 3 items\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high value-to-weight ratio (exploitation)\n    value_to_weight_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_to_weight_ratio)[::-1]  # Descending order\n    for idx in sorted_indices[:min(5, n_items)]:  # Consider top 5 items\n        if random.random() < 0.3:  # 30% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        # Remove items with lowest value-to-weight ratio until feasible\n        sorted_indices = np.argsort(value_to_weight_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess > 0:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n            if excess <= 0:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.3023629911577182,
            2.623727262020111
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to a random solution if all are infeasible\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    # Here, we select a solution that is not too crowded in the objective space (simplified heuristic)\n    base_solution = max(candidates, key=lambda x: np.sum(value1_lst * x) + np.sum(value2_lst * x))\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_items = len(new_solution)\n    swap_indices = random.sample(range(n_items), min(3, n_items))  # Swap up to 3 items\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high value-to-weight ratio (exploitation)\n    value_to_weight_ratio = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_to_weight_ratio)[::-1]  # Descending order\n    for idx in sorted_indices[:min(5, n_items)]:  # Consider top 5 items\n        if random.random() < 0.3:  # 30% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        # Remove items with lowest value-to-weight ratio until feasible\n        sorted_indices = np.argsort(value_to_weight_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess > 0:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n            if excess <= 0:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 80,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty\")\n\n    # Step 1: Select a promising solution with high potential\n    # Sort solutions by their objective values (prioritize high values)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n\n    # Select top 20% solutions or at least 2 solutions\n    top_n = max(2, int(len(archive_sorted) * 0.2))\n    candidates = archive_sorted[:top_n]\n    selected_idx = random.randint(0, top_n - 1)\n    base_solution, _ = candidates[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine gains with randomness for exploration\n    combined_gains = 0.7 * marginal_gains1 + 0.3 * marginal_gains2 + 0.1 * np.random.rand(n_items)\n\n    # Determine how many items to flip (between 1 and 10% of items)\n    flip_count = min(max(1, int(0.1 * n_items)), n_items)\n\n    # Select items to flip based on combined gains\n    flip_indices = np.argsort(combined_gains)[-flip_count:]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is currently included, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is currently excluded, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional diversification: flip one random bit if no improvement is made\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.randint(0, n_items - 1)\n        if new_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9025059848402185,
            0.9025804102420807
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty\")\n\n    # Step 1: Select a promising solution with high potential\n    # Sort solutions by their objective values (prioritize high values)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n\n    # Select top 20% solutions or at least 2 solutions\n    top_n = max(2, int(len(archive_sorted) * 0.2))\n    candidates = archive_sorted[:top_n]\n    selected_idx = random.randint(0, top_n - 1)\n    base_solution, _ = candidates[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine gains with randomness for exploration\n    combined_gains = 0.7 * marginal_gains1 + 0.3 * marginal_gains2 + 0.1 * np.random.rand(n_items)\n\n    # Determine how many items to flip (between 1 and 10% of items)\n    flip_count = min(max(1, int(0.1 * n_items)), n_items)\n\n    # Select items to flip based on combined gains\n    flip_indices = np.argsort(combined_gains)[-flip_count:]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is currently included, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is currently excluded, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional diversification: flip one random bit if no improvement is made\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.randint(0, n_items - 1)\n        if new_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 81,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (simple heuristic)\n    selected_solution = archive[0][0].copy()\n    selected_value1, selected_value2 = archive[0][1]\n\n    # Initialize new solution\n    new_solution = selected_solution.copy()\n\n    # Step 1: Randomly flip a subset of items to introduce diversity\n    flip_indices = random.sample(range(len(new_solution)), min(3, len(new_solution)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        while total_weight > capacity and len(excess_indices) > 0:\n            remove_idx = random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            excess_indices = np.where(new_solution == 1)[0]\n\n    # Step 2: Greedy improvement step for both objectives\n    # Calculate marginal gains for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by marginal value for objective 1\n    sorted_indices1 = np.argsort(marginal_value1)[::-1]\n\n    # Try adding items with highest marginal value for objective 1 if feasible\n    for idx in sorted_indices1:\n        if new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Sort items by marginal value for objective 2\n    sorted_indices2 = np.argsort(marginal_value2)[::-1]\n\n    # Try adding items with highest marginal value for objective 2 if feasible\n    for idx in sorted_indices2:\n        if new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Step 3: Local fine-tuning - flip one item if it improves both objectives\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = total_weight - weight_lst[idx]\n            temp_value1 = selected_value1 - value1_lst[idx]\n            temp_value2 = selected_value2 - value2_lst[idx]\n\n            # Check if removal improves both objectives\n            if temp_weight <= capacity and temp_value1 > selected_value1 and temp_value2 > selected_value2:\n                new_solution = temp_solution\n                total_weight = temp_weight\n                selected_value1 = temp_value1\n                selected_value2 = temp_value2\n        else:\n            # Try adding the item if feasible\n            if total_weight + weight_lst[idx] <= capacity:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = selected_value1 + value1_lst[idx]\n                temp_value2 = selected_value2 + value2_lst[idx]\n\n                # Check if addition improves both objectives\n                if temp_value1 > selected_value1 and temp_value2 > selected_value2:\n                    new_solution = temp_solution\n                    total_weight += weight_lst[idx]\n                    selected_value1 = temp_value1\n                    selected_value2 = temp_value2\n\n    return new_solution\n\n",
        "score": [
            -0.3593715458329162,
            3.169307768344879
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (simple heuristic)\n    selected_solution = archive[0][0].copy()\n    selected_value1, selected_value2 = archive[0][1]\n\n    # Initialize new solution\n    new_solution = selected_solution.copy()\n\n    # Step 1: Randomly flip a subset of items to introduce diversity\n    flip_indices = random.sample(range(len(new_solution)), min(3, len(new_solution)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        while total_weight > capacity and len(excess_indices) > 0:\n            remove_idx = random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            excess_indices = np.where(new_solution == 1)[0]\n\n    # Step 2: Greedy improvement step for both objectives\n    # Calculate marginal gains for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by marginal value for objective 1\n    sorted_indices1 = np.argsort(marginal_value1)[::-1]\n\n    # Try adding items with highest marginal value for objective 1 if feasible\n    for idx in sorted_indices1:\n        if new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Sort items by marginal value for objective 2\n    sorted_indices2 = np.argsort(marginal_value2)[::-1]\n\n    # Try adding items with highest marginal value for objective 2 if feasible\n    for idx in sorted_indices2:\n        if new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Step 3: Local fine-tuning - flip one item if it improves both objectives\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = total_weight - weight_lst[idx]\n            temp_value1 = selected_value1 - value1_lst[idx]\n            temp_value2 = selected_value2 - value2_lst[idx]\n\n            # Check if removal improves both objectives\n            if temp_weight <= capacity and temp_value1 > selected_value1 and temp_value2 > selected_value2:\n                new_solution = temp_solution\n                total_weight = temp_weight\n                selected_value1 = temp_value1\n                selected_value2 = temp_value2\n        else:\n            # Try adding the item if feasible\n            if total_weight + weight_lst[idx] <= capacity:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_value1 = selected_value1 + value1_lst[idx]\n                temp_value2 = selected_value2 + value2_lst[idx]\n\n                # Check if addition improves both objectives\n                if temp_value1 > selected_value1 and temp_value2 > selected_value2:\n                    new_solution = temp_solution\n                    total_weight += weight_lst[idx]\n                    selected_value1 = temp_value1\n                    selected_value2 = temp_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 82,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the current archive\n    base_solution, base_objective = archive[np.random.choice(len(archive))]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip bits intelligently\n    for _ in range(10):  # Limit the number of attempts to avoid excessive computation\n        # Randomly select a candidate item to flip\n        candidate_idx = np.random.randint(0, len(new_solution))\n\n        if new_solution[candidate_idx] == 1:\n            # If the item is currently included, try to exclude it if it doesn't improve both objectives\n            new_weight = current_weight - weight_lst[candidate_idx]\n            if new_weight <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight = new_weight\n        else:\n            # If the item is currently excluded, try to include it if it improves both objectives\n            new_weight = current_weight + weight_lst[candidate_idx]\n            if new_weight <= capacity:\n                # Check if including this item would improve both objectives\n                if (value1_lst[candidate_idx] > 0) and (value2_lst[candidate_idx] > 0):\n                    new_solution[candidate_idx] = 1\n                    current_weight = new_weight\n\n    # Additional greedy improvement: try to add items that have high value-to-weight ratio for both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Create a combined score (geometric mean of ratios)\n        combined_score = np.sqrt(v1_ratio * v2_ratio)\n\n        # Sort items by combined score in descending order\n        sorted_indices = np.argsort(-combined_score)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3770232921149842,
            1.5703650414943695
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the current archive\n    base_solution, base_objective = archive[np.random.choice(len(archive))]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip bits intelligently\n    for _ in range(10):  # Limit the number of attempts to avoid excessive computation\n        # Randomly select a candidate item to flip\n        candidate_idx = np.random.randint(0, len(new_solution))\n\n        if new_solution[candidate_idx] == 1:\n            # If the item is currently included, try to exclude it if it doesn't improve both objectives\n            new_weight = current_weight - weight_lst[candidate_idx]\n            if new_weight <= capacity:\n                new_solution[candidate_idx] = 0\n                current_weight = new_weight\n        else:\n            # If the item is currently excluded, try to include it if it improves both objectives\n            new_weight = current_weight + weight_lst[candidate_idx]\n            if new_weight <= capacity:\n                # Check if including this item would improve both objectives\n                if (value1_lst[candidate_idx] > 0) and (value2_lst[candidate_idx] > 0):\n                    new_solution[candidate_idx] = 1\n                    current_weight = new_weight\n\n    # Additional greedy improvement: try to add items that have high value-to-weight ratio for both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Create a combined score (geometric mean of ratios)\n        combined_score = np.sqrt(v1_ratio * v2_ratio)\n\n        # Sort items by combined score in descending order\n        sorted_indices = np.argsort(-combined_score)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 83,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = archive[np.random.choice(len(archive))]\n    current_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst[current_solution == 1])\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Number of local search steps\n        # Step 1: Random swap of two items\n        indices = np.where(current_solution == 1)[0]\n        if len(indices) >= 2:\n            i, j = np.random.choice(indices, 2, replace=False)\n            new_solution = current_solution.copy()\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            new_weight = np.sum(weight_lst[new_solution == 1])\n            if new_weight <= capacity:\n                current_solution = new_solution\n                current_weight = new_weight\n\n        # Step 2: Flip an item based on value-to-weight ratio\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            value_ratio1 = value1_lst / (weight_lst + 1e-6)\n            value_ratio2 = value2_lst / (weight_lst + 1e-6)\n            combined_ratio = value_ratio1 + value_ratio2\n            sorted_indices = np.argsort(-combined_ratio)  # Highest ratio first\n            for idx in sorted_indices:\n                if current_solution[idx] == 1:\n                    new_solution = current_solution.copy()\n                    new_solution[idx] = 0\n                    new_weight = current_weight - weight_lst[idx]\n                    if new_weight >= 0:\n                        current_solution = new_solution\n                        current_weight = new_weight\n                        break\n                else:\n                    new_solution = current_solution.copy()\n                    new_solution[idx] = 1\n                    new_weight = current_weight + weight_lst[idx]\n                    if new_weight <= capacity:\n                        current_solution = new_solution\n                        current_weight = new_weight\n                        break\n\n    return current_solution\n\n",
        "score": [
            -0.6159015763445,
            9.153044879436493
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = archive[np.random.choice(len(archive))]\n    current_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst[current_solution == 1])\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Number of local search steps\n        # Step 1: Random swap of two items\n        indices = np.where(current_solution == 1)[0]\n        if len(indices) >= 2:\n            i, j = np.random.choice(indices, 2, replace=False)\n            new_solution = current_solution.copy()\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            new_weight = np.sum(weight_lst[new_solution == 1])\n            if new_weight <= capacity:\n                current_solution = new_solution\n                current_weight = new_weight\n\n        # Step 2: Flip an item based on value-to-weight ratio\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            value_ratio1 = value1_lst / (weight_lst + 1e-6)\n            value_ratio2 = value2_lst / (weight_lst + 1e-6)\n            combined_ratio = value_ratio1 + value_ratio2\n            sorted_indices = np.argsort(-combined_ratio)  # Highest ratio first\n            for idx in sorted_indices:\n                if current_solution[idx] == 1:\n                    new_solution = current_solution.copy()\n                    new_solution[idx] = 0\n                    new_weight = current_weight - weight_lst[idx]\n                    if new_weight >= 0:\n                        current_solution = new_solution\n                        current_weight = new_weight\n                        break\n                else:\n                    new_solution = current_solution.copy()\n                    new_solution[idx] = 1\n                    new_weight = current_weight + weight_lst[idx]\n                    if new_weight <= capacity:\n                        current_solution = new_solution\n                        current_weight = new_weight\n                        break\n\n    return current_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 84,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions with high potential for improvement (margin-based selection)\n    margins = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        # Calculate margin for each objective\n        margin1 = np.sum(value1_lst * (1 - sol))  # Potential additional value1 if all remaining items were added\n        margin2 = np.sum(value2_lst * (1 - sol))  # Potential additional value2 if all remaining items were added\n        # Combine margins with a weighted approach\n        combined_margin = margin1 + margin2\n        margins.append(combined_margin)\n\n    # Select top 30% of solutions with highest margins\n    top_indices = np.argsort(margins)[-max(1, len(margins) // 3):]\n    selected_sol, _ = random.choice([archive[i] for i in top_indices])\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = selected_sol.copy()\n\n    # Strategy 1: Random flip with value-weighted probability\n    if random.random() < 0.7:  # 70% chance to try random flip\n        # Calculate value-weighted probabilities for flipping\n        flip_probs = (value1_lst + value2_lst) / np.sum(value1_lst + value2_lst)\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) > 0:\n            # Prefer flipping items with high value\n            flip_idx = np.random.choice(candidate_indices, p=flip_probs[candidate_indices]/np.sum(flip_probs[candidate_indices]))\n            new_solution[flip_idx] = 0\n\n            # Try to add a new item that fits\n            available_indices = np.where((new_solution == 0) & (weight_lst <= capacity - np.sum(weight_lst * new_solution)))[0]\n            if len(available_indices) > 0:\n                add_idx = np.random.choice(available_indices, p=flip_probs[available_indices]/np.sum(flip_probs[available_indices]))\n                new_solution[add_idx] = 1\n\n    # Strategy 2: Value-weighted swap operator\n    else:\n        # Find items that can be swapped (value1 and value2 improvements)\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) >= 2:\n            # Select two items to swap\n            i, j = random.sample(list(candidate_items), 2)\n\n            # Calculate potential improvement\n            delta_value1 = value1_lst[j] - value1_lst[i]\n            delta_value2 = value2_lst[j] - value2_lst[i]\n            delta_weight = weight_lst[j] - weight_lst[i]\n\n            # Accept swap if it improves at least one objective\n            if (delta_value1 > 0 or delta_value2 > 0) and np.sum(weight_lst * new_solution) + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution remains feasible\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove random item if overweight\n        overweight_items = np.where(new_solution == 1)[0]\n        if len(overweight_items) > 0:\n            remove_idx = random.choice(overweight_items)\n            new_solution[remove_idx] = 0\n        else:\n            break  # No items to remove, solution is invalid\n\n    return new_solution\n\n",
        "score": [
            -0.8581373687922546,
            3.2526666820049286
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions with high potential for improvement (margin-based selection)\n    margins = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        # Calculate margin for each objective\n        margin1 = np.sum(value1_lst * (1 - sol))  # Potential additional value1 if all remaining items were added\n        margin2 = np.sum(value2_lst * (1 - sol))  # Potential additional value2 if all remaining items were added\n        # Combine margins with a weighted approach\n        combined_margin = margin1 + margin2\n        margins.append(combined_margin)\n\n    # Select top 30% of solutions with highest margins\n    top_indices = np.argsort(margins)[-max(1, len(margins) // 3):]\n    selected_sol, _ = random.choice([archive[i] for i in top_indices])\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = selected_sol.copy()\n\n    # Strategy 1: Random flip with value-weighted probability\n    if random.random() < 0.7:  # 70% chance to try random flip\n        # Calculate value-weighted probabilities for flipping\n        flip_probs = (value1_lst + value2_lst) / np.sum(value1_lst + value2_lst)\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) > 0:\n            # Prefer flipping items with high value\n            flip_idx = np.random.choice(candidate_indices, p=flip_probs[candidate_indices]/np.sum(flip_probs[candidate_indices]))\n            new_solution[flip_idx] = 0\n\n            # Try to add a new item that fits\n            available_indices = np.where((new_solution == 0) & (weight_lst <= capacity - np.sum(weight_lst * new_solution)))[0]\n            if len(available_indices) > 0:\n                add_idx = np.random.choice(available_indices, p=flip_probs[available_indices]/np.sum(flip_probs[available_indices]))\n                new_solution[add_idx] = 1\n\n    # Strategy 2: Value-weighted swap operator\n    else:\n        # Find items that can be swapped (value1 and value2 improvements)\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) >= 2:\n            # Select two items to swap\n            i, j = random.sample(list(candidate_items), 2)\n\n            # Calculate potential improvement\n            delta_value1 = value1_lst[j] - value1_lst[i]\n            delta_value2 = value2_lst[j] - value2_lst[i]\n            delta_weight = weight_lst[j] - weight_lst[i]\n\n            # Accept swap if it improves at least one objective\n            if (delta_value1 > 0 or delta_value2 > 0) and np.sum(weight_lst * new_solution) + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution remains feasible\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove random item if overweight\n        overweight_items = np.where(new_solution == 1)[0]\n        if len(overweight_items) > 0:\n            remove_idx = random.choice(overweight_items)\n            new_solution[remove_idx] = 0\n        else:\n            break  # No items to remove, solution is invalid\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 85,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution intelligently (e.g., with high potential for improvement)\n    # We prioritize solutions that have both objectives above a certain threshold or are on the Pareto front\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.dot(sol, weight_lst)\n        if total_weight <= capacity:\n            # Simple heuristic: solutions with high combined value and not too close to capacity\n            combined_value = obj[0] + obj[1]\n            candidates.append((sol, combined_value, total_weight))\n\n    if not candidates:\n        # Fallback: if no candidates, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest combined value\n        base_solution = max(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search operator\n    # Hybrid of:\n    # 1. Random flip of a subset of items (to escape local optima)\n    # 2. Greedy addition of items with high marginal value-to-weight ratio\n    # 3. Removal of items with low marginal value-to-weight ratio\n\n    # 1. Random flip (with probability 0.3)\n    if random.random() < 0.3:\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Greedy addition of high-value items\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Calculate marginal value-to-weight ratios for items not in the solution\n    marginal_ratio1 = (value1_lst - np.dot(new_solution, value1_lst)) / (weight_lst + 1e-10)\n    marginal_ratio2 = (value2_lst - np.dot(new_solution, value2_lst)) / (weight_lst + 1e-10)\n\n    # Combine ratios (simple average)\n    combined_ratio = 0.5 * marginal_ratio1 + 0.5 * marginal_ratio2\n\n    # Sort by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Try to add top items until capacity is reached\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # 3. Removal of low-value items\n    # Calculate marginal ratios for items in the solution\n    marginal_ratio1 = value1_lst / (weight_lst + 1e-10)\n    marginal_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = 0.5 * marginal_ratio1 + 0.5 * marginal_ratio2\n\n    # Sort by combined ratio in ascending order\n    sorted_indices = np.argsort(combined_ratio)\n\n    # Try to remove worst items until feasible\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = np.dot(temp_solution, weight_lst)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.9390720557751371,
            2.9505019783973694
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution intelligently (e.g., with high potential for improvement)\n    # We prioritize solutions that have both objectives above a certain threshold or are on the Pareto front\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.dot(sol, weight_lst)\n        if total_weight <= capacity:\n            # Simple heuristic: solutions with high combined value and not too close to capacity\n            combined_value = obj[0] + obj[1]\n            candidates.append((sol, combined_value, total_weight))\n\n    if not candidates:\n        # Fallback: if no candidates, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest combined value\n        base_solution = max(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search operator\n    # Hybrid of:\n    # 1. Random flip of a subset of items (to escape local optima)\n    # 2. Greedy addition of items with high marginal value-to-weight ratio\n    # 3. Removal of items with low marginal value-to-weight ratio\n\n    # 1. Random flip (with probability 0.3)\n    if random.random() < 0.3:\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Greedy addition of high-value items\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Calculate marginal value-to-weight ratios for items not in the solution\n    marginal_ratio1 = (value1_lst - np.dot(new_solution, value1_lst)) / (weight_lst + 1e-10)\n    marginal_ratio2 = (value2_lst - np.dot(new_solution, value2_lst)) / (weight_lst + 1e-10)\n\n    # Combine ratios (simple average)\n    combined_ratio = 0.5 * marginal_ratio1 + 0.5 * marginal_ratio2\n\n    # Sort by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Try to add top items until capacity is reached\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # 3. Removal of low-value items\n    # Calculate marginal ratios for items in the solution\n    marginal_ratio1 = value1_lst / (weight_lst + 1e-10)\n    marginal_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = 0.5 * marginal_ratio1 + 0.5 * marginal_ratio2\n\n    # Sort by combined ratio in ascending order\n    sorted_indices = np.argsort(combined_ratio)\n\n    # Try to remove worst items until feasible\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = np.dot(temp_solution, weight_lst)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 86,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with high potential for improvement\n    base_solution, (base_value1, base_value2) = random.choices(\n        archive,\n        weights=[(1 + np.sum(sol[0])) for sol in archive],  # Prefer solutions with more items\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select a subset of items to flip (1 to 5 items)\n    flip_indices = random.sample(range(len(new_solution)), min(5, len(new_solution)))\n\n    for idx in flip_indices:\n        # Try flipping the item\n        if new_solution[idx] == 1:\n            # Remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Add the item if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedily improve the solution by adding items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.43897626504802734,
            3.1878810822963715
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with high potential for improvement\n    base_solution, (base_value1, base_value2) = random.choices(\n        archive,\n        weights=[(1 + np.sum(sol[0])) for sol in archive],  # Prefer solutions with more items\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select a subset of items to flip (1 to 5 items)\n    flip_indices = random.sample(range(len(new_solution)), min(5, len(new_solution)))\n\n    for idx in flip_indices:\n        # Try flipping the item\n        if new_solution[idx] == 1:\n            # Remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Add the item if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedily improve the solution by adding items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 87,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher potential for improvement\n    # We define potential as the ratio of the sum of marginal gains for items not in the solution\n    potentials = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        # Calculate potential by considering items not in the solution\n        not_in_sol = 1 - sol\n        # Normalize potential by the number of items not in the solution to avoid bias\n        potential = np.sum(value1_lst * not_in_sol) + np.sum(value2_lst * not_in_sol)\n        potential /= max(1, np.sum(not_in_sol))  # Avoid division by zero\n        potentials.append(potential)\n\n    # Select solution with highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with a bias towards those that can be added without exceeding capacity)\n    # 2. If the solution is still feasible, perform a greedy swap of items that improve both objectives\n\n    # Step 1: Random flip with capacity consideration\n    not_in_sol = 1 - base_solution\n    feasible_items = (weight_lst <= (capacity - np.sum(weight_lst * base_solution)))\n    flip_candidates = np.where((not_in_sol == 1) & feasible_items)[0]\n\n    if len(flip_candidates) > 0:\n        num_flips = min(3, len(flip_candidates))  # Limit the number of flips\n        flip_indices = random.sample(list(flip_candidates), num_flips)\n        new_solution[flip_indices] = 1\n\n    # Step 2: Greedy swap for improvement\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Find items not in the solution that can be added without exceeding capacity\n    add_candidates = np.where((1 - new_solution) & (weight_lst <= remaining_capacity))[0]\n\n    if len(add_candidates) > 0:\n        # Evaluate items by their combined value improvement\n        value_improvements = value1_lst + value2_lst\n        best_candidate = add_candidates[np.argmax(value_improvements[add_candidates])]\n\n        # Check if adding this item improves both objectives\n        if (value_improvements[best_candidate] > 0) and (current_weight + weight_lst[best_candidate] <= capacity):\n            new_solution[best_candidate] = 1\n\n    # Ensure the solution is feasible\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break  # Shouldn't happen due to previous checks\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8034706023041203,
            3.3069968223571777
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher potential for improvement\n    # We define potential as the ratio of the sum of marginal gains for items not in the solution\n    potentials = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        # Calculate potential by considering items not in the solution\n        not_in_sol = 1 - sol\n        # Normalize potential by the number of items not in the solution to avoid bias\n        potential = np.sum(value1_lst * not_in_sol) + np.sum(value2_lst * not_in_sol)\n        potential /= max(1, np.sum(not_in_sol))  # Avoid division by zero\n        potentials.append(potential)\n\n    # Select solution with highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with a bias towards those that can be added without exceeding capacity)\n    # 2. If the solution is still feasible, perform a greedy swap of items that improve both objectives\n\n    # Step 1: Random flip with capacity consideration\n    not_in_sol = 1 - base_solution\n    feasible_items = (weight_lst <= (capacity - np.sum(weight_lst * base_solution)))\n    flip_candidates = np.where((not_in_sol == 1) & feasible_items)[0]\n\n    if len(flip_candidates) > 0:\n        num_flips = min(3, len(flip_candidates))  # Limit the number of flips\n        flip_indices = random.sample(list(flip_candidates), num_flips)\n        new_solution[flip_indices] = 1\n\n    # Step 2: Greedy swap for improvement\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Find items not in the solution that can be added without exceeding capacity\n    add_candidates = np.where((1 - new_solution) & (weight_lst <= remaining_capacity))[0]\n\n    if len(add_candidates) > 0:\n        # Evaluate items by their combined value improvement\n        value_improvements = value1_lst + value2_lst\n        best_candidate = add_candidates[np.argmax(value_improvements[add_candidates])]\n\n        # Check if adding this item improves both objectives\n        if (value_improvements[best_candidate] > 0) and (current_weight + weight_lst[best_candidate] <= capacity):\n            new_solution[best_candidate] = 1\n\n    # Ensure the solution is feasible\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break  # Shouldn't happen due to previous checks\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 88,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    norm_objectives = objectives / np.linalg.norm(objectives, axis=0, keepdims=True)\n    weights = np.sum(norm_objectives, axis=1)\n    weights /= np.sum(weights)\n\n    base_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[base_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    if random.random() < 0.7:  # 70% chance for value-based perturbation\n        # Identify items with high marginal value-to-weight ratio for both objectives\n        marginal_value1 = value1_lst / (weight_lst + 1e-6)\n        marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine both objectives' marginal values\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n\n        # Sort items by combined marginal value (descending)\n        sorted_items = np.argsort(-combined_marginal)\n\n        # Try to add or remove items based on their position in the sorted list\n        for item in sorted_items:\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            elif new_solution[item] == 1 and random.random() < 0.3:  # 30% chance to remove\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n    else:  # 30% chance for random perturbation\n        # Randomly select a number of items to flip (between 1 and 10% of total items)\n        num_flips = min(random.randint(1, max(1, len(weight_lst) // 10)), len(weight_lst))\n\n        # Randomly select items to flip\n        items_to_flip = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n        for item in items_to_flip:\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            elif new_solution[item] == 1:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.4427275075191202,
            1.5679515600204468
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    norm_objectives = objectives / np.linalg.norm(objectives, axis=0, keepdims=True)\n    weights = np.sum(norm_objectives, axis=1)\n    weights /= np.sum(weights)\n\n    base_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[base_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    if random.random() < 0.7:  # 70% chance for value-based perturbation\n        # Identify items with high marginal value-to-weight ratio for both objectives\n        marginal_value1 = value1_lst / (weight_lst + 1e-6)\n        marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine both objectives' marginal values\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n\n        # Sort items by combined marginal value (descending)\n        sorted_items = np.argsort(-combined_marginal)\n\n        # Try to add or remove items based on their position in the sorted list\n        for item in sorted_items:\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            elif new_solution[item] == 1 and random.random() < 0.3:  # 30% chance to remove\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n    else:  # 30% chance for random perturbation\n        # Randomly select a number of items to flip (between 1 and 10% of total items)\n        num_flips = min(random.randint(1, max(1, len(weight_lst) // 10)), len(weight_lst))\n\n        # Randomly select items to flip\n        items_to_flip = np.random.choice(len(weight_lst), num_flips, replace=False)\n\n        for item in items_to_flip:\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            elif new_solution[item] == 1:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 89,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the current Pareto front\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(archive))\n    objectives_array = np.array(archive_objectives)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives_array[:, m])\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            crowding_distances[sorted_idx[i]] += (objectives_array[sorted_idx[i+1], m] - objectives_array[sorted_idx[i-1], m]) / (objectives_array[sorted_idx[-1], m] - objectives_array[sorted_idx[0], m])\n\n    # Select the solution with the highest crowding distance (less crowded)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate a neighbor using a hybrid strategy: random flip followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip: randomly select k items to flip (k is a small number)\n    k = min(3, len(base_solution))  # Flip up to 3 items\n    flip_indices = random.sample(range(len(base_solution)), k)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Ensure the flip is feasible\n            if np.dot(new_solution, weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.dot(new_solution, weight_lst)\n\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if value1_lst[idx] > 0 and value2_lst[idx] > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure the solution is feasible\n    while np.dot(new_solution, weight_lst) > capacity:\n        # Remove items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6825137619037516,
            2.366159200668335
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the current Pareto front\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(archive))\n    objectives_array = np.array(archive_objectives)\n\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives_array[:, m])\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            crowding_distances[sorted_idx[i]] += (objectives_array[sorted_idx[i+1], m] - objectives_array[sorted_idx[i-1], m]) / (objectives_array[sorted_idx[-1], m] - objectives_array[sorted_idx[0], m])\n\n    # Select the solution with the highest crowding distance (less crowded)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate a neighbor using a hybrid strategy: random flip followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip: randomly select k items to flip (k is a small number)\n    k = min(3, len(base_solution))  # Flip up to 3 items\n    flip_indices = random.sample(range(len(base_solution)), k)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Ensure the flip is feasible\n            if np.dot(new_solution, weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.dot(new_solution, weight_lst)\n\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if value1_lst[idx] > 0 and value2_lst[idx] > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure the solution is feasible\n    while np.dot(new_solution, weight_lst) > capacity:\n        # Remove items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 90,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a promising solution from the archive\n    # Prefer solutions with high value-to-weight ratios for both objectives\n    ratios = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(sol * weight_lst)\n        ratio1 = val1 / (total_weight + 1e-10)  # Avoid division by zero\n        ratio2 = val2 / (total_weight + 1e-10)\n        ratios.append((ratio1 + ratio2) / 2)  # Combined ratio for both objectives\n\n    # Select top 20% of solutions with highest combined ratios\n    top_indices = np.argsort(ratios)[-max(1, len(ratios) // 5):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # First, try to add items that improve both objectives while keeping weight feasible\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Check if adding this item improves both objectives\n            val1_gain = value1_lst[i]\n            val2_gain = value2_lst[i]\n            # If we can find at least one other item to remove that maintains feasibility\n            # and doesn't worsen the objectives, we can proceed\n            for j in range(len(new_solution)):\n                if new_solution[j] == 1 and (current_weight + weight_lst[i] - weight_lst[j]) <= capacity:\n                    # Check if removing j and adding i improves both objectives\n                    # This is a simplified check - in practice you might want a more sophisticated evaluation\n                    if val1_gain > 0 and val2_gain > 0:\n                        new_solution[i] = 1\n                        new_solution[j] = 0\n                        current_weight = np.sum(new_solution * weight_lst)\n                        break\n            if new_solution[i] == 1:\n                break\n\n    # If no improvement found, perform a random flip with feasibility check\n    if np.array_equal(new_solution, base_solution):\n        # Randomly select items to flip\n        candidates = [i for i in range(len(new_solution)) if new_solution[i] == 1 or (new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity)]\n        if candidates:\n            idx = random.choice(candidates)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8937638313572719,
            2.1337000727653503
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a promising solution from the archive\n    # Prefer solutions with high value-to-weight ratios for both objectives\n    ratios = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(sol * weight_lst)\n        ratio1 = val1 / (total_weight + 1e-10)  # Avoid division by zero\n        ratio2 = val2 / (total_weight + 1e-10)\n        ratios.append((ratio1 + ratio2) / 2)  # Combined ratio for both objectives\n\n    # Select top 20% of solutions with highest combined ratios\n    top_indices = np.argsort(ratios)[-max(1, len(ratios) // 5):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # First, try to add items that improve both objectives while keeping weight feasible\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            # Check if adding this item improves both objectives\n            val1_gain = value1_lst[i]\n            val2_gain = value2_lst[i]\n            # If we can find at least one other item to remove that maintains feasibility\n            # and doesn't worsen the objectives, we can proceed\n            for j in range(len(new_solution)):\n                if new_solution[j] == 1 and (current_weight + weight_lst[i] - weight_lst[j]) <= capacity:\n                    # Check if removing j and adding i improves both objectives\n                    # This is a simplified check - in practice you might want a more sophisticated evaluation\n                    if val1_gain > 0 and val2_gain > 0:\n                        new_solution[i] = 1\n                        new_solution[j] = 0\n                        current_weight = np.sum(new_solution * weight_lst)\n                        break\n            if new_solution[i] == 1:\n                break\n\n    # If no improvement found, perform a random flip with feasibility check\n    if np.array_equal(new_solution, base_solution):\n        # Randomly select items to flip\n        candidates = [i for i in range(len(new_solution)) if new_solution[i] == 1 or (new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity)]\n        if candidates:\n            idx = random.choice(candidates)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 91,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_solution = max(archive, key=lambda x: (x[1][0] + x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip\n    # 2. Use a value-to-weight ratio heuristic to prioritize flips\n    n_items = len(weight_lst)\n    num_flips = min(3, n_items)  # Limit the number of flips for efficiency\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios for a balanced approach\n    combined_ratio = (ratio1 + ratio2) / 2\n\n    # Select items to flip based on combined ratio and current solution state\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        # Prioritize removing items with low combined ratio\n        items_to_remove = sorted(candidates, key=lambda x: combined_ratio[x])[:num_flips//2]\n        for item in items_to_remove:\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    # Add items with high combined ratio that fit\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        # Prioritize adding items with high combined ratio\n        items_to_add = sorted(candidates, key=lambda x: -combined_ratio[x])[:num_flips - num_flips//2]\n        for item in items_to_add:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Additional random flip to maintain diversity\n    if random.random() < 0.3 and len(candidates) > 0:\n        random_item = random.choice(candidates)\n        if new_solution[random_item] == 0 and current_weight + weight_lst[random_item] <= capacity:\n            new_solution[random_item] = 1\n        elif new_solution[random_item] == 1 and current_weight - weight_lst[random_item] <= capacity:\n            new_solution[random_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.2731223117579609,
            5.09452360868454
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_solution = max(archive, key=lambda x: (x[1][0] + x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip\n    # 2. Use a value-to-weight ratio heuristic to prioritize flips\n    n_items = len(weight_lst)\n    num_flips = min(3, n_items)  # Limit the number of flips for efficiency\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios for a balanced approach\n    combined_ratio = (ratio1 + ratio2) / 2\n\n    # Select items to flip based on combined ratio and current solution state\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        # Prioritize removing items with low combined ratio\n        items_to_remove = sorted(candidates, key=lambda x: combined_ratio[x])[:num_flips//2]\n        for item in items_to_remove:\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    # Add items with high combined ratio that fit\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        # Prioritize adding items with high combined ratio\n        items_to_add = sorted(candidates, key=lambda x: -combined_ratio[x])[:num_flips - num_flips//2]\n        for item in items_to_add:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Additional random flip to maintain diversity\n    if random.random() < 0.3 and len(candidates) > 0:\n        random_item = random.choice(candidates)\n        if new_solution[random_item] == 0 and current_weight + weight_lst[random_item] <= capacity:\n            new_solution[random_item] = 1\n        elif new_solution[random_item] == 1 and current_weight - weight_lst[random_item] <= capacity:\n            new_solution[random_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 92,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with promising potential for improvement\n    # Here, we select a solution that is not already at the boundary of the Pareto front\n    # and has a reasonable balance between the two objectives\n    selected_solution = None\n    for sol, obj in archive:\n        # Check if the solution is not already optimal in both objectives\n        if obj[0] < sum(value1_lst) or obj[1] < sum(value2_lst):\n            selected_solution = sol.copy()\n            break\n    if selected_solution is None:\n        selected_solution = archive[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of bits to explore the neighborhood\n    # 2. Apply a greedy improvement step to ensure feasibility and potential for improvement\n\n    new_solution = selected_solution.copy()\n    num_items = len(new_solution)\n\n    # Random mutation: flip a random subset of bits\n    mutation_rate = 0.2  # Probability of flipping each bit\n    for i in range(num_items):\n        if random.random() < mutation_rate:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Check feasibility and apply greedy improvement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            # Select an item to remove based on the ratio of marginal contribution to weight\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove, solution is invalid\n            # Calculate marginal contribution per weight for each included item\n            marginal_contribution = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            # Remove the item with the lowest marginal contribution\n            item_to_remove = included_items[np.argmin(marginal_contribution)]\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n\n    # Greedy improvement: add items that improve at least one objective without violating capacity\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves at least one objective\n            if value1_lst[item] > 0 or value2_lst[item] > 0:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3983350922859837,
            1.6322157979011536
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with promising potential for improvement\n    # Here, we select a solution that is not already at the boundary of the Pareto front\n    # and has a reasonable balance between the two objectives\n    selected_solution = None\n    for sol, obj in archive:\n        # Check if the solution is not already optimal in both objectives\n        if obj[0] < sum(value1_lst) or obj[1] < sum(value2_lst):\n            selected_solution = sol.copy()\n            break\n    if selected_solution is None:\n        selected_solution = archive[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of bits to explore the neighborhood\n    # 2. Apply a greedy improvement step to ensure feasibility and potential for improvement\n\n    new_solution = selected_solution.copy()\n    num_items = len(new_solution)\n\n    # Random mutation: flip a random subset of bits\n    mutation_rate = 0.2  # Probability of flipping each bit\n    for i in range(num_items):\n        if random.random() < mutation_rate:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Check feasibility and apply greedy improvement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            # Select an item to remove based on the ratio of marginal contribution to weight\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove, solution is invalid\n            # Calculate marginal contribution per weight for each included item\n            marginal_contribution = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            # Remove the item with the lowest marginal contribution\n            item_to_remove = included_items[np.argmin(marginal_contribution)]\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n\n    # Greedy improvement: add items that improve at least one objective without violating capacity\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves at least one objective\n            if value1_lst[item] > 0 or value2_lst[item] > 0:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 93,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards those with higher combined value\n    values = np.array([sum(obj) for _, obj in archive])\n    probs = values / values.sum()\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(3):  # Number of perturbation attempts\n        # Random flip with value-based probability\n        flip_candidates = np.where(new_solution == 0)[0]\n        if len(flip_candidates) > 0:\n            flip_prob = value1_lst[flip_candidates] + value2_lst[flip_candidates]\n            flip_prob = flip_prob / flip_prob.sum()\n            flip_idx = np.random.choice(flip_candidates, p=flip_prob)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n                current_value1 += value1_lst[flip_idx]\n                current_value2 += value2_lst[flip_idx]\n\n        # Value-based swap between included and excluded items\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n        if len(included) > 0 and len(excluded) > 0:\n            # Select item to remove based on marginal value\n            remove_candidates = included\n            remove_values = value1_lst[included] + value2_lst[included]\n            remove_prob = remove_values / remove_values.sum()\n            remove_idx = np.random.choice(remove_candidates, p=remove_prob)\n\n            # Select item to add based on value-to-weight ratio\n            add_candidates = excluded[weight_lst[excluded] <= capacity - current_weight + weight_lst[remove_idx]]\n            if len(add_candidates) > 0:\n                add_values = (value1_lst[add_candidates] + value2_lst[add_candidates]) / weight_lst[add_candidates]\n                add_prob = add_values / add_values.sum()\n                add_idx = np.random.choice(add_candidates, p=add_prob)\n\n                # Perform the swap\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                current_value1 = current_value1 - value1_lst[remove_idx] + value1_lst[add_idx]\n                current_value2 = current_value2 - value2_lst[remove_idx] + value2_lst[add_idx]\n\n    # Final check to ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items with lowest marginal value\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n        remove_values = value1_lst[included] + value2_lst[included]\n        remove_idx = included[np.argmin(remove_values)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.40896890265591546,
            2.389859199523926
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards those with higher combined value\n    values = np.array([sum(obj) for _, obj in archive])\n    probs = values / values.sum()\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(3):  # Number of perturbation attempts\n        # Random flip with value-based probability\n        flip_candidates = np.where(new_solution == 0)[0]\n        if len(flip_candidates) > 0:\n            flip_prob = value1_lst[flip_candidates] + value2_lst[flip_candidates]\n            flip_prob = flip_prob / flip_prob.sum()\n            flip_idx = np.random.choice(flip_candidates, p=flip_prob)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n                current_value1 += value1_lst[flip_idx]\n                current_value2 += value2_lst[flip_idx]\n\n        # Value-based swap between included and excluded items\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n        if len(included) > 0 and len(excluded) > 0:\n            # Select item to remove based on marginal value\n            remove_candidates = included\n            remove_values = value1_lst[included] + value2_lst[included]\n            remove_prob = remove_values / remove_values.sum()\n            remove_idx = np.random.choice(remove_candidates, p=remove_prob)\n\n            # Select item to add based on value-to-weight ratio\n            add_candidates = excluded[weight_lst[excluded] <= capacity - current_weight + weight_lst[remove_idx]]\n            if len(add_candidates) > 0:\n                add_values = (value1_lst[add_candidates] + value2_lst[add_candidates]) / weight_lst[add_candidates]\n                add_prob = add_values / add_values.sum()\n                add_idx = np.random.choice(add_candidates, p=add_prob)\n\n                # Perform the swap\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                current_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                current_value1 = current_value1 - value1_lst[remove_idx] + value1_lst[add_idx]\n                current_value2 = current_value2 - value2_lst[remove_idx] + value2_lst[add_idx]\n\n    # Final check to ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items with lowest marginal value\n        included = np.where(new_solution == 1)[0]\n        if len(included) == 0:\n            break\n        remove_values = value1_lst[included] + value2_lst[included]\n        remove_idx = included[np.argmin(remove_values)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 94,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on its potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (i.e., not all items are selected)\n    # and have a good balance between the two objectives\n    selected_idx = -1\n    max_potential = -1\n    for i, (solution, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst * solution)\n        remaining_capacity = capacity - total_weight\n        potential = remaining_capacity * (1 - np.sum(solution) / len(solution))  # Encourage exploration of unused capacity\n        if potential > max_potential:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Selectively flip items with high marginal value (exploitation)\n    # 3. Ensure feasibility by adjusting flips if necessary\n\n    # Step 1: Random flipping (exploration)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 2: Selective flipping based on marginal value\n    # Calculate marginal value for each item (value per unit weight)\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Sort items by marginal value (descending)\n    sorted_indices1 = np.argsort(-marginal_value1)\n    sorted_indices2 = np.argsort(-marginal_value2)\n\n    # Flip top-k items based on marginal value (k is a small fraction of items)\n    k = max(1, int(0.1 * len(new_solution)))  # Flip top 10% of items\n    for idx in sorted_indices1[:k]:\n        if new_solution[idx] == 0 and (np.sum(weight_lst * new_solution) + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n    for idx in sorted_indices2[:k]:\n        if new_solution[idx] == 0 and (np.sum(weight_lst * new_solution) + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n\n    # Step 3: Ensure feasibility by removing items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        # Remove the item with the smallest marginal value\n        current_marginal = marginal_value1 * new_solution + marginal_value2 * new_solution\n        remove_idx = np.argmin(current_marginal)\n        if new_solution[remove_idx] == 1:\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n        else:\n            break  # No more items to remove\n\n    return new_solution\n\n",
        "score": [
            -0.3647671866521341,
            1.9111164212226868
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on its potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (i.e., not all items are selected)\n    # and have a good balance between the two objectives\n    selected_idx = -1\n    max_potential = -1\n    for i, (solution, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst * solution)\n        remaining_capacity = capacity - total_weight\n        potential = remaining_capacity * (1 - np.sum(solution) / len(solution))  # Encourage exploration of unused capacity\n        if potential > max_potential:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Selectively flip items with high marginal value (exploitation)\n    # 3. Ensure feasibility by adjusting flips if necessary\n\n    # Step 1: Random flipping (exploration)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 2: Selective flipping based on marginal value\n    # Calculate marginal value for each item (value per unit weight)\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Sort items by marginal value (descending)\n    sorted_indices1 = np.argsort(-marginal_value1)\n    sorted_indices2 = np.argsort(-marginal_value2)\n\n    # Flip top-k items based on marginal value (k is a small fraction of items)\n    k = max(1, int(0.1 * len(new_solution)))  # Flip top 10% of items\n    for idx in sorted_indices1[:k]:\n        if new_solution[idx] == 0 and (np.sum(weight_lst * new_solution) + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n    for idx in sorted_indices2[:k]:\n        if new_solution[idx] == 0 and (np.sum(weight_lst * new_solution) + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n\n    # Step 3: Ensure feasibility by removing items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        # Remove the item with the smallest marginal value\n        current_marginal = marginal_value1 * new_solution + marginal_value2 * new_solution\n        remove_idx = np.argmin(current_marginal)\n        if new_solution[remove_idx] == 1:\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n        else:\n            break  # No more items to remove\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 95,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution from the archive with higher probability for solutions near the Pareto front\n    base_solution, _ = archive[0]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded without exceeding capacity)\n    # For included items, we check if excluding them keeps the solution feasible\n    # For excluded items, we check if including them keeps the solution feasible\n    flippable_indices = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                flippable_indices.append(i)\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                flippable_indices.append(i)\n\n    if not flippable_indices:\n        return new_solution  # No feasible flips possible\n\n    # Hybrid selection strategy: combine randomness with value-weighted selection\n    # 70% chance to select based on combined value, 30% chance to select randomly\n    selection_prob = 0.7\n    if np.random.rand() < selection_prob:\n        # Value-weighted selection: prioritize items with high combined value\n        combined_value = value1_lst + value2_lst\n        weights = combined_value[flippable_indices]\n        weights = np.maximum(weights, 0)  # Ensure non-negative weights\n        if np.sum(weights) == 0:\n            weights = np.ones_like(weights)  # Avoid division by zero\n        weights = weights / np.sum(weights)\n        flip_index = np.random.choice(flippable_indices, p=weights)\n    else:\n        # Random selection\n        flip_index = np.random.choice(flippable_indices)\n\n    # Flip the selected item\n    new_solution[flip_index] = 1 - new_solution[flip_index]\n\n    return new_solution\n\n",
        "score": [
            -0.8795244659813335,
            1.2434362471103668
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution from the archive with higher probability for solutions near the Pareto front\n    base_solution, _ = archive[0]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded without exceeding capacity)\n    # For included items, we check if excluding them keeps the solution feasible\n    # For excluded items, we check if including them keeps the solution feasible\n    flippable_indices = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                flippable_indices.append(i)\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                flippable_indices.append(i)\n\n    if not flippable_indices:\n        return new_solution  # No feasible flips possible\n\n    # Hybrid selection strategy: combine randomness with value-weighted selection\n    # 70% chance to select based on combined value, 30% chance to select randomly\n    selection_prob = 0.7\n    if np.random.rand() < selection_prob:\n        # Value-weighted selection: prioritize items with high combined value\n        combined_value = value1_lst + value2_lst\n        weights = combined_value[flippable_indices]\n        weights = np.maximum(weights, 0)  # Ensure non-negative weights\n        if np.sum(weights) == 0:\n            weights = np.ones_like(weights)  # Avoid division by zero\n        weights = weights / np.sum(weights)\n        flip_index = np.random.choice(flippable_indices, p=weights)\n    else:\n        # Random selection\n        flip_index = np.random.choice(flippable_indices)\n\n    # Flip the selected item\n    new_solution[flip_index] = 1 - new_solution[flip_index]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 96,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random flipping with targeted improvement\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Randomly flip a subset of items (to escape local optima)\n    flip_mask = np.random.rand(n_items) < 0.1  # 10% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if total_weight <= capacity:\n                break\n            new_solution[item] = 0\n            total_weight -= weight_lst[item]\n\n    # Step 2: Targeted improvement - add highest-value items not in the solution\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate marginal gains for each item (combining both objectives)\n        marginal_gain = (value1_lst + value2_lst) / weight_lst\n        candidate_items = np.where(new_solution == 0)[0]\n\n        # Sort candidates by marginal gain (descending)\n        sorted_candidates = sorted(candidate_items, key=lambda x: -marginal_gain[x])\n\n        # Greedily add items until capacity is reached\n        for item in sorted_candidates:\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.28644055990931927,
            1.2877182066440582
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random flipping with targeted improvement\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 1: Randomly flip a subset of items (to escape local optima)\n    flip_mask = np.random.rand(n_items) < 0.1  # 10% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if total_weight <= capacity:\n                break\n            new_solution[item] = 0\n            total_weight -= weight_lst[item]\n\n    # Step 2: Targeted improvement - add highest-value items not in the solution\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate marginal gains for each item (combining both objectives)\n        marginal_gain = (value1_lst + value2_lst) / weight_lst\n        candidate_items = np.where(new_solution == 0)[0]\n\n        # Sort candidates by marginal gain (descending)\n        sorted_candidates = sorted(candidate_items, key=lambda x: -marginal_gain[x])\n\n        # Greedily add items until capacity is reached\n        for item in sorted_candidates:\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 97,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its non-dominated rank\n    # Here, we approximate rank by the sum of the two objectives (higher sum = better)\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.sum(objectives, axis=1)\n    selected_idx = np.random.choice(len(archive), p=ranks/np.sum(ranks))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Create a copy for modification\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Random flip of a subset of items (2-5 items)\n    flip_indices = np.random.choice(len(new_solution), size=random.randint(2, 5), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If removing the item keeps the solution feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # If adding the item keeps the solution feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Step 2: Greedy improvement - try to add the most valuable items not in the solution\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0:\n        # Sort by combined value (could also use other criteria)\n        combined_values = value1_lst[available_items] + value2_lst[available_items]\n        sorted_indices = available_items[np.argsort(-combined_values)]\n\n        for idx in sorted_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Step 3: Greedy removal - try to remove the least valuable items in the solution\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Sort by combined value (ascending to remove worst first)\n        combined_values = value1_lst[included_items] + value2_lst[included_items]\n        sorted_indices = included_items[np.argsort(combined_values)]\n\n        for idx in sorted_indices:\n            # If removing this item doesn't make the solution worse in both objectives\n            new_value1 = current_value1 - value1_lst[idx]\n            new_value2 = current_value2 - value2_lst[idx]\n            if (new_value1 >= current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2) or \\\n               (new_value1 > current_value1 and new_value2 >= current_value2):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.3674023950935784,
            4.148697346448898
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its non-dominated rank\n    # Here, we approximate rank by the sum of the two objectives (higher sum = better)\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.sum(objectives, axis=1)\n    selected_idx = np.random.choice(len(archive), p=ranks/np.sum(ranks))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Create a copy for modification\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Random flip of a subset of items (2-5 items)\n    flip_indices = np.random.choice(len(new_solution), size=random.randint(2, 5), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If removing the item keeps the solution feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # If adding the item keeps the solution feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Step 2: Greedy improvement - try to add the most valuable items not in the solution\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0:\n        # Sort by combined value (could also use other criteria)\n        combined_values = value1_lst[available_items] + value2_lst[available_items]\n        sorted_indices = available_items[np.argsort(-combined_values)]\n\n        for idx in sorted_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Step 3: Greedy removal - try to remove the least valuable items in the solution\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Sort by combined value (ascending to remove worst first)\n        combined_values = value1_lst[included_items] + value2_lst[included_items]\n        sorted_indices = included_items[np.argsort(combined_values)]\n\n        for idx in sorted_indices:\n            # If removing this item doesn't make the solution worse in both objectives\n            new_value1 = current_value1 - value1_lst[idx]\n            new_value2 = current_value2 - value2_lst[idx]\n            if (new_value1 >= current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2) or \\\n               (new_value1 > current_value1 and new_value2 >= current_value2):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 98,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objective values (ascending)\n        archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n        # Select from the top 30% of solutions to encourage exploration\n        selection_pool = archive_sorted[:max(1, int(0.3 * len(archive)))]\n        # Randomly select a solution from the pool\n        base_solution, _ = random.choice(selection_pool)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (1-3 items)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Check feasibility and fix if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If overweight, randomly remove items until feasible\n        while total_weight > capacity:\n            # Find items that are currently included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove, solution is infeasible\n            # Randomly select an item to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # 3. Greedy improvement step: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Calculate potential improvement\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            # Add item if it improves both objectives\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6432658428550281,
            1.236590176820755
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objective values (ascending)\n        archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n        # Select from the top 30% of solutions to encourage exploration\n        selection_pool = archive_sorted[:max(1, int(0.3 * len(archive)))]\n        # Randomly select a solution from the pool\n        base_solution, _ = random.choice(selection_pool)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (1-3 items)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Check feasibility and fix if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If overweight, randomly remove items until feasible\n        while total_weight > capacity:\n            # Find items that are currently included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove, solution is infeasible\n            # Randomly select an item to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # 3. Greedy improvement step: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Calculate potential improvement\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            # Add item if it improves both objectives\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 99,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (low density or high marginal gain)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst[sol == 1])\n        density1 = obj[0] / total_weight if total_weight > 0 else 0\n        density2 = obj[1] / total_weight if total_weight > 0 else 0\n        # Calculate marginal gain potential (simplified)\n        marginal_gain = np.sum(value1_lst[sol == 0] + value2_lst[sol == 0])\n        candidates.append((sol, density1, density2, marginal_gain, obj))\n\n    # Sort by density (lower density first) and marginal gain (higher first)\n    candidates.sort(key=lambda x: (x[1] + x[2], -x[3]))\n    selected = candidates[0][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = selected.copy()\n    n_items = len(weight_lst)\n\n    # Option 1: Random flip with feasibility check\n    if random.random() < 0.5:\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Option 2: Density-based swap\n    else:\n        # Find items with low density in the solution\n        in_sol = np.where(new_solution == 1)[0]\n        out_sol = np.where(new_solution == 0)[0]\n\n        if len(in_sol) > 0 and len(out_sol) > 0:\n            # Calculate densities of items in solution\n            densities_in = value1_lst[in_sol] + value2_lst[in_sol] / weight_lst[in_sol]\n            densities_out = value1_lst[out_sol] + value2_lst[out_sol] / weight_lst[out_sol]\n\n            # Find items to swap (low density in vs. high density out)\n            low_density_in = in_sol[np.argmin(densities_in)]\n            high_density_out = out_sol[np.argmax(densities_out)]\n\n            # Check feasibility of swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            delta_weight = weight_lst[high_density_out] - weight_lst[low_density_in]\n\n            if current_weight + delta_weight <= capacity:\n                new_solution[low_density_in] = 0\n                new_solution[high_density_out] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8040392864770127,
            2.833543360233307
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (low density or high marginal gain)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst[sol == 1])\n        density1 = obj[0] / total_weight if total_weight > 0 else 0\n        density2 = obj[1] / total_weight if total_weight > 0 else 0\n        # Calculate marginal gain potential (simplified)\n        marginal_gain = np.sum(value1_lst[sol == 0] + value2_lst[sol == 0])\n        candidates.append((sol, density1, density2, marginal_gain, obj))\n\n    # Sort by density (lower density first) and marginal gain (higher first)\n    candidates.sort(key=lambda x: (x[1] + x[2], -x[3]))\n    selected = candidates[0][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = selected.copy()\n    n_items = len(weight_lst)\n\n    # Option 1: Random flip with feasibility check\n    if random.random() < 0.5:\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Option 2: Density-based swap\n    else:\n        # Find items with low density in the solution\n        in_sol = np.where(new_solution == 1)[0]\n        out_sol = np.where(new_solution == 0)[0]\n\n        if len(in_sol) > 0 and len(out_sol) > 0:\n            # Calculate densities of items in solution\n            densities_in = value1_lst[in_sol] + value2_lst[in_sol] / weight_lst[in_sol]\n            densities_out = value1_lst[out_sol] + value2_lst[out_sol] / weight_lst[out_sol]\n\n            # Find items to swap (low density in vs. high density out)\n            low_density_in = in_sol[np.argmin(densities_in)]\n            high_density_out = out_sol[np.argmax(densities_out)]\n\n            # Check feasibility of swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            delta_weight = weight_lst[high_density_out] - weight_lst[low_density_in]\n\n            if current_weight + delta_weight <= capacity:\n                new_solution[low_density_in] = 0\n                new_solution[high_density_out] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 100,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with high potential for improvement\n    # Potential is measured by the ratio of current values to the maximum possible values\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        potential1 = (max_value1 - val1) / max_value1 if max_value1 > 0 else 0\n        potential2 = (max_value2 - val2) / max_value2 if max_value2 > 0 else 0\n        score = potential1 + potential2\n        candidates.append((score, sol))\n\n    # Sort candidates by score in descending order and select the top 20% or at least 1\n    candidates.sort(reverse=True, key=lambda x: x[0])\n    top_k = max(1, len(candidates) // 5)\n    selected = random.choice(candidates[:top_k])[1]\n    base_solution = selected.copy()\n\n    # Hybrid local search strategy: adaptive bit-flip with weight-aware selection\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution that could be added without exceeding capacity\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If there are candidate items, select one to add with probability based on value ratios\n    if len(candidate_items) > 0:\n        # Calculate value ratios for each candidate item\n        ratios = []\n        for item in candidate_items:\n            ratio1 = value1_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n            ratio2 = value2_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n            ratios.append((ratio1 + ratio2, item))\n\n        # Sort by combined ratio and select top 30% or at least 1\n        ratios.sort(reverse=True, key=lambda x: x[0])\n        top_items = [item for _, item in ratios[:max(1, len(ratios) // 3)]]\n        selected_item = random.choice(top_items)\n        new_solution[selected_item] = 1\n    else:\n        # If no items can be added, consider removing items with low value ratios\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            # Calculate value ratios for items in solution\n            ratios = []\n            for item in items_in_solution:\n                ratio1 = value1_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n                ratio2 = value2_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n                ratios.append((ratio1 + ratio2, item))\n\n            # Sort by combined ratio and select bottom 30% or at least 1\n            ratios.sort(key=lambda x: x[0])\n            bottom_items = [item for _, item in ratios[:max(1, len(ratios) // 3)]]\n            selected_item = random.choice(bottom_items)\n            new_solution[selected_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8136012584131771,
            1.6178294718265533
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with high potential for improvement\n    # Potential is measured by the ratio of current values to the maximum possible values\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        potential1 = (max_value1 - val1) / max_value1 if max_value1 > 0 else 0\n        potential2 = (max_value2 - val2) / max_value2 if max_value2 > 0 else 0\n        score = potential1 + potential2\n        candidates.append((score, sol))\n\n    # Sort candidates by score in descending order and select the top 20% or at least 1\n    candidates.sort(reverse=True, key=lambda x: x[0])\n    top_k = max(1, len(candidates) // 5)\n    selected = random.choice(candidates[:top_k])[1]\n    base_solution = selected.copy()\n\n    # Hybrid local search strategy: adaptive bit-flip with weight-aware selection\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution that could be added without exceeding capacity\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If there are candidate items, select one to add with probability based on value ratios\n    if len(candidate_items) > 0:\n        # Calculate value ratios for each candidate item\n        ratios = []\n        for item in candidate_items:\n            ratio1 = value1_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n            ratio2 = value2_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n            ratios.append((ratio1 + ratio2, item))\n\n        # Sort by combined ratio and select top 30% or at least 1\n        ratios.sort(reverse=True, key=lambda x: x[0])\n        top_items = [item for _, item in ratios[:max(1, len(ratios) // 3)]]\n        selected_item = random.choice(top_items)\n        new_solution[selected_item] = 1\n    else:\n        # If no items can be added, consider removing items with low value ratios\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            # Calculate value ratios for items in solution\n            ratios = []\n            for item in items_in_solution:\n                ratio1 = value1_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n                ratio2 = value2_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n                ratios.append((ratio1 + ratio2, item))\n\n            # Sort by combined ratio and select bottom 30% or at least 1\n            ratios.sort(key=lambda x: x[0])\n            bottom_items = [item for _, item in ratios[:max(1, len(ratios) // 3)]]\n            selected_item = random.choice(bottom_items)\n            new_solution[selected_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 101,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    promising_indices = []\n    for idx, (sol, _) in enumerate(archive):\n        # Calculate current weight and potential for improvement\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            promising_indices.append(idx)\n\n    if not promising_indices:\n        # If no promising solutions, pick a random one\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select a solution with the most potential for improvement\n        base_solution = archive[random.choice(promising_indices)][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search strategy\n    # Strategy 1: Randomly flip bits (with capacity check)\n    flip_indices = np.random.permutation(len(new_solution))[:random.randint(1, min(5, len(new_solution)))]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if feasible\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add item if feasible\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: Objective-aware swap (if solution is not empty)\n    if np.sum(new_solution) > 0:\n        # Find items with high value1 but low value2 or vice versa\n        value_ratio = value1_lst / (value2_lst + 1e-6)\n        sorted_indices = np.argsort(value_ratio)\n\n        # Randomly select a pair to swap\n        if len(sorted_indices) >= 2:\n            i, j = random.sample(range(len(sorted_indices)), 2)\n            if new_solution[i] != new_solution[j]:\n                # Check feasibility before swap\n                if (new_solution[i] == 1 and np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (new_solution[j] == 1 and np.sum(weight_lst * new_solution) - weight_lst[j] + weight_lst[i] <= capacity):\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.36830241631016714,
            2.6718463599681854
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    promising_indices = []\n    for idx, (sol, _) in enumerate(archive):\n        # Calculate current weight and potential for improvement\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            promising_indices.append(idx)\n\n    if not promising_indices:\n        # If no promising solutions, pick a random one\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select a solution with the most potential for improvement\n        base_solution = archive[random.choice(promising_indices)][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search strategy\n    # Strategy 1: Randomly flip bits (with capacity check)\n    flip_indices = np.random.permutation(len(new_solution))[:random.randint(1, min(5, len(new_solution)))]\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if feasible\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add item if feasible\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: Objective-aware swap (if solution is not empty)\n    if np.sum(new_solution) > 0:\n        # Find items with high value1 but low value2 or vice versa\n        value_ratio = value1_lst / (value2_lst + 1e-6)\n        sorted_indices = np.argsort(value_ratio)\n\n        # Randomly select a pair to swap\n        if len(sorted_indices) >= 2:\n            i, j = random.sample(range(len(sorted_indices)), 2)\n            if new_solution[i] != new_solution[j]:\n                # Check feasibility before swap\n                if (new_solution[i] == 1 and np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j] <= capacity) or \\\n                   (new_solution[j] == 1 and np.sum(weight_lst * new_solution) - weight_lst[j] + weight_lst[i] <= capacity):\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 102,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidate_indices = []\n    for i, (solution, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst * solution)\n        # Consider solutions that are not at full capacity for potential improvement\n        if total_weight < capacity * 0.95:  # Threshold to avoid overfilling\n            candidate_indices.append(i)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small subset of items (perturbation)\n    num_items = len(weight_lst)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Perform value-based swaps to improve both objectives\n    # Identify items not in the solution with high marginal value\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate marginal value for each item not in solution\n        marginal_values = value1_lst + value2_lst  # Combined marginal value\n        best_candidate = not_in_solution[np.argmax(marginal_values[not_in_solution])]\n\n        # Check if adding this item is feasible\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    # 3. Remove low-value items to free up capacity\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal value for each item in solution\n        marginal_values = value1_lst + value2_lst  # Combined marginal value\n        worst_candidate = in_solution[np.argmin(marginal_values[in_solution])]\n\n        # Check if removing this item maintains feasibility (redundant here but good practice)\n        new_solution[worst_candidate] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.42086106227890296,
            1.3309058845043182
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidate_indices = []\n    for i, (solution, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst * solution)\n        # Consider solutions that are not at full capacity for potential improvement\n        if total_weight < capacity * 0.95:  # Threshold to avoid overfilling\n            candidate_indices.append(i)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small subset of items (perturbation)\n    num_items = len(weight_lst)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Perform value-based swaps to improve both objectives\n    # Identify items not in the solution with high marginal value\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate marginal value for each item not in solution\n        marginal_values = value1_lst + value2_lst  # Combined marginal value\n        best_candidate = not_in_solution[np.argmax(marginal_values[not_in_solution])]\n\n        # Check if adding this item is feasible\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    # 3. Remove low-value items to free up capacity\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal value for each item in solution\n        marginal_values = value1_lst + value2_lst  # Combined marginal value\n        worst_candidate = in_solution[np.argmin(marginal_values[in_solution])]\n\n        # Check if removing this item maintains feasibility (redundant here but good practice)\n        new_solution[worst_candidate] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 103,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidate_indices = []\n    for idx, (sol, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < 0.9 * capacity:  # Avoid solutions already near capacity\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random perturbation + value-based swaps\n    n_items = len(base_solution)\n    perturbations = min(3, n_items)  # Limit number of perturbations\n\n    for _ in range(perturbations):\n        # Randomly select an item to flip\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1:\n            new_solution[flip_idx] = 0\n        else:\n            # Only flip to 1 if it keeps the solution feasible\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Value-based swaps: prioritize items with high marginal value for either objective\n    for _ in range(2):  # Perform a few value-based swaps\n        # Calculate marginal values for each item\n        marginal_value1 = value1_lst * (1 - base_solution)  # Items not in solution\n        marginal_value2 = value2_lst * (1 - base_solution)\n\n        # Combine marginal values for both objectives (weighted sum)\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n\n        # Select top items for potential inclusion\n        top_items = np.argsort(combined_marginal)[-3:]  # Top 3 items\n\n        for item in top_items:\n            if new_solution[item] == 0:\n                current_weight = np.sum(weight_lst * new_solution)\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break  # Only swap one item per iteration\n\n    return new_solution\n\n",
        "score": [
            -0.3919898782666003,
            3.464689701795578
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidate_indices = []\n    for idx, (sol, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < 0.9 * capacity:  # Avoid solutions already near capacity\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random perturbation + value-based swaps\n    n_items = len(base_solution)\n    perturbations = min(3, n_items)  # Limit number of perturbations\n\n    for _ in range(perturbations):\n        # Randomly select an item to flip\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1:\n            new_solution[flip_idx] = 0\n        else:\n            # Only flip to 1 if it keeps the solution feasible\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Value-based swaps: prioritize items with high marginal value for either objective\n    for _ in range(2):  # Perform a few value-based swaps\n        # Calculate marginal values for each item\n        marginal_value1 = value1_lst * (1 - base_solution)  # Items not in solution\n        marginal_value2 = value2_lst * (1 - base_solution)\n\n        # Combine marginal values for both objectives (weighted sum)\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n\n        # Select top items for potential inclusion\n        top_items = np.argsort(combined_marginal)[-3:]  # Top 3 items\n\n        for item in top_items:\n            if new_solution[item] == 0:\n                current_weight = np.sum(weight_lst * new_solution)\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break  # Only swap one item per iteration\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 104,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Identify promising solutions (those with high potential for improvement)\n    promising_indices = []\n    for idx, (solution, _) in enumerate(archive):\n        current_weight = np.sum(solution * weight_lst)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Solutions with remaining capacity are more likely to be improved\n            promising_indices.append(idx)\n\n    if not promising_indices:\n        # If no promising solutions, select a random one\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        # Select a random promising solution\n        selected_idx = random.choice(promising_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search operator\n    # First, perform random flipping of items with a probability based on their contribution\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to flip\n            if new_solution[i] == 1:\n                # If item is included, remove it\n                new_solution[i] = 0\n            else:\n                # If item is not included, add it if feasible\n                current_weight = np.sum(new_solution * weight_lst)\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Step 3: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for each item\n    marginal_gains = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            marginal_gain = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            marginal_gains.append((i, marginal_gain))\n\n    # Sort items by marginal gain (highest first)\n    marginal_gains.sort(key=lambda x: -x[1])\n\n    # Add items that improve both objectives\n    for item_idx, _ in marginal_gains:\n        if remaining_capacity >= weight_lst[item_idx]:\n            new_solution[item_idx] = 1\n            remaining_capacity -= weight_lst[item_idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.32958775626996517,
            2.712257832288742
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Identify promising solutions (those with high potential for improvement)\n    promising_indices = []\n    for idx, (solution, _) in enumerate(archive):\n        current_weight = np.sum(solution * weight_lst)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Solutions with remaining capacity are more likely to be improved\n            promising_indices.append(idx)\n\n    if not promising_indices:\n        # If no promising solutions, select a random one\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        # Select a random promising solution\n        selected_idx = random.choice(promising_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search operator\n    # First, perform random flipping of items with a probability based on their contribution\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to flip\n            if new_solution[i] == 1:\n                # If item is included, remove it\n                new_solution[i] = 0\n            else:\n                # If item is not included, add it if feasible\n                current_weight = np.sum(new_solution * weight_lst)\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Step 3: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for each item\n    marginal_gains = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            marginal_gain = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            marginal_gains.append((i, marginal_gain))\n\n    # Sort items by marginal gain (highest first)\n    marginal_gains.sort(key=lambda x: -x[1])\n\n    # Add items that improve both objectives\n    for item_idx, _ in marginal_gains:\n        if remaining_capacity >= weight_lst[item_idx]:\n            new_solution[item_idx] = 1\n            remaining_capacity -= weight_lst[item_idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 105,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, (val1, val2) in archive:\n        # Calculate marginal contributions for each item\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        # Items not in the solution with high marginal contribution to one objective\n        not_in_sol = ~sol.astype(bool)\n        potential1 = np.sum(marginal1[not_in_sol]) - np.sum(marginal2[not_in_sol])\n        potential2 = np.sum(marginal2[not_in_sol]) - np.sum(marginal1[not_in_sol])\n        candidates.append((sol, val1, val2, potential1, potential2))\n\n    # Sort by potential and select the top 30% of candidates\n    candidates.sort(key=lambda x: -(x[3] + x[4]))\n    selected = candidates[:max(1, len(candidates) // 3)]\n    base_sol, _, _, _, _ = selected[np.random.randint(len(selected))]\n\n    new_solution = base_sol.copy()\n    current_weight = np.sum(weight_lst[new_solution.astype(bool)])\n\n    # Hybrid local search: guided flip based on marginal contributions\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        # Calculate marginal contributions for the current solution\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n\n        # Identify items to potentially flip\n        in_sol = new_solution.astype(bool)\n        not_in_sol = ~in_sol\n\n        # Calculate potential gain/loss for each item\n        gains1 = marginal1[not_in_sol] * weight_lst[not_in_sol]\n        gains2 = marginal2[not_in_sol] * weight_lst[not_in_sol]\n        losses1 = marginal1[in_sol] * weight_lst[in_sol]\n        losses2 = marginal2[in_sol] * weight_lst[in_sol]\n\n        # Combine gains and losses for a balanced approach\n        total_gain1 = np.sum(gains1) - np.sum(losses1)\n        total_gain2 = np.sum(gains2) - np.sum(losses2)\n\n        # Decide whether to add or remove items based on the objective with more potential\n        if total_gain1 > total_gain2:\n            # Try to add items with high marginal contribution to objective 1\n            candidates_to_add = np.where(not_in_sol)[0]\n            if len(candidates_to_add) > 0:\n                # Select the item with the highest marginal contribution to objective 1\n                idx = np.argmax(marginal1[candidates_to_add])\n                item_idx = candidates_to_add[idx]\n                if current_weight + weight_lst[item_idx] <= capacity:\n                    new_solution[item_idx] = 1\n                    current_weight += weight_lst[item_idx]\n        else:\n            # Try to add items with high marginal contribution to objective 2\n            candidates_to_add = np.where(not_in_sol)[0]\n            if len(candidates_to_add) > 0:\n                # Select the item with the highest marginal contribution to objective 2\n                idx = np.argmax(marginal2[candidates_to_add])\n                item_idx = candidates_to_add[idx]\n                if current_weight + weight_lst[item_idx] <= capacity:\n                    new_solution[item_idx] = 1\n                    current_weight += weight_lst[item_idx]\n\n        # Also consider removing items with low marginal contribution\n        candidates_to_remove = np.where(in_sol)[0]\n        if len(candidates_to_remove) > 0:\n            # Select the item with the lowest marginal contribution to both objectives\n            idx = np.argmin(marginal1[candidates_to_remove] + marginal2[candidates_to_remove])\n            item_idx = candidates_to_remove[idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4507553229674842,
            5.277249753475189
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, (val1, val2) in archive:\n        # Calculate marginal contributions for each item\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n        # Items not in the solution with high marginal contribution to one objective\n        not_in_sol = ~sol.astype(bool)\n        potential1 = np.sum(marginal1[not_in_sol]) - np.sum(marginal2[not_in_sol])\n        potential2 = np.sum(marginal2[not_in_sol]) - np.sum(marginal1[not_in_sol])\n        candidates.append((sol, val1, val2, potential1, potential2))\n\n    # Sort by potential and select the top 30% of candidates\n    candidates.sort(key=lambda x: -(x[3] + x[4]))\n    selected = candidates[:max(1, len(candidates) // 3)]\n    base_sol, _, _, _, _ = selected[np.random.randint(len(selected))]\n\n    new_solution = base_sol.copy()\n    current_weight = np.sum(weight_lst[new_solution.astype(bool)])\n\n    # Hybrid local search: guided flip based on marginal contributions\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        # Calculate marginal contributions for the current solution\n        marginal1 = value1_lst / (weight_lst + 1e-6)\n        marginal2 = value2_lst / (weight_lst + 1e-6)\n\n        # Identify items to potentially flip\n        in_sol = new_solution.astype(bool)\n        not_in_sol = ~in_sol\n\n        # Calculate potential gain/loss for each item\n        gains1 = marginal1[not_in_sol] * weight_lst[not_in_sol]\n        gains2 = marginal2[not_in_sol] * weight_lst[not_in_sol]\n        losses1 = marginal1[in_sol] * weight_lst[in_sol]\n        losses2 = marginal2[in_sol] * weight_lst[in_sol]\n\n        # Combine gains and losses for a balanced approach\n        total_gain1 = np.sum(gains1) - np.sum(losses1)\n        total_gain2 = np.sum(gains2) - np.sum(losses2)\n\n        # Decide whether to add or remove items based on the objective with more potential\n        if total_gain1 > total_gain2:\n            # Try to add items with high marginal contribution to objective 1\n            candidates_to_add = np.where(not_in_sol)[0]\n            if len(candidates_to_add) > 0:\n                # Select the item with the highest marginal contribution to objective 1\n                idx = np.argmax(marginal1[candidates_to_add])\n                item_idx = candidates_to_add[idx]\n                if current_weight + weight_lst[item_idx] <= capacity:\n                    new_solution[item_idx] = 1\n                    current_weight += weight_lst[item_idx]\n        else:\n            # Try to add items with high marginal contribution to objective 2\n            candidates_to_add = np.where(not_in_sol)[0]\n            if len(candidates_to_add) > 0:\n                # Select the item with the highest marginal contribution to objective 2\n                idx = np.argmax(marginal2[candidates_to_add])\n                item_idx = candidates_to_add[idx]\n                if current_weight + weight_lst[item_idx] <= capacity:\n                    new_solution[item_idx] = 1\n                    current_weight += weight_lst[item_idx]\n\n        # Also consider removing items with low marginal contribution\n        candidates_to_remove = np.where(in_sol)[0]\n        if len(candidates_to_remove) > 0:\n            # Select the item with the lowest marginal contribution to both objectives\n            idx = np.argmin(marginal1[candidates_to_remove] + marginal2[candidates_to_remove])\n            item_idx = candidates_to_remove[idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 106,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher combined value\n    combined_values = np.array([sum(obj) for _, obj in archive])\n    probabilities = combined_values / combined_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly select a subset of items to flip (1-3 items)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))\n    flip_mask = np.zeros(num_items, dtype=bool)\n    flip_mask[flip_indices] = True\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Flip selected items with feasibility check\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to exclude it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a value-based greedy improvement step\n    # Calculate marginal gains for each item\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Sort items by combined marginal gain in descending order\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx] <= capacity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and (current_weight - weight_lst[idx] <= capacity):\n            # Only flip if it doesn't hurt both objectives\n            if (value1_lst[idx] + value2_lst[idx]) < (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1])):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.45723587614156347,
            7.320540726184845
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher combined value\n    combined_values = np.array([sum(obj) for _, obj in archive])\n    probabilities = combined_values / combined_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly select a subset of items to flip (1-3 items)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))\n    flip_mask = np.zeros(num_items, dtype=bool)\n    flip_mask[flip_indices] = True\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Flip selected items with feasibility check\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to exclude it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a value-based greedy improvement step\n    # Calculate marginal gains for each item\n    marginal_gain1 = value1_lst / (weight_lst + 1e-10)\n    marginal_gain2 = value2_lst / (weight_lst + 1e-10)\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Sort items by combined marginal gain in descending order\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx] <= capacity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and (current_weight - weight_lst[idx] <= capacity):\n            # Only flip if it doesn't hurt both objectives\n            if (value1_lst[idx] + value2_lst[idx]) < (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1])):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 107,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly weighted by solution quality)\n    weights = [obj[0] + obj[1] for _, obj in archive]\n    total_weight = sum(weights)\n    probabilities = [w / total_weight for w in weights]\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (1-3)\n    flip_count = random.randint(1, 3)\n    flip_indices = np.random.choice(len(new_solution), flip_count, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not included, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Add items with high value-to-weight ratio for both objectives\n    # Calculate value-to-weight ratios\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # 3. Remove items with low value-to-weight ratio if space allows\n    # Calculate marginal value-to-weight ratios\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_ratio1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_ratio2 = value2_lst[included_items] / weight_lst[included_items]\n        marginal_combined = marginal_ratio1 + marginal_ratio2\n        sorted_marginal = np.argsort(marginal_combined)\n\n        # Try to remove items with lowest marginal value\n        for i in sorted_marginal:\n            idx = included_items[i]\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.812818784552104,
            2.0547022223472595
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly weighted by solution quality)\n    weights = [obj[0] + obj[1] for _, obj in archive]\n    total_weight = sum(weights)\n    probabilities = [w / total_weight for w in weights]\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (1-3)\n    flip_count = random.randint(1, 3)\n    flip_indices = np.random.choice(len(new_solution), flip_count, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not included, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Add items with high value-to-weight ratio for both objectives\n    # Calculate value-to-weight ratios\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # 3. Remove items with low value-to-weight ratio if space allows\n    # Calculate marginal value-to-weight ratios\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_ratio1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_ratio2 = value2_lst[included_items] / weight_lst[included_items]\n        marginal_combined = marginal_ratio1 + marginal_ratio2\n        sorted_marginal = np.argsort(marginal_combined)\n\n        # Try to remove items with lowest marginal value\n        for i in sorted_marginal:\n            idx = included_items[i]\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 108,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on a combination of randomness and potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        # Calculate the current total weight\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight >= capacity:\n            continue  # Skip infeasible solutions\n\n        # Calculate the potential for improvement (items not in the solution)\n        potential_items = np.where(sol == 0)[0]\n        if len(potential_items) == 0:\n            continue  # No items to add\n\n        # Calculate the value-to-weight ratios for potential items\n        value1_ratios = value1_lst[potential_items] / weight_lst[potential_items]\n        value2_ratios = value2_lst[potential_items] / weight_lst[potential_items]\n\n        # Select items with high value-to-weight ratios for both objectives\n        high_value1_items = potential_items[value1_ratios >= np.percentile(value1_ratios, 75)]\n        high_value2_items = potential_items[value2_ratios >= np.percentile(value2_ratios, 75)]\n\n        # Combine with randomness to add diversity\n        if len(high_value1_items) > 0:\n            candidates.append(sol)\n        if len(high_value2_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select a candidate with higher potential for improvement\n        base_solution = max(candidates, key=lambda x: np.sum(value1_lst[x == 0] + value2_lst[x == 0]))\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with higher probability for items with high value-to-weight ratios)\n    # 2. Adjust the solution to maximize one objective while keeping the other objective stable\n    # 3. Ensure feasibility by removing items if capacity is exceeded\n\n    # Step 1: Random flips with value-aware probability\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Remove item with probability proportional to its value-to-weight ratio\n            remove_prob = 0.1 * (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            if random.random() < remove_prob:\n                new_solution[i] = 0\n        else:\n            # Add item with probability proportional to its value-to-weight ratio\n            add_prob = 0.1 * (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            if random.random() < add_prob:\n                new_solution[i] = 1\n\n    # Step 2: Adjust to maximize one objective while keeping the other stable\n    # Choose the objective to maximize randomly\n    if random.random() < 0.5:\n        # Maximize value1\n        # Sort items not in the solution by value1-to-weight ratio\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            value1_ratios = value1_lst[potential_items] / weight_lst[potential_items]\n            sorted_items = potential_items[np.argsort(value1_ratios)[::-1]]\n            # Add items until capacity is exceeded\n            for item in sorted_items:\n                if np.sum(weight_lst * new_solution) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                else:\n                    break\n    else:\n        # Maximize value2\n        # Sort items not in the solution by value2-to-weight ratio\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            value2_ratios = value2_lst[potential_items] / weight_lst[potential_items]\n            sorted_items = potential_items[np.argsort(value2_ratios)[::-1]]\n            # Add items until capacity is exceeded\n            for item in sorted_items:\n                if np.sum(weight_lst * new_solution) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                else:\n                    break\n\n    # Step 3: Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while current_weight > capacity:\n            # Find items in the solution\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break  # No items to remove, solution is infeasible\n            # Calculate value-to-weight ratios for items in the solution\n            ratios = (value1_lst[items_in_solution] + value2_lst[items_in_solution]) / weight_lst[items_in_solution]\n            # Remove the item with the lowest ratio\n            item_to_remove = items_in_solution[np.argmin(ratios)]\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.3745403092720494,
            6.364809066057205
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on a combination of randomness and potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        # Calculate the current total weight\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight >= capacity:\n            continue  # Skip infeasible solutions\n\n        # Calculate the potential for improvement (items not in the solution)\n        potential_items = np.where(sol == 0)[0]\n        if len(potential_items) == 0:\n            continue  # No items to add\n\n        # Calculate the value-to-weight ratios for potential items\n        value1_ratios = value1_lst[potential_items] / weight_lst[potential_items]\n        value2_ratios = value2_lst[potential_items] / weight_lst[potential_items]\n\n        # Select items with high value-to-weight ratios for both objectives\n        high_value1_items = potential_items[value1_ratios >= np.percentile(value1_ratios, 75)]\n        high_value2_items = potential_items[value2_ratios >= np.percentile(value2_ratios, 75)]\n\n        # Combine with randomness to add diversity\n        if len(high_value1_items) > 0:\n            candidates.append(sol)\n        if len(high_value2_items) > 0:\n            candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select a candidate with higher potential for improvement\n        base_solution = max(candidates, key=lambda x: np.sum(value1_lst[x == 0] + value2_lst[x == 0]))\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with higher probability for items with high value-to-weight ratios)\n    # 2. Adjust the solution to maximize one objective while keeping the other objective stable\n    # 3. Ensure feasibility by removing items if capacity is exceeded\n\n    # Step 1: Random flips with value-aware probability\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Remove item with probability proportional to its value-to-weight ratio\n            remove_prob = 0.1 * (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            if random.random() < remove_prob:\n                new_solution[i] = 0\n        else:\n            # Add item with probability proportional to its value-to-weight ratio\n            add_prob = 0.1 * (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            if random.random() < add_prob:\n                new_solution[i] = 1\n\n    # Step 2: Adjust to maximize one objective while keeping the other stable\n    # Choose the objective to maximize randomly\n    if random.random() < 0.5:\n        # Maximize value1\n        # Sort items not in the solution by value1-to-weight ratio\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            value1_ratios = value1_lst[potential_items] / weight_lst[potential_items]\n            sorted_items = potential_items[np.argsort(value1_ratios)[::-1]]\n            # Add items until capacity is exceeded\n            for item in sorted_items:\n                if np.sum(weight_lst * new_solution) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                else:\n                    break\n    else:\n        # Maximize value2\n        # Sort items not in the solution by value2-to-weight ratio\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            value2_ratios = value2_lst[potential_items] / weight_lst[potential_items]\n            sorted_items = potential_items[np.argsort(value2_ratios)[::-1]]\n            # Add items until capacity is exceeded\n            for item in sorted_items:\n                if np.sum(weight_lst * new_solution) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                else:\n                    break\n\n    # Step 3: Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while current_weight > capacity:\n            # Find items in the solution\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break  # No items to remove, solution is infeasible\n            # Calculate value-to-weight ratios for items in the solution\n            ratios = (value1_lst[items_in_solution] + value2_lst[items_in_solution]) / weight_lst[items_in_solution]\n            # Remove the item with the lowest ratio\n            item_to_remove = items_in_solution[np.argmin(ratios)]\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 109,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # (assuming archive is already non-dominated, we can pick randomly or based on some metric)\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: perform random swaps and greedy additions\n    num_swaps = min(3, len(new_solution) // 2)  # Limit the number of swaps to avoid excessive changes\n    for _ in range(num_swaps):\n        # Randomly select two items to swap\n        i, j = random.sample(range(len(new_solution)), 2)\n\n        # Calculate the effect of swapping\n        if new_solution[i] == new_solution[j]:\n            continue  # No change if both are the same\n\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n\n    # Greedy addition of items not in the solution\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utils = []\n        for idx in np.where(new_solution == 0)[0]:\n            marginal_utils.append((value1_lst[idx] + value2_lst[idx], weight_lst[idx], idx))\n\n        # Sort by marginal utility (highest first) and weight (lowest first)\n        marginal_utils.sort(key=lambda x: (-x[0], x[1]))\n\n        # Add items until capacity is reached\n        for _, weight, idx in marginal_utils:\n            if weight <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight\n\n    return new_solution\n\n",
        "score": [
            -0.35633385815698504,
            3.801400810480118
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # (assuming archive is already non-dominated, we can pick randomly or based on some metric)\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: perform random swaps and greedy additions\n    num_swaps = min(3, len(new_solution) // 2)  # Limit the number of swaps to avoid excessive changes\n    for _ in range(num_swaps):\n        # Randomly select two items to swap\n        i, j = random.sample(range(len(new_solution)), 2)\n\n        # Calculate the effect of swapping\n        if new_solution[i] == new_solution[j]:\n            continue  # No change if both are the same\n\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n\n    # Greedy addition of items not in the solution\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utils = []\n        for idx in np.where(new_solution == 0)[0]:\n            marginal_utils.append((value1_lst[idx] + value2_lst[idx], weight_lst[idx], idx))\n\n        # Sort by marginal utility (highest first) and weight (lowest first)\n        marginal_utils.sort(key=lambda x: (-x[0], x[1]))\n\n        # Add items until capacity is reached\n        for _, weight, idx in marginal_utils:\n            if weight <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 110,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the objective space\n    # This helps in exploring less-explored regions\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (to identify less crowded regions)\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1])\n        # Select a solution from the middle 50% to balance exploration and exploitation\n        base_solution = random.choice(archive_sorted[len(archive_sorted)//4 : 3*len(archive_sorted)//4])[0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1 to 3 items)\n    num_flips = random.randint(1, min(3, len(base_solution)))\n    flip_indices = random.sample(range(len(base_solution)), num_flips)\n\n    # 2. For each selected item, decide to flip based on its potential to improve both objectives\n    for idx in flip_indices:\n        current_value1 = value1_lst[idx] if new_solution[idx] == 0 else -value1_lst[idx]\n        current_value2 = value2_lst[idx] if new_solution[idx] == 0 else -value2_lst[idx]\n        current_weight = weight_lst[idx] if new_solution[idx] == 0 else -weight_lst[idx]\n\n        # Calculate the new total weight if we flip this item\n        new_total_weight = np.sum(weight_lst * new_solution) + current_weight\n\n        # Only flip if the new solution remains feasible\n        if new_total_weight <= capacity:\n            # Flip the item with a probability based on the improvement potential\n            # Higher probability for items that improve both objectives\n            improvement1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n            improvement2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n            flip_prob = 0.5 * (improvement1 + improvement2)\n\n            if random.random() < flip_prob:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure the solution is feasible (in case of any rounding errors)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Randomly remove an item until the solution is feasible\n        selected_items = np.where(new_solution == 1)[0]\n        if len(selected_items) == 0:\n            break  # No items to remove\n        remove_idx = random.choice(selected_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9206236028539103,
            0.7451761960983276
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the objective space\n    # This helps in exploring less-explored regions\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (to identify less crowded regions)\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1])\n        # Select a solution from the middle 50% to balance exploration and exploitation\n        base_solution = random.choice(archive_sorted[len(archive_sorted)//4 : 3*len(archive_sorted)//4])[0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1 to 3 items)\n    num_flips = random.randint(1, min(3, len(base_solution)))\n    flip_indices = random.sample(range(len(base_solution)), num_flips)\n\n    # 2. For each selected item, decide to flip based on its potential to improve both objectives\n    for idx in flip_indices:\n        current_value1 = value1_lst[idx] if new_solution[idx] == 0 else -value1_lst[idx]\n        current_value2 = value2_lst[idx] if new_solution[idx] == 0 else -value2_lst[idx]\n        current_weight = weight_lst[idx] if new_solution[idx] == 0 else -weight_lst[idx]\n\n        # Calculate the new total weight if we flip this item\n        new_total_weight = np.sum(weight_lst * new_solution) + current_weight\n\n        # Only flip if the new solution remains feasible\n        if new_total_weight <= capacity:\n            # Flip the item with a probability based on the improvement potential\n            # Higher probability for items that improve both objectives\n            improvement1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n            improvement2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n            flip_prob = 0.5 * (improvement1 + improvement2)\n\n            if random.random() < flip_prob:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure the solution is feasible (in case of any rounding errors)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Randomly remove an item until the solution is feasible\n        selected_items = np.where(new_solution == 1)[0]\n        if len(selected_items) == 0:\n            break  # No items to remove\n        remove_idx = random.choice(selected_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 111,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions close to the knee of the Pareto front\n    def knee_metric(sol):\n        v1, v2 = sol[1]\n        return abs(v1 - v2)  # Simple knee metric: minimize the difference\n\n    archive_sorted = sorted(archive, key=knee_metric)\n    base_solution = archive_sorted[min(3, len(archive_sorted) - 1)][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flip and greedy improvement\n    # Step 1: Randomly flip a small number of items (1-3)\n    n_flips = random.randint(1, 3)\n    flip_indices = random.sample(range(len(new_solution)), n_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement - try to add items that improve at least one objective\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Get items not in the solution\n    candidate_indices = np.where(new_solution == 0)[0]\n\n    for idx in candidate_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Remove items that don't contribute to any objective (if any)\n    for idx in np.where(new_solution == 1)[0]:\n        if value1_lst[idx] == 0 and value2_lst[idx] == 0:\n            new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6880007215092178,
            0.7153050303459167
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions close to the knee of the Pareto front\n    def knee_metric(sol):\n        v1, v2 = sol[1]\n        return abs(v1 - v2)  # Simple knee metric: minimize the difference\n\n    archive_sorted = sorted(archive, key=knee_metric)\n    base_solution = archive_sorted[min(3, len(archive_sorted) - 1)][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flip and greedy improvement\n    # Step 1: Randomly flip a small number of items (1-3)\n    n_flips = random.randint(1, 3)\n    flip_indices = random.sample(range(len(new_solution)), n_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement - try to add items that improve at least one objective\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Get items not in the solution\n    candidate_indices = np.where(new_solution == 0)[0]\n\n    for idx in candidate_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Remove items that don't contribute to any objective (if any)\n    for idx in np.where(new_solution == 1)[0]:\n        if value1_lst[idx] == 0 and value2_lst[idx] == 0:\n            new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 112,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on a combination of objective values and diversity\n    def score_solution(solution, objective):\n        # Score based on normalized objective values and diversity (distance from other solutions)\n        diversity = sum(np.linalg.norm(solution - other_sol[0]) for other_sol in archive)\n        return (objective[0] + objective[1]) / (1 + diversity)  # Avoid division by zero\n\n    scored_solutions = [(score_solution(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n    selected_solution = scored_solutions[0][1].copy()\n\n    # Hybrid local search strategy: combination of item swaps, flips, and cluster-based moves\n    new_solution = selected_solution.copy()\n\n    # 1. Randomly flip a subset of items (with probability based on their marginal contribution)\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.2:  # 20% chance to flip\n            if new_solution[i] == 1:\n                # Check if removing the item keeps the solution feasible\n                if (np.sum(weight_lst * new_solution) - weight_lst[i]) <= capacity:\n                    new_solution[i] = 0\n            else:\n                # Check if adding the item keeps the solution feasible\n                if (np.sum(weight_lst * new_solution) + weight_lst[i]) <= capacity:\n                    new_solution[i] = 1\n\n    # 2. Perform a cluster-based move: find items with similar value ratios and flip them together\n    if len(new_solution) > 1:\n        # Calculate value ratios for items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            value_ratios = value1_lst[in_solution] / (value2_lst[in_solution] + 1e-10)  # Avoid division by zero\n            cluster_center = np.median(value_ratios)\n\n            # Identify items in the solution with similar value ratios to the cluster center\n            similar_items = in_solution[np.abs(value_ratios - cluster_center) < 0.5 * np.std(value_ratios)]\n\n            # Flip a random subset of these similar items (with probability based on their count)\n            flip_prob = min(0.5, len(similar_items) / len(new_solution))\n            for i in similar_items:\n                if np.random.rand() < flip_prob:\n                    if (np.sum(weight_lst * new_solution) - weight_lst[i]) <= capacity:\n                        new_solution[i] = 0\n\n    # 3. Randomly add or remove items based on their marginal contribution\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.1:  # 10% chance to consider adding/removing\n            if new_solution[i] == 0:\n                # Calculate marginal contribution for adding this item\n                marginal_value1 = value1_lst[i]\n                marginal_value2 = value2_lst[i]\n                marginal_weight = weight_lst[i]\n\n                # Check if adding this item improves at least one objective without violating capacity\n                current_value1, current_value2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n                if (np.sum(weight_lst * new_solution) + marginal_weight) <= capacity and \\\n                   (marginal_value1 > 0 or marginal_value2 > 0):\n                    new_solution[i] = 1\n            else:\n                # Check if removing this item doesn't hurt both objectives too much\n                marginal_value1 = -value1_lst[i]\n                marginal_value2 = -value2_lst[i]\n                if (marginal_value1 >= 0 or marginal_value2 >= 0):\n                    new_solution[i] = 0\n\n    # Ensure the solution is feasible (in case of any errors in the above steps)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Randomly remove items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break  # No items to remove, but this should not happen as capacity is positive\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.35889393326310914,
            6.515410989522934
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on a combination of objective values and diversity\n    def score_solution(solution, objective):\n        # Score based on normalized objective values and diversity (distance from other solutions)\n        diversity = sum(np.linalg.norm(solution - other_sol[0]) for other_sol in archive)\n        return (objective[0] + objective[1]) / (1 + diversity)  # Avoid division by zero\n\n    scored_solutions = [(score_solution(sol, obj), sol) for sol, obj in archive]\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n    selected_solution = scored_solutions[0][1].copy()\n\n    # Hybrid local search strategy: combination of item swaps, flips, and cluster-based moves\n    new_solution = selected_solution.copy()\n\n    # 1. Randomly flip a subset of items (with probability based on their marginal contribution)\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.2:  # 20% chance to flip\n            if new_solution[i] == 1:\n                # Check if removing the item keeps the solution feasible\n                if (np.sum(weight_lst * new_solution) - weight_lst[i]) <= capacity:\n                    new_solution[i] = 0\n            else:\n                # Check if adding the item keeps the solution feasible\n                if (np.sum(weight_lst * new_solution) + weight_lst[i]) <= capacity:\n                    new_solution[i] = 1\n\n    # 2. Perform a cluster-based move: find items with similar value ratios and flip them together\n    if len(new_solution) > 1:\n        # Calculate value ratios for items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            value_ratios = value1_lst[in_solution] / (value2_lst[in_solution] + 1e-10)  # Avoid division by zero\n            cluster_center = np.median(value_ratios)\n\n            # Identify items in the solution with similar value ratios to the cluster center\n            similar_items = in_solution[np.abs(value_ratios - cluster_center) < 0.5 * np.std(value_ratios)]\n\n            # Flip a random subset of these similar items (with probability based on their count)\n            flip_prob = min(0.5, len(similar_items) / len(new_solution))\n            for i in similar_items:\n                if np.random.rand() < flip_prob:\n                    if (np.sum(weight_lst * new_solution) - weight_lst[i]) <= capacity:\n                        new_solution[i] = 0\n\n    # 3. Randomly add or remove items based on their marginal contribution\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.1:  # 10% chance to consider adding/removing\n            if new_solution[i] == 0:\n                # Calculate marginal contribution for adding this item\n                marginal_value1 = value1_lst[i]\n                marginal_value2 = value2_lst[i]\n                marginal_weight = weight_lst[i]\n\n                # Check if adding this item improves at least one objective without violating capacity\n                current_value1, current_value2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n                if (np.sum(weight_lst * new_solution) + marginal_weight) <= capacity and \\\n                   (marginal_value1 > 0 or marginal_value2 > 0):\n                    new_solution[i] = 1\n            else:\n                # Check if removing this item doesn't hurt both objectives too much\n                marginal_value1 = -value1_lst[i]\n                marginal_value2 = -value2_lst[i]\n                if (marginal_value1 >= 0 or marginal_value2 >= 0):\n                    new_solution[i] = 0\n\n    # Ensure the solution is feasible (in case of any errors in the above steps)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Randomly remove items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break  # No items to remove, but this should not happen as capacity is positive\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 113,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a bias towards those with higher potential improvement\n    weights = np.array([(obj[0] + obj[1]) for (_, obj) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip items with a probability based on their value contribution\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to consider flipping\n            flip_value1 = value1_lst[i] if new_solution[i] == 0 else -value1_lst[i]\n            flip_value2 = value2_lst[i] if new_solution[i] == 0 else -value2_lst[i]\n            flip_weight = weight_lst[i] if new_solution[i] == 0 else -weight_lst[i]\n\n            # Only flip if it maintains feasibility or improves the solution\n            if current_weight + flip_weight <= capacity:\n                if (new_solution[i] == 0 and (flip_value1 > 0 or flip_value2 > 0)) or \\\n                   (new_solution[i] == 1 and (flip_value1 < 0 or flip_value2 < 0)):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += flip_weight\n\n    # Additional diversification: randomly flip one item to escape local optima\n    if random.random() < 0.2:  # 20% chance for diversification\n        candidate_items = [i for i in range(len(new_solution)) if weight_lst[i] <= capacity - current_weight]\n        if candidate_items:\n            i = random.choice(candidate_items)\n            new_solution[i] = 1 - new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4066314974353449,
            1.312861680984497
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a bias towards those with higher potential improvement\n    weights = np.array([(obj[0] + obj[1]) for (_, obj) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip items with a probability based on their value contribution\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to consider flipping\n            flip_value1 = value1_lst[i] if new_solution[i] == 0 else -value1_lst[i]\n            flip_value2 = value2_lst[i] if new_solution[i] == 0 else -value2_lst[i]\n            flip_weight = weight_lst[i] if new_solution[i] == 0 else -weight_lst[i]\n\n            # Only flip if it maintains feasibility or improves the solution\n            if current_weight + flip_weight <= capacity:\n                if (new_solution[i] == 0 and (flip_value1 > 0 or flip_value2 > 0)) or \\\n                   (new_solution[i] == 1 and (flip_value1 < 0 or flip_value2 < 0)):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += flip_weight\n\n    # Additional diversification: randomly flip one item to escape local optima\n    if random.random() < 0.2:  # 20% chance for diversification\n        candidate_items = [i for i in range(len(new_solution)) if weight_lst[i] <= capacity - current_weight]\n        if candidate_items:\n            i = random.choice(candidate_items)\n            new_solution[i] = 1 - new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 114,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified heuristic: pick a solution not on the extreme Pareto front)\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n        candidate_solutions = [sol for sol in archive_sorted if sol[1][0] < archive_sorted[-1][1][0] and sol[1][1] < archive_sorted[-1][1][1]]\n        if candidate_solutions:\n            base_solution, _ = random.choice(candidate_solutions)\n        else:\n            base_solution, _ = random.choice(archive)\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid local search strategy: combine swap and flip operations\n    # Step 1: Randomly select a subset of items to flip (10% of items)\n    flip_indices = random.sample(range(n_items), max(1, n_items // 10))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while total_weight > capacity and len(excess_items) > 0:\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(new_solution * weight_lst)\n            excess_items = np.where(new_solution == 1)[0]\n\n    # Step 3: Apply a swap operation between two randomly selected items\n    if n_items > 1:\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure final feasibility (edge case)\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove the heaviest items until feasible\n        sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight = np.sum(new_solution * weight_lst)\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.4597608077725464,
            1.3991848230361938
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified heuristic: pick a solution not on the extreme Pareto front)\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n        candidate_solutions = [sol for sol in archive_sorted if sol[1][0] < archive_sorted[-1][1][0] and sol[1][1] < archive_sorted[-1][1][1]]\n        if candidate_solutions:\n            base_solution, _ = random.choice(candidate_solutions)\n        else:\n            base_solution, _ = random.choice(archive)\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid local search strategy: combine swap and flip operations\n    # Step 1: Randomly select a subset of items to flip (10% of items)\n    flip_indices = random.sample(range(n_items), max(1, n_items // 10))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while total_weight > capacity and len(excess_items) > 0:\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(new_solution * weight_lst)\n            excess_items = np.where(new_solution == 1)[0]\n\n    # Step 3: Apply a swap operation between two randomly selected items\n    if n_items > 1:\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure final feasibility (edge case)\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove the heaviest items until feasible\n        sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight = np.sum(new_solution * weight_lst)\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 115,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate improvement potential (normalized value-to-weight ratio)\n    potential = []\n    for sol, w, v1, v2 in zip(archive_solutions, archive_weights, archive_values1, archive_values2):\n        if w >= capacity:  # Skip infeasible solutions\n            potential.append(0)\n            continue\n        # Normalized value-to-weight ratio for both objectives\n        ratio1 = v1 / (w + 1e-6)  # Avoid division by zero\n        ratio2 = v2 / (w + 1e-6)\n        potential.append(ratio1 + ratio2)\n\n    # Select top 20% solutions with highest potential\n    top_k = max(1, len(potential) // 5)\n    top_indices = np.argsort(potential)[-top_k:]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search: combine random flip with value-to-weight ratio\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine which objective to prioritize based on current solution\n    current_v1 = np.sum(value1_lst * new_solution)\n    current_v2 = np.sum(value2_lst * new_solution)\n    prioritize_v1 = current_v1 < np.mean(archive_values1)\n\n    # Flip bits based on value-to-weight ratio and objective priority\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to flip each bit\n            if new_solution[i] == 1:\n                # Try removing item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n            else:\n                # Try adding item based on value-to-weight ratio\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    # Calculate combined value-to-weight ratio\n                    v1_ratio = value1_lst[i] / (weight_lst[i] + 1e-6)\n                    v2_ratio = value2_lst[i] / (weight_lst[i] + 1e-6)\n                    combined_ratio = v1_ratio if prioritize_v1 else v2_ratio\n\n                    # Add item with probability proportional to its ratio\n                    if random.random() < combined_ratio / (combined_ratio + 1):\n                        new_solution[i] = 1\n                        current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3487388495474237,
            1.5110778510570526
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate improvement potential (normalized value-to-weight ratio)\n    potential = []\n    for sol, w, v1, v2 in zip(archive_solutions, archive_weights, archive_values1, archive_values2):\n        if w >= capacity:  # Skip infeasible solutions\n            potential.append(0)\n            continue\n        # Normalized value-to-weight ratio for both objectives\n        ratio1 = v1 / (w + 1e-6)  # Avoid division by zero\n        ratio2 = v2 / (w + 1e-6)\n        potential.append(ratio1 + ratio2)\n\n    # Select top 20% solutions with highest potential\n    top_k = max(1, len(potential) // 5)\n    top_indices = np.argsort(potential)[-top_k:]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search: combine random flip with value-to-weight ratio\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine which objective to prioritize based on current solution\n    current_v1 = np.sum(value1_lst * new_solution)\n    current_v2 = np.sum(value2_lst * new_solution)\n    prioritize_v1 = current_v1 < np.mean(archive_values1)\n\n    # Flip bits based on value-to-weight ratio and objective priority\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # 30% chance to flip each bit\n            if new_solution[i] == 1:\n                # Try removing item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n                    current_weight = new_weight\n            else:\n                # Try adding item based on value-to-weight ratio\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    # Calculate combined value-to-weight ratio\n                    v1_ratio = value1_lst[i] / (weight_lst[i] + 1e-6)\n                    v2_ratio = value2_lst[i] / (weight_lst[i] + 1e-6)\n                    combined_ratio = v1_ratio if prioritize_v1 else v2_ratio\n\n                    # Add item with probability proportional to its ratio\n                    if random.random() < combined_ratio / (combined_ratio + 1):\n                        new_solution[i] = 1\n                        current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 116,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% of solutions)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_solutions = sorted_archive[:max(1, len(archive) // 3)]\n    selected_solution = random.choice(top_solutions)[0]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(new_solution * weight_lst)\n    current_value1 = np.sum(new_solution * value1_lst)\n    current_value2 = np.sum(new_solution * value2_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of bits (1-3) to escape local optima\n    num_flips = random.randint(1, 3)\n    for _ in range(num_flips):\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # 2. Greedily add items with high marginal value-to-weight ratio for both objectives\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Calculate marginal values\n        marginal_value1 = value1_lst - np.sum(value1_lst * new_solution) / len(new_solution)\n        marginal_value2 = value2_lst - np.sum(value2_lst * new_solution) / len(new_solution)\n        combined_marginal = marginal_value1 + marginal_value2\n\n        # Sort items by combined marginal value\n        sorted_indices = np.argsort(combined_marginal)[::-1]\n\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_weight and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n                if remaining_weight <= 0:\n                    break\n\n    # Ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove items with lowest value contribution until feasible\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Calculate value contribution (combined for both objectives)\n        value_contributions = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        remove_idx = included_items[np.argmin(value_contributions)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3320731777165592,
            4.476426810026169
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% of solutions)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_solutions = sorted_archive[:max(1, len(archive) // 3)]\n    selected_solution = random.choice(top_solutions)[0]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(new_solution * weight_lst)\n    current_value1 = np.sum(new_solution * value1_lst)\n    current_value2 = np.sum(new_solution * value2_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of bits (1-3) to escape local optima\n    num_flips = random.randint(1, 3)\n    for _ in range(num_flips):\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # 2. Greedily add items with high marginal value-to-weight ratio for both objectives\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Calculate marginal values\n        marginal_value1 = value1_lst - np.sum(value1_lst * new_solution) / len(new_solution)\n        marginal_value2 = value2_lst - np.sum(value2_lst * new_solution) / len(new_solution)\n        combined_marginal = marginal_value1 + marginal_value2\n\n        # Sort items by combined marginal value\n        sorted_indices = np.argsort(combined_marginal)[::-1]\n\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_weight and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n                if remaining_weight <= 0:\n                    break\n\n    # Ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove items with lowest value contribution until feasible\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Calculate value contribution (combined for both objectives)\n        value_contributions = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        remove_idx = included_items[np.argmin(value_contributions)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 117,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for those with higher combined value\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n\n    # Filter items that can be added without exceeding capacity\n    feasible_additions = [i for i in not_in_solution if weight_lst[i] <= remaining_capacity]\n\n    if not feasible_additions:\n        # If no items can be added, try removing items with low marginal contribution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Calculate marginal contribution for each item in the solution\n            marginal_contributions = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n            # Remove the item with the lowest marginal contribution\n            item_to_remove = in_solution[np.argmin(marginal_contributions)]\n            new_solution[item_to_remove] = 0\n    else:\n        # Add a random item from feasible additions\n        item_to_add = np.random.choice(feasible_additions)\n        new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9451637686207708,
            1.1407275199890137
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for those with higher combined value\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n\n    # Filter items that can be added without exceeding capacity\n    feasible_additions = [i for i in not_in_solution if weight_lst[i] <= remaining_capacity]\n\n    if not feasible_additions:\n        # If no items can be added, try removing items with low marginal contribution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Calculate marginal contribution for each item in the solution\n            marginal_contributions = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n            # Remove the item with the lowest marginal contribution\n            item_to_remove = in_solution[np.argmin(marginal_contributions)]\n            new_solution[item_to_remove] = 0\n    else:\n        # Add a random item from feasible additions\n        item_to_add = np.random.choice(feasible_additions)\n        new_solution[item_to_add] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 117,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for those with higher combined value\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n\n    # Filter items that can be added without exceeding capacity\n    feasible_additions = [i for i in not_in_solution if weight_lst[i] <= remaining_capacity]\n\n    if not feasible_additions:\n        # If no items can be added, try removing items with low marginal contribution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Calculate marginal contribution for each item in the solution\n            marginal_contributions = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n            # Remove the item with the lowest marginal contribution\n            item_to_remove = in_solution[np.argmin(marginal_contributions)]\n            new_solution[item_to_remove] = 0\n    else:\n        # Add a random item from feasible additions\n        item_to_add = np.random.choice(feasible_additions)\n        new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9451637686207708,
            1.1407275199890137
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for those with higher combined value\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n\n    # Filter items that can be added without exceeding capacity\n    feasible_additions = [i for i in not_in_solution if weight_lst[i] <= remaining_capacity]\n\n    if not feasible_additions:\n        # If no items can be added, try removing items with low marginal contribution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Calculate marginal contribution for each item in the solution\n            marginal_contributions = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n            # Remove the item with the lowest marginal contribution\n            item_to_remove = in_solution[np.argmin(marginal_contributions)]\n            new_solution[item_to_remove] = 0\n    else:\n        # Add a random item from feasible additions\n        item_to_add = np.random.choice(feasible_additions)\n        new_solution[item_to_add] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 118,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    promising_solutions = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        slack = capacity - current_weight\n        if slack > 0:  # Only consider feasible solutions\n            promising_solutions.append(sol)\n\n    if not promising_solutions:\n        return archive[0][0].copy()  # Fallback to first solution if no promising ones\n\n    # Step 2: Select a base solution with probability proportional to its slack\n    weights = [capacity - np.sum(weight_lst * sol) for sol in promising_solutions]\n    selected_idx = random.choices(range(len(promising_solutions)), weights=weights, k=1)[0]\n    base_solution = promising_solutions[selected_idx].copy()\n\n    # Step 3: Hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Randomly flip a small number of items (1-3)\n    flip_count = random.randint(1, 3)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        flip_indices = random.sample(list(candidates), min(flip_count, len(candidates)))\n        for idx in flip_indices:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Strategy 2: Add new items if capacity allows\n    available_items = np.where(new_solution == 0)[0]\n    random.shuffle(available_items)\n    for idx in available_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Strategy 3: Swap items between objectives (value1 and value2)\n    if random.random() < 0.5:\n        # Find items that are good for one objective but not the other\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        swap_candidates = np.where((new_solution == 1) &\n                                  ((obj1_ratio > 1.5 * obj2_ratio) | (obj2_ratio > 1.5 * obj1_ratio)))[0]\n\n        if len(swap_candidates) > 0:\n            swap_idx = random.choice(swap_candidates)\n            new_solution[swap_idx] = 0\n            current_weight -= weight_lst[swap_idx]\n\n            # Find best item to add in its place\n            add_candidates = np.where((new_solution == 0) &\n                                    (weight_lst <= capacity - current_weight))[0]\n            if len(add_candidates) > 0:\n                add_idx = random.choice(add_candidates)\n                new_solution[add_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3911718027816845,
            4.8816545605659485
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    promising_solutions = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        slack = capacity - current_weight\n        if slack > 0:  # Only consider feasible solutions\n            promising_solutions.append(sol)\n\n    if not promising_solutions:\n        return archive[0][0].copy()  # Fallback to first solution if no promising ones\n\n    # Step 2: Select a base solution with probability proportional to its slack\n    weights = [capacity - np.sum(weight_lst * sol) for sol in promising_solutions]\n    selected_idx = random.choices(range(len(promising_solutions)), weights=weights, k=1)[0]\n    base_solution = promising_solutions[selected_idx].copy()\n\n    # Step 3: Hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Randomly flip a small number of items (1-3)\n    flip_count = random.randint(1, 3)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        flip_indices = random.sample(list(candidates), min(flip_count, len(candidates)))\n        for idx in flip_indices:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Strategy 2: Add new items if capacity allows\n    available_items = np.where(new_solution == 0)[0]\n    random.shuffle(available_items)\n    for idx in available_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Strategy 3: Swap items between objectives (value1 and value2)\n    if random.random() < 0.5:\n        # Find items that are good for one objective but not the other\n        obj1_ratio = value1_lst / (weight_lst + 1e-6)\n        obj2_ratio = value2_lst / (weight_lst + 1e-6)\n        swap_candidates = np.where((new_solution == 1) &\n                                  ((obj1_ratio > 1.5 * obj2_ratio) | (obj2_ratio > 1.5 * obj1_ratio)))[0]\n\n        if len(swap_candidates) > 0:\n            swap_idx = random.choice(swap_candidates)\n            new_solution[swap_idx] = 0\n            current_weight -= weight_lst[swap_idx]\n\n            # Find best item to add in its place\n            add_candidates = np.where((new_solution == 0) &\n                                    (weight_lst <= capacity - current_weight))[0]\n            if len(add_candidates) > 0:\n                add_idx = random.choice(add_candidates)\n                new_solution[add_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 119,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total values and lower weights\n    base_solution, _ = max(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst[x[0] == 1]) + 1e-6))\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current total weight and value-to-weight ratios\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    value1_to_weight = value1_lst / (weight_lst + 1e-6)\n    value2_to_weight = value2_lst / (weight_lst + 1e-6)\n\n    # Hybrid local search: combine random perturbation with value-to-weight ratio-based selection\n    for _ in range(10):  # Number of perturbation attempts\n        # Randomly select a subset of items to consider flipping\n        candidate_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n\n        for idx in candidate_indices:\n            if new_solution[idx] == 1:\n                # Try removing the item if it's in the solution\n                temp_weight = current_weight - weight_lst[idx]\n                if temp_weight <= capacity:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n            else:\n                # Try adding the item if it's not in the solution\n                temp_weight = current_weight + weight_lst[idx]\n                if temp_weight <= capacity:\n                    # Prefer items with higher value-to-weight ratios for both objectives\n                    if (value1_to_weight[idx] > 0.5 * np.mean(value1_to_weight)) or (value2_to_weight[idx] > 0.5 * np.mean(value2_to_weight)):\n                        new_solution[idx] = 1\n                        current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.4371198588023393,
            4.623630255460739
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total values and lower weights\n    base_solution, _ = max(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(weight_lst[x[0] == 1]) + 1e-6))\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current total weight and value-to-weight ratios\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    value1_to_weight = value1_lst / (weight_lst + 1e-6)\n    value2_to_weight = value2_lst / (weight_lst + 1e-6)\n\n    # Hybrid local search: combine random perturbation with value-to-weight ratio-based selection\n    for _ in range(10):  # Number of perturbation attempts\n        # Randomly select a subset of items to consider flipping\n        candidate_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n\n        for idx in candidate_indices:\n            if new_solution[idx] == 1:\n                # Try removing the item if it's in the solution\n                temp_weight = current_weight - weight_lst[idx]\n                if temp_weight <= capacity:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight\n            else:\n                # Try adding the item if it's not in the solution\n                temp_weight = current_weight + weight_lst[idx]\n                if temp_weight <= capacity:\n                    # Prefer items with higher value-to-weight ratios for both objectives\n                    if (value1_to_weight[idx] > 0.5 * np.mean(value1_to_weight)) or (value2_to_weight[idx] > 0.5 * np.mean(value2_to_weight)):\n                        new_solution[idx] = 1\n                        current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 120,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of both objectives (higher score = more potential)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a random solution from the top 30% to encourage diversity\n        selected_idx = random.randint(0, max(0, len(archive_sorted) // 3 - 1))\n        base_solution = archive_sorted[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (perturbation)\n    num_flips = min(3, len(new_solution))  # Flip up to 3 items\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Swap items based on value-to-weight ratio to improve both objectives\n    # Calculate value-to-weight ratios for both objectives\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Identify items to potentially swap (those not in the current solution)\n    candidate_indices = np.where(new_solution == 0)[0]\n\n    if len(candidate_indices) > 0:\n        # Select the top 2 items with highest combined value-to-weight ratio\n        combined_ratio = value1_ratio + value2_ratio\n        top_items = sorted(candidate_indices, key=lambda x: -combined_ratio[x])[:2]\n\n        # Try to add these items if feasible\n        for idx in top_items:\n            if (weight_lst[idx] + np.sum(weight_lst[new_solution == 1])) <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility by removing the least valuable items if capacity exceeded\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Calculate marginal contribution (value1 + value2) per weight\n        included_items = np.where(new_solution == 1)[0]\n        marginal_contribution = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n        # Sort by marginal contribution and remove items until feasible\n        sorted_indices = included_items[np.argsort(marginal_contribution)]\n        for idx in sorted_indices:\n            if current_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.32802643272513365,
            1.5780946612358093
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of both objectives (higher score = more potential)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a random solution from the top 30% to encourage diversity\n        selected_idx = random.randint(0, max(0, len(archive_sorted) // 3 - 1))\n        base_solution = archive_sorted[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (perturbation)\n    num_flips = min(3, len(new_solution))  # Flip up to 3 items\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Swap items based on value-to-weight ratio to improve both objectives\n    # Calculate value-to-weight ratios for both objectives\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n\n    # Identify items to potentially swap (those not in the current solution)\n    candidate_indices = np.where(new_solution == 0)[0]\n\n    if len(candidate_indices) > 0:\n        # Select the top 2 items with highest combined value-to-weight ratio\n        combined_ratio = value1_ratio + value2_ratio\n        top_items = sorted(candidate_indices, key=lambda x: -combined_ratio[x])[:2]\n\n        # Try to add these items if feasible\n        for idx in top_items:\n            if (weight_lst[idx] + np.sum(weight_lst[new_solution == 1])) <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility by removing the least valuable items if capacity exceeded\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Calculate marginal contribution (value1 + value2) per weight\n        included_items = np.where(new_solution == 1)[0]\n        marginal_contribution = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n        # Sort by marginal contribution and remove items until feasible\n        sorted_indices = included_items[np.argsort(marginal_contribution)]\n        for idx in sorted_indices:\n            if current_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 121,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in objective space)\n    selected_solution, _ = random.choice(archive)\n    current_solution = selected_solution.copy()\n    total_weight = np.sum(weight_lst[current_solution == 1])\n\n    # Hybrid local search: random flip followed by greedy improvement\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        # Random flip: flip a random bit and check feasibility\n        flip_idx = random.randint(0, len(current_solution) - 1)\n        new_solution = current_solution.copy()\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Check feasibility\n        new_weight = total_weight + (weight_lst[flip_idx] if new_solution[flip_idx] == 1 else -weight_lst[flip_idx])\n        if new_weight <= capacity:\n            current_solution = new_solution\n            total_weight = new_weight\n\n    # Greedy improvement step: try to add items with high marginal value\n    remaining_capacity = capacity - total_weight\n    if remaining_capacity > 0:\n        # Calculate marginal value for each item not in the solution\n        marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine marginal values for both objectives (weighted sum)\n        combined_marginal = marginal_value1 + marginal_value2\n\n        # Sort items by combined marginal value in descending order\n        sorted_indices = np.argsort(-combined_marginal)\n\n        # Greedily add items until capacity is reached\n        for idx in sorted_indices:\n            if current_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                current_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return current_solution\n\n",
        "score": [
            -0.36596010614452346,
            1.4499914646148682
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in objective space)\n    selected_solution, _ = random.choice(archive)\n    current_solution = selected_solution.copy()\n    total_weight = np.sum(weight_lst[current_solution == 1])\n\n    # Hybrid local search: random flip followed by greedy improvement\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        # Random flip: flip a random bit and check feasibility\n        flip_idx = random.randint(0, len(current_solution) - 1)\n        new_solution = current_solution.copy()\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Check feasibility\n        new_weight = total_weight + (weight_lst[flip_idx] if new_solution[flip_idx] == 1 else -weight_lst[flip_idx])\n        if new_weight <= capacity:\n            current_solution = new_solution\n            total_weight = new_weight\n\n    # Greedy improvement step: try to add items with high marginal value\n    remaining_capacity = capacity - total_weight\n    if remaining_capacity > 0:\n        # Calculate marginal value for each item not in the solution\n        marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine marginal values for both objectives (weighted sum)\n        combined_marginal = marginal_value1 + marginal_value2\n\n        # Sort items by combined marginal value in descending order\n        sorted_indices = np.argsort(-combined_marginal)\n\n        # Greedily add items until capacity is reached\n        for idx in sorted_indices:\n            if current_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                current_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return current_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 122,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.dot(sol, weight_lst)\n        # Prefer solutions that are neither too full nor too empty\n        if 0.3 * capacity <= current_weight <= 0.7 * capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        # Fallback to random selection if no candidates meet the criteria\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    n_items = len(weight_lst)\n    if n_items == 0:\n        return new_solution\n\n    # Random flip: flip a random subset of items (up to 10% of items or 5 items, whichever is smaller)\n    flip_count = min(5, max(1, int(0.1 * n_items)))\n    flip_indices = random.sample(range(n_items), flip_count)\n\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # If item is in the solution, try to remove it (check feasibility)\n            if np.dot(new_solution, weight_lst) - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n        else:\n            # If item is not in the solution, try to add it (check feasibility)\n            if np.dot(new_solution, weight_lst) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n\n    # Greedy improvement: try to add items that improve both objectives\n    remaining_items = [i for i in range(n_items) if new_solution[i] == 0]\n    random.shuffle(remaining_items)\n\n    for i in remaining_items:\n        if np.dot(new_solution, weight_lst) + weight_lst[i] > capacity:\n            continue\n\n        # Calculate potential improvement in both objectives\n        delta_value1 = value1_lst[i]\n        delta_value2 = value2_lst[i]\n\n        # If adding the item improves both objectives, add it\n        if delta_value1 > 0 and delta_value2 > 0:\n            new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.44235638137299227,
            3.248514086008072
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.dot(sol, weight_lst)\n        # Prefer solutions that are neither too full nor too empty\n        if 0.3 * capacity <= current_weight <= 0.7 * capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        # Fallback to random selection if no candidates meet the criteria\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    n_items = len(weight_lst)\n    if n_items == 0:\n        return new_solution\n\n    # Random flip: flip a random subset of items (up to 10% of items or 5 items, whichever is smaller)\n    flip_count = min(5, max(1, int(0.1 * n_items)))\n    flip_indices = random.sample(range(n_items), flip_count)\n\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # If item is in the solution, try to remove it (check feasibility)\n            if np.dot(new_solution, weight_lst) - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n        else:\n            # If item is not in the solution, try to add it (check feasibility)\n            if np.dot(new_solution, weight_lst) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n\n    # Greedy improvement: try to add items that improve both objectives\n    remaining_items = [i for i in range(n_items) if new_solution[i] == 0]\n    random.shuffle(remaining_items)\n\n    for i in remaining_items:\n        if np.dot(new_solution, weight_lst) + weight_lst[i] > capacity:\n            continue\n\n        # Calculate potential improvement in both objectives\n        delta_value1 = value1_lst[i]\n        delta_value2 = value2_lst[i]\n\n        # If adding the item improves both objectives, add it\n        if delta_value1 > 0 and delta_value2 > 0:\n            new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 123,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not at the Pareto frontier)\n    # Here, we select a solution that is not dominated by others in the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items\n    n_items = len(weight_lst)\n    swap_indices = random.sample(range(n_items), min(3, n_items))  # Swap up to 3 items\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Add items with high value-to-weight ratio if capacity allows\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n        v2_ratio = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios (simple average for diversity)\n        combined_ratio = (v1_ratio + v2_ratio) / 2\n\n        # Sort items by combined ratio in descending order\n        sorted_indices = np.argsort(-combined_ratio)\n\n        # Add items with highest combined ratio until capacity is reached\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        combined_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(combined_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.34722708938973723,
            1.3634892404079437
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not at the Pareto frontier)\n    # Here, we select a solution that is not dominated by others in the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items\n    n_items = len(weight_lst)\n    swap_indices = random.sample(range(n_items), min(3, n_items))  # Swap up to 3 items\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Add items with high value-to-weight ratio if capacity allows\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n        v2_ratio = value2_lst / (weight_lst + 1e-10)\n\n        # Combine ratios (simple average for diversity)\n        combined_ratio = (v1_ratio + v2_ratio) / 2\n\n        # Sort items by combined ratio in descending order\n        sorted_indices = np.argsort(-combined_ratio)\n\n        # Add items with highest combined ratio until capacity is reached\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest combined ratio until feasible\n        combined_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(combined_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 124,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate combined value for each solution\n        combined_values = [obj[0] + obj[1] for (_, obj) in archive]\n        # Select solutions with top 50% combined value\n        top_indices = np.argsort(combined_values)[-len(archive)//2:]\n        selected = random.choice(top_indices)\n        base_solution = archive[selected][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for flipping\n    flip_candidates = random.sample(range(n_items), min(5, n_items))\n\n    for item in flip_candidates:\n        # Calculate potential impact of flipping this item\n        if new_solution[item] == 1:\n            # If item is currently in the solution, consider removing it\n            new_weight = np.sum(weight_lst * new_solution) - weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 0\n        else:\n            # If item is currently not in the solution, consider adding it\n            new_weight = np.sum(weight_lst * new_solution) + weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 1\n\n    # 2. Greedy improvement for one objective (alternating between objectives)\n    if random.random() < 0.5:\n        # Improve value1\n        for item in range(n_items):\n            if new_solution[item] == 0:\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[item]\n                if new_weight <= capacity:\n                    # Calculate marginal gain for value1\n                    marginal_gain = value1_lst[item]\n                    if marginal_gain > 0:\n                        new_solution[item] = 1\n    else:\n        # Improve value2\n        for item in range(n_items):\n            if new_solution[item] == 0:\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[item]\n                if new_weight <= capacity:\n                    # Calculate marginal gain for value2\n                    marginal_gain = value2_lst[item]\n                    if marginal_gain > 0:\n                        new_solution[item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.34972628257635674,
            4.838443756103516
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate combined value for each solution\n        combined_values = [obj[0] + obj[1] for (_, obj) in archive]\n        # Select solutions with top 50% combined value\n        top_indices = np.argsort(combined_values)[-len(archive)//2:]\n        selected = random.choice(top_indices)\n        base_solution = archive[selected][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for flipping\n    flip_candidates = random.sample(range(n_items), min(5, n_items))\n\n    for item in flip_candidates:\n        # Calculate potential impact of flipping this item\n        if new_solution[item] == 1:\n            # If item is currently in the solution, consider removing it\n            new_weight = np.sum(weight_lst * new_solution) - weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 0\n        else:\n            # If item is currently not in the solution, consider adding it\n            new_weight = np.sum(weight_lst * new_solution) + weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 1\n\n    # 2. Greedy improvement for one objective (alternating between objectives)\n    if random.random() < 0.5:\n        # Improve value1\n        for item in range(n_items):\n            if new_solution[item] == 0:\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[item]\n                if new_weight <= capacity:\n                    # Calculate marginal gain for value1\n                    marginal_gain = value1_lst[item]\n                    if marginal_gain > 0:\n                        new_solution[item] = 1\n    else:\n        # Improve value2\n        for item in range(n_items):\n            if new_solution[item] == 0:\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[item]\n                if new_weight <= capacity:\n                    # Calculate marginal gain for value2\n                    marginal_gain = value2_lst[item]\n                    if marginal_gain > 0:\n                        new_solution[item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 125,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    # Here, we select a solution that is not dominated by others in the archive\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        # If all solutions are non-dominated, select randomly\n        base_solution, _ = random.choice(archive)\n    else:\n        # Select the solution with the highest sum of normalized objective values\n        normalized = []\n        max_v1 = max(obj[0] for _, obj in non_dominated)\n        max_v2 = max(obj[1] for _, obj in non_dominated)\n        for sol, obj in non_dominated:\n            if max_v1 == 0 or max_v2 == 0:\n                normalized.append((sol, obj, 0))\n            else:\n                normalized.append((sol, obj, (obj[0]/max_v1 + obj[1]/max_v2)))\n\n        # Select the solution with the highest normalized score\n        base_solution, _, _ = max(normalized, key=lambda x: x[2])\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (add/remove)\n    # 2. Use a greedy approach to ensure feasibility\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            new_solution[idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight > capacity:\n                # If removing makes it infeasible, try to find a replacement\n                # Find items not in the solution that can be added without exceeding capacity\n                current_weight = total_weight - weight_lst[idx]\n                possible_additions = np.where((new_solution == 0) &\n                                            (weight_lst <= (capacity - current_weight)))[0]\n                if len(possible_additions) > 0:\n                    # Add the best item (highest value1 + value2)\n                    best_item = max(possible_additions,\n                                  key=lambda i: value1_lst[i] + value2_lst[i])\n                    new_solution[best_item] = 1\n        else:\n            # Try to add the item if feasible\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n            else:\n                # If adding makes it infeasible, try to remove the worst item\n                # Find items in the solution that can be removed to make space\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                needed_space = weight_lst[idx] - (capacity - current_weight)\n                if needed_space > 0:\n                    # Remove items with the lowest value1 + value2 until enough space is made\n                    items_in_solution = np.where(new_solution == 1)[0]\n                    sorted_items = sorted(items_in_solution,\n                                        key=lambda i: value1_lst[i] + value2_lst[i])\n                    for i in sorted_items:\n                        if needed_space <= 0:\n                            break\n                        new_solution[i] = 0\n                        needed_space -= weight_lst[i]\n                    # If still not feasible, revert the change\n                    if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] > capacity:\n                        new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3070488145062148,
            1.013973742723465
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    # Here, we select a solution that is not dominated by others in the archive\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        # If all solutions are non-dominated, select randomly\n        base_solution, _ = random.choice(archive)\n    else:\n        # Select the solution with the highest sum of normalized objective values\n        normalized = []\n        max_v1 = max(obj[0] for _, obj in non_dominated)\n        max_v2 = max(obj[1] for _, obj in non_dominated)\n        for sol, obj in non_dominated:\n            if max_v1 == 0 or max_v2 == 0:\n                normalized.append((sol, obj, 0))\n            else:\n                normalized.append((sol, obj, (obj[0]/max_v1 + obj[1]/max_v2)))\n\n        # Select the solution with the highest normalized score\n        base_solution, _, _ = max(normalized, key=lambda x: x[2])\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (add/remove)\n    # 2. Use a greedy approach to ensure feasibility\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            new_solution[idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight > capacity:\n                # If removing makes it infeasible, try to find a replacement\n                # Find items not in the solution that can be added without exceeding capacity\n                current_weight = total_weight - weight_lst[idx]\n                possible_additions = np.where((new_solution == 0) &\n                                            (weight_lst <= (capacity - current_weight)))[0]\n                if len(possible_additions) > 0:\n                    # Add the best item (highest value1 + value2)\n                    best_item = max(possible_additions,\n                                  key=lambda i: value1_lst[i] + value2_lst[i])\n                    new_solution[best_item] = 1\n        else:\n            # Try to add the item if feasible\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n            else:\n                # If adding makes it infeasible, try to remove the worst item\n                # Find items in the solution that can be removed to make space\n                current_weight = np.sum(weight_lst[new_solution == 1])\n                needed_space = weight_lst[idx] - (capacity - current_weight)\n                if needed_space > 0:\n                    # Remove items with the lowest value1 + value2 until enough space is made\n                    items_in_solution = np.where(new_solution == 1)[0]\n                    sorted_items = sorted(items_in_solution,\n                                        key=lambda i: value1_lst[i] + value2_lst[i])\n                    for i in sorted_items:\n                        if needed_space <= 0:\n                            break\n                        new_solution[i] = 0\n                        needed_space -= weight_lst[i]\n                    # If still not feasible, revert the change\n                    if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] > capacity:\n                        new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 126,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already near the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Make a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly perturb the solution (flip a few bits)\n    num_perturbations = min(3, len(new_solution))  # Limit perturbations to avoid excessive changes\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    new_solution[perturb_indices] = 1 - new_solution[perturb_indices]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            # Remove the heaviest item to minimize impact on objectives\n            heavy_items = np.where(new_solution == 1)[0]\n            if len(heavy_items) == 0:\n                break  # No items left to remove\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight -= weight_lst[heaviest_idx]\n            excess = current_weight - capacity\n\n    # 2. Greedily improve the solution by adding items with high marginal value\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate marginal values for each item not in the solution\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            # Use a weighted sum of objectives for marginal value\n            marginal_value1 = value1_lst[candidate_items]\n            marginal_value2 = value2_lst[candidate_items]\n            marginal_weights = weight_lst[candidate_items]\n\n            # Normalize objectives to avoid bias\n            normalized_value1 = (marginal_value1 - np.min(marginal_value1)) / (np.max(marginal_value1) - np.min(marginal_value1) + 1e-6)\n            normalized_value2 = (marginal_value2 - np.min(marginal_value2)) / (np.max(marginal_value2) - np.min(marginal_value2) + 1e-6)\n\n            # Combine objectives with equal weight (can be adjusted)\n            combined_value = normalized_value1 + normalized_value2\n\n            # Sort candidates by combined value and select top-k\n            top_k = min(5, len(candidate_items))  # Limit to avoid excessive additions\n            top_indices = np.argsort(combined_value)[-top_k:][::-1]\n\n            for idx in top_indices:\n                if marginal_weights[idx] <= remaining_capacity:\n                    new_solution[candidate_items[idx]] = 1\n                    remaining_capacity -= marginal_weights[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.37588206096012,
            1.0310450494289398
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already near the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Make a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly perturb the solution (flip a few bits)\n    num_perturbations = min(3, len(new_solution))  # Limit perturbations to avoid excessive changes\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    new_solution[perturb_indices] = 1 - new_solution[perturb_indices]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            # Remove the heaviest item to minimize impact on objectives\n            heavy_items = np.where(new_solution == 1)[0]\n            if len(heavy_items) == 0:\n                break  # No items left to remove\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight -= weight_lst[heaviest_idx]\n            excess = current_weight - capacity\n\n    # 2. Greedily improve the solution by adding items with high marginal value\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate marginal values for each item not in the solution\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            # Use a weighted sum of objectives for marginal value\n            marginal_value1 = value1_lst[candidate_items]\n            marginal_value2 = value2_lst[candidate_items]\n            marginal_weights = weight_lst[candidate_items]\n\n            # Normalize objectives to avoid bias\n            normalized_value1 = (marginal_value1 - np.min(marginal_value1)) / (np.max(marginal_value1) - np.min(marginal_value1) + 1e-6)\n            normalized_value2 = (marginal_value2 - np.min(marginal_value2)) / (np.max(marginal_value2) - np.min(marginal_value2) + 1e-6)\n\n            # Combine objectives with equal weight (can be adjusted)\n            combined_value = normalized_value1 + normalized_value2\n\n            # Sort candidates by combined value and select top-k\n            top_k = min(5, len(candidate_items))  # Limit to avoid excessive additions\n            top_indices = np.argsort(combined_value)[-top_k:][::-1]\n\n            for idx in top_indices:\n                if marginal_weights[idx] <= remaining_capacity:\n                    new_solution[candidate_items[idx]] = 1\n                    remaining_capacity -= marginal_weights[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 127,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    base_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1 to 3 items)\n    num_flips = np.random.randint(1, min(4, len(base_solution)))\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n\n    # 2. Attempt to flip each selected item, ensuring feasibility\n    new_solution = base_solution.copy()\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item if it's included\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item if it's excluded\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 3. If no changes were made, perform a more aggressive flip (swap two items)\n    if np.array_equal(new_solution, base_solution):\n        swap_indices = np.random.choice(len(base_solution), size=2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            new_weight = current_weight + (weight_lst[swap_indices[1]] - weight_lst[swap_indices[0]]) * (new_solution[swap_indices[1]] - new_solution[swap_indices[0]])\n            if new_weight <= capacity:\n                new_solution[swap_indices] = 1 - new_solution[swap_indices]\n\n    return new_solution\n\n",
        "score": [
            -0.42281398263961434,
            1.1287295818328857
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    base_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1 to 3 items)\n    num_flips = np.random.randint(1, min(4, len(base_solution)))\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n\n    # 2. Attempt to flip each selected item, ensuring feasibility\n    new_solution = base_solution.copy()\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item if it's included\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item if it's excluded\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 3. If no changes were made, perform a more aggressive flip (swap two items)\n    if np.array_equal(new_solution, base_solution):\n        swap_indices = np.random.choice(len(base_solution), size=2, replace=False)\n        if new_solution[swap_indices[0]] != new_solution[swap_indices[1]]:\n            new_weight = current_weight + (weight_lst[swap_indices[1]] - weight_lst[swap_indices[0]]) * (new_solution[swap_indices[1]] - new_solution[swap_indices[0]])\n            if new_weight <= capacity:\n                new_solution[swap_indices] = 1 - new_solution[swap_indices]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 128,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a bias towards those with higher total value sums\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    total_values = [sum(obj) for obj in archive_objectives]\n    probabilities = np.array(total_values) / sum(total_values) if sum(total_values) > 0 else np.ones(len(archive)) / len(archive)\n    base_solution = random.choices(archive_solutions, weights=probabilities, k=1)[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip + greedy improvement\n    # Step 1: Random flip (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_items = excess_items[np.argsort(weight_lst[excess_items])]  # Sort by weight\n        for idx in excess_items:\n            if excess_weight <= 0:\n                break\n            new_solution[idx] = 0\n            excess_weight -= weight_lst[idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Sort remaining items by value density (sum of normalized values)\n    value_density = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_indices = remaining_items[np.argsort(-value_density[remaining_items])]\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3233956664677209,
            1.5777548551559448
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a bias towards those with higher total value sums\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    total_values = [sum(obj) for obj in archive_objectives]\n    probabilities = np.array(total_values) / sum(total_values) if sum(total_values) > 0 else np.ones(len(archive)) / len(archive)\n    base_solution = random.choices(archive_solutions, weights=probabilities, k=1)[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip + greedy improvement\n    # Step 1: Random flip (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_items = excess_items[np.argsort(weight_lst[excess_items])]  # Sort by weight\n        for idx in excess_items:\n            if excess_weight <= 0:\n                break\n            new_solution[idx] = 0\n            excess_weight -= weight_lst[idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Sort remaining items by value density (sum of normalized values)\n    value_density = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_indices = remaining_items[np.argsort(-value_density[remaining_items])]\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 129,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards higher value solutions\n    values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = values / np.sum(values)\n    base_index = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[base_index][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate potential improvements for each item\n    potential_value1 = value1_lst / weight_lst\n    potential_value2 = value2_lst / weight_lst\n\n    # Hybrid local search strategy: prioritize items with high value/weight ratio in either objective\n    candidate_indices = np.where(base_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        candidate_weights = weight_lst[candidate_indices]\n        candidate_value1 = value1_lst[candidate_indices]\n        candidate_value2 = value2_lst[candidate_indices]\n\n        # Combine both objectives for selection probability\n        combined_potential = (candidate_value1 + candidate_value2) / (candidate_weights + 1e-6)\n        probabilities = combined_potential / np.sum(combined_potential)\n\n        # Select a candidate to add\n        selected_candidate = np.random.choice(candidate_indices, p=probabilities)\n        if current_weight + weight_lst[selected_candidate] <= capacity:\n            new_solution = base_solution.copy()\n            new_solution[selected_candidate] = 1\n            return new_solution\n\n    # If no addition is possible, try removing low-value items\n    candidate_indices = np.where(base_solution == 1)[0]\n    if len(candidate_indices) > 0:\n        candidate_value1 = value1_lst[candidate_indices]\n        candidate_value2 = value2_lst[candidate_indices]\n\n        # Combine both objectives for removal probability\n        combined_value = candidate_value1 + candidate_value2\n        probabilities = 1 / (combined_value + 1e-6)\n        probabilities /= np.sum(probabilities)\n\n        # Select a candidate to remove\n        selected_candidate = np.random.choice(candidate_indices, p=probabilities)\n        new_solution = base_solution.copy()\n        new_solution[selected_candidate] = 0\n        return new_solution\n\n    return base_solution.copy()\n\n",
        "score": [
            -0.8996321872201583,
            1.0936834216117859
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards higher value solutions\n    values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = values / np.sum(values)\n    base_index = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[base_index][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Calculate potential improvements for each item\n    potential_value1 = value1_lst / weight_lst\n    potential_value2 = value2_lst / weight_lst\n\n    # Hybrid local search strategy: prioritize items with high value/weight ratio in either objective\n    candidate_indices = np.where(base_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        candidate_weights = weight_lst[candidate_indices]\n        candidate_value1 = value1_lst[candidate_indices]\n        candidate_value2 = value2_lst[candidate_indices]\n\n        # Combine both objectives for selection probability\n        combined_potential = (candidate_value1 + candidate_value2) / (candidate_weights + 1e-6)\n        probabilities = combined_potential / np.sum(combined_potential)\n\n        # Select a candidate to add\n        selected_candidate = np.random.choice(candidate_indices, p=probabilities)\n        if current_weight + weight_lst[selected_candidate] <= capacity:\n            new_solution = base_solution.copy()\n            new_solution[selected_candidate] = 1\n            return new_solution\n\n    # If no addition is possible, try removing low-value items\n    candidate_indices = np.where(base_solution == 1)[0]\n    if len(candidate_indices) > 0:\n        candidate_value1 = value1_lst[candidate_indices]\n        candidate_value2 = value2_lst[candidate_indices]\n\n        # Combine both objectives for removal probability\n        combined_value = candidate_value1 + candidate_value2\n        probabilities = 1 / (combined_value + 1e-6)\n        probabilities /= np.sum(probabilities)\n\n        # Select a candidate to remove\n        selected_candidate = np.random.choice(candidate_indices, p=probabilities)\n        new_solution = base_solution.copy()\n        new_solution[selected_candidate] = 0\n        return new_solution\n\n    return base_solution.copy()\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 130,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% solutions)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_k = max(1, int(0.3 * len(sorted_archive)))\n    selected_solution = random.choice(sorted_archive[:top_k])[0].copy()\n\n    # Calculate current total weight and value-to-weight ratios\n    current_weight = np.sum(weight_lst * selected_solution)\n    current_value1 = np.sum(value1_lst * selected_solution)\n    current_value2 = np.sum(value2_lst * selected_solution)\n\n    # Hybrid local search: combine random flips with value-to-weight ratio heuristic\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (up to 10% of items)\n    flip_indices = random.sample(range(n_items), min(10, n_items))\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Apply value-to-weight ratio heuristic to fill remaining capacity\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate efficiency for each item (average of both objectives)\n        efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n        # Sort items by efficiency in descending order\n        sorted_indices = np.argsort(efficiency)[::-1]\n        for i in sorted_indices:\n            if weight_lst[i] <= remaining_capacity and new_solution[i] == 0:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.33631617754491194,
            1.971095085144043
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% solutions)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_k = max(1, int(0.3 * len(sorted_archive)))\n    selected_solution = random.choice(sorted_archive[:top_k])[0].copy()\n\n    # Calculate current total weight and value-to-weight ratios\n    current_weight = np.sum(weight_lst * selected_solution)\n    current_value1 = np.sum(value1_lst * selected_solution)\n    current_value2 = np.sum(value2_lst * selected_solution)\n\n    # Hybrid local search: combine random flips with value-to-weight ratio heuristic\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (up to 10% of items)\n    flip_indices = random.sample(range(n_items), min(10, n_items))\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Apply value-to-weight ratio heuristic to fill remaining capacity\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate efficiency for each item (average of both objectives)\n        efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n        # Sort items by efficiency in descending order\n        sorted_indices = np.argsort(efficiency)[::-1]\n        for i in sorted_indices:\n            if weight_lst[i] <= remaining_capacity and new_solution[i] == 0:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 131,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution in the archive\n    def calculate_crowding_distance(archive):\n        if len(archive) < 2:\n            return [0.0] * len(archive)\n\n        # Sort by each objective\n        sorted1 = sorted(archive, key=lambda x: x[1][0])\n        sorted2 = sorted(archive, key=lambda x: x[1][1])\n\n        # Initialize distances\n        distances = [0.0] * len(archive)\n\n        # Calculate distances for each objective\n        for i in range(2):\n            current_sorted = sorted1 if i == 0 else sorted2\n            distances[current_sorted[0][2]] = float('inf')\n            distances[current_sorted[-1][2]] = float('inf')\n\n            for j in range(1, len(current_sorted)-1):\n                idx = current_sorted[j][2]\n                prev_idx = current_sorted[j-1][2]\n                next_idx = current_sorted[j+1][2]\n                distances[idx] += (current_sorted[j+1][1][i] - current_sorted[j-1][1][i]) / (current_sorted[-1][1][i] - current_sorted[0][1][i])\n\n        return distances\n\n    # Add indices to archive for tracking\n    indexed_archive = [(sol, obj, idx) for idx, (sol, obj) in enumerate(archive)]\n    distances = calculate_crowding_distance(indexed_archive)\n\n    # Select solutions with high crowding distance (top 30%)\n    threshold = np.percentile(distances, 70)\n    candidates = [sol for sol, _, idx in indexed_archive if distances[idx] >= threshold]\n\n    if not candidates:\n        candidates = [sol for sol, _, _ in indexed_archive]\n\n    # Randomly select a base solution from candidates\n    base_solution = random.choice(candidates).copy()\n\n    # Generate neighbor using value-weighted swap\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items to consider for swap\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) == 0 or len(excluded) == 0:\n        return new_solution\n\n    # Calculate value ratios for included items\n    value_ratios = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n\n    # Select items to swap based on value ratios\n    swap_candidates = random.choices(\n        included,\n        weights=value_ratios,\n        k=min(3, len(included))\n    )\n\n    for item_in in swap_candidates:\n        # Find potential items to swap with\n        potential_swaps = []\n        for item_out in excluded:\n            delta_weight = weight_lst[item_out] - weight_lst[item_in]\n            if current_weight + delta_weight <= capacity:\n                potential_swaps.append(item_out)\n\n        if potential_swaps:\n            # Select swap with highest combined value improvement\n            best_item_out = max(\n                potential_swaps,\n                key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x]\n            )\n\n            # Perform the swap\n            new_solution[item_in] = 0\n            new_solution[best_item_out] = 1\n            current_weight += weight_lst[best_item_out] - weight_lst[item_in]\n\n    return new_solution\n\n",
        "score": [
            -0.5067136203850512,
            4.063351690769196
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution in the archive\n    def calculate_crowding_distance(archive):\n        if len(archive) < 2:\n            return [0.0] * len(archive)\n\n        # Sort by each objective\n        sorted1 = sorted(archive, key=lambda x: x[1][0])\n        sorted2 = sorted(archive, key=lambda x: x[1][1])\n\n        # Initialize distances\n        distances = [0.0] * len(archive)\n\n        # Calculate distances for each objective\n        for i in range(2):\n            current_sorted = sorted1 if i == 0 else sorted2\n            distances[current_sorted[0][2]] = float('inf')\n            distances[current_sorted[-1][2]] = float('inf')\n\n            for j in range(1, len(current_sorted)-1):\n                idx = current_sorted[j][2]\n                prev_idx = current_sorted[j-1][2]\n                next_idx = current_sorted[j+1][2]\n                distances[idx] += (current_sorted[j+1][1][i] - current_sorted[j-1][1][i]) / (current_sorted[-1][1][i] - current_sorted[0][1][i])\n\n        return distances\n\n    # Add indices to archive for tracking\n    indexed_archive = [(sol, obj, idx) for idx, (sol, obj) in enumerate(archive)]\n    distances = calculate_crowding_distance(indexed_archive)\n\n    # Select solutions with high crowding distance (top 30%)\n    threshold = np.percentile(distances, 70)\n    candidates = [sol for sol, _, idx in indexed_archive if distances[idx] >= threshold]\n\n    if not candidates:\n        candidates = [sol for sol, _, _ in indexed_archive]\n\n    # Randomly select a base solution from candidates\n    base_solution = random.choice(candidates).copy()\n\n    # Generate neighbor using value-weighted swap\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items to consider for swap\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) == 0 or len(excluded) == 0:\n        return new_solution\n\n    # Calculate value ratios for included items\n    value_ratios = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n\n    # Select items to swap based on value ratios\n    swap_candidates = random.choices(\n        included,\n        weights=value_ratios,\n        k=min(3, len(included))\n    )\n\n    for item_in in swap_candidates:\n        # Find potential items to swap with\n        potential_swaps = []\n        for item_out in excluded:\n            delta_weight = weight_lst[item_out] - weight_lst[item_in]\n            if current_weight + delta_weight <= capacity:\n                potential_swaps.append(item_out)\n\n        if potential_swaps:\n            # Select swap with highest combined value improvement\n            best_item_out = max(\n                potential_swaps,\n                key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x]\n            )\n\n            # Perform the swap\n            new_solution[item_in] = 0\n            new_solution[best_item_out] = 1\n            current_weight += weight_lst[best_item_out] - weight_lst[item_in]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 132,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions with higher total values\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy\n    # 1. Random flip with probability based on remaining capacity\n    flip_prob = min(0.5, remaining_capacity / capacity)\n    if random.random() < flip_prob:\n        # Flip a random bit, ensuring feasibility\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = np.random.choice(candidates)\n            new_solution[flip_idx] = 0\n            # Add an item if possible\n            candidates = np.where(new_solution == 0)[0]\n            for idx in np.random.permutation(candidates):\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # 2. Value-based swap: swap two items if it improves both objectives\n    if len(new_solution) >= 2:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select a pair of items to swap\n            in_idx = np.random.choice(in_items)\n            out_idx = np.random.choice(out_items)\n\n            # Check if the swap is feasible and beneficial\n            delta_weight = weight_lst[out_idx] - weight_lst[in_idx]\n            if delta_weight <= remaining_capacity:\n                new_solution[in_idx] = 0\n                new_solution[out_idx] = 1\n\n    # 3. Capacity-aware adjustment: remove items until feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio\n        ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.5371210913108513,
            1.4801307022571564
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions with higher total values\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy\n    # 1. Random flip with probability based on remaining capacity\n    flip_prob = min(0.5, remaining_capacity / capacity)\n    if random.random() < flip_prob:\n        # Flip a random bit, ensuring feasibility\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            flip_idx = np.random.choice(candidates)\n            new_solution[flip_idx] = 0\n            # Add an item if possible\n            candidates = np.where(new_solution == 0)[0]\n            for idx in np.random.permutation(candidates):\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # 2. Value-based swap: swap two items if it improves both objectives\n    if len(new_solution) >= 2:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select a pair of items to swap\n            in_idx = np.random.choice(in_items)\n            out_idx = np.random.choice(out_items)\n\n            # Check if the swap is feasible and beneficial\n            delta_weight = weight_lst[out_idx] - weight_lst[in_idx]\n            if delta_weight <= remaining_capacity:\n                new_solution[in_idx] = 0\n                new_solution[out_idx] = 1\n\n    # 3. Capacity-aware adjustment: remove items until feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio\n        ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 133,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    # Here, we select a solution that is not at the extreme ends of the Pareto front\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Make a copy to modify\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (perturbation)\n    # 2. Apply a greedy improvement step based on the most promising flips\n\n    # Step 1: Random perturbation (flip a few random items)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If over capacity, remove the heaviest items until feasible\n        excess = total_weight - capacity\n        sorted_indices = np.argsort(weight_lst * new_solution)[::-1]  # Heaviest first\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess > 0:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n                if excess <= 0:\n                    break\n\n    # Step 2: Greedy improvement step\n    # Evaluate flipping each item to see if it improves both objectives\n    best_improvement = 0\n    best_flip = None\n\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Evaluate removing the item\n            new_weight = total_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                delta_value1 = -value1_lst[idx]\n                delta_value2 = -value2_lst[idx]\n                # Check if removing improves both objectives\n                if delta_value1 > 0 and delta_value2 > 0:\n                    improvement = delta_value1 + delta_value2\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_flip = idx\n        else:\n            # Evaluate adding the item\n            new_weight = total_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                delta_value1 = value1_lst[idx]\n                delta_value2 = value2_lst[idx]\n                # Check if adding improves both objectives\n                if delta_value1 > 0 and delta_value2 > 0:\n                    improvement = delta_value1 + delta_value2\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_flip = idx\n\n    # Apply the best flip if it exists\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    return new_solution\n\n",
        "score": [
            -0.3917982420448812,
            1.1457708179950714
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    # Here, we select a solution that is not at the extreme ends of the Pareto front\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Make a copy to modify\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (perturbation)\n    # 2. Apply a greedy improvement step based on the most promising flips\n\n    # Step 1: Random perturbation (flip a few random items)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 random items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If over capacity, remove the heaviest items until feasible\n        excess = total_weight - capacity\n        sorted_indices = np.argsort(weight_lst * new_solution)[::-1]  # Heaviest first\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess > 0:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n                if excess <= 0:\n                    break\n\n    # Step 2: Greedy improvement step\n    # Evaluate flipping each item to see if it improves both objectives\n    best_improvement = 0\n    best_flip = None\n\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Evaluate removing the item\n            new_weight = total_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                delta_value1 = -value1_lst[idx]\n                delta_value2 = -value2_lst[idx]\n                # Check if removing improves both objectives\n                if delta_value1 > 0 and delta_value2 > 0:\n                    improvement = delta_value1 + delta_value2\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_flip = idx\n        else:\n            # Evaluate adding the item\n            new_weight = total_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                delta_value1 = value1_lst[idx]\n                delta_value2 = value2_lst[idx]\n                # Check if adding improves both objectives\n                if delta_value1 > 0 and delta_value2 > 0:\n                    improvement = delta_value1 + delta_value2\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_flip = idx\n\n    # Apply the best flip if it exists\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 134,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with better potential (higher values)\n    base_solutions = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(base_solutions) * 0.2), len(base_solutions) - 1)  # Top 20% of solutions\n    base_solution, _ = base_solutions[random.randint(0, selected_idx)]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Random perturbation (flip 10% of items randomly)\n    flip_indices = np.random.choice(n_items, size=max(1, n_items // 10), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Greedy improvement (add items with highest marginal value for either objective)\n    remaining_items = np.where(new_solution == 0)[0]\n    remaining_weight = capacity - current_weight\n\n    if remaining_weight > 0:\n        # Sort remaining items by marginal value (sum of both objectives)\n        marginal_value = (value1_lst + value2_lst) * (weight_lst <= remaining_weight)\n        sorted_indices = np.argsort(marginal_value)[::-1]\n\n        for i in sorted_indices:\n            if weight_lst[i] <= remaining_weight and new_solution[i] == 0:\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3390544618157469,
            1.2264609038829803
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with better potential (higher values)\n    base_solutions = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(base_solutions) * 0.2), len(base_solutions) - 1)  # Top 20% of solutions\n    base_solution, _ = base_solutions[random.randint(0, selected_idx)]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Random perturbation (flip 10% of items randomly)\n    flip_indices = np.random.choice(n_items, size=max(1, n_items // 10), replace=False)\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 2: Greedy improvement (add items with highest marginal value for either objective)\n    remaining_items = np.where(new_solution == 0)[0]\n    remaining_weight = capacity - current_weight\n\n    if remaining_weight > 0:\n        # Sort remaining items by marginal value (sum of both objectives)\n        marginal_value = (value1_lst + value2_lst) * (weight_lst <= remaining_weight)\n        sorted_indices = np.argsort(marginal_value)[::-1]\n\n        for i in sorted_indices:\n            if weight_lst[i] <= remaining_weight and new_solution[i] == 0:\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 135,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based flip\n    # Step 1: Randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility by removing the heaviest items if capacity is exceeded\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Sort items by (value1 + value2) / weight ratio in descending order\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(-item_ratios)\n\n        # Remove items with lowest ratio until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    # Step 3: Add promising items with high value/weight ratio\n    remaining_capacity = capacity - np.sum(new_solution * weight_lst)\n    if remaining_capacity > 0:\n        # Sort items by (value1 + value2) / weight ratio in descending order\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(-item_ratios)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.33163447678886226,
            1.2969135344028473
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based flip\n    # Step 1: Randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility by removing the heaviest items if capacity is exceeded\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Sort items by (value1 + value2) / weight ratio in descending order\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(-item_ratios)\n\n        # Remove items with lowest ratio until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    # Step 3: Add promising items with high value/weight ratio\n    remaining_capacity = capacity - np.sum(new_solution * weight_lst)\n    if remaining_capacity > 0:\n        # Sort items by (value1 + value2) / weight ratio in descending order\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(-item_ratios)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 136,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution based on objective diversity and potential for improvement\n    # We prioritize solutions that are non-dominated and have the highest potential for improvement\n    # in either objective, but are not already at the Pareto front.\n    selected_idx = 0\n    max_potential = -1\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        current_weight = np.sum(weight_lst * sol)\n        # Calculate potential for improvement by evaluating the impact of flipping each item\n        potential = 0\n        for j in range(len(sol)):\n            if sol[j] == 1:\n                # Potential if we remove this item\n                new_weight = current_weight - weight_lst[j]\n                if new_weight <= capacity:\n                    potential += (value1_lst[j] + value2_lst[j])  # Combined potential\n            else:\n                # Potential if we add this item\n                new_weight = current_weight + weight_lst[j]\n                if new_weight <= capacity:\n                    potential += (value1_lst[j] + value2_lst[j])  # Combined potential\n        if potential > max_potential:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    # First, perform a random perturbation to escape local optima\n    num_perturbations = min(3, len(new_solution) // 2)  # Limit the number of perturbations\n    perturb_indices = random.sample(range(len(new_solution)), num_perturbations)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        while excess_weight > 0 and np.sum(new_solution) > 0:\n            remove_indices = np.where(new_solution == 1)[0]\n            if len(remove_indices) == 0:\n                break\n            remove_idx = random.choice(remove_indices)\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Step 3: Perform a greedy improvement step to maximize both objectives\n    # We use a combined objective function to balance both objectives\n    improved = True\n    while improved:\n        improved = False\n        best_gain = 0\n        best_idx = -1\n        best_action = None  # 'add' or 'remove'\n\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Evaluate removing this item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    gain = -(value1_lst[i] + value2_lst[i])  # Negative because we're removing\n                    if gain < best_gain:  # We want the least negative gain (i.e., smallest reduction)\n                        best_gain = gain\n                        best_idx = i\n                        best_action = 'remove'\n            else:\n                # Evaluate adding this item\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    gain = (value1_lst[i] + value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = i\n                        best_action = 'add'\n\n        # Apply the best improvement\n        if best_idx != -1 and best_gain > 0:  # Only apply if there's a positive gain\n            if best_action == 'add':\n                new_solution[best_idx] = 1\n                current_weight += weight_lst[best_idx]\n            else:\n                new_solution[best_idx] = 0\n                current_weight -= weight_lst[best_idx]\n            improved = True\n\n    return new_solution\n\n",
        "score": [
            -0.3570709615965163,
            5.352350831031799
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution based on objective diversity and potential for improvement\n    # We prioritize solutions that are non-dominated and have the highest potential for improvement\n    # in either objective, but are not already at the Pareto front.\n    selected_idx = 0\n    max_potential = -1\n    for i, (sol, (v1, v2)) in enumerate(archive):\n        current_weight = np.sum(weight_lst * sol)\n        # Calculate potential for improvement by evaluating the impact of flipping each item\n        potential = 0\n        for j in range(len(sol)):\n            if sol[j] == 1:\n                # Potential if we remove this item\n                new_weight = current_weight - weight_lst[j]\n                if new_weight <= capacity:\n                    potential += (value1_lst[j] + value2_lst[j])  # Combined potential\n            else:\n                # Potential if we add this item\n                new_weight = current_weight + weight_lst[j]\n                if new_weight <= capacity:\n                    potential += (value1_lst[j] + value2_lst[j])  # Combined potential\n        if potential > max_potential:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    # First, perform a random perturbation to escape local optima\n    num_perturbations = min(3, len(new_solution) // 2)  # Limit the number of perturbations\n    perturb_indices = random.sample(range(len(new_solution)), num_perturbations)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        while excess_weight > 0 and np.sum(new_solution) > 0:\n            remove_indices = np.where(new_solution == 1)[0]\n            if len(remove_indices) == 0:\n                break\n            remove_idx = random.choice(remove_indices)\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Step 3: Perform a greedy improvement step to maximize both objectives\n    # We use a combined objective function to balance both objectives\n    improved = True\n    while improved:\n        improved = False\n        best_gain = 0\n        best_idx = -1\n        best_action = None  # 'add' or 'remove'\n\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Evaluate removing this item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight <= capacity:\n                    gain = -(value1_lst[i] + value2_lst[i])  # Negative because we're removing\n                    if gain < best_gain:  # We want the least negative gain (i.e., smallest reduction)\n                        best_gain = gain\n                        best_idx = i\n                        best_action = 'remove'\n            else:\n                # Evaluate adding this item\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    gain = (value1_lst[i] + value2_lst[i])\n                    if gain > best_gain:\n                        best_gain = gain\n                        best_idx = i\n                        best_action = 'add'\n\n        # Apply the best improvement\n        if best_idx != -1 and best_gain > 0:  # Only apply if there's a positive gain\n            if best_action == 'add':\n                new_solution[best_idx] = 1\n                current_weight += weight_lst[best_idx]\n            else:\n                new_solution[best_idx] = 0\n                current_weight -= weight_lst[best_idx]\n            improved = True\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 137,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Calculate the ratio of the two objectives for each solution\n    ratios = [obj[0] / (obj[1] + 1e-10) for (sol, obj) in archive]  # Avoid division by zero\n    # Select solutions with the highest ratio (potential for improvement)\n    max_ratio = max(ratios)\n    candidates = [sol for (sol, obj), ratio in zip(archive, ratios) if ratio == max_ratio]\n    base_solution = random.choice(candidates).copy()\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Randomly select a subset of items to flip (1 to 3 items)\n    flip_indices = random.sample(range(n_items), random.randint(1, min(3, n_items)))\n\n    # Calculate the current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Flip the selected items and ensure feasibility\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Remove item if it's currently in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Add item if it's not currently in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional improvement: Consider swapping items between objectives\n    # Find items that are not currently selected but could improve both objectives\n    unselected_items = np.where(base_solution == 0)[0]\n    for idx in unselected_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if value1_lst[idx] > 0 and value2_lst[idx] > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.22779813536249022,
            1.2595587968826294
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Calculate the ratio of the two objectives for each solution\n    ratios = [obj[0] / (obj[1] + 1e-10) for (sol, obj) in archive]  # Avoid division by zero\n    # Select solutions with the highest ratio (potential for improvement)\n    max_ratio = max(ratios)\n    candidates = [sol for (sol, obj), ratio in zip(archive, ratios) if ratio == max_ratio]\n    base_solution = random.choice(candidates).copy()\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Randomly select a subset of items to flip (1 to 3 items)\n    flip_indices = random.sample(range(n_items), random.randint(1, min(3, n_items)))\n\n    # Calculate the current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Flip the selected items and ensure feasibility\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Remove item if it's currently in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Add item if it's not currently in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional improvement: Consider swapping items between objectives\n    # Find items that are not currently selected but could improve both objectives\n    unselected_items = np.where(base_solution == 0)[0]\n    for idx in unselected_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if value1_lst[idx] > 0 and value2_lst[idx] > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 138,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions with lower total weight (more room to add items)\n    # or solutions with high diversity (fewer duplicates in archive)\n    selected_idx = 0\n    min_weight = np.inf\n    for i, (sol, _) in enumerate(archive):\n        current_weight = np.dot(sol, weight_lst)\n        if current_weight < min_weight:\n            min_weight = current_weight\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip: flip a random item if feasible\n    if random.random() < 0.5:\n        flip_idx = random.randint(0, len(weight_lst) - 1)\n        if base_solution[flip_idx] == 0:\n            if np.dot(new_solution, weight_lst) + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        else:\n            new_solution[flip_idx] = 0\n\n    # 2. Weight-based swap: swap an item in the solution with an item not in the solution\n    #    prioritize items with lower weight to maximize capacity utilization\n    if random.random() < 0.5:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select the lightest item in the solution\n            lightest_in = min(in_items, key=lambda x: weight_lst[x])\n            # Select the heaviest item not in the solution that can fit\n            feasible_out = [x for x in out_items if weight_lst[x] <= capacity - (np.dot(new_solution, weight_lst) - weight_lst[lightest_in])]\n            if feasible_out:\n                heaviest_out = max(feasible_out, key=lambda x: weight_lst[x])\n                new_solution[lightest_in] = 0\n                new_solution[heaviest_out] = 1\n\n    # 3. Value-based swap: swap an item in the solution with an item not in the solution\n    #    prioritize items with higher value to maximize objective values\n    if random.random() < 0.5:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select the item with lowest value in the solution (for both objectives)\n            lowest_value_in = min(in_items, key=lambda x: value1_lst[x] + value2_lst[x])\n            # Select the item with highest value not in the solution that can fit\n            feasible_out = [x for x in out_items if weight_lst[x] <= capacity - (np.dot(new_solution, weight_lst) - weight_lst[lowest_value_in])]\n            if feasible_out:\n                highest_value_out = max(feasible_out, key=lambda x: value1_lst[x] + value2_lst[x])\n                new_solution[lowest_value_in] = 0\n                new_solution[highest_value_out] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7672708651902429,
            7.53075635433197
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions with lower total weight (more room to add items)\n    # or solutions with high diversity (fewer duplicates in archive)\n    selected_idx = 0\n    min_weight = np.inf\n    for i, (sol, _) in enumerate(archive):\n        current_weight = np.dot(sol, weight_lst)\n        if current_weight < min_weight:\n            min_weight = current_weight\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip: flip a random item if feasible\n    if random.random() < 0.5:\n        flip_idx = random.randint(0, len(weight_lst) - 1)\n        if base_solution[flip_idx] == 0:\n            if np.dot(new_solution, weight_lst) + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        else:\n            new_solution[flip_idx] = 0\n\n    # 2. Weight-based swap: swap an item in the solution with an item not in the solution\n    #    prioritize items with lower weight to maximize capacity utilization\n    if random.random() < 0.5:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select the lightest item in the solution\n            lightest_in = min(in_items, key=lambda x: weight_lst[x])\n            # Select the heaviest item not in the solution that can fit\n            feasible_out = [x for x in out_items if weight_lst[x] <= capacity - (np.dot(new_solution, weight_lst) - weight_lst[lightest_in])]\n            if feasible_out:\n                heaviest_out = max(feasible_out, key=lambda x: weight_lst[x])\n                new_solution[lightest_in] = 0\n                new_solution[heaviest_out] = 1\n\n    # 3. Value-based swap: swap an item in the solution with an item not in the solution\n    #    prioritize items with higher value to maximize objective values\n    if random.random() < 0.5:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select the item with lowest value in the solution (for both objectives)\n            lowest_value_in = min(in_items, key=lambda x: value1_lst[x] + value2_lst[x])\n            # Select the item with highest value not in the solution that can fit\n            feasible_out = [x for x in out_items if weight_lst[x] <= capacity - (np.dot(new_solution, weight_lst) - weight_lst[lowest_value_in])]\n            if feasible_out:\n                highest_value_out = max(feasible_out, key=lambda x: value1_lst[x] + value2_lst[x])\n                new_solution[lowest_value_in] = 0\n                new_solution[highest_value_out] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 139,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (np.sum(x[0]) / len(x[0])) * (1 - np.sum(x[0]) / len(x[0])))\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    marginal_value1 = value1_lst / (weight_lst + 1e-8)\n    marginal_value2 = value2_lst / (weight_lst + 1e-8)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top 20% items with highest combined marginal value\n    n_flip = max(1, int(0.2 * n_items))\n    top_items = np.argsort(-combined_marginal)[:n_flip]\n\n    for item in top_items:\n        if new_solution[item] == 1:\n            # Try removing the item\n            if total_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n        else:\n            # Try adding the item\n            if total_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n\n    # If no change, perform a random flip to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        available_items = [i for i in range(n_items) if (new_solution[i] == 0 and total_weight + weight_lst[i] <= capacity) or\n                          (new_solution[i] == 1 and total_weight - weight_lst[i] >= 0)]\n        if available_items:\n            item = np.random.choice(available_items)\n            new_solution[item] = 1 - new_solution[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8993197007769448,
            1.3590286672115326
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (np.sum(x[0]) / len(x[0])) * (1 - np.sum(x[0]) / len(x[0])))\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    marginal_value1 = value1_lst / (weight_lst + 1e-8)\n    marginal_value2 = value2_lst / (weight_lst + 1e-8)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top 20% items with highest combined marginal value\n    n_flip = max(1, int(0.2 * n_items))\n    top_items = np.argsort(-combined_marginal)[:n_flip]\n\n    for item in top_items:\n        if new_solution[item] == 1:\n            # Try removing the item\n            if total_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n        else:\n            # Try adding the item\n            if total_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n\n    # If no change, perform a random flip to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        available_items = [i for i in range(n_items) if (new_solution[i] == 0 and total_weight + weight_lst[i] <= capacity) or\n                          (new_solution[i] == 1 and total_weight - weight_lst[i] >= 0)]\n        if available_items:\n            item = np.random.choice(available_items)\n            new_solution[item] = 1 - new_solution[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 140,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Hybrid local search: random swaps + greedy improvement\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly select a subset of items to consider for swaps\n    swap_candidates = random.sample(range(n_items), min(5, n_items))\n\n    for i in swap_candidates:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if the removal improves either objective\n                temp_value1 = np.sum(value1_lst * temp_solution)\n                temp_value2 = np.sum(value2_lst * temp_solution)\n                if (temp_value1 >= archive[selected_idx][1][0] and temp_value2 >= archive[selected_idx][1][1]) or \\\n                   (random.random() < 0.3):  # 30% chance to accept non-improving moves\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if the addition improves either objective\n                temp_value1 = np.sum(value1_lst * temp_solution)\n                temp_value2 = np.sum(value2_lst * temp_solution)\n                if (temp_value1 >= archive[selected_idx][1][0] and temp_value2 >= archive[selected_idx][1][1]) or \\\n                   (random.random() < 0.3):  # 30% chance to accept non-improving moves\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    # Greedy improvement step: add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(available_items)\n    for i in available_items:\n        if current_weight + weight_lst[i] <= capacity:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_value1 = np.sum(value1_lst * temp_solution)\n            temp_value2 = np.sum(value2_lst * temp_solution)\n            if temp_value1 > archive[selected_idx][1][0] and temp_value2 > archive[selected_idx][1][1]:\n                new_solution = temp_solution\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.2970229504360714,
            2.810719281435013
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Hybrid local search: random swaps + greedy improvement\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly select a subset of items to consider for swaps\n    swap_candidates = random.sample(range(n_items), min(5, n_items))\n\n    for i in swap_candidates:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if the removal improves either objective\n                temp_value1 = np.sum(value1_lst * temp_solution)\n                temp_value2 = np.sum(value2_lst * temp_solution)\n                if (temp_value1 >= archive[selected_idx][1][0] and temp_value2 >= archive[selected_idx][1][1]) or \\\n                   (random.random() < 0.3):  # 30% chance to accept non-improving moves\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n        else:\n            # Try adding item i\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                # Check if the addition improves either objective\n                temp_value1 = np.sum(value1_lst * temp_solution)\n                temp_value2 = np.sum(value2_lst * temp_solution)\n                if (temp_value1 >= archive[selected_idx][1][0] and temp_value2 >= archive[selected_idx][1][1]) or \\\n                   (random.random() < 0.3):  # 30% chance to accept non-improving moves\n                    new_solution = temp_solution\n                    current_weight = temp_weight\n\n    # Greedy improvement step: add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(available_items)\n    for i in available_items:\n        if current_weight + weight_lst[i] <= capacity:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_value1 = np.sum(value1_lst * temp_solution)\n            temp_value2 = np.sum(value2_lst * temp_solution)\n            if temp_value1 > archive[selected_idx][1][0] and temp_value2 > archive[selected_idx][1][1]:\n                new_solution = temp_solution\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 141,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution from the archive\n    # Here, we select a solution that is not too close to the boundary (to allow more room for improvement)\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Ensure there's room to add more items\n            candidates.append((sol, val1, val2))\n\n    if not candidates:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select the solution with the highest combined value (normalized)\n        max_combined = -1\n        base_solution = None\n        for sol, val1, val2 in candidates:\n            combined = (val1 + val2) / (np.sum(weight_lst * sol) + 1e-6)  # Avoid division by zero\n            if combined > max_combined:\n                max_combined = combined\n                base_solution = sol.copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip: Flip a random item\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        new_solution[idx] = 1 - new_solution[idx]\n        if np.sum(weight_lst * new_solution) > capacity:\n            new_solution[idx] = 1 - new_solution[idx]  # Revert if infeasible\n\n    # 2. Value-based flip: Flip the item with the highest marginal value\n    else:\n        # Calculate marginal values\n        current_weight = np.sum(weight_lst * new_solution)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate marginal value for each item\n        marginal_values = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if weight_lst[i] <= remaining_capacity:\n                    # Marginal value is the sum of the two objectives\n                    marginal_value = value1_lst[i] + value2_lst[i]\n                    marginal_values.append((marginal_value, i))\n            else:\n                # If item is in the solution, consider removing it\n                marginal_value = -(value1_lst[i] + value2_lst[i])\n                marginal_values.append((marginal_value, i))\n\n        if marginal_values:\n            # Sort by marginal value (descending)\n            marginal_values.sort(reverse=True, key=lambda x: x[0])\n            best_idx = marginal_values[0][1]\n            new_solution[best_idx] = 1 - new_solution[best_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7599963052722607,
            1.5807670652866364
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution from the archive\n    # Here, we select a solution that is not too close to the boundary (to allow more room for improvement)\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Ensure there's room to add more items\n            candidates.append((sol, val1, val2))\n\n    if not candidates:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select the solution with the highest combined value (normalized)\n        max_combined = -1\n        base_solution = None\n        for sol, val1, val2 in candidates:\n            combined = (val1 + val2) / (np.sum(weight_lst * sol) + 1e-6)  # Avoid division by zero\n            if combined > max_combined:\n                max_combined = combined\n                base_solution = sol.copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip: Flip a random item\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        new_solution[idx] = 1 - new_solution[idx]\n        if np.sum(weight_lst * new_solution) > capacity:\n            new_solution[idx] = 1 - new_solution[idx]  # Revert if infeasible\n\n    # 2. Value-based flip: Flip the item with the highest marginal value\n    else:\n        # Calculate marginal values\n        current_weight = np.sum(weight_lst * new_solution)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate marginal value for each item\n        marginal_values = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if weight_lst[i] <= remaining_capacity:\n                    # Marginal value is the sum of the two objectives\n                    marginal_value = value1_lst[i] + value2_lst[i]\n                    marginal_values.append((marginal_value, i))\n            else:\n                # If item is in the solution, consider removing it\n                marginal_value = -(value1_lst[i] + value2_lst[i])\n                marginal_values.append((marginal_value, i))\n\n        if marginal_values:\n            # Sort by marginal value (descending)\n            marginal_values.sort(reverse=True, key=lambda x: x[0])\n            best_idx = marginal_values[0][1]\n            new_solution[best_idx] = 1 - new_solution[best_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 142,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for solutions that are not too similar to others\n    base_solution, _ = max(archive, key=lambda x: np.sum([np.sum(np.abs(x[0] - other[0])) for other in archive]))\n\n    new_solution = base_solution.copy()\n\n    # Randomly select a subset of items to flip (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        # Remove items with the smallest marginal contribution to total weight\n        while excess > 0:\n            # Calculate marginal contribution of each item to the total weight\n            marginal_contribution = new_solution * weight_lst\n            if np.sum(marginal_contribution) == 0:\n                break\n            # Find the item with the smallest marginal contribution\n            min_contrib_idx = np.argmin(marginal_contribution)\n            if marginal_contribution[min_contrib_idx] > 0:\n                new_solution[min_contrib_idx] = 0\n                excess -= weight_lst[min_contrib_idx]\n            else:\n                break\n\n    # Greedy improvement step (exploitation)\n    # Try to add items that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if np.sum(new_solution * weight_lst) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                # Check if this improves both objectives\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n                # If not improving both, revert\n                if not (current_value1 > np.sum(base_solution * value1_lst) and current_value2 > np.sum(base_solution * value2_lst)):\n                    new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.23884560533361832,
            8.716392427682877
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for solutions that are not too similar to others\n    base_solution, _ = max(archive, key=lambda x: np.sum([np.sum(np.abs(x[0] - other[0])) for other in archive]))\n\n    new_solution = base_solution.copy()\n\n    # Randomly select a subset of items to flip (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        # Remove items with the smallest marginal contribution to total weight\n        while excess > 0:\n            # Calculate marginal contribution of each item to the total weight\n            marginal_contribution = new_solution * weight_lst\n            if np.sum(marginal_contribution) == 0:\n                break\n            # Find the item with the smallest marginal contribution\n            min_contrib_idx = np.argmin(marginal_contribution)\n            if marginal_contribution[min_contrib_idx] > 0:\n                new_solution[min_contrib_idx] = 0\n                excess -= weight_lst[min_contrib_idx]\n            else:\n                break\n\n    # Greedy improvement step (exploitation)\n    # Try to add items that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if np.sum(new_solution * weight_lst) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                # Check if this improves both objectives\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n                # If not improving both, revert\n                if not (current_value1 > np.sum(base_solution * value1_lst) and current_value2 > np.sum(base_solution * value2_lst)):\n                    new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 143,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a solution with high potential for improvement\n    # Here, we select a solution with the highest sum of normalized objective values\n    normalized_objectives = []\n    for sol, obj in archive:\n        norm_obj = (obj[0] / (np.sum(value1_lst) + 1e-10), obj[1] / (np.sum(value2_lst) + 1e-10))\n        normalized_objectives.append(norm_obj)\n\n    # Calculate potential for improvement (distance to ideal point)\n    ideal_point = (1.0, 1.0)\n    potentials = [np.linalg.norm(np.array(ideal_point) - np.array(obj)) for obj in normalized_objectives]\n    selected_idx = np.argmin(potentials)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: combine bit-flip and swap operations\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Bit-flip operation (flip a random bit)\n    if n_items > 0:\n        flip_idx = np.random.randint(0, n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after bit-flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # Remove the heaviest item if over capacity\n            if new_solution[flip_idx] == 1:\n                # Try to remove the flipped item first\n                new_solution[flip_idx] = 0\n                total_weight = np.sum(weight_lst * new_solution)\n                if total_weight > capacity:\n                    # If still over, remove the heaviest items until feasible\n                    sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n                    for idx in sorted_indices:\n                        if new_solution[idx] == 1:\n                            new_solution[idx] = 0\n                            total_weight = np.sum(weight_lst * new_solution)\n                            if total_weight <= capacity:\n                                break\n\n    # Swap operation (swap two random items)\n    if n_items > 1:\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n\n        # Ensure feasibility after swap\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # Remove the heaviest item if over capacity\n            sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n            for idx in sorted_indices:\n                if new_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    total_weight = np.sum(weight_lst * new_solution)\n                    if total_weight <= capacity:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.3285780469445535,
            6.532773315906525
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a solution with high potential for improvement\n    # Here, we select a solution with the highest sum of normalized objective values\n    normalized_objectives = []\n    for sol, obj in archive:\n        norm_obj = (obj[0] / (np.sum(value1_lst) + 1e-10), obj[1] / (np.sum(value2_lst) + 1e-10))\n        normalized_objectives.append(norm_obj)\n\n    # Calculate potential for improvement (distance to ideal point)\n    ideal_point = (1.0, 1.0)\n    potentials = [np.linalg.norm(np.array(ideal_point) - np.array(obj)) for obj in normalized_objectives]\n    selected_idx = np.argmin(potentials)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: combine bit-flip and swap operations\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Bit-flip operation (flip a random bit)\n    if n_items > 0:\n        flip_idx = np.random.randint(0, n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after bit-flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # Remove the heaviest item if over capacity\n            if new_solution[flip_idx] == 1:\n                # Try to remove the flipped item first\n                new_solution[flip_idx] = 0\n                total_weight = np.sum(weight_lst * new_solution)\n                if total_weight > capacity:\n                    # If still over, remove the heaviest items until feasible\n                    sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n                    for idx in sorted_indices:\n                        if new_solution[idx] == 1:\n                            new_solution[idx] = 0\n                            total_weight = np.sum(weight_lst * new_solution)\n                            if total_weight <= capacity:\n                                break\n\n    # Swap operation (swap two random items)\n    if n_items > 1:\n        swap_idx1, swap_idx2 = np.random.choice(n_items, 2, replace=False)\n        new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n\n        # Ensure feasibility after swap\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # Remove the heaviest item if over capacity\n            sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n            for idx in sorted_indices:\n                if new_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    total_weight = np.sum(weight_lst * new_solution)\n                    if total_weight <= capacity:\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 144,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with higher combined value\n    base_solution, _ = max(archive, key=lambda x: x[1][0] + x[1][1])\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random perturbation with value-weighted greedy selection\n    n_items = len(weight_lst)\n    n_perturbations = min(3, n_items)  # Number of items to perturb\n\n    # Randomly select items to consider for perturbation\n    perturb_indices = np.random.choice(n_items, size=n_perturbations, replace=False)\n\n    for idx in perturb_indices:\n        # Calculate the effect of flipping the item\n        if new_solution[idx] == 1:\n            # If item is currently included, try to exclude it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # If item is currently excluded, try to include it\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                # Use a value-weighted probability to decide whether to include the item\n                value_weight = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n                if np.random.rand() < value_weight / (value_weight + 1):\n                    new_solution[idx] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.29547156409359737,
            0.8034487366676331
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with higher combined value\n    base_solution, _ = max(archive, key=lambda x: x[1][0] + x[1][1])\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random perturbation with value-weighted greedy selection\n    n_items = len(weight_lst)\n    n_perturbations = min(3, n_items)  # Number of items to perturb\n\n    # Randomly select items to consider for perturbation\n    perturb_indices = np.random.choice(n_items, size=n_perturbations, replace=False)\n\n    for idx in perturb_indices:\n        # Calculate the effect of flipping the item\n        if new_solution[idx] == 1:\n            # If item is currently included, try to exclude it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # If item is currently excluded, try to include it\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                # Use a value-weighted probability to decide whether to include the item\n                value_weight = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n                if np.random.rand() < value_weight / (value_weight + 1):\n                    new_solution[idx] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 145,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_solutions = [sol for sol, _ in archive]\n    if not archive_solutions:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Prioritize solutions with higher potential for improvement (e.g., not too close to capacity)\n    selected_solution = random.choices(\n        archive_solutions,\n        weights=[1 - (np.sum(sol * weight_lst) / capacity) for sol in archive_solutions],\n        k=1\n    )[0].copy()\n\n    # Hybrid local search: flip a subset of items based on their value ratios\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        # Calculate value ratios to decide whether to flip\n        value_ratio = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n        if random.random() < 0.5 or value_ratio > 1.0:  # Higher ratio items are more likely to be flipped\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess weight\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items with lowest value ratios until feasible\n        while total_weight > capacity:\n            # Find items with the lowest value-to-weight ratio\n            ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            worst_item = np.argmin(new_solution * ratios)\n            if new_solution[worst_item] == 1:\n                new_solution[worst_item] = 0\n                total_weight -= weight_lst[worst_item]\n            else:\n                break  # No more items to remove\n\n    return new_solution\n\n",
        "score": [
            -0.4233397336854351,
            0.7720806300640106
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_solutions = [sol for sol, _ in archive]\n    if not archive_solutions:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Prioritize solutions with higher potential for improvement (e.g., not too close to capacity)\n    selected_solution = random.choices(\n        archive_solutions,\n        weights=[1 - (np.sum(sol * weight_lst) / capacity) for sol in archive_solutions],\n        k=1\n    )[0].copy()\n\n    # Hybrid local search: flip a subset of items based on their value ratios\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        # Calculate value ratios to decide whether to flip\n        value_ratio = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n        if random.random() < 0.5 or value_ratio > 1.0:  # Higher ratio items are more likely to be flipped\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess weight\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items with lowest value ratios until feasible\n        while total_weight > capacity:\n            # Find items with the lowest value-to-weight ratio\n            ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n            worst_item = np.argmin(new_solution * ratios)\n            if new_solution[worst_item] == 1:\n                new_solution[worst_item] = 0\n                total_weight -= weight_lst[worst_item]\n            else:\n                break  # No more items to remove\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 146,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy: Randomly select items to flip (add/remove) with a bias towards high-value items\n    # First, compute the \"value density\" for each item (value1 + value2) / weight\n    value_density = (value1_lst + value2_lst) / weight_lst\n\n    # Create a list of candidate items to flip (either add or remove)\n    candidates = np.where(new_solution == 1)[0].tolist() + np.where(new_solution == 0)[0].tolist()\n    if not candidates:\n        return new_solution\n\n    # Sort candidates by value density (descending) to prioritize high-value items\n    candidates_sorted = sorted(candidates, key=lambda x: -value_density[x])\n\n    # Randomly select a subset of candidates to flip (to avoid full exploration)\n    num_candidates = min(5, len(candidates_sorted))\n    selected_candidates = np.random.choice(candidates_sorted, num_candidates, replace=False)\n\n    # Attempt to flip each selected candidate\n    for item in selected_candidates:\n        if new_solution[item] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.41452488680436766,
            1.1724779605865479
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy: Randomly select items to flip (add/remove) with a bias towards high-value items\n    # First, compute the \"value density\" for each item (value1 + value2) / weight\n    value_density = (value1_lst + value2_lst) / weight_lst\n\n    # Create a list of candidate items to flip (either add or remove)\n    candidates = np.where(new_solution == 1)[0].tolist() + np.where(new_solution == 0)[0].tolist()\n    if not candidates:\n        return new_solution\n\n    # Sort candidates by value density (descending) to prioritize high-value items\n    candidates_sorted = sorted(candidates, key=lambda x: -value_density[x])\n\n    # Randomly select a subset of candidates to flip (to avoid full exploration)\n    num_candidates = min(5, len(candidates_sorted))\n    selected_candidates = np.random.choice(candidates_sorted, num_candidates, replace=False)\n\n    # Attempt to flip each selected candidate\n    for item in selected_candidates:\n        if new_solution[item] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 147,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher total value\n    weights = np.array([obj[0] + obj[1] for _, obj in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine items to consider for flip (those not in the solution)\n    not_included = np.where(new_solution == 0)[0]\n\n    if len(not_included) == 0:\n        # If all items are included, consider removing some\n        included = np.where(new_solution == 1)[0]\n        candidates = np.random.choice(included, size=min(3, len(included)), replace=False)\n    else:\n        # Consider adding items that improve both objectives\n        candidates = not_included[np.argsort(-(value1_lst[not_included] + value2_lst[not_included]))[:min(5, len(not_included))]]\n\n    # Try to flip each candidate item\n    for item in candidates:\n        if new_solution[item] == 0:\n            # Adding item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            # Removing item\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Additional random flips to escape local optima\n    flip_indices = np.random.choice(len(new_solution), size=min(2, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n        else:\n            new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.27442013123676035,
            8.113196849822998
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher total value\n    weights = np.array([obj[0] + obj[1] for _, obj in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine items to consider for flip (those not in the solution)\n    not_included = np.where(new_solution == 0)[0]\n\n    if len(not_included) == 0:\n        # If all items are included, consider removing some\n        included = np.where(new_solution == 1)[0]\n        candidates = np.random.choice(included, size=min(3, len(included)), replace=False)\n    else:\n        # Consider adding items that improve both objectives\n        candidates = not_included[np.argsort(-(value1_lst[not_included] + value2_lst[not_included]))[:min(5, len(not_included))]]\n\n    # Try to flip each candidate item\n    for item in candidates:\n        if new_solution[item] == 0:\n            # Adding item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            # Removing item\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    # Additional random flips to escape local optima\n    flip_indices = np.random.choice(len(new_solution), size=min(2, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n        else:\n            new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 148,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a random subset of items\n    num_flips = min(5, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it's included\n            new_solution[idx] = 0\n        else:\n            # Add item if it's excluded and doesn't exceed capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add one more item that improves both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    for idx in remaining_items:\n        new_weight = current_weight + weight_lst[idx]\n        if new_weight <= capacity:\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n            # Check if adding this item improves both objectives\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[idx] = 1\n                break  # Only add one item per improvement step\n\n    return new_solution\n\n",
        "score": [
            -0.34529016853522926,
            0.8955050110816956
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a random subset of items\n    num_flips = min(5, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it's included\n            new_solution[idx] = 0\n        else:\n            # Add item if it's excluded and doesn't exceed capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Greedy improvement: try to add one more item that improves both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    for idx in remaining_items:\n        new_weight = current_weight + weight_lst[idx]\n        if new_weight <= capacity:\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n            # Check if adding this item improves both objectives\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[idx] = 1\n                break  # Only add one item per improvement step\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 149,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on the objective space coverage\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: random bit flips followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly flip a subset of bits (with probability to maintain feasibility)\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance per bit\n    candidate_solution = new_solution.copy()\n    candidate_solution[flip_mask] = 1 - candidate_solution[flip_mask]\n\n    # Check feasibility and revert if necessary\n    candidate_weight = np.sum(weight_lst * candidate_solution)\n    if candidate_weight > capacity:\n        # Greedy removal of items to restore feasibility\n        excess_weight = candidate_weight - capacity\n        while excess_weight > 0 and np.any(candidate_solution):\n            # Remove the item with the smallest ratio of total value to weight\n            value_ratio = (value1_lst + value2_lst) / weight_lst\n            value_ratio[candidate_solution == 0] = np.inf\n            remove_idx = np.argmin(value_ratio)\n            if candidate_solution[remove_idx] == 1:\n                candidate_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n    else:\n        # Greedy addition of items to improve objectives\n        remaining_capacity = capacity - candidate_weight\n        for i in range(n_items):\n            if candidate_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                # Add the item that improves both objectives the most\n                value1_gain = value1_lst[i]\n                value2_gain = value2_lst[i]\n                if value1_gain > 0 or value2_gain > 0:\n                    candidate_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    return candidate_solution\n\n",
        "score": [
            -0.37261776465169,
            1.707796722650528
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on the objective space coverage\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: random bit flips followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly flip a subset of bits (with probability to maintain feasibility)\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance per bit\n    candidate_solution = new_solution.copy()\n    candidate_solution[flip_mask] = 1 - candidate_solution[flip_mask]\n\n    # Check feasibility and revert if necessary\n    candidate_weight = np.sum(weight_lst * candidate_solution)\n    if candidate_weight > capacity:\n        # Greedy removal of items to restore feasibility\n        excess_weight = candidate_weight - capacity\n        while excess_weight > 0 and np.any(candidate_solution):\n            # Remove the item with the smallest ratio of total value to weight\n            value_ratio = (value1_lst + value2_lst) / weight_lst\n            value_ratio[candidate_solution == 0] = np.inf\n            remove_idx = np.argmin(value_ratio)\n            if candidate_solution[remove_idx] == 1:\n                candidate_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n    else:\n        # Greedy addition of items to improve objectives\n        remaining_capacity = capacity - candidate_weight\n        for i in range(n_items):\n            if candidate_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                # Add the item that improves both objectives the most\n                value1_gain = value1_lst[i]\n                value2_gain = value2_lst[i]\n                if value1_gain > 0 or value2_gain > 0:\n                    candidate_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    return candidate_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 150,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution: prioritize solutions with high objective values\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives\n    selected_idx = min(3, len(archive) - 1)  # Select from top 3 or all if archive is small\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on objective values)\n    # 2. Greedily select items with high marginal value-to-weight ratio for one objective\n    # 3. Ensure feasibility by rejecting flips that exceed capacity\n\n    # Step 1: Random flip with probability inversely proportional to current value\n    flip_prob = 0.3  # Base probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                # Remove item if it doesn't violate capacity\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    current_value1 -= value1_lst[i]\n                    current_value2 -= value2_lst[i]\n            else:\n                # Add item if it fits within capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    current_value1 += value1_lst[i]\n                    current_value2 += value2_lst[i]\n\n    # Step 2: Greedy improvement for one objective (alternate between objectives)\n    # Choose which objective to prioritize based on current values\n    prioritize_value1 = current_value1 <= current_value2\n\n    # Calculate marginal value-to-weight ratios for the prioritized objective\n    if prioritize_value1:\n        marginal_ratios = value1_lst / (weight_lst + 1e-8)  # Avoid division by zero\n    else:\n        marginal_ratios = value2_lst / (weight_lst + 1e-8)\n\n    # Sort items by marginal ratio in descending order\n    sorted_indices = np.argsort(marginal_ratios)[::-1]\n\n    # Try to add the best items that fit\n    for i in sorted_indices:\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            current_value1 += value1_lst[i]\n            current_value2 += value2_lst[i]\n\n    # Try to remove the worst items (lowest marginal ratio) if space allows\n    for i in sorted_indices[::-1]:\n        if new_solution[i] == 1 and current_weight - weight_lst[i] >= 0:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            current_value1 -= value1_lst[i]\n            current_value2 -= value2_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8750711383623202,
            2.020687520503998
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution: prioritize solutions with high objective values\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives\n    selected_idx = min(3, len(archive) - 1)  # Select from top 3 or all if archive is small\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on objective values)\n    # 2. Greedily select items with high marginal value-to-weight ratio for one objective\n    # 3. Ensure feasibility by rejecting flips that exceed capacity\n\n    # Step 1: Random flip with probability inversely proportional to current value\n    flip_prob = 0.3  # Base probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                # Remove item if it doesn't violate capacity\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    current_value1 -= value1_lst[i]\n                    current_value2 -= value2_lst[i]\n            else:\n                # Add item if it fits within capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    current_value1 += value1_lst[i]\n                    current_value2 += value2_lst[i]\n\n    # Step 2: Greedy improvement for one objective (alternate between objectives)\n    # Choose which objective to prioritize based on current values\n    prioritize_value1 = current_value1 <= current_value2\n\n    # Calculate marginal value-to-weight ratios for the prioritized objective\n    if prioritize_value1:\n        marginal_ratios = value1_lst / (weight_lst + 1e-8)  # Avoid division by zero\n    else:\n        marginal_ratios = value2_lst / (weight_lst + 1e-8)\n\n    # Sort items by marginal ratio in descending order\n    sorted_indices = np.argsort(marginal_ratios)[::-1]\n\n    # Try to add the best items that fit\n    for i in sorted_indices:\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            current_value1 += value1_lst[i]\n            current_value2 += value2_lst[i]\n\n    # Try to remove the worst items (lowest marginal ratio) if space allows\n    for i in sorted_indices[::-1]:\n        if new_solution[i] == 1 and current_weight - weight_lst[i] >= 0:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            current_value1 -= value1_lst[i]\n            current_value2 -= value2_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 151,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # We prioritize solutions that are not too close to the current Pareto front\n    # and have a high value-to-weight ratio in at least one objective\n    candidate_indices = []\n    for i, (solution, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst[solution == 1])\n        if total_weight <= capacity:\n            value1_ratio = np.sum(value1_lst[solution == 1]) / (total_weight + 1e-6)\n            value2_ratio = np.sum(value2_lst[solution == 1]) / (total_weight + 1e-6)\n            if value1_ratio > 0.5 or value2_ratio > 0.5:  # Arbitrary threshold for \"promising\"\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a number of items to flip (1-3)\n    # 2. For each selected item, consider flipping based on:\n    #    - Current inclusion status\n    #    - Value-to-weight ratio in both objectives\n    #    - Potential to improve the solution\n    new_solution = base_solution.copy()\n    num_flips = random.randint(1, 3)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate value-to-weight ratios for all items\n    value1_ratios = value1_lst / (weight_lst + 1e-6)\n    value2_ratios = value2_lst / (weight_lst + 1e-6)\n\n    # Combine ratios for selection probability\n    combined_ratios = value1_ratios + value2_ratios\n\n    # Select items to potentially flip based on combined ratios\n    flip_candidates = np.argsort(-combined_ratios)[:num_flips]\n\n    for item in flip_candidates:\n        if new_solution[item] == 1:\n            # If item is included, consider removing it if it's not critical\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # If item is not included, consider adding it if it fits\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Additional random flips to ensure diversity\n    for _ in range(random.randint(0, 2)):\n        item = random.randint(0, len(new_solution) - 1)\n        if new_solution[item] == 1:\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.5074311236572802,
            2.331357955932617
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # We prioritize solutions that are not too close to the current Pareto front\n    # and have a high value-to-weight ratio in at least one objective\n    candidate_indices = []\n    for i, (solution, _) in enumerate(archive):\n        total_weight = np.sum(weight_lst[solution == 1])\n        if total_weight <= capacity:\n            value1_ratio = np.sum(value1_lst[solution == 1]) / (total_weight + 1e-6)\n            value2_ratio = np.sum(value2_lst[solution == 1]) / (total_weight + 1e-6)\n            if value1_ratio > 0.5 or value2_ratio > 0.5:  # Arbitrary threshold for \"promising\"\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a number of items to flip (1-3)\n    # 2. For each selected item, consider flipping based on:\n    #    - Current inclusion status\n    #    - Value-to-weight ratio in both objectives\n    #    - Potential to improve the solution\n    new_solution = base_solution.copy()\n    num_flips = random.randint(1, 3)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate value-to-weight ratios for all items\n    value1_ratios = value1_lst / (weight_lst + 1e-6)\n    value2_ratios = value2_lst / (weight_lst + 1e-6)\n\n    # Combine ratios for selection probability\n    combined_ratios = value1_ratios + value2_ratios\n\n    # Select items to potentially flip based on combined ratios\n    flip_candidates = np.argsort(-combined_ratios)[:num_flips]\n\n    for item in flip_candidates:\n        if new_solution[item] == 1:\n            # If item is included, consider removing it if it's not critical\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # If item is not included, consider adding it if it fits\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Additional random flips to ensure diversity\n    for _ in range(random.randint(0, 2)):\n        item = random.randint(0, len(new_solution) - 1)\n        if new_solution[item] == 1:\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 152,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher potential for improvement\n    # Here, we select a solution with the highest sum of normalized objective values\n    normalized_archive = []\n    for sol, (v1, v2) in archive:\n        norm_v1 = v1 / np.max(value1_lst) if np.max(value1_lst) != 0 else 0\n        norm_v2 = v2 / np.max(value2_lst) if np.max(value2_lst) != 0 else 0\n        normalized_archive.append((sol, (norm_v1 + norm_v2)))\n\n    # Sort by normalized sum of objectives (descending) to prioritize high-value solutions\n    normalized_archive.sort(key=lambda x: x[1], reverse=True)\n    base_solution = normalized_archive[0][0].copy()\n\n    # Create a neighbor solution by performing a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly select a subset of items to flip (swap 0s and 1s)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement step - add items that improve at least one objective without violating capacity\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Find items not in the solution that can be added without exceeding capacity\n    candidate_indices = np.where(new_solution == 0)[0]\n    for idx in candidate_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Greedy removal step - remove items that do not contribute to either objective\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            if (value1_lst[idx] == 0) and (value2_lst[idx] == 0):\n                new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.334547226271963,
            1.7985578775405884
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher potential for improvement\n    # Here, we select a solution with the highest sum of normalized objective values\n    normalized_archive = []\n    for sol, (v1, v2) in archive:\n        norm_v1 = v1 / np.max(value1_lst) if np.max(value1_lst) != 0 else 0\n        norm_v2 = v2 / np.max(value2_lst) if np.max(value2_lst) != 0 else 0\n        normalized_archive.append((sol, (norm_v1 + norm_v2)))\n\n    # Sort by normalized sum of objectives (descending) to prioritize high-value solutions\n    normalized_archive.sort(key=lambda x: x[1], reverse=True)\n    base_solution = normalized_archive[0][0].copy()\n\n    # Create a neighbor solution by performing a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly select a subset of items to flip (swap 0s and 1s)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement step - add items that improve at least one objective without violating capacity\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Find items not in the solution that can be added without exceeding capacity\n    candidate_indices = np.where(new_solution == 0)[0]\n    for idx in candidate_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Greedy removal step - remove items that do not contribute to either objective\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            if (value1_lst[idx] == 0) and (value2_lst[idx] == 0):\n                new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 153,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(1, 0.1, len(archive)) / np.linspace(1, 0.1, len(archive)).sum())\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    for _ in range(5):  # Number of attempts to improve the solution\n        # Flip-based move (randomly flip one item)\n        flip_idx = np.random.randint(0, len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n        # Swap-based move (randomly swap two items)\n        swap_idx1, swap_idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            weight_diff = (new_solution[swap_idx1] * weight_lst[swap_idx1] +\n                          new_solution[swap_idx2] * weight_lst[swap_idx2] -\n                          (1 - new_solution[swap_idx1]) * weight_lst[swap_idx1] -\n                          (1 - new_solution[swap_idx2]) * weight_lst[swap_idx2])\n            if current_weight + weight_diff <= capacity:\n                new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n                current_weight += weight_diff\n\n    return new_solution\n\n",
        "score": [
            -0.37818477593495026,
            2.05237352848053
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(1, 0.1, len(archive)) / np.linspace(1, 0.1, len(archive)).sum())\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    for _ in range(5):  # Number of attempts to improve the solution\n        # Flip-based move (randomly flip one item)\n        flip_idx = np.random.randint(0, len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n        # Swap-based move (randomly swap two items)\n        swap_idx1, swap_idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            weight_diff = (new_solution[swap_idx1] * weight_lst[swap_idx1] +\n                          new_solution[swap_idx2] * weight_lst[swap_idx2] -\n                          (1 - new_solution[swap_idx1]) * weight_lst[swap_idx1] -\n                          (1 - new_solution[swap_idx2]) * weight_lst[swap_idx2])\n            if current_weight + weight_diff <= capacity:\n                new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n                current_weight += weight_diff\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 154,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive\n    # Sort solutions by the sum of their objectives (higher is better)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n    # Select top 20% of solutions, or at least 1 if archive is small\n    top_k = max(1, len(archive_sorted) // 5)\n    selected_solutions = archive_sorted[:top_k]\n    # Randomly pick one from the top candidates\n    base_solution, base_objectives = random.choice(selected_solutions)\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # Identify items that are in the base solution\n    selected_items = np.where(new_solution == 1)[0]\n    # Identify items that are not in the base solution\n    unselected_items = np.where(new_solution == 0)[0]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[selected_items])\n\n    # Step 3: Perform swap-based local search with bias towards improving both objectives\n    for _ in range(10):  # Limit the number of attempts to avoid excessive computation\n        if len(selected_items) == 0 or len(unselected_items) == 0:\n            break\n\n        # Select a random item to remove\n        remove_idx = random.choice(selected_items)\n        remove_weight = weight_lst[remove_idx]\n        remove_value1 = value1_lst[remove_idx]\n        remove_value2 = value2_lst[remove_idx]\n\n        # Calculate potential weight after removal\n        potential_weight = current_weight - remove_weight\n\n        # Find candidates to add that improve both objectives\n        add_candidates = []\n        for add_idx in unselected_items:\n            add_weight = weight_lst[add_idx]\n            if potential_weight + add_weight <= capacity:\n                add_value1 = value1_lst[add_idx]\n                add_value2 = value2_lst[add_idx]\n                # Check if adding this item improves both objectives\n                if add_value1 > remove_value1 and add_value2 > remove_value2:\n                    add_candidates.append(add_idx)\n\n        if add_candidates:\n            # Select the best candidate (highest sum of improvements)\n            best_add_idx = max(add_candidates, key=lambda idx: value1_lst[idx] + value2_lst[idx])\n            # Perform the swap\n            new_solution[remove_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = potential_weight + weight_lst[best_add_idx]\n            # Update selected and unselected items\n            selected_items = np.where(new_solution == 1)[0]\n            unselected_items = np.where(new_solution == 0)[0]\n        else:\n            # If no improving swap found, perform a random swap to escape local optima\n            random_add_idx = random.choice(unselected_items)\n            if potential_weight + weight_lst[random_add_idx] <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[random_add_idx] = 1\n                current_weight = potential_weight + weight_lst[random_add_idx]\n                # Update selected and unselected items\n                selected_items = np.where(new_solution == 1)[0]\n                unselected_items = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.5862913008820911,
            4.4718446135520935
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive\n    # Sort solutions by the sum of their objectives (higher is better)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n    # Select top 20% of solutions, or at least 1 if archive is small\n    top_k = max(1, len(archive_sorted) // 5)\n    selected_solutions = archive_sorted[:top_k]\n    # Randomly pick one from the top candidates\n    base_solution, base_objectives = random.choice(selected_solutions)\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # Identify items that are in the base solution\n    selected_items = np.where(new_solution == 1)[0]\n    # Identify items that are not in the base solution\n    unselected_items = np.where(new_solution == 0)[0]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[selected_items])\n\n    # Step 3: Perform swap-based local search with bias towards improving both objectives\n    for _ in range(10):  # Limit the number of attempts to avoid excessive computation\n        if len(selected_items) == 0 or len(unselected_items) == 0:\n            break\n\n        # Select a random item to remove\n        remove_idx = random.choice(selected_items)\n        remove_weight = weight_lst[remove_idx]\n        remove_value1 = value1_lst[remove_idx]\n        remove_value2 = value2_lst[remove_idx]\n\n        # Calculate potential weight after removal\n        potential_weight = current_weight - remove_weight\n\n        # Find candidates to add that improve both objectives\n        add_candidates = []\n        for add_idx in unselected_items:\n            add_weight = weight_lst[add_idx]\n            if potential_weight + add_weight <= capacity:\n                add_value1 = value1_lst[add_idx]\n                add_value2 = value2_lst[add_idx]\n                # Check if adding this item improves both objectives\n                if add_value1 > remove_value1 and add_value2 > remove_value2:\n                    add_candidates.append(add_idx)\n\n        if add_candidates:\n            # Select the best candidate (highest sum of improvements)\n            best_add_idx = max(add_candidates, key=lambda idx: value1_lst[idx] + value2_lst[idx])\n            # Perform the swap\n            new_solution[remove_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = potential_weight + weight_lst[best_add_idx]\n            # Update selected and unselected items\n            selected_items = np.where(new_solution == 1)[0]\n            unselected_items = np.where(new_solution == 0)[0]\n        else:\n            # If no improving swap found, perform a random swap to escape local optima\n            random_add_idx = random.choice(unselected_items)\n            if potential_weight + weight_lst[random_add_idx] <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[random_add_idx] = 1\n                current_weight = potential_weight + weight_lst[random_add_idx]\n                # Update selected and unselected items\n                selected_items = np.where(new_solution == 1)[0]\n                unselected_items = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 155,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential for improvement\n    weights = [1 / (1 + np.sum(solution[0])) for solution in archive]  # Prefer solutions with fewer items\n    base_solution, _ = random.choices(archive, weights=weights, k=1)[0]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Identify items that can be potentially added without exceeding capacity\n    remaining_capacity = capacity - current_weight\n    addable_items = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    # Identify items that can be removed to potentially improve both objectives\n    removable_items = np.where(new_solution == 1)[0]\n\n    # Hybrid local search strategy:\n    # 1. With 50% probability, try to add an item that has high potential in both objectives\n    if random.random() < 0.5 and len(addable_items) > 0:\n        # Calculate potential improvement for each addable item\n        potential_improvement = (value1_lst[addable_items] + value2_lst[addable_items]) / (weight_lst[addable_items] + 1e-6)\n        best_add_item = addable_items[np.argmax(potential_improvement)]\n        new_solution[best_add_item] = 1\n\n    # 2. With 50% probability, try to remove an item that has low marginal contribution\n    else:\n        if len(removable_items) > 0:\n            # Calculate marginal contribution for each removable item\n            marginal_contribution = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-6)\n            worst_remove_item = removable_items[np.argmin(marginal_contribution)]\n            new_solution[worst_remove_item] = 0\n\n    # Ensure the new solution is feasible\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while total_weight > capacity:\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) == 0:\n                break  # No items left to remove\n            item_to_remove = random.choice(removable_items)\n            new_solution[item_to_remove] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    return new_solution\n\n",
        "score": [
            -0.8402562915449479,
            0.9781208634376526
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential for improvement\n    weights = [1 / (1 + np.sum(solution[0])) for solution in archive]  # Prefer solutions with fewer items\n    base_solution, _ = random.choices(archive, weights=weights, k=1)[0]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Identify items that can be potentially added without exceeding capacity\n    remaining_capacity = capacity - current_weight\n    addable_items = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n\n    # Identify items that can be removed to potentially improve both objectives\n    removable_items = np.where(new_solution == 1)[0]\n\n    # Hybrid local search strategy:\n    # 1. With 50% probability, try to add an item that has high potential in both objectives\n    if random.random() < 0.5 and len(addable_items) > 0:\n        # Calculate potential improvement for each addable item\n        potential_improvement = (value1_lst[addable_items] + value2_lst[addable_items]) / (weight_lst[addable_items] + 1e-6)\n        best_add_item = addable_items[np.argmax(potential_improvement)]\n        new_solution[best_add_item] = 1\n\n    # 2. With 50% probability, try to remove an item that has low marginal contribution\n    else:\n        if len(removable_items) > 0:\n            # Calculate marginal contribution for each removable item\n            marginal_contribution = (value1_lst[removable_items] + value2_lst[removable_items]) / (weight_lst[removable_items] + 1e-6)\n            worst_remove_item = removable_items[np.argmin(marginal_contribution)]\n            new_solution[worst_remove_item] = 0\n\n    # Ensure the new solution is feasible\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while total_weight > capacity:\n            removable_items = np.where(new_solution == 1)[0]\n            if len(removable_items) == 0:\n                break  # No items left to remove\n            item_to_remove = random.choice(removable_items)\n            new_solution[item_to_remove] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 156,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too dense)\n    selected_solution, _ = random.choice(archive)\n    current_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Determine items that can be flipped (either included or excluded without violating capacity)\n    candidate_indices = []\n    for i in range(len(current_solution)):\n        if current_solution[i] == 1:\n            # Check if excluding the item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n        else:\n            # Check if including the item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        # If no candidates, return a random solution from the archive\n        return random.choice(archive)[0].copy()\n\n    # Hybrid local search: flip a subset of items based on a weighted random selection\n    flip_count = min(3, len(candidate_indices))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(candidate_indices, flip_count)\n\n    new_solution = current_solution.copy()\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]  # Flip the item\n\n    # Ensure feasibility (should not be necessary due to candidate selection, but added as a safeguard)\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If somehow infeasible, revert the last flip (simplistic repair)\n        new_solution[flip_indices[-1]] = current_solution[flip_indices[-1]]\n\n    return new_solution\n\n",
        "score": [
            -0.8391754582673943,
            1.061070054769516
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too dense)\n    selected_solution, _ = random.choice(archive)\n    current_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Determine items that can be flipped (either included or excluded without violating capacity)\n    candidate_indices = []\n    for i in range(len(current_solution)):\n        if current_solution[i] == 1:\n            # Check if excluding the item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n        else:\n            # Check if including the item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        # If no candidates, return a random solution from the archive\n        return random.choice(archive)[0].copy()\n\n    # Hybrid local search: flip a subset of items based on a weighted random selection\n    flip_count = min(3, len(candidate_indices))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(candidate_indices, flip_count)\n\n    new_solution = current_solution.copy()\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]  # Flip the item\n\n    # Ensure feasibility (should not be necessary due to candidate selection, but added as a safeguard)\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If somehow infeasible, revert the last flip (simplistic repair)\n        new_solution[flip_indices[-1]] = current_solution[flip_indices[-1]]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 157,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate the total weight and objective values for each solution in the archive\n    archive_with_metrics = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        archive_with_metrics.append((sol, obj, total_weight))\n\n    # Sort solutions by the sum of their objectives (higher is better)\n    archive_with_metrics.sort(key=lambda x: -(x[1][0] + x[1][1]))\n\n    # Select the top 30% of solutions for consideration\n    top_k = max(1, int(0.3 * len(archive_with_metrics)))\n    candidates = archive_with_metrics[:top_k]\n\n    # Randomly select a base solution from the top candidates\n    base_solution, _, base_weight = random.choice(candidates)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with a bias towards low-weight, high-value items)\n    # 2. If the solution becomes infeasible, apply a repair mechanism\n    new_solution = base_solution.copy()\n\n    # Calculate the marginal benefit-to-weight ratio for each item\n    marginal_ratio1 = value1_lst / (weight_lst + 1e-10)\n    marginal_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = marginal_ratio1 + marginal_ratio2\n\n    # Select items to flip based on a probability weighted by their combined ratio\n    flip_probs = combined_ratio / (np.sum(combined_ratio) + 1e-10)\n    flip_mask = np.random.rand(len(new_solution)) < flip_probs\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items in a way that minimizes the impact on the objectives\n        over_weight = current_weight - capacity\n        items_to_remove = np.where(new_solution == 1)[0]\n\n        # Sort items to remove by their marginal contribution (least important first)\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(marginal_contribution[items_to_remove])\n\n        # Remove items until the solution is feasible\n        for idx in sorted_indices:\n            if over_weight <= 0:\n                break\n            item_idx = items_to_remove[idx]\n            if new_solution[item_idx] == 1:\n                new_solution[item_idx] = 0\n                over_weight -= weight_lst[item_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3099533122970831,
            5.910250306129456
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate the total weight and objective values for each solution in the archive\n    archive_with_metrics = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        archive_with_metrics.append((sol, obj, total_weight))\n\n    # Sort solutions by the sum of their objectives (higher is better)\n    archive_with_metrics.sort(key=lambda x: -(x[1][0] + x[1][1]))\n\n    # Select the top 30% of solutions for consideration\n    top_k = max(1, int(0.3 * len(archive_with_metrics)))\n    candidates = archive_with_metrics[:top_k]\n\n    # Randomly select a base solution from the top candidates\n    base_solution, _, base_weight = random.choice(candidates)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with a bias towards low-weight, high-value items)\n    # 2. If the solution becomes infeasible, apply a repair mechanism\n    new_solution = base_solution.copy()\n\n    # Calculate the marginal benefit-to-weight ratio for each item\n    marginal_ratio1 = value1_lst / (weight_lst + 1e-10)\n    marginal_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = marginal_ratio1 + marginal_ratio2\n\n    # Select items to flip based on a probability weighted by their combined ratio\n    flip_probs = combined_ratio / (np.sum(combined_ratio) + 1e-10)\n    flip_mask = np.random.rand(len(new_solution)) < flip_probs\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items in a way that minimizes the impact on the objectives\n        over_weight = current_weight - capacity\n        items_to_remove = np.where(new_solution == 1)[0]\n\n        # Sort items to remove by their marginal contribution (least important first)\n        marginal_contribution = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        sorted_indices = np.argsort(marginal_contribution[items_to_remove])\n\n        # Remove items until the solution is feasible\n        for idx in sorted_indices:\n            if over_weight <= 0:\n                break\n            item_idx = items_to_remove[idx]\n            if new_solution[item_idx] == 1:\n                new_solution[item_idx] = 0\n                over_weight -= weight_lst[item_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 158,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    base_solution, (current_value1, current_value2) = archive[np.random.randint(len(archive))]\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items that can be flipped (added or removed) without violating capacity\n    feasible_indices = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                feasible_indices.append(i)\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                feasible_indices.append(i)\n\n    if not feasible_indices:\n        # If no feasible flips, return a random solution from archive\n        return archive[np.random.randint(len(archive))][0].copy()\n\n    # Select a random item to flip\n    flip_idx = np.random.choice(feasible_indices)\n\n    # Create neighbor by flipping the selected item\n    new_solution = base_solution.copy()\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Check if the flip improves both objectives (optional: can be replaced with more sophisticated criteria)\n    new_weight = np.sum(weight_lst * new_solution)\n    new_value1 = np.sum(value1_lst * new_solution)\n    new_value2 = np.sum(value2_lst * new_solution)\n\n    if new_weight > capacity:\n        # Revert if capacity is exceeded (should not happen due to feasibility check)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8755628779885999,
            1.1314379274845123
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    base_solution, (current_value1, current_value2) = archive[np.random.randint(len(archive))]\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items that can be flipped (added or removed) without violating capacity\n    feasible_indices = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                feasible_indices.append(i)\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                feasible_indices.append(i)\n\n    if not feasible_indices:\n        # If no feasible flips, return a random solution from archive\n        return archive[np.random.randint(len(archive))][0].copy()\n\n    # Select a random item to flip\n    flip_idx = np.random.choice(feasible_indices)\n\n    # Create neighbor by flipping the selected item\n    new_solution = base_solution.copy()\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Check if the flip improves both objectives (optional: can be replaced with more sophisticated criteria)\n    new_weight = np.sum(weight_lst * new_solution)\n    new_value1 = np.sum(value1_lst * new_solution)\n    new_value2 = np.sum(value2_lst * new_solution)\n\n    if new_weight > capacity:\n        # Revert if capacity is exceeded (should not happen due to feasibility check)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 159,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement (e.g., not too crowded in objective space)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with bias toward high-value items)\n    # 2. Perform a value-based perturbation to ensure diversity\n\n    # Step 1: Random flip with value-based bias\n    flip_prob = 0.3  # Base probability to flip an item\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            # Increase flip probability for high-value items\n            value1 = value1_lst[i]\n            value2 = value2_lst[i]\n            adjusted_prob = flip_prob * (1 + 0.5 * (value1 + value2) / (np.max(value1_lst) + np.max(value2_lst)))\n            if random.random() < adjusted_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Value-based perturbation to add diversity\n    # Identify items with high marginal contribution in either objective\n    marginal_value1 = value1_lst / (weight_lst + 1e-8)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-8)\n\n    # Select top-k items with highest marginal value in either objective\n    k = max(1, len(new_solution) // 10)  # Perturb at most 10% of items\n    top_items1 = np.argsort(marginal_value1)[-k:]\n    top_items2 = np.argsort(marginal_value2)[-k:]\n\n    # Combine and perturb these items\n    perturb_items = np.union1d(top_items1, top_items2)\n    for i in perturb_items:\n        if random.random() < 0.5:  # 50% chance to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible (greedy approach)\n        items_sorted = np.argsort(-weight_lst * new_solution)  # Heaviest first\n        for i in items_sorted:\n            if new_solution[i] == 1 and total_weight > capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3419926963778023,
            3.8976471424102783
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement (e.g., not too crowded in objective space)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with bias toward high-value items)\n    # 2. Perform a value-based perturbation to ensure diversity\n\n    # Step 1: Random flip with value-based bias\n    flip_prob = 0.3  # Base probability to flip an item\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            # Increase flip probability for high-value items\n            value1 = value1_lst[i]\n            value2 = value2_lst[i]\n            adjusted_prob = flip_prob * (1 + 0.5 * (value1 + value2) / (np.max(value1_lst) + np.max(value2_lst)))\n            if random.random() < adjusted_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Value-based perturbation to add diversity\n    # Identify items with high marginal contribution in either objective\n    marginal_value1 = value1_lst / (weight_lst + 1e-8)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-8)\n\n    # Select top-k items with highest marginal value in either objective\n    k = max(1, len(new_solution) // 10)  # Perturb at most 10% of items\n    top_items1 = np.argsort(marginal_value1)[-k:]\n    top_items2 = np.argsort(marginal_value2)[-k:]\n\n    # Combine and perturb these items\n    perturb_items = np.union1d(top_items1, top_items2)\n    for i in perturb_items:\n        if random.random() < 0.5:  # 50% chance to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible (greedy approach)\n        items_sorted = np.argsort(-weight_lst * new_solution)  # Heaviest first\n        for i in items_sorted:\n            if new_solution[i] == 1 and total_weight > capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 160,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty.\")\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the capacity\n    current_weights = [np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    remaining_capacities = [capacity - w for w in current_weights]\n    # Prefer solutions with remaining capacity and high objective values\n    scores = [(remaining_capacities[i] * (sol[1][0] + sol[1][1])) for i, sol in enumerate(archive)]\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of bits (with probability)\n    # 2. Greedily add items that improve both objectives\n    # 3. Remove items that worsen both objectives\n\n    # Step 1: Random bit flips (with probability 0.3 per bit)\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Greedy addition of items that improve both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate potential improvements for each item not in solution\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate normalized improvement scores for both objectives\n        value1_improvements = value1_lst[potential_items] / np.max(value1_lst)\n        value2_improvements = value2_lst[potential_items] / np.max(value2_lst)\n        combined_improvements = value1_improvements + value2_improvements\n\n        # Sort by combined improvement and weight\n        sorted_indices = np.argsort(-combined_improvements)\n        for idx in sorted_indices:\n            item = potential_items[idx]\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    # Step 3: Remove items that worsen both objectives\n    current_items = np.where(new_solution == 1)[0]\n    if len(current_items) > 0:\n        # Calculate normalized objective values\n        value1_values = value1_lst[current_items] / np.max(value1_lst)\n        value2_values = value2_lst[current_items] / np.max(value2_lst)\n        combined_values = value1_values + value2_values\n\n        # Sort by combined value (ascending to remove worst items first)\n        sorted_indices = np.argsort(combined_values)\n        for idx in sorted_indices:\n            item = current_items[idx]\n            # Check if removing this item keeps the solution feasible\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8035410902242207,
            5.763810366392136
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty.\")\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the capacity\n    current_weights = [np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    remaining_capacities = [capacity - w for w in current_weights]\n    # Prefer solutions with remaining capacity and high objective values\n    scores = [(remaining_capacities[i] * (sol[1][0] + sol[1][1])) for i, sol in enumerate(archive)]\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of bits (with probability)\n    # 2. Greedily add items that improve both objectives\n    # 3. Remove items that worsen both objectives\n\n    # Step 1: Random bit flips (with probability 0.3 per bit)\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Greedy addition of items that improve both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate potential improvements for each item not in solution\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate normalized improvement scores for both objectives\n        value1_improvements = value1_lst[potential_items] / np.max(value1_lst)\n        value2_improvements = value2_lst[potential_items] / np.max(value2_lst)\n        combined_improvements = value1_improvements + value2_improvements\n\n        # Sort by combined improvement and weight\n        sorted_indices = np.argsort(-combined_improvements)\n        for idx in sorted_indices:\n            item = potential_items[idx]\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    # Step 3: Remove items that worsen both objectives\n    current_items = np.where(new_solution == 1)[0]\n    if len(current_items) > 0:\n        # Calculate normalized objective values\n        value1_values = value1_lst[current_items] / np.max(value1_lst)\n        value2_values = value2_lst[current_items] / np.max(value2_lst)\n        combined_values = value1_values + value2_values\n\n        # Sort by combined value (ascending to remove worst items first)\n        sorted_indices = np.argsort(combined_values)\n        for idx in sorted_indices:\n            item = current_items[idx]\n            # Check if removing this item keeps the solution feasible\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 161,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: 1. Value-based swap, 2. Weight-based adjustment\n    # Step 1: Identify items with high marginal value-to-weight ratio in either objective\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 2: Perform a value-based swap (flip items with high marginal value)\n    high_value_items1 = np.where((marginal_value1 > np.percentile(marginal_value1, 75)) & (new_solution == 0))[0]\n    high_value_items2 = np.where((marginal_value2 > np.percentile(marginal_value2, 75)) & (new_solution == 0))[0]\n\n    if len(high_value_items1) > 0 or len(high_value_items2) > 0:\n        # Randomly select a high-value item to add\n        candidate_items = np.concatenate([high_value_items1, high_value_items2])\n        if len(candidate_items) > 0:\n            selected_item = np.random.choice(candidate_items)\n            if current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Step 3: If weight exceeds capacity, perform a weight-based adjustment (remove low-value items)\n    if current_weight > capacity:\n        low_value_items = np.where((new_solution == 1) &\n                                 ((value1_lst + value2_lst) < np.percentile(value1_lst + value2_lst, 25)))[0]\n        if len(low_value_items) > 0:\n            # Remove the least valuable item(s) until feasible\n            while current_weight > capacity and len(low_value_items) > 0:\n                item_to_remove = np.random.choice(low_value_items)\n                new_solution[item_to_remove] = 0\n                current_weight -= weight_lst[item_to_remove]\n                low_value_items = low_value_items[low_value_items != item_to_remove]\n\n    # Step 4: If no changes were made, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        # Randomly flip a small subset of items\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4474034919049365,
            5.399194300174713
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: 1. Value-based swap, 2. Weight-based adjustment\n    # Step 1: Identify items with high marginal value-to-weight ratio in either objective\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Step 2: Perform a value-based swap (flip items with high marginal value)\n    high_value_items1 = np.where((marginal_value1 > np.percentile(marginal_value1, 75)) & (new_solution == 0))[0]\n    high_value_items2 = np.where((marginal_value2 > np.percentile(marginal_value2, 75)) & (new_solution == 0))[0]\n\n    if len(high_value_items1) > 0 or len(high_value_items2) > 0:\n        # Randomly select a high-value item to add\n        candidate_items = np.concatenate([high_value_items1, high_value_items2])\n        if len(candidate_items) > 0:\n            selected_item = np.random.choice(candidate_items)\n            if current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Step 3: If weight exceeds capacity, perform a weight-based adjustment (remove low-value items)\n    if current_weight > capacity:\n        low_value_items = np.where((new_solution == 1) &\n                                 ((value1_lst + value2_lst) < np.percentile(value1_lst + value2_lst, 25)))[0]\n        if len(low_value_items) > 0:\n            # Remove the least valuable item(s) until feasible\n            while current_weight > capacity and len(low_value_items) > 0:\n                item_to_remove = np.random.choice(low_value_items)\n                new_solution[item_to_remove] = 0\n                current_weight -= weight_lst[item_to_remove]\n                low_value_items = low_value_items[low_value_items != item_to_remove]\n\n    # Step 4: If no changes were made, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        # Randomly flip a small subset of items\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 162,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with a bias towards solutions near the knee of the Pareto front\n    # Calculate the crowding distance or other diversity metrics to identify promising solutions\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # For simplicity, we'll select a solution with a high combined objective value\n    combined_values = [v1 + v2 for v1, v2 in objectives]\n    max_combined = max(combined_values)\n    candidates = [sol for sol, val in zip(solutions, combined_values) if val == max_combined]\n\n    # If multiple candidates, select one randomly\n    base_solution = random.choice(candidates).copy()\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n\n    # Operator 1: Random flip with weight adjustment (to maintain feasibility)\n    current_weight = np.sum(weight_lst * base_solution)\n    available_items = np.where(base_solution == 0)[0]\n    included_items = np.where(base_solution == 1)[0]\n\n    # Randomly select an item to flip (either add or remove)\n    if random.random() < 0.5 and len(available_items) > 0:\n        # Add an item if possible\n        candidate = random.choice(available_items)\n        if current_weight + weight_lst[candidate] <= capacity:\n            new_solution[candidate] = 1\n    elif len(included_items) > 0:\n        # Remove an item if possible\n        candidate = random.choice(included_items)\n        new_solution[candidate] = 0\n\n    # Operator 2: Greedy improvement for one objective, constrained by the other\n    if random.random() < 0.3:  # 30% chance to apply this operator\n        # Select an objective to prioritize (alternate between them)\n        if random.random() < 0.5:\n            # Prioritize value1\n            remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n            for item in available_items:\n                if weight_lst[item] <= remaining_capacity:\n                    # Greedily add the item with highest value1\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n        else:\n            # Prioritize value2\n            remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n            for item in available_items:\n                if weight_lst[item] <= remaining_capacity:\n                    # Greedily add the item with highest value2\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.35343173692524865,
            3.496020495891571
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with a bias towards solutions near the knee of the Pareto front\n    # Calculate the crowding distance or other diversity metrics to identify promising solutions\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # For simplicity, we'll select a solution with a high combined objective value\n    combined_values = [v1 + v2 for v1, v2 in objectives]\n    max_combined = max(combined_values)\n    candidates = [sol for sol, val in zip(solutions, combined_values) if val == max_combined]\n\n    # If multiple candidates, select one randomly\n    base_solution = random.choice(candidates).copy()\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n\n    # Operator 1: Random flip with weight adjustment (to maintain feasibility)\n    current_weight = np.sum(weight_lst * base_solution)\n    available_items = np.where(base_solution == 0)[0]\n    included_items = np.where(base_solution == 1)[0]\n\n    # Randomly select an item to flip (either add or remove)\n    if random.random() < 0.5 and len(available_items) > 0:\n        # Add an item if possible\n        candidate = random.choice(available_items)\n        if current_weight + weight_lst[candidate] <= capacity:\n            new_solution[candidate] = 1\n    elif len(included_items) > 0:\n        # Remove an item if possible\n        candidate = random.choice(included_items)\n        new_solution[candidate] = 0\n\n    # Operator 2: Greedy improvement for one objective, constrained by the other\n    if random.random() < 0.3:  # 30% chance to apply this operator\n        # Select an objective to prioritize (alternate between them)\n        if random.random() < 0.5:\n            # Prioritize value1\n            remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n            for item in available_items:\n                if weight_lst[item] <= remaining_capacity:\n                    # Greedily add the item with highest value1\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n        else:\n            # Prioritize value2\n            remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n            for item in available_items:\n                if weight_lst[item] <= remaining_capacity:\n                    # Greedily add the item with highest value2\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 163,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_val1 = np.sum(value1_lst * new_solution)\n    current_val2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: random swaps + greedy selection\n    num_swaps = min(3, len(weight_lst) // 2)  # Limit swaps to avoid excessive computation\n    for _ in range(num_swaps):\n        # Randomly select items to swap\n        swap_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        i, j = swap_indices\n\n        # Calculate new weight and values if we swap items i and j\n        new_weight = current_weight - weight_lst[i] * new_solution[i] + weight_lst[i] * (1 - new_solution[i]) \\\n                                      - weight_lst[j] * new_solution[j] + weight_lst[j] * (1 - new_solution[j])\n        new_val1 = current_val1 - value1_lst[i] * new_solution[i] + value1_lst[i] * (1 - new_solution[i]) \\\n                                    - value1_lst[j] * new_solution[j] + value1_lst[j] * (1 - new_solution[j])\n        new_val2 = current_val2 - value2_lst[i] * new_solution[i] + value2_lst[i] * (1 - new_solution[i]) \\\n                                    - value2_lst[j] * new_solution[j] + value2_lst[j] * (1 - new_solution[j])\n\n        # Check feasibility and potential improvement\n        if new_weight <= capacity and (new_val1 > current_val1 or new_val2 > current_val2):\n            # Perform the swap\n            new_solution[i], new_solution[j] = 1 - new_solution[i], 1 - new_solution[j]\n            current_weight, current_val1, current_val2 = new_weight, new_val1, new_val2\n\n    # Additional greedy step: try to add high-value items not in the solution\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal gains for items not in the solution\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            # Sort candidates by a combined score (prioritize high value1 and value2)\n            scores = (value1_lst[candidate_items] + value2_lst[candidate_items]) / (weight_lst[candidate_items] + 1e-6)\n            sorted_indices = np.argsort(-scores)\n            for idx in sorted_indices:\n                item = candidate_items[idx]\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3371569811727802,
            4.469242721796036
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_val1 = np.sum(value1_lst * new_solution)\n    current_val2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: random swaps + greedy selection\n    num_swaps = min(3, len(weight_lst) // 2)  # Limit swaps to avoid excessive computation\n    for _ in range(num_swaps):\n        # Randomly select items to swap\n        swap_indices = np.random.choice(len(weight_lst), size=2, replace=False)\n        i, j = swap_indices\n\n        # Calculate new weight and values if we swap items i and j\n        new_weight = current_weight - weight_lst[i] * new_solution[i] + weight_lst[i] * (1 - new_solution[i]) \\\n                                      - weight_lst[j] * new_solution[j] + weight_lst[j] * (1 - new_solution[j])\n        new_val1 = current_val1 - value1_lst[i] * new_solution[i] + value1_lst[i] * (1 - new_solution[i]) \\\n                                    - value1_lst[j] * new_solution[j] + value1_lst[j] * (1 - new_solution[j])\n        new_val2 = current_val2 - value2_lst[i] * new_solution[i] + value2_lst[i] * (1 - new_solution[i]) \\\n                                    - value2_lst[j] * new_solution[j] + value2_lst[j] * (1 - new_solution[j])\n\n        # Check feasibility and potential improvement\n        if new_weight <= capacity and (new_val1 > current_val1 or new_val2 > current_val2):\n            # Perform the swap\n            new_solution[i], new_solution[j] = 1 - new_solution[i], 1 - new_solution[j]\n            current_weight, current_val1, current_val2 = new_weight, new_val1, new_val2\n\n    # Additional greedy step: try to add high-value items not in the solution\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal gains for items not in the solution\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            # Sort candidates by a combined score (prioritize high value1 and value2)\n            scores = (value1_lst[candidate_items] + value2_lst[candidate_items]) / (weight_lst[candidate_items] + 1e-6)\n            sorted_indices = np.argsort(-scores)\n            for idx in sorted_indices:\n                item = candidate_items[idx]\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 164,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (swap inclusion/exclusion)\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Objective-specific improvement: try to improve one objective while keeping the other stable\n    if random.random() < 0.5:\n        # Improve value1\n        for idx in np.argsort(-value1_lst[base_solution == 0] / (weight_lst[base_solution == 0] + 1e-10)):\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n    else:\n        # Improve value2\n        for idx in np.argsort(-value2_lst[base_solution == 0] / (weight_lst[base_solution == 0] + 1e-10)):\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # Ensure feasibility (fallback in case of numerical precision issues)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with lowest ratio of (value1 + value2)/weight until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Calculate removal priority based on combined value-to-weight ratio\n            ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            remove_idx = included_items[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.36904551391950646,
            1.0574141442775726
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (swap inclusion/exclusion)\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Objective-specific improvement: try to improve one objective while keeping the other stable\n    if random.random() < 0.5:\n        # Improve value1\n        for idx in np.argsort(-value1_lst[base_solution == 0] / (weight_lst[base_solution == 0] + 1e-10)):\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n    else:\n        # Improve value2\n        for idx in np.argsort(-value2_lst[base_solution == 0] / (weight_lst[base_solution == 0] + 1e-10)):\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                break\n\n    # Ensure feasibility (fallback in case of numerical precision issues)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with lowest ratio of (value1 + value2)/weight until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Calculate removal priority based on combined value-to-weight ratio\n            ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            remove_idx = included_items[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 165,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    # Step 1: Randomly flip a subset of items (10% chance per item)\n    flip_mask = np.random.random(len(new_solution)) < 0.1\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility by removing excess items\n    excess_weight = np.sum(weight_lst[new_solution == 1]) - capacity\n    if excess_weight > 0:\n        # Remove items with lowest value-to-weight ratio until feasible\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    # Step 2: Add promising items not in the current solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate potential value-to-weight ratio for remaining items\n        potential_ratios = (value1_lst[remaining_items] + value2_lst[remaining_items]) / weight_lst[remaining_items]\n        sorted_potential = np.argsort(potential_ratios)[::-1]\n\n        # Add top 20% of remaining items if they fit\n        num_to_add = max(1, int(0.2 * len(remaining_items)))\n        for i in range(num_to_add):\n            idx = remaining_items[sorted_potential[i]]\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3796014791357751,
            1.1693461537361145
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    # Step 1: Randomly flip a subset of items (10% chance per item)\n    flip_mask = np.random.random(len(new_solution)) < 0.1\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility by removing excess items\n    excess_weight = np.sum(weight_lst[new_solution == 1]) - capacity\n    if excess_weight > 0:\n        # Remove items with lowest value-to-weight ratio until feasible\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    # Step 2: Add promising items not in the current solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate potential value-to-weight ratio for remaining items\n        potential_ratios = (value1_lst[remaining_items] + value2_lst[remaining_items]) / weight_lst[remaining_items]\n        sorted_potential = np.argsort(potential_ratios)[::-1]\n\n        # Add top 20% of remaining items if they fit\n        num_to_add = max(1, int(0.2 * len(remaining_items)))\n        for i in range(num_to_add):\n            idx = remaining_items[sorted_potential[i]]\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 166,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    # Here, we randomly select a solution with a probability inversely proportional to its objective values\n    # to encourage exploration of less crowded regions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / max_obj\n    scores = 1 / (1 + np.sum(normalized_obj, axis=1))  # Higher score for less crowded solutions\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by flipping a random subset of bits (1-3 bits)\n    new_solution = base_solution.copy()\n    flip_indices = np.random.choice(len(new_solution), size=random.randint(1, min(3, len(new_solution))), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items that exceed capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Sort items by their combined value-to-weight ratio (greedy heuristic)\n        value_ratio = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_ratio)[::-1]\n\n        # Remove items with lowest value-to-weight ratio until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    # Apply a greedy improvement step: try to add items with high value-to-weight ratio\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Sort items by value-to-weight ratio in descending order\n        value_ratio = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3282157449994785,
            2.794261872768402
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    # Here, we randomly select a solution with a probability inversely proportional to its objective values\n    # to encourage exploration of less crowded regions\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / max_obj\n    scores = 1 / (1 + np.sum(normalized_obj, axis=1))  # Higher score for less crowded solutions\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by flipping a random subset of bits (1-3 bits)\n    new_solution = base_solution.copy()\n    flip_indices = np.random.choice(len(new_solution), size=random.randint(1, min(3, len(new_solution))), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items that exceed capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Sort items by their combined value-to-weight ratio (greedy heuristic)\n        value_ratio = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_ratio)[::-1]\n\n        # Remove items with lowest value-to-weight ratio until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    # Apply a greedy improvement step: try to add items with high value-to-weight ratio\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Sort items by value-to-weight ratio in descending order\n        value_ratio = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 167,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (top 30% by combined objective value)\n    sorted_archive = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = random.randint(0, max(0, len(sorted_archive) // 3 - 1))\n    base_solution, _ = sorted_archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and marginal utilities\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Hybrid local search operator\n    # 1. Randomly flip some items in the solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        flip_count = min(3, len(in_solution))\n        flip_indices = np.random.choice(in_solution, flip_count, replace=False)\n        new_solution[flip_indices] = 0\n        current_weight -= np.sum(weight_lst[flip_indices])\n\n    # 2. Add promising items not in solution\n    out_solution = np.where(new_solution == 0)[0]\n    if len(out_solution) > 0:\n        # Calculate potential marginal utility (combined)\n        marginal_utility = (marginal_value1 + marginal_value2)[out_solution]\n        # Select top 5% of items by marginal utility\n        top_items = out_solution[np.argsort(marginal_utility)[-max(1, len(out_solution)//20):]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # 3. Small random perturbation to escape local optima\n    if random.random() < 0.3:\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) > 0:\n            item = random.choice(candidate_items)\n            new_solution[item] = 0\n            # Try to add a different item\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                potential_items = [i for i in out_items if weight_lst[i] <= capacity - current_weight]\n                if potential_items:\n                    item = random.choice(potential_items)\n                    new_solution[item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.31598053043705465,
            2.93585667014122
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (top 30% by combined objective value)\n    sorted_archive = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = random.randint(0, max(0, len(sorted_archive) // 3 - 1))\n    base_solution, _ = sorted_archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and marginal utilities\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Hybrid local search operator\n    # 1. Randomly flip some items in the solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        flip_count = min(3, len(in_solution))\n        flip_indices = np.random.choice(in_solution, flip_count, replace=False)\n        new_solution[flip_indices] = 0\n        current_weight -= np.sum(weight_lst[flip_indices])\n\n    # 2. Add promising items not in solution\n    out_solution = np.where(new_solution == 0)[0]\n    if len(out_solution) > 0:\n        # Calculate potential marginal utility (combined)\n        marginal_utility = (marginal_value1 + marginal_value2)[out_solution]\n        # Select top 5% of items by marginal utility\n        top_items = out_solution[np.argsort(marginal_utility)[-max(1, len(out_solution)//20):]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # 3. Small random perturbation to escape local optima\n    if random.random() < 0.3:\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) > 0:\n            item = random.choice(candidate_items)\n            new_solution[item] = 0\n            # Try to add a different item\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                potential_items = [i for i in out_items if weight_lst[i] <= capacity - current_weight]\n                if potential_items:\n                    item = random.choice(potential_items)\n                    new_solution[item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 168,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (higher potential for improvement)\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2)\n        # Select a solution from the middle of the sorted list (not too extreme)\n        base_idx = min(len(archive_sorted) // 2, len(archive_sorted) - 1)\n        base_solution, _ = archive_sorted[base_idx]\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily improve the solution by flipping items that improve both objectives (exploitation)\n\n    # Step 1: Random flipping (exploration)\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flipping\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Iterate through all items to find those that can improve both objectives\n    for i in range(num_items):\n        if new_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                # Calculate the change in both objectives\n                delta_value1 = -(value1_lst[i] if new_solution[i] == 1 else 0)\n                delta_value2 = -(value2_lst[i] if new_solution[i] == 1 else 0)\n                # If both objectives improve, keep the change\n                if delta_value1 >= 0 and delta_value2 >= 0:\n                    new_solution = temp_solution\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                # Calculate the change in both objectives\n                delta_value1 = value1_lst[i] if new_solution[i] == 0 else 0\n                delta_value2 = value2_lst[i] if new_solution[i] == 0 else 0\n                # If both objectives improve, keep the change\n                if delta_value1 >= 0 and delta_value2 >= 0:\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.4038889655427196,
            8.667254388332367
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (higher potential for improvement)\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2)\n        # Select a solution from the middle of the sorted list (not too extreme)\n        base_idx = min(len(archive_sorted) // 2, len(archive_sorted) - 1)\n        base_solution, _ = archive_sorted[base_idx]\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily improve the solution by flipping items that improve both objectives (exploitation)\n\n    # Step 1: Random flipping (exploration)\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flipping\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Iterate through all items to find those that can improve both objectives\n    for i in range(num_items):\n        if new_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                # Calculate the change in both objectives\n                delta_value1 = -(value1_lst[i] if new_solution[i] == 1 else 0)\n                delta_value2 = -(value2_lst[i] if new_solution[i] == 1 else 0)\n                # If both objectives improve, keep the change\n                if delta_value1 >= 0 and delta_value2 >= 0:\n                    new_solution = temp_solution\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                # Calculate the change in both objectives\n                delta_value1 = value1_lst[i] if new_solution[i] == 0 else 0\n                delta_value2 = value2_lst[i] if new_solution[i] == 0 else 0\n                # If both objectives improve, keep the change\n                if delta_value1 >= 0 and delta_value2 >= 0:\n                    new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 169,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_items = len(new_solution)\n    num_flips = min(3, num_items)  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(num_items), num_flips)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item if it's included\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item if it's excluded\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement phase: try to improve the solution by flipping items\n    # that could increase the total value without violating capacity\n    improved = True\n    while improved:\n        improved = False\n        # Evaluate the current solution's objective values\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n\n        # Try flipping each item to see if it improves the solution\n        for i in range(num_items):\n            if new_solution[i] == 1:\n                # Try removing item i\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight >= 0:\n                    temp_value1 = current_value1 - value1_lst[i]\n                    temp_value2 = current_value2 - value2_lst[i]\n                    # Check if the new solution is better (dominates or is non-dominated)\n                    if (temp_value1 >= current_value1 and temp_value2 >= current_value2) and \\\n                       (temp_value1 > current_value1 or temp_value2 > current_value2):\n                        new_solution[i] = 0\n                        current_weight = temp_weight\n                        current_value1 = temp_value1\n                        current_value2 = temp_value2\n                        improved = True\n                        break\n            else:\n                # Try adding item i\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    temp_value1 = current_value1 + value1_lst[i]\n                    temp_value2 = current_value2 + value2_lst[i]\n                    # Check if the new solution is better (dominates or is non-dominated)\n                    if (temp_value1 >= current_value1 and temp_value2 >= current_value2) and \\\n                       (temp_value1 > current_value1 or temp_value2 > current_value2):\n                        new_solution[i] = 1\n                        current_weight = temp_weight\n                        current_value1 = temp_value1\n                        current_value2 = temp_value2\n                        improved = True\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.4263277090140493,
            2.6177124083042145
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_items = len(new_solution)\n    num_flips = min(3, num_items)  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(num_items), num_flips)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item if it's included\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item if it's excluded\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement phase: try to improve the solution by flipping items\n    # that could increase the total value without violating capacity\n    improved = True\n    while improved:\n        improved = False\n        # Evaluate the current solution's objective values\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n\n        # Try flipping each item to see if it improves the solution\n        for i in range(num_items):\n            if new_solution[i] == 1:\n                # Try removing item i\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight >= 0:\n                    temp_value1 = current_value1 - value1_lst[i]\n                    temp_value2 = current_value2 - value2_lst[i]\n                    # Check if the new solution is better (dominates or is non-dominated)\n                    if (temp_value1 >= current_value1 and temp_value2 >= current_value2) and \\\n                       (temp_value1 > current_value1 or temp_value2 > current_value2):\n                        new_solution[i] = 0\n                        current_weight = temp_weight\n                        current_value1 = temp_value1\n                        current_value2 = temp_value2\n                        improved = True\n                        break\n            else:\n                # Try adding item i\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    temp_value1 = current_value1 + value1_lst[i]\n                    temp_value2 = current_value2 + value2_lst[i]\n                    # Check if the new solution is better (dominates or is non-dominated)\n                    if (temp_value1 >= current_value1 and temp_value2 >= current_value2) and \\\n                       (temp_value1 > current_value1 or temp_value2 > current_value2):\n                        new_solution[i] = 1\n                        current_weight = temp_weight\n                        current_value1 = temp_value1\n                        current_value2 = temp_value2\n                        improved = True\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 170,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with high potential for improvement (randomly biased towards better solutions)\n    base_solution, _ = random.choices(\n        archive,\n        weights=[1.0 / (i + 1) for i in range(len(archive))],  # Prefer earlier (better) solutions\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search operator: random swaps + greedy item selection\n    for _ in range(10):  # Number of local search steps\n        # Randomly select a subset of items to consider for swap\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(weight_lst))\n\n        # Randomly choose an item to swap (or add/remove)\n        idx = random.choice(candidate_indices)\n\n        # Try removing the item\n        if new_solution[idx] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = current_weight - weight_lst[idx]\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n        # Try adding a random item not in the solution\n        zero_indices = np.where(new_solution == 0)[0]\n        if len(zero_indices) > 0:\n            idx_add = random.choice(zero_indices)\n            if current_weight + weight_lst[idx_add] <= capacity:\n                new_solution[idx_add] = 1\n                current_weight += weight_lst[idx_add]\n\n    # Greedy improvement: add items with highest marginal utility (weighted sum of values)\n    zero_indices = np.where(new_solution == 0)[0]\n    if len(zero_indices) > 0:\n        # Calculate marginal utility for each candidate item\n        marginal_utilities = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = sorted(zero_indices, key=lambda i: -marginal_utilities[i])\n\n        for idx in sorted_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.375049492871786,
            1.404222846031189
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with high potential for improvement (randomly biased towards better solutions)\n    base_solution, _ = random.choices(\n        archive,\n        weights=[1.0 / (i + 1) for i in range(len(archive))],  # Prefer earlier (better) solutions\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search operator: random swaps + greedy item selection\n    for _ in range(10):  # Number of local search steps\n        # Randomly select a subset of items to consider for swap\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(weight_lst))\n\n        # Randomly choose an item to swap (or add/remove)\n        idx = random.choice(candidate_indices)\n\n        # Try removing the item\n        if new_solution[idx] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = current_weight - weight_lst[idx]\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n        # Try adding a random item not in the solution\n        zero_indices = np.where(new_solution == 0)[0]\n        if len(zero_indices) > 0:\n            idx_add = random.choice(zero_indices)\n            if current_weight + weight_lst[idx_add] <= capacity:\n                new_solution[idx_add] = 1\n                current_weight += weight_lst[idx_add]\n\n    # Greedy improvement: add items with highest marginal utility (weighted sum of values)\n    zero_indices = np.where(new_solution == 0)[0]\n    if len(zero_indices) > 0:\n        # Calculate marginal utility for each candidate item\n        marginal_utilities = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = sorted(zero_indices, key=lambda i: -marginal_utilities[i])\n\n        for idx in sorted_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 171,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a probability proportional to its potential for improvement\n    weights = np.array([1 / (1 + np.sum(sol[0])) for sol in archive])  # Inverse of solution size as a proxy for potential\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (add/remove)\n    # 2. If the flip increases both objectives, accept it\n    # 3. If not, try to find a compensating flip that improves one objective without hurting the other\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    subset_size = min(3, n_items)  # Small subset for local search\n    subset_indices = np.random.choice(n_items, subset_size, replace=False)\n\n    for i in subset_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n\n        # Calculate new weight and values\n        new_weight = current_weight + (temp_solution[i] - new_solution[i]) * weight_lst[i]\n        new_value1 = current_value1 + (temp_solution[i] - new_solution[i]) * value1_lst[i]\n        new_value2 = current_value2 + (temp_solution[i] - new_solution[i]) * value2_lst[i]\n\n        # Check feasibility and dominance\n        if new_weight <= capacity:\n            if (new_value1 > current_value1 and new_value2 > current_value2):\n                # Dominating solution found\n                new_solution = temp_solution\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n            elif (new_value1 >= current_value1 and new_value2 >= current_value2) and (new_value1 > current_value1 or new_value2 > current_value2):\n                # Non-dominated but better in at least one objective\n                new_solution = temp_solution\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n            elif random.random() < 0.3:  # Small probability to accept non-dominated solutions\n                new_solution = temp_solution\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # If no improvement found, try a more aggressive flip\n    if np.array_equal(new_solution, base_solution):\n        # Select the item with highest marginal value ratio (value1/weight or value2/weight)\n        if random.random() < 0.5:\n            value_ratio = value1_lst / weight_lst\n        else:\n            value_ratio = value2_lst / weight_lst\n\n        # Find the best candidate to flip\n        best_candidate = -1\n        best_improvement = 0\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 + value1_lst[i]\n                    new_value2 = current_value2 + value2_lst[i]\n                    improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_candidate = i\n            else:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:  # Always feasible when removing\n                    new_value1 = current_value1 - value1_lst[i]\n                    new_value2 = current_value2 - value2_lst[i]\n                    improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_candidate = i\n\n        if best_candidate != -1:\n            new_solution[best_candidate] = 1 - new_solution[best_candidate]\n\n    return new_solution\n\n",
        "score": [
            -0.2929898433502872,
            7.35793074965477
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a probability proportional to its potential for improvement\n    weights = np.array([1 / (1 + np.sum(sol[0])) for sol in archive])  # Inverse of solution size as a proxy for potential\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (add/remove)\n    # 2. If the flip increases both objectives, accept it\n    # 3. If not, try to find a compensating flip that improves one objective without hurting the other\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    subset_size = min(3, n_items)  # Small subset for local search\n    subset_indices = np.random.choice(n_items, subset_size, replace=False)\n\n    for i in subset_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n\n        # Calculate new weight and values\n        new_weight = current_weight + (temp_solution[i] - new_solution[i]) * weight_lst[i]\n        new_value1 = current_value1 + (temp_solution[i] - new_solution[i]) * value1_lst[i]\n        new_value2 = current_value2 + (temp_solution[i] - new_solution[i]) * value2_lst[i]\n\n        # Check feasibility and dominance\n        if new_weight <= capacity:\n            if (new_value1 > current_value1 and new_value2 > current_value2):\n                # Dominating solution found\n                new_solution = temp_solution\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n            elif (new_value1 >= current_value1 and new_value2 >= current_value2) and (new_value1 > current_value1 or new_value2 > current_value2):\n                # Non-dominated but better in at least one objective\n                new_solution = temp_solution\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n            elif random.random() < 0.3:  # Small probability to accept non-dominated solutions\n                new_solution = temp_solution\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # If no improvement found, try a more aggressive flip\n    if np.array_equal(new_solution, base_solution):\n        # Select the item with highest marginal value ratio (value1/weight or value2/weight)\n        if random.random() < 0.5:\n            value_ratio = value1_lst / weight_lst\n        else:\n            value_ratio = value2_lst / weight_lst\n\n        # Find the best candidate to flip\n        best_candidate = -1\n        best_improvement = 0\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 + value1_lst[i]\n                    new_value2 = current_value2 + value2_lst[i]\n                    improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_candidate = i\n            else:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[i]\n                if new_weight >= 0:  # Always feasible when removing\n                    new_value1 = current_value1 - value1_lst[i]\n                    new_value2 = current_value2 - value2_lst[i]\n                    improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_candidate = i\n\n        if best_candidate != -1:\n            new_solution[best_candidate] = 1 - new_solution[best_candidate]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 172,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Prioritize solutions that are not on the Pareto front and have room for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Step 2: Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Flip a random subset of items (with probability based on their marginal contribution)\n    flip_prob = 0.3  # Base probability to flip an item\n    for i in range(n_items):\n        if np.random.rand() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Strategy 2: Add items that improve both objectives if feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    for i in range(n_items):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            if value1_lst[i] > 0 and value2_lst[i] > 0:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Strategy 3: Remove items that don't contribute to either objective\n    for i in range(n_items):\n        if new_solution[i] == 1 and value1_lst[i] == 0 and value2_lst[i] == 0:\n            new_solution[i] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        items_in = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in)\n        for i in items_in:\n            if weight_lst[i] <= excess and new_solution[i] == 1:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9560275605333415,
            2.0777795016765594
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Prioritize solutions that are not on the Pareto front and have room for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Step 2: Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Flip a random subset of items (with probability based on their marginal contribution)\n    flip_prob = 0.3  # Base probability to flip an item\n    for i in range(n_items):\n        if np.random.rand() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Strategy 2: Add items that improve both objectives if feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    for i in range(n_items):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            if value1_lst[i] > 0 and value2_lst[i] > 0:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Strategy 3: Remove items that don't contribute to either objective\n    for i in range(n_items):\n        if new_solution[i] == 1 and value1_lst[i] == 0 and value2_lst[i] == 0:\n            new_solution[i] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        items_in = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in)\n        for i in items_in:\n            if weight_lst[i] <= excess and new_solution[i] == 1:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 172,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Prioritize solutions that are not on the Pareto front and have room for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Step 2: Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Flip a random subset of items (with probability based on their marginal contribution)\n    flip_prob = 0.3  # Base probability to flip an item\n    for i in range(n_items):\n        if np.random.rand() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Strategy 2: Add items that improve both objectives if feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    for i in range(n_items):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            if value1_lst[i] > 0 and value2_lst[i] > 0:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Strategy 3: Remove items that don't contribute to either objective\n    for i in range(n_items):\n        if new_solution[i] == 1 and value1_lst[i] == 0 and value2_lst[i] == 0:\n            new_solution[i] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        items_in = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in)\n        for i in items_in:\n            if weight_lst[i] <= excess and new_solution[i] == 1:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9560275605333415,
            2.0777795016765594
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Prioritize solutions that are not on the Pareto front and have room for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Step 2: Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Flip a random subset of items (with probability based on their marginal contribution)\n    flip_prob = 0.3  # Base probability to flip an item\n    for i in range(n_items):\n        if np.random.rand() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Strategy 2: Add items that improve both objectives if feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    for i in range(n_items):\n        if new_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity:\n            if value1_lst[i] > 0 and value2_lst[i] > 0:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Strategy 3: Remove items that don't contribute to either objective\n    for i in range(n_items):\n        if new_solution[i] == 1 and value1_lst[i] == 0 and value2_lst[i] == 0:\n            new_solution[i] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        items_in = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in)\n        for i in items_in:\n            if weight_lst[i] <= excess and new_solution[i] == 1:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 173,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip items with high marginal gain for both objectives\n    # First, identify items that can be flipped (either included or excluded)\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if excluding this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if including this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    if not flip_candidates:\n        # If no flips are possible, return a random flip that maintains feasibility\n        feasible_flips = [i for i in range(len(new_solution)) if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                          (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_flips:\n            flip_idx = np.random.choice(feasible_flips)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Greedily select the best flip based on combined marginal gain\n    best_flip = None\n    best_gain = -float('inf')\n\n    for i in flip_candidates:\n        if new_solution[i] == 1:\n            # Excluding item i\n            new_weight = current_weight - weight_lst[i]\n            gain1 = -value1_lst[i]\n            gain2 = -value2_lst[i]\n        else:\n            # Including item i\n            new_weight = current_weight + weight_lst[i]\n            gain1 = value1_lst[i]\n            gain2 = value2_lst[i]\n\n        # Combined gain: simple sum of normalized gains\n        norm_gain1 = gain1 / (np.max(value1_lst) + 1e-6)\n        norm_gain2 = gain2 / (np.max(value2_lst) + 1e-6)\n        total_gain = norm_gain1 + norm_gain2\n\n        if total_gain > best_gain:\n            best_gain = total_gain\n            best_flip = i\n\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    return new_solution\n\n",
        "score": [
            -0.8126087785705887,
            3.5692244172096252
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip items with high marginal gain for both objectives\n    # First, identify items that can be flipped (either included or excluded)\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if excluding this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if including this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    if not flip_candidates:\n        # If no flips are possible, return a random flip that maintains feasibility\n        feasible_flips = [i for i in range(len(new_solution)) if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                          (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_flips:\n            flip_idx = np.random.choice(feasible_flips)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Greedily select the best flip based on combined marginal gain\n    best_flip = None\n    best_gain = -float('inf')\n\n    for i in flip_candidates:\n        if new_solution[i] == 1:\n            # Excluding item i\n            new_weight = current_weight - weight_lst[i]\n            gain1 = -value1_lst[i]\n            gain2 = -value2_lst[i]\n        else:\n            # Including item i\n            new_weight = current_weight + weight_lst[i]\n            gain1 = value1_lst[i]\n            gain2 = value2_lst[i]\n\n        # Combined gain: simple sum of normalized gains\n        norm_gain1 = gain1 / (np.max(value1_lst) + 1e-6)\n        norm_gain2 = gain2 / (np.max(value2_lst) + 1e-6)\n        total_gain = norm_gain1 + norm_gain2\n\n        if total_gain > best_gain:\n            best_gain = total_gain\n            best_flip = i\n\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 174,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution: prioritize those with high objective values or low dominance\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate dominance ranks (simplified for selection)\n    dominance_ranks = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and archive_objectives[j][0] >= archive_objectives[i][0] and archive_objectives[j][1] >= archive_objectives[i][1] and (archive_objectives[j][0] > archive_objectives[i][0] or archive_objectives[j][1] > archive_objectives[i][1]):\n                dominated = True\n                break\n        dominance_ranks[i] = 1 if dominated else 0\n\n    # Select non-dominated solutions with higher probability\n    non_dominated_indices = np.where(dominance_ranks == 0)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine random flips with objective-aware flips\n    flip_indices = np.where(base_solution == 1)[0]\n    if len(flip_indices) == 0:\n        flip_indices = np.arange(len(weight_lst))\n\n    # Random flip: flip a random item\n    random_flip_idx = np.random.choice(flip_indices)\n    new_solution[random_flip_idx] = 1 - new_solution[random_flip_idx]\n\n    # Check feasibility and adjust if necessary\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items with the least value contribution in both objectives\n        while new_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Calculate value contribution (sum of value1 and value2 for included items)\n            value_contributions = value1_lst[included_items] + value2_lst[included_items]\n            item_to_remove = included_items[np.argmin(value_contributions)]\n            new_solution[item_to_remove] = 0\n            new_weight = np.sum(weight_lst * new_solution)\n\n    # Objective-aware flip: flip an item that improves one objective without worsening the other\n    if np.random.rand() < 0.5:  # 50% chance to apply objective-aware flip\n        for idx in np.where(base_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                # Check if flipping this item improves at least one objective\n                new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx] - (value1_lst[idx] if new_solution[idx] == 1 else 0)\n                new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx] - (value2_lst[idx] if new_solution[idx] == 1 else 0)\n                if new_value1 >= archive_objectives[selected_idx][0] or new_value2 >= archive_objectives[selected_idx][1]:\n                    new_solution[idx] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8528179570591994,
            1.2957409918308258
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution: prioritize those with high objective values or low dominance\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate dominance ranks (simplified for selection)\n    dominance_ranks = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and archive_objectives[j][0] >= archive_objectives[i][0] and archive_objectives[j][1] >= archive_objectives[i][1] and (archive_objectives[j][0] > archive_objectives[i][0] or archive_objectives[j][1] > archive_objectives[i][1]):\n                dominated = True\n                break\n        dominance_ranks[i] = 1 if dominated else 0\n\n    # Select non-dominated solutions with higher probability\n    non_dominated_indices = np.where(dominance_ranks == 0)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine random flips with objective-aware flips\n    flip_indices = np.where(base_solution == 1)[0]\n    if len(flip_indices) == 0:\n        flip_indices = np.arange(len(weight_lst))\n\n    # Random flip: flip a random item\n    random_flip_idx = np.random.choice(flip_indices)\n    new_solution[random_flip_idx] = 1 - new_solution[random_flip_idx]\n\n    # Check feasibility and adjust if necessary\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items with the least value contribution in both objectives\n        while new_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Calculate value contribution (sum of value1 and value2 for included items)\n            value_contributions = value1_lst[included_items] + value2_lst[included_items]\n            item_to_remove = included_items[np.argmin(value_contributions)]\n            new_solution[item_to_remove] = 0\n            new_weight = np.sum(weight_lst * new_solution)\n\n    # Objective-aware flip: flip an item that improves one objective without worsening the other\n    if np.random.rand() < 0.5:  # 50% chance to apply objective-aware flip\n        for idx in np.where(base_solution == 0)[0]:\n            if current_weight + weight_lst[idx] <= capacity:\n                # Check if flipping this item improves at least one objective\n                new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx] - (value1_lst[idx] if new_solution[idx] == 1 else 0)\n                new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx] - (value2_lst[idx] if new_solution[idx] == 1 else 0)\n                if new_value1 >= archive_objectives[selected_idx][0] or new_value2 >= archive_objectives[selected_idx][1]:\n                    new_solution[idx] = 1\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 175,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a higher probability for those with lower weights (promising for local search)\n    weights = np.array([np.sum(weight_lst[sol[0] == 1]) for sol in archive])\n    weights = np.maximum(weights, 1e-6)  # Avoid division by zero\n    probs = 1 / weights\n    probs /= probs.sum()\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: Random swaps with value-to-weight ratio consideration\n    n_items = len(weight_lst)\n    max_attempts = min(10, n_items)  # Limit attempts to avoid excessive computation\n\n    for _ in range(max_attempts):\n        # Randomly select an item to flip (0 to 1 or 1 to 0)\n        item_idx = random.randint(0, n_items - 1)\n        item_weight = weight_lst[item_idx]\n\n        if new_solution[item_idx] == 1:\n            # Try to remove the item\n            if current_weight - item_weight >= 0:\n                new_solution[item_idx] = 0\n                current_weight -= item_weight\n        else:\n            # Try to add the item if it improves the value-to-weight ratio\n            if current_weight + item_weight <= capacity:\n                # Calculate value-to-weight ratios for both objectives\n                ratio1 = value1_lst[item_idx] / item_weight if item_weight > 0 else 0\n                ratio2 = value2_lst[item_idx] / item_weight if item_weight > 0 else 0\n\n                # Add the item if it has a high value-to-weight ratio in either objective\n                if ratio1 > np.mean(value1_lst / weight_lst) or ratio2 > np.mean(value2_lst / weight_lst):\n                    new_solution[item_idx] = 1\n                    current_weight += item_weight\n\n    return new_solution\n\n",
        "score": [
            -0.6225123496104944,
            2.269614428281784
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a higher probability for those with lower weights (promising for local search)\n    weights = np.array([np.sum(weight_lst[sol[0] == 1]) for sol in archive])\n    weights = np.maximum(weights, 1e-6)  # Avoid division by zero\n    probs = 1 / weights\n    probs /= probs.sum()\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: Random swaps with value-to-weight ratio consideration\n    n_items = len(weight_lst)\n    max_attempts = min(10, n_items)  # Limit attempts to avoid excessive computation\n\n    for _ in range(max_attempts):\n        # Randomly select an item to flip (0 to 1 or 1 to 0)\n        item_idx = random.randint(0, n_items - 1)\n        item_weight = weight_lst[item_idx]\n\n        if new_solution[item_idx] == 1:\n            # Try to remove the item\n            if current_weight - item_weight >= 0:\n                new_solution[item_idx] = 0\n                current_weight -= item_weight\n        else:\n            # Try to add the item if it improves the value-to-weight ratio\n            if current_weight + item_weight <= capacity:\n                # Calculate value-to-weight ratios for both objectives\n                ratio1 = value1_lst[item_idx] / item_weight if item_weight > 0 else 0\n                ratio2 = value2_lst[item_idx] / item_weight if item_weight > 0 else 0\n\n                # Add the item if it has a high value-to-weight ratio in either objective\n                if ratio1 > np.mean(value1_lst / weight_lst) or ratio2 > np.mean(value2_lst / weight_lst):\n                    new_solution[item_idx] = 1\n                    current_weight += item_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 176,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified: higher value1 + value2 is less dominated)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution that is not the best but has room for improvement\n        selected_idx = min(1, len(archive) // 2)  # Avoid always picking the best solution\n        base_solution = archive_sorted[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    n_items = len(weight_lst)\n    for _ in range(10):  # Limit the number of attempts to avoid excessive computation\n        # Randomly select two items to potentially swap or flip\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Flip-based move (single item)\n        if np.random.rand() < 0.7:  # Higher probability for flip\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1 - temp_solution[i]\n            temp_weight = current_weight + (1 - 2 * new_solution[i]) * weight_lst[i]\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        # Swap-based move (two items)\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            temp_weight = current_weight + (weight_lst[j] - weight_lst[i]) * (new_solution[i] - new_solution[j])\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.37248465745899145,
            2.0367651879787445
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified: higher value1 + value2 is less dominated)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution that is not the best but has room for improvement\n        selected_idx = min(1, len(archive) // 2)  # Avoid always picking the best solution\n        base_solution = archive_sorted[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    n_items = len(weight_lst)\n    for _ in range(10):  # Limit the number of attempts to avoid excessive computation\n        # Randomly select two items to potentially swap or flip\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Flip-based move (single item)\n        if np.random.rand() < 0.7:  # Higher probability for flip\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1 - temp_solution[i]\n            temp_weight = current_weight + (1 - 2 * new_solution[i]) * weight_lst[i]\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        # Swap-based move (two items)\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            temp_weight = current_weight + (weight_lst[j] - weight_lst[i]) * (new_solution[i] - new_solution[j])\n\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 177,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected = random.choices(archive_sorted[:max(3, len(archive) // 3)], k=1)[0][0].copy()\n\n    # Generate neighbor by swapping items with high marginal gain\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    items = list(range(len(new_solution)))\n\n    # Try to add items not in the solution (greedy improvement)\n    for i in random.sample(items, min(5, len(items))):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Try to remove items in the solution (greedy improvement)\n    for i in random.sample(items, min(5, len(items))):\n        if new_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            # Ensure feasibility after removal\n            if current_weight > capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Random swap to escape local optima\n    if random.random() < 0.3:\n        i, j = random.sample(items, 2)\n        if (new_solution[i] != new_solution[j] and\n            current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.286922852501876,
            0.8931469321250916
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selected = random.choices(archive_sorted[:max(3, len(archive) // 3)], k=1)[0][0].copy()\n\n    # Generate neighbor by swapping items with high marginal gain\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    items = list(range(len(new_solution)))\n\n    # Try to add items not in the solution (greedy improvement)\n    for i in random.sample(items, min(5, len(items))):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Try to remove items in the solution (greedy improvement)\n    for i in random.sample(items, min(5, len(items))):\n        if new_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            # Ensure feasibility after removal\n            if current_weight > capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Random swap to escape local optima\n    if random.random() < 0.3:\n        i, j = random.sample(items, 2)\n        if (new_solution[i] != new_solution[j] and\n            current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 178,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate the total value for each solution in the archive\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n\n    # Normalize the total values to create a probability distribution\n    if np.max(total_values) == np.min(total_values):\n        probabilities = np.ones(len(archive)) / len(archive)\n    else:\n        normalized_values = (total_values - np.min(total_values)) / (np.max(total_values) - np.min(total_values))\n        probabilities = normalized_values / np.sum(normalized_values)\n\n    # Select a solution based on the probability distribution\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: random swaps followed by a greedy improvement step\n    n_items = len(base_solution)\n    if n_items < 2:\n        return new_solution  # No possible swaps\n\n    # Step 1: Randomly swap a subset of items\n    n_swaps = min(3, n_items // 2)  # Limit the number of swaps to avoid excessive changes\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure the solution remains feasible after swaps\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # If the solution is infeasible, flip items randomly until feasibility is restored\n        while total_weight > capacity:\n            # Select a random item to flip\n            flip_indices = np.where(new_solution == 1)[0]\n            if len(flip_indices) == 0:\n                break  # No items to flip, must accept infeasible solution\n            flip_idx = random.choice(flip_indices)\n            new_solution[flip_idx] = 0\n            total_weight -= weight_lst[flip_idx]\n\n    # Step 2: Greedy improvement step - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(new_solution * weight_lst)\n    current_value1 = np.sum(new_solution * value1_lst)\n    current_value2 = np.sum(new_solution * value2_lst)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate the potential improvement in both objectives\n            delta_value1 = value1_lst[item]\n            delta_value2 = value2_lst[item]\n\n            # If adding the item improves both objectives, do it\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                current_value1 += delta_value1\n                current_value2 += delta_value2\n\n    return new_solution\n\n",
        "score": [
            -0.33424273170426566,
            1.8058022558689117
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate the total value for each solution in the archive\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n\n    # Normalize the total values to create a probability distribution\n    if np.max(total_values) == np.min(total_values):\n        probabilities = np.ones(len(archive)) / len(archive)\n    else:\n        normalized_values = (total_values - np.min(total_values)) / (np.max(total_values) - np.min(total_values))\n        probabilities = normalized_values / np.sum(normalized_values)\n\n    # Select a solution based on the probability distribution\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: random swaps followed by a greedy improvement step\n    n_items = len(base_solution)\n    if n_items < 2:\n        return new_solution  # No possible swaps\n\n    # Step 1: Randomly swap a subset of items\n    n_swaps = min(3, n_items // 2)  # Limit the number of swaps to avoid excessive changes\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure the solution remains feasible after swaps\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # If the solution is infeasible, flip items randomly until feasibility is restored\n        while total_weight > capacity:\n            # Select a random item to flip\n            flip_indices = np.where(new_solution == 1)[0]\n            if len(flip_indices) == 0:\n                break  # No items to flip, must accept infeasible solution\n            flip_idx = random.choice(flip_indices)\n            new_solution[flip_idx] = 0\n            total_weight -= weight_lst[flip_idx]\n\n    # Step 2: Greedy improvement step - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(new_solution * weight_lst)\n    current_value1 = np.sum(new_solution * value1_lst)\n    current_value2 = np.sum(new_solution * value2_lst)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate the potential improvement in both objectives\n            delta_value1 = value1_lst[item]\n            delta_value2 = value2_lst[item]\n\n            # If adding the item improves both objectives, do it\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                current_value1 += delta_value1\n                current_value2 += delta_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 179,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = [sol_obj[0] for sol_obj in archive]\n    if len(candidates) > 1:\n        # Sort candidates by a combination of objective values (e.g., sum of normalized values)\n        normalized_values = np.array([(v1 + v2) / (np.sum(value1_lst) + np.sum(value2_lst))\n                                    for _, (v1, v2) in archive])\n        selected_idx = np.argmin(normalized_values)  # Select the least \"dominant\" solution\n        base_solution = candidates[selected_idx].copy()\n    else:\n        base_solution = candidates[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedily add items with high marginal utility (exploitation)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utility1 = value1_lst - np.average(value1_lst)\n        marginal_utility2 = value2_lst - np.average(value2_lst)\n        combined_utility = marginal_utility1 + marginal_utility2\n\n        # Sort items by combined utility and add until capacity is reached\n        sorted_indices = np.argsort(combined_utility)[::-1]\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove heavy items until feasible\n        sorted_indices = np.argsort(weight_lst[new_solution == 1])[::-1]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[new_solution == 1][idx] = 0\n            total_weight -= weight_lst[new_solution == 1][idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4910818704054877,
            1.7860641479492188
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = [sol_obj[0] for sol_obj in archive]\n    if len(candidates) > 1:\n        # Sort candidates by a combination of objective values (e.g., sum of normalized values)\n        normalized_values = np.array([(v1 + v2) / (np.sum(value1_lst) + np.sum(value2_lst))\n                                    for _, (v1, v2) in archive])\n        selected_idx = np.argmin(normalized_values)  # Select the least \"dominant\" solution\n        base_solution = candidates[selected_idx].copy()\n    else:\n        base_solution = candidates[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedily add items with high marginal utility (exploitation)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utility1 = value1_lst - np.average(value1_lst)\n        marginal_utility2 = value2_lst - np.average(value2_lst)\n        combined_utility = marginal_utility1 + marginal_utility2\n\n        # Sort items by combined utility and add until capacity is reached\n        sorted_indices = np.argsort(combined_utility)[::-1]\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove heavy items until feasible\n        sorted_indices = np.argsort(weight_lst[new_solution == 1])[::-1]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[new_solution == 1][idx] = 0\n            total_weight -= weight_lst[new_solution == 1][idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 180,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Prioritize solutions with high variance in objectives or those with marginal improvements\n    objectives = np.array([obj for _, obj in archive])\n    objective_variance = np.var(objectives, axis=0)\n    promising_indices = np.argsort(-objective_variance[0] * objective_variance[1])  # Solutions with high variance in both objectives\n\n    if len(promising_indices) == 0:\n        promising_indices = np.arange(len(archive))\n\n    selected_idx = np.random.choice(promising_indices[:min(3, len(promising_indices))])  # Randomly select from top 3\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    max_attempts = 10  # Limit attempts to avoid infinite loops\n\n    for _ in range(max_attempts):\n        # Strategy 1: Random bit flip with probability based on value-to-weight ratio\n        flip_prob = 0.3  # Base probability\n        value_to_weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        flip_probabilities = flip_prob * value_to_weight_ratio / np.max(value_to_weight_ratio)\n\n        # Apply random flips\n        for i in range(len(new_solution)):\n            if np.random.rand() < flip_probabilities[i]:\n                if new_solution[i] == 1:\n                    # Remove item if it's in the solution\n                    new_solution[i] = 0\n                else:\n                    # Add item if it fits\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n\n        # Strategy 2: Value-based swap (swap items with high value1 and low value2 or vice versa)\n        if np.random.rand() < 0.5:\n            high_value1_items = np.where((value1_lst > np.median(value1_lst)) & (new_solution == 1))[0]\n            low_value2_items = np.where((value2_lst < np.median(value2_lst)) & (new_solution == 0))[0]\n\n            if len(high_value1_items) > 0 and len(low_value2_items) > 0:\n                swap_item1 = np.random.choice(high_value1_items)\n                swap_item2 = np.random.choice(low_value2_items)\n\n                if current_weight - weight_lst[swap_item1] + weight_lst[swap_item2] <= capacity:\n                    new_solution[swap_item1], new_solution[swap_item2] = new_solution[swap_item2], new_solution[swap_item1]\n\n        # Strategy 3: Weight-based adjustment (remove items with low value-to-weight ratio)\n        if np.random.rand() < 0.3:\n            low_value_items = np.where((value_to_weight_ratio < np.median(value_to_weight_ratio)) & (new_solution == 1))[0]\n            if len(low_value_items) > 0:\n                remove_item = np.random.choice(low_value_items)\n                new_solution[remove_item] = 0\n\n        # Update current weight and check feasibility\n        new_weight = np.sum(weight_lst * new_solution)\n        if new_weight <= capacity:\n            current_weight = new_weight\n            break  # Found a feasible solution\n\n    return new_solution\n\n",
        "score": [
            -0.8540308621213741,
            2.3220648765563965
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Prioritize solutions with high variance in objectives or those with marginal improvements\n    objectives = np.array([obj for _, obj in archive])\n    objective_variance = np.var(objectives, axis=0)\n    promising_indices = np.argsort(-objective_variance[0] * objective_variance[1])  # Solutions with high variance in both objectives\n\n    if len(promising_indices) == 0:\n        promising_indices = np.arange(len(archive))\n\n    selected_idx = np.random.choice(promising_indices[:min(3, len(promising_indices))])  # Randomly select from top 3\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    max_attempts = 10  # Limit attempts to avoid infinite loops\n\n    for _ in range(max_attempts):\n        # Strategy 1: Random bit flip with probability based on value-to-weight ratio\n        flip_prob = 0.3  # Base probability\n        value_to_weight_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        flip_probabilities = flip_prob * value_to_weight_ratio / np.max(value_to_weight_ratio)\n\n        # Apply random flips\n        for i in range(len(new_solution)):\n            if np.random.rand() < flip_probabilities[i]:\n                if new_solution[i] == 1:\n                    # Remove item if it's in the solution\n                    new_solution[i] = 0\n                else:\n                    # Add item if it fits\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n\n        # Strategy 2: Value-based swap (swap items with high value1 and low value2 or vice versa)\n        if np.random.rand() < 0.5:\n            high_value1_items = np.where((value1_lst > np.median(value1_lst)) & (new_solution == 1))[0]\n            low_value2_items = np.where((value2_lst < np.median(value2_lst)) & (new_solution == 0))[0]\n\n            if len(high_value1_items) > 0 and len(low_value2_items) > 0:\n                swap_item1 = np.random.choice(high_value1_items)\n                swap_item2 = np.random.choice(low_value2_items)\n\n                if current_weight - weight_lst[swap_item1] + weight_lst[swap_item2] <= capacity:\n                    new_solution[swap_item1], new_solution[swap_item2] = new_solution[swap_item2], new_solution[swap_item1]\n\n        # Strategy 3: Weight-based adjustment (remove items with low value-to-weight ratio)\n        if np.random.rand() < 0.3:\n            low_value_items = np.where((value_to_weight_ratio < np.median(value_to_weight_ratio)) & (new_solution == 1))[0]\n            if len(low_value_items) > 0:\n                remove_item = np.random.choice(low_value_items)\n                new_solution[remove_item] = 0\n\n        # Update current weight and check feasibility\n        new_weight = np.sum(weight_lst * new_solution)\n        if new_weight <= capacity:\n            current_weight = new_weight\n            break  # Found a feasible solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 181,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy\n    # 1. Random swap of two items\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        # Ensure the swap maintains feasibility\n        if (new_solution[i] != new_solution[j]):\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = 0, 1\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                if current_weight + weight_lst[i] - weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = 1, 0\n\n    # 2. Objective-specific flip (flip an item with low value1 but high value2 or vice versa)\n    if random.random() < 0.3:  # 30% chance\n        # Find items that could improve the other objective\n        if random.random() < 0.5:\n            # Flip an item with low value1 but high value2\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 1 and value1_lst[i] < np.mean(value1_lst) and value2_lst[i] > np.mean(value2_lst)]\n        else:\n            # Flip an item with high value1 but low value2\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 1 and value1_lst[i] > np.mean(value1_lst) and value2_lst[i] < np.mean(value2_lst)]\n\n        if eligible_items:\n            i = random.choice(eligible_items)\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n\n    # 3. Weight-balanced flip (flip an item that brings the weight closer to capacity)\n    if random.random() < 0.5:  # 50% chance\n        # Find items that could be flipped to balance weight\n        if current_weight < capacity * 0.8:  # Underweight\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity]\n        else:  # Overweight\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity]\n\n        if eligible_items:\n            i = random.choice(eligible_items)\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure the solution is feasible (as a safeguard)\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If not feasible, revert to the original solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.5418176446009864,
            1.643147885799408
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy\n    # 1. Random swap of two items\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        # Ensure the swap maintains feasibility\n        if (new_solution[i] != new_solution[j]):\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = 0, 1\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                if current_weight + weight_lst[i] - weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = 1, 0\n\n    # 2. Objective-specific flip (flip an item with low value1 but high value2 or vice versa)\n    if random.random() < 0.3:  # 30% chance\n        # Find items that could improve the other objective\n        if random.random() < 0.5:\n            # Flip an item with low value1 but high value2\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 1 and value1_lst[i] < np.mean(value1_lst) and value2_lst[i] > np.mean(value2_lst)]\n        else:\n            # Flip an item with high value1 but low value2\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 1 and value1_lst[i] > np.mean(value1_lst) and value2_lst[i] < np.mean(value2_lst)]\n\n        if eligible_items:\n            i = random.choice(eligible_items)\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n\n    # 3. Weight-balanced flip (flip an item that brings the weight closer to capacity)\n    if random.random() < 0.5:  # 50% chance\n        # Find items that could be flipped to balance weight\n        if current_weight < capacity * 0.8:  # Underweight\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity]\n        else:  # Overweight\n            eligible_items = [i for i in range(len(new_solution))\n                            if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity]\n\n        if eligible_items:\n            i = random.choice(eligible_items)\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure the solution is feasible (as a safeguard)\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If not feasible, revert to the original solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 182,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and possible improvements\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution that can be added without exceeding capacity\n    candidate_items = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If no items can be added, consider removing items to free up space\n    if len(candidate_items) == 0:\n        # Select items to remove based on their contribution to the objectives\n        remove_candidates = np.where(base_solution == 1)[0]\n        if len(remove_candidates) > 0:\n            # Remove items with the least contribution to both objectives\n            contributions = (value1_lst[remove_candidates] + value2_lst[remove_candidates]) / weight_lst[remove_candidates]\n            item_to_remove = remove_candidates[np.argmin(contributions)]\n            new_solution[item_to_remove] = 0\n    else:\n        # Hybrid local search: add items with high value-to-weight ratio and remove low-value items\n        # Calculate value-to-weight ratios for candidate items\n        ratios = (value1_lst[candidate_items] + value2_lst[candidate_items]) / weight_lst[candidate_items]\n        if len(ratios) > 0:\n            # Add the item with the highest ratio\n            best_item = candidate_items[np.argmax(ratios)]\n            new_solution[best_item] = 1\n\n            # After adding, check if we can remove low-value items to free up space\n            current_weight = np.sum(weight_lst * new_solution)\n            remaining_capacity = capacity - current_weight\n\n            # Identify items to potentially remove (those with low value and high weight)\n            remove_candidates = np.where(new_solution == 1)[0]\n            if len(remove_candidates) > 0:\n                # Remove items with the least contribution to both objectives\n                contributions = (value1_lst[remove_candidates] + value2_lst[remove_candidates]) / weight_lst[remove_candidates]\n                item_to_remove = remove_candidates[np.argmin(contributions)]\n                if (current_weight - weight_lst[item_to_remove]) >= 0:\n                    new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9248522965260281,
            0.7568546235561371
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and possible improvements\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution that can be added without exceeding capacity\n    candidate_items = np.where((base_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If no items can be added, consider removing items to free up space\n    if len(candidate_items) == 0:\n        # Select items to remove based on their contribution to the objectives\n        remove_candidates = np.where(base_solution == 1)[0]\n        if len(remove_candidates) > 0:\n            # Remove items with the least contribution to both objectives\n            contributions = (value1_lst[remove_candidates] + value2_lst[remove_candidates]) / weight_lst[remove_candidates]\n            item_to_remove = remove_candidates[np.argmin(contributions)]\n            new_solution[item_to_remove] = 0\n    else:\n        # Hybrid local search: add items with high value-to-weight ratio and remove low-value items\n        # Calculate value-to-weight ratios for candidate items\n        ratios = (value1_lst[candidate_items] + value2_lst[candidate_items]) / weight_lst[candidate_items]\n        if len(ratios) > 0:\n            # Add the item with the highest ratio\n            best_item = candidate_items[np.argmax(ratios)]\n            new_solution[best_item] = 1\n\n            # After adding, check if we can remove low-value items to free up space\n            current_weight = np.sum(weight_lst * new_solution)\n            remaining_capacity = capacity - current_weight\n\n            # Identify items to potentially remove (those with low value and high weight)\n            remove_candidates = np.where(new_solution == 1)[0]\n            if len(remove_candidates) > 0:\n                # Remove items with the least contribution to both objectives\n                contributions = (value1_lst[remove_candidates] + value2_lst[remove_candidates]) / weight_lst[remove_candidates]\n                item_to_remove = remove_candidates[np.argmin(contributions)]\n                if (current_weight - weight_lst[item_to_remove]) >= 0:\n                    new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 183,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the frontier)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distance to identify less crowded solutions\n    if len(archive) > 1:\n        sorted_values = np.sort(archive_values, axis=0)\n        crowding_distance = np.zeros(len(archive))\n        for i in range(2):  # For both objectives\n            sorted_idx = np.argsort(archive_values[:, i])\n            crowding_distance[sorted_idx[0]] = np.inf\n            crowding_distance[sorted_idx[-1]] = np.inf\n            for j in range(1, len(archive)-1):\n                crowding_distance[sorted_idx[j]] += (sorted_values[sorted_idx[j+1], i] - sorted_values[sorted_idx[j-1], i]) / (sorted_values[-1, i] - sorted_values[0, i])\n\n        # Select a solution with low crowding distance (promising for improvement)\n        selected_idx = np.argmin(crowding_distance)\n    else:\n        selected_idx = 0\n\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps with value-based selection\n    num_swaps = random.randint(1, min(5, len(weight_lst) // 2))\n    for _ in range(num_swaps):\n        # Identify items that can be swapped to improve both objectives\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Select an item to remove (highest weight or low value)\n            remove_candidates = included_items[np.argsort(weight_lst[included_items] - value1_lst[included_items] - value2_lst[included_items])]\n            remove_item = remove_candidates[0]\n\n            # Select an item to add (high value and low weight)\n            add_candidates = excluded_items[np.argsort(-(value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items])]\n            add_item = add_candidates[0]\n\n            # Calculate new weight\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[remove_item] + weight_lst[add_item]\n\n            # Perform swap if feasible\n            if new_weight <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    # Additional random flips to escape local optima\n    num_flips = random.randint(0, min(3, len(weight_lst) // 4))\n    for _ in range(num_flips):\n        flip_item = random.choice(np.where(new_solution == 1)[0])\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[flip_item]\n\n        if new_weight <= capacity:\n            new_solution[flip_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7214246973703202,
            1.545360118150711
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the frontier)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = np.array([obj for _, obj in archive])\n\n    # Calculate crowding distance to identify less crowded solutions\n    if len(archive) > 1:\n        sorted_values = np.sort(archive_values, axis=0)\n        crowding_distance = np.zeros(len(archive))\n        for i in range(2):  # For both objectives\n            sorted_idx = np.argsort(archive_values[:, i])\n            crowding_distance[sorted_idx[0]] = np.inf\n            crowding_distance[sorted_idx[-1]] = np.inf\n            for j in range(1, len(archive)-1):\n                crowding_distance[sorted_idx[j]] += (sorted_values[sorted_idx[j+1], i] - sorted_values[sorted_idx[j-1], i]) / (sorted_values[-1, i] - sorted_values[0, i])\n\n        # Select a solution with low crowding distance (promising for improvement)\n        selected_idx = np.argmin(crowding_distance)\n    else:\n        selected_idx = 0\n\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps with value-based selection\n    num_swaps = random.randint(1, min(5, len(weight_lst) // 2))\n    for _ in range(num_swaps):\n        # Identify items that can be swapped to improve both objectives\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Select an item to remove (highest weight or low value)\n            remove_candidates = included_items[np.argsort(weight_lst[included_items] - value1_lst[included_items] - value2_lst[included_items])]\n            remove_item = remove_candidates[0]\n\n            # Select an item to add (high value and low weight)\n            add_candidates = excluded_items[np.argsort(-(value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items])]\n            add_item = add_candidates[0]\n\n            # Calculate new weight\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            new_weight = current_weight - weight_lst[remove_item] + weight_lst[add_item]\n\n            # Perform swap if feasible\n            if new_weight <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    # Additional random flips to escape local optima\n    num_flips = random.randint(0, min(3, len(weight_lst) // 4))\n    for _ in range(num_flips):\n        flip_item = random.choice(np.where(new_solution == 1)[0])\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[flip_item]\n\n        if new_weight <= capacity:\n            new_solution[flip_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 184,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of objective values (higher is better)\n        sorted_archive = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n        # Select top 30% solutions with some randomness\n        top_solutions = sorted_archive[:max(1, len(sorted_archive) // 3)]\n        selected = random.choice(top_solutions)\n    else:\n        selected = archive[0]\n\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of addition, removal, and swap\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    available_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    # Step 1: Try to add an item (if space allows)\n    if len(available_items) > 0 and current_weight < capacity:\n        # Select items with high marginal value-to-weight ratio\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        candidate_items = [i for i in available_items if weight_lst[i] <= (capacity - current_weight)]\n        if candidate_items:\n            best_item = max(candidate_items, key=lambda i: marginal_values[i])\n            new_solution[best_item] = 1\n\n    # Step 2: Try to remove an item (if solution is not empty)\n    if len(included_items) > 0:\n        # Select items with low marginal value-to-weight ratio\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        worst_item = min(included_items, key=lambda i: marginal_values[i])\n        new_solution[worst_item] = 0\n\n    # Step 3: Try a swap (if both addition and removal are possible)\n    if len(available_items) > 0 and len(included_items) > 0:\n        # Find the best item to add and worst to remove\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        candidate_items = [i for i in available_items if weight_lst[i] <= (capacity - current_weight)]\n        if candidate_items:\n            best_item = max(candidate_items, key=lambda i: marginal_values[i])\n            worst_item = min(included_items, key=lambda i: marginal_values[i])\n            # Only perform swap if it improves the solution\n            if marginal_values[best_item] > marginal_values[worst_item]:\n                new_solution[best_item] = 1\n                new_solution[worst_item] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items with lowest marginal value until feasible\n        included_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(included_items) > 0:\n            marginal_values = (value1_lst + value2_lst) / weight_lst\n            worst_item = min(included_items, key=lambda i: marginal_values[i])\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n            included_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.9125909005130677,
            1.0672235488891602
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of objective values (higher is better)\n        sorted_archive = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n        # Select top 30% solutions with some randomness\n        top_solutions = sorted_archive[:max(1, len(sorted_archive) // 3)]\n        selected = random.choice(top_solutions)\n    else:\n        selected = archive[0]\n\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of addition, removal, and swap\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    available_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    # Step 1: Try to add an item (if space allows)\n    if len(available_items) > 0 and current_weight < capacity:\n        # Select items with high marginal value-to-weight ratio\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        candidate_items = [i for i in available_items if weight_lst[i] <= (capacity - current_weight)]\n        if candidate_items:\n            best_item = max(candidate_items, key=lambda i: marginal_values[i])\n            new_solution[best_item] = 1\n\n    # Step 2: Try to remove an item (if solution is not empty)\n    if len(included_items) > 0:\n        # Select items with low marginal value-to-weight ratio\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        worst_item = min(included_items, key=lambda i: marginal_values[i])\n        new_solution[worst_item] = 0\n\n    # Step 3: Try a swap (if both addition and removal are possible)\n    if len(available_items) > 0 and len(included_items) > 0:\n        # Find the best item to add and worst to remove\n        marginal_values = (value1_lst + value2_lst) / weight_lst\n        candidate_items = [i for i in available_items if weight_lst[i] <= (capacity - current_weight)]\n        if candidate_items:\n            best_item = max(candidate_items, key=lambda i: marginal_values[i])\n            worst_item = min(included_items, key=lambda i: marginal_values[i])\n            # Only perform swap if it improves the solution\n            if marginal_values[best_item] > marginal_values[worst_item]:\n                new_solution[best_item] = 1\n                new_solution[worst_item] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items with lowest marginal value until feasible\n        included_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(included_items) > 0:\n            marginal_values = (value1_lst + value2_lst) / weight_lst\n            worst_item = min(included_items, key=lambda i: marginal_values[i])\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n            included_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 185,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their value1 + value2 (higher sum indicates more potential)\n        archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% of solutions with the highest sum\n        top_solutions = archive[:max(1, len(archive) // 3)]\n        base_solution, _ = random.choice(top_solutions)\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random flip with value-based swaps\n    # First, perform a random flip with probability 0.3\n    if random.random() < 0.3:\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        # Ensure feasibility\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Then perform value-based swaps (higher value items more likely to be swapped)\n    if random.random() < 0.7:\n        # Calculate value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        value_ratio2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine ratios with weights\n        combined_ratio = 0.5 * value_ratio1 + 0.5 * value_ratio2\n\n        # Select items to consider for swap (top 30% by combined ratio)\n        n_items = len(new_solution)\n        top_items = np.argsort(combined_ratio)[-max(1, n_items // 3):]\n\n        # Randomly select two items from top candidates\n        if len(top_items) >= 2:\n            i, j = random.sample(list(top_items), 2)\n            # Swap the items\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            # Ensure feasibility\n            if np.dot(new_solution, weight_lst) > capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3786758122955524,
            4.951692759990692
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their value1 + value2 (higher sum indicates more potential)\n        archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% of solutions with the highest sum\n        top_solutions = archive[:max(1, len(archive) // 3)]\n        base_solution, _ = random.choice(top_solutions)\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random flip with value-based swaps\n    # First, perform a random flip with probability 0.3\n    if random.random() < 0.3:\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        # Ensure feasibility\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Then perform value-based swaps (higher value items more likely to be swapped)\n    if random.random() < 0.7:\n        # Calculate value ratios for both objectives\n        value_ratio1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        value_ratio2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine ratios with weights\n        combined_ratio = 0.5 * value_ratio1 + 0.5 * value_ratio2\n\n        # Select items to consider for swap (top 30% by combined ratio)\n        n_items = len(new_solution)\n        top_items = np.argsort(combined_ratio)[-max(1, n_items // 3):]\n\n        # Randomly select two items from top candidates\n        if len(top_items) >= 2:\n            i, j = random.sample(list(top_items), 2)\n            # Swap the items\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            # Ensure feasibility\n            if np.dot(new_solution, weight_lst) > capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 186,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We prioritize solutions that are not already optimal in both objectives\n    # and have a good balance between the two objectives\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate the \"promise\" score: higher for solutions with potential for improvement\n            # in either objective while maintaining feasibility\n            promise_score = (val1 + val2) * (1 - total_weight / capacity)\n            candidates.append((sol, promise_score))\n\n    if not candidates:\n        # If no candidates, fall back to random selection\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest promise score\n        candidates.sort(key=lambda x: -x[1])\n        base_solution = candidates[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search\n    # First, perform random bit flips to escape local optima\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        # Flip the bit and check feasibility\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n\n    # Step 3: Greedy improvement step\n    # Try to add items that improve at least one objective without violating capacity\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                # Check if adding this item improves at least one objective\n                current_val1, current_val2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n                new_val1 = current_val1 + value1_lst[i]\n                new_val2 = current_val2 + value2_lst[i]\n\n                if (new_val1 > current_val1) or (new_val2 > current_val2):\n                    new_solution[i] = 1\n\n    # Step 4: Remove items that don't contribute to either objective\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and value1_lst[i] == 0 and value2_lst[i] == 0:\n            new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3372991103455544,
            7.526688814163208
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We prioritize solutions that are not already optimal in both objectives\n    # and have a good balance between the two objectives\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate the \"promise\" score: higher for solutions with potential for improvement\n            # in either objective while maintaining feasibility\n            promise_score = (val1 + val2) * (1 - total_weight / capacity)\n            candidates.append((sol, promise_score))\n\n    if not candidates:\n        # If no candidates, fall back to random selection\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest promise score\n        candidates.sort(key=lambda x: -x[1])\n        base_solution = candidates[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search\n    # First, perform random bit flips to escape local optima\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        # Flip the bit and check feasibility\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        temp_weight = np.sum(weight_lst * temp_solution)\n\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n\n    # Step 3: Greedy improvement step\n    # Try to add items that improve at least one objective without violating capacity\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                # Check if adding this item improves at least one objective\n                current_val1, current_val2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n                new_val1 = current_val1 + value1_lst[i]\n                new_val2 = current_val2 + value2_lst[i]\n\n                if (new_val1 > current_val1) or (new_val2 > current_val2):\n                    new_solution[i] = 1\n\n    # Step 4: Remove items that don't contribute to either objective\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and value1_lst[i] == 0 and value2_lst[i] == 0:\n            new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 187,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability inversely proportional to its objective values\n    # This prioritizes solutions that are less explored or have higher potential for improvement\n    objectives = np.array([obj for (_, obj) in archive])\n    normalized = objectives / (objectives.sum(axis=0) + 1e-10)  # Avoid division by zero\n    weights = 1 / (normalized.sum(axis=1) + 1e-10)  # Higher weights for less dominant solutions\n    weights = weights / weights.sum()  # Normalize to probabilities\n    base_idx = np.random.choice(len(archive), p=weights)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly select a subset of items to flip (value-based)\n    # 2. Perform a controlled swap between items to balance objectives\n\n    # Step 1: Value-based flip with probability proportional to value\n    for i in range(len(new_solution)):\n        if random.random() < 0.1:  # 10% chance to consider flipping\n            value_ratio = (value1_lst[i] + value2_lst[i]) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-10)\n            if random.random() < value_ratio:  # Higher value items more likely to flip\n                if new_solution[i] == 1:\n                    if current_weight - weight_lst[i] <= capacity:\n                        new_solution[i] = 0\n                        current_weight -= weight_lst[i]\n                else:\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Step 2: Controlled swap to balance objectives\n    # Find two items where one is in the knapsack and the other is out\n    # Swap them if it improves the balance between objectives\n    candidates_in = np.where(new_solution == 1)[0]\n    candidates_out = np.where(new_solution == 0)[0]\n\n    if len(candidates_in) > 0 and len(candidates_out) > 0:\n        # Select a random item to remove\n        item_to_remove = random.choice(candidates_in)\n        # Select a random item to add\n        item_to_add = random.choice(candidates_out)\n\n        # Check if swap is feasible\n        if (current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]) <= capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n            current_weight = current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]\n\n    return new_solution\n\n",
        "score": [
            -0.39057755609706246,
            2.295299917459488
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability inversely proportional to its objective values\n    # This prioritizes solutions that are less explored or have higher potential for improvement\n    objectives = np.array([obj for (_, obj) in archive])\n    normalized = objectives / (objectives.sum(axis=0) + 1e-10)  # Avoid division by zero\n    weights = 1 / (normalized.sum(axis=1) + 1e-10)  # Higher weights for less dominant solutions\n    weights = weights / weights.sum()  # Normalize to probabilities\n    base_idx = np.random.choice(len(archive), p=weights)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly select a subset of items to flip (value-based)\n    # 2. Perform a controlled swap between items to balance objectives\n\n    # Step 1: Value-based flip with probability proportional to value\n    for i in range(len(new_solution)):\n        if random.random() < 0.1:  # 10% chance to consider flipping\n            value_ratio = (value1_lst[i] + value2_lst[i]) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-10)\n            if random.random() < value_ratio:  # Higher value items more likely to flip\n                if new_solution[i] == 1:\n                    if current_weight - weight_lst[i] <= capacity:\n                        new_solution[i] = 0\n                        current_weight -= weight_lst[i]\n                else:\n                    if current_weight + weight_lst[i] <= capacity:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Step 2: Controlled swap to balance objectives\n    # Find two items where one is in the knapsack and the other is out\n    # Swap them if it improves the balance between objectives\n    candidates_in = np.where(new_solution == 1)[0]\n    candidates_out = np.where(new_solution == 0)[0]\n\n    if len(candidates_in) > 0 and len(candidates_out) > 0:\n        # Select a random item to remove\n        item_to_remove = random.choice(candidates_in)\n        # Select a random item to add\n        item_to_add = random.choice(candidates_out)\n\n        # Check if swap is feasible\n        if (current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]) <= capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n            current_weight = current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 188,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., near the Pareto front)\n    # Here, we prioritize solutions with high total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected = random.choices(archive_sorted[:3], k=1)[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Flip a random item (basic local search)\n    # 2. If feasible, consider swapping two items (diversification)\n    # 3. If not feasible, try adding items with highest marginal utility\n\n    new_solution = selected.copy()\n    items = np.where(new_solution == 1)[0]\n    not_included = np.where(new_solution == 0)[0]\n\n    # Attempt to flip a random item\n    if len(items) > 0:\n        flip_idx = random.choice(items)\n        new_solution[flip_idx] = 0\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # Attempt to swap two items if feasible\n    if len(items) >= 2:\n        i, j = random.sample(list(items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # If not feasible, try adding items with highest marginal utility\n    # Calculate marginal utility for each not-included item\n    marginal_utils = []\n    for idx in not_included:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1\n        if np.dot(temp_solution, weight_lst) <= capacity:\n            marginal_util = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n            marginal_utils.append((marginal_util, idx))\n\n    if marginal_utils:\n        marginal_utils.sort(reverse=True, key=lambda x: x[0])\n        best_idx = marginal_utils[0][1]\n        new_solution[best_idx] = 1\n        return new_solution\n\n    # If no improvement possible, return the original solution\n    return selected\n\n",
        "score": [
            -0.7629507821309937,
            0.6548876166343689
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., near the Pareto front)\n    # Here, we prioritize solutions with high total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected = random.choices(archive_sorted[:3], k=1)[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Flip a random item (basic local search)\n    # 2. If feasible, consider swapping two items (diversification)\n    # 3. If not feasible, try adding items with highest marginal utility\n\n    new_solution = selected.copy()\n    items = np.where(new_solution == 1)[0]\n    not_included = np.where(new_solution == 0)[0]\n\n    # Attempt to flip a random item\n    if len(items) > 0:\n        flip_idx = random.choice(items)\n        new_solution[flip_idx] = 0\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # Attempt to swap two items if feasible\n    if len(items) >= 2:\n        i, j = random.sample(list(items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # If not feasible, try adding items with highest marginal utility\n    # Calculate marginal utility for each not-included item\n    marginal_utils = []\n    for idx in not_included:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1\n        if np.dot(temp_solution, weight_lst) <= capacity:\n            marginal_util = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n            marginal_utils.append((marginal_util, idx))\n\n    if marginal_utils:\n        marginal_utils.sort(reverse=True, key=lambda x: x[0])\n        best_idx = marginal_utils[0][1]\n        new_solution[best_idx] = 1\n        return new_solution\n\n    # If no improvement possible, return the original solution\n    return selected\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 188,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., near the Pareto front)\n    # Here, we prioritize solutions with high total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected = random.choices(archive_sorted[:3], k=1)[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Flip a random item (basic local search)\n    # 2. If feasible, consider swapping two items (diversification)\n    # 3. If not feasible, try adding items with highest marginal utility\n\n    new_solution = selected.copy()\n    items = np.where(new_solution == 1)[0]\n    not_included = np.where(new_solution == 0)[0]\n\n    # Attempt to flip a random item\n    if len(items) > 0:\n        flip_idx = random.choice(items)\n        new_solution[flip_idx] = 0\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # Attempt to swap two items if feasible\n    if len(items) >= 2:\n        i, j = random.sample(list(items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # If not feasible, try adding items with highest marginal utility\n    # Calculate marginal utility for each not-included item\n    marginal_utils = []\n    for idx in not_included:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1\n        if np.dot(temp_solution, weight_lst) <= capacity:\n            marginal_util = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n            marginal_utils.append((marginal_util, idx))\n\n    if marginal_utils:\n        marginal_utils.sort(reverse=True, key=lambda x: x[0])\n        best_idx = marginal_utils[0][1]\n        new_solution[best_idx] = 1\n        return new_solution\n\n    # If no improvement possible, return the original solution\n    return selected\n\n",
        "score": [
            -0.7629507821309937,
            0.6548876166343689
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., near the Pareto front)\n    # Here, we prioritize solutions with high total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected = random.choices(archive_sorted[:3], k=1)[0][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Flip a random item (basic local search)\n    # 2. If feasible, consider swapping two items (diversification)\n    # 3. If not feasible, try adding items with highest marginal utility\n\n    new_solution = selected.copy()\n    items = np.where(new_solution == 1)[0]\n    not_included = np.where(new_solution == 0)[0]\n\n    # Attempt to flip a random item\n    if len(items) > 0:\n        flip_idx = random.choice(items)\n        new_solution[flip_idx] = 0\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # Attempt to swap two items if feasible\n    if len(items) >= 2:\n        i, j = random.sample(list(items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        if np.dot(new_solution, weight_lst) <= capacity:\n            return new_solution\n\n    # If not feasible, try adding items with highest marginal utility\n    # Calculate marginal utility for each not-included item\n    marginal_utils = []\n    for idx in not_included:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1\n        if np.dot(temp_solution, weight_lst) <= capacity:\n            marginal_util = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n            marginal_utils.append((marginal_util, idx))\n\n    if marginal_utils:\n        marginal_utils.sort(reverse=True, key=lambda x: x[0])\n        best_idx = marginal_utils[0][1]\n        new_solution[best_idx] = 1\n        return new_solution\n\n    # If no improvement possible, return the original solution\n    return selected\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 189,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select a candidate with high potential for improvement (e.g., not already optimal in both objectives)\n    base_solution, _ = random.choice(candidates)\n\n    # Hybrid local search strategy: combination of bit-flip and swap\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Bit-flip (flip a random bit if feasible)\n    if n_items > 1:\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Swap two items if feasible\n    if n_items > 1:\n        idx1, idx2 = random.sample(range(n_items), 2)\n        if new_solution[idx1] != new_solution[idx2]:\n            # Calculate new weights\n            current_weight = np.sum(weight_lst * new_solution)\n            weight_diff = (weight_lst[idx2] - weight_lst[idx1]) if new_solution[idx1] == 1 else (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + weight_diff <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Step 3: Add a random item if possible\n    if np.sum(weight_lst * new_solution) < capacity:\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            idx = random.choice(available_items)\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3809067677570257,
            3.8959358036518097
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select a candidate with high potential for improvement (e.g., not already optimal in both objectives)\n    base_solution, _ = random.choice(candidates)\n\n    # Hybrid local search strategy: combination of bit-flip and swap\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Bit-flip (flip a random bit if feasible)\n    if n_items > 1:\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Swap two items if feasible\n    if n_items > 1:\n        idx1, idx2 = random.sample(range(n_items), 2)\n        if new_solution[idx1] != new_solution[idx2]:\n            # Calculate new weights\n            current_weight = np.sum(weight_lst * new_solution)\n            weight_diff = (weight_lst[idx2] - weight_lst[idx1]) if new_solution[idx1] == 1 else (weight_lst[idx1] - weight_lst[idx2])\n            if current_weight + weight_diff <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Step 3: Add a random item if possible\n    if np.sum(weight_lst * new_solution) < capacity:\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            idx = random.choice(available_items)\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 190,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not on the Pareto front)\n    # Here, we prioritize solutions that are not dominated by others in the archive\n    dominated_solutions = []\n    for i, (sol, _) in enumerate(archive):\n        is_dominated = False\n        for j, (other_sol, _) in enumerate(archive):\n            if i == j:\n                continue\n            if (archive[j][1][0] >= archive[i][1][0] and archive[j][1][1] >= archive[i][1][1]) and \\\n               (archive[j][1][0] > archive[i][1][0] or archive[j][1][1] > archive[i][1][1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            dominated_solutions.append(sol)\n\n    if dominated_solutions:\n        base_solution = random.choice(dominated_solutions).copy()\n    else:\n        base_solution = random.choice(archive)[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. If feasible, apply a greedy improvement step (exploitation)\n    # 3. If not feasible, repair by removing items with lowest marginal value-to-weight ratio\n\n    # Step 1: Random flip\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Check feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Step 3: Repair by removing items with lowest marginal value-to-weight ratio\n        while total_weight > capacity:\n            # Calculate marginal value-to-weight ratio for included items\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove, solution is invalid\n            marginal_ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            worst_item = included_items[np.argmin(marginal_ratios)]\n            new_solution[worst_item] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n    else:\n        # Step 2: Greedy improvement\n        # Try to add items with highest marginal value-to-weight ratio\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            marginal_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            best_item = excluded_items[np.argmax(marginal_ratios)]\n            if total_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.38764316544689686,
            7.084159225225449
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not on the Pareto front)\n    # Here, we prioritize solutions that are not dominated by others in the archive\n    dominated_solutions = []\n    for i, (sol, _) in enumerate(archive):\n        is_dominated = False\n        for j, (other_sol, _) in enumerate(archive):\n            if i == j:\n                continue\n            if (archive[j][1][0] >= archive[i][1][0] and archive[j][1][1] >= archive[i][1][1]) and \\\n               (archive[j][1][0] > archive[i][1][0] or archive[j][1][1] > archive[i][1][1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            dominated_solutions.append(sol)\n\n    if dominated_solutions:\n        base_solution = random.choice(dominated_solutions).copy()\n    else:\n        base_solution = random.choice(archive)[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. If feasible, apply a greedy improvement step (exploitation)\n    # 3. If not feasible, repair by removing items with lowest marginal value-to-weight ratio\n\n    # Step 1: Random flip\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Check feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Step 3: Repair by removing items with lowest marginal value-to-weight ratio\n        while total_weight > capacity:\n            # Calculate marginal value-to-weight ratio for included items\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove, solution is invalid\n            marginal_ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            worst_item = included_items[np.argmin(marginal_ratios)]\n            new_solution[worst_item] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n    else:\n        # Step 2: Greedy improvement\n        # Try to add items with highest marginal value-to-weight ratio\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            marginal_ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            best_item = excluded_items[np.argmax(marginal_ratios)]\n            if total_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 191,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    # Here, we select a solution with a relatively low objective sum (could be adjusted)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the \"potential\" of each solution (e.g., based on normalized objective values)\n    normalized_objectives = np.array(archive_objectives)\n    normalized_objectives = (normalized_objectives - normalized_objectives.min(axis=0)) / (normalized_objectives.max(axis=0) - normalized_objectives.min(axis=0) + 1e-8)\n    potential_scores = normalized_objectives.sum(axis=1)\n\n    # Select the solution with the lowest potential score (most room for improvement)\n    selected_idx = np.argmin(potential_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search strategy: combination of swap and bit-flip with weight adjustment\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for swap or flip\n    candidate_indices = np.where(new_solution == 1)[0]\n    if len(candidate_indices) < 2:\n        candidate_indices = np.arange(len(weight_lst))\n\n    # Perform a swap or bit-flip with weight adjustment\n    if np.random.rand() < 0.7:  # Higher probability for swap\n        # Swap two items\n        i, j = np.random.choice(candidate_indices, size=2, replace=False)\n        if new_solution[i] == 1 and new_solution[j] == 1:\n            # Ensure swapping doesn't violate capacity\n            delta_weight = weight_lst[j] - weight_lst[i]\n            if current_weight + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # Bit-flip with weight adjustment\n        i = np.random.choice(candidate_indices)\n        if new_solution[i] == 1:\n            # Try to remove item\n            if current_weight - weight_lst[i] >= 0:\n                new_solution[i] = 0\n        else:\n            # Try to add item\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8489724936387487,
            0.8323237299919128
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    # Here, we select a solution with a relatively low objective sum (could be adjusted)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the \"potential\" of each solution (e.g., based on normalized objective values)\n    normalized_objectives = np.array(archive_objectives)\n    normalized_objectives = (normalized_objectives - normalized_objectives.min(axis=0)) / (normalized_objectives.max(axis=0) - normalized_objectives.min(axis=0) + 1e-8)\n    potential_scores = normalized_objectives.sum(axis=1)\n\n    # Select the solution with the lowest potential score (most room for improvement)\n    selected_idx = np.argmin(potential_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search strategy: combination of swap and bit-flip with weight adjustment\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for swap or flip\n    candidate_indices = np.where(new_solution == 1)[0]\n    if len(candidate_indices) < 2:\n        candidate_indices = np.arange(len(weight_lst))\n\n    # Perform a swap or bit-flip with weight adjustment\n    if np.random.rand() < 0.7:  # Higher probability for swap\n        # Swap two items\n        i, j = np.random.choice(candidate_indices, size=2, replace=False)\n        if new_solution[i] == 1 and new_solution[j] == 1:\n            # Ensure swapping doesn't violate capacity\n            delta_weight = weight_lst[j] - weight_lst[i]\n            if current_weight + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # Bit-flip with weight adjustment\n        i = np.random.choice(candidate_indices)\n        if new_solution[i] == 1:\n            # Try to remove item\n            if current_weight - weight_lst[i] >= 0:\n                new_solution[i] = 0\n        else:\n            # Try to add item\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 192,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: choose a solution with high potential for improvement\n    selected = random.choices(archive, weights=[1 / (1 + obj[0] + obj[1]) for _, obj in archive], k=1)[0][0]\n    base_solution = selected.copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flips and objective-driven swaps\n    # Step 1: Randomly flip a few items to escape local optima\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Step 2: Ensure feasibility by removing items that exceed capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with smallest marginal contribution to the highest objective\n        while current_weight > capacity:\n            # Calculate marginal contributions\n            marginal1 = value1_lst / (weight_lst + 1e-6)\n            marginal2 = value2_lst / (weight_lst + 1e-6)\n            # Prioritize items that are in the solution and have high marginal contribution\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) == 0:\n                break\n            # Select item with highest combined marginal contribution\n            best_idx = candidates[np.argmax(marginal1[candidates] + marginal2[candidates])]\n            new_solution[best_idx] = 0\n            current_weight -= weight_lst[best_idx]\n\n    # Step 3: Objective-driven swap to improve both objectives\n    # Select two items: one in the solution and one out\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Select item to remove (highest marginal contribution)\n        remove_idx = in_items[np.argmax(value1_lst[in_items] + value2_lst[in_items])]\n        # Select item to add (highest marginal contribution within capacity)\n        add_candidates = [i for i in out_items if weight_lst[i] <= (capacity - current_weight + weight_lst[remove_idx])]\n        if add_candidates:\n            add_idx = add_candidates[np.argmax(value1_lst[add_candidates] + value2_lst[add_candidates])]\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3200260784334035,
            1.8267977237701416
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: choose a solution with high potential for improvement\n    selected = random.choices(archive, weights=[1 / (1 + obj[0] + obj[1]) for _, obj in archive], k=1)[0][0]\n    base_solution = selected.copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flips and objective-driven swaps\n    # Step 1: Randomly flip a few items to escape local optima\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Step 2: Ensure feasibility by removing items that exceed capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with smallest marginal contribution to the highest objective\n        while current_weight > capacity:\n            # Calculate marginal contributions\n            marginal1 = value1_lst / (weight_lst + 1e-6)\n            marginal2 = value2_lst / (weight_lst + 1e-6)\n            # Prioritize items that are in the solution and have high marginal contribution\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) == 0:\n                break\n            # Select item with highest combined marginal contribution\n            best_idx = candidates[np.argmax(marginal1[candidates] + marginal2[candidates])]\n            new_solution[best_idx] = 0\n            current_weight -= weight_lst[best_idx]\n\n    # Step 3: Objective-driven swap to improve both objectives\n    # Select two items: one in the solution and one out\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Select item to remove (highest marginal contribution)\n        remove_idx = in_items[np.argmax(value1_lst[in_items] + value2_lst[in_items])]\n        # Select item to add (highest marginal contribution within capacity)\n        add_candidates = [i for i in out_items if weight_lst[i] <= (capacity - current_weight + weight_lst[remove_idx])]\n        if add_candidates:\n            add_idx = add_candidates[np.argmax(value1_lst[add_candidates] + value2_lst[add_candidates])]\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 193,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives to identify less explored regions\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1])\n        # Select a solution from the middle of the sorted list to encourage exploration\n        base_solution = archive_sorted[len(archive_sorted) // 2][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # Step 1: Randomly flip a subset of items to introduce diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and adjust if necessary\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n            # Calculate value-to-weight ratios for included items\n            ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            # Remove the item with the lowest ratio\n            remove_idx = included_items[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 3: Objective-specific flips to improve both objectives\n    # Flip items that improve both objectives when added\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 0:\n            if (total_weight + weight_lst[idx]) <= capacity:\n                # Check if adding the item improves both objectives\n                if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    # Step 4: Randomly swap items to diversify the solution\n    if len(new_solution) >= 2:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Final feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If still infeasible, revert to the base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.33846007289281355,
            4.20162358880043
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives to identify less explored regions\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1])\n        # Select a solution from the middle of the sorted list to encourage exploration\n        base_solution = archive_sorted[len(archive_sorted) // 2][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # Step 1: Randomly flip a subset of items to introduce diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and adjust if necessary\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n            # Calculate value-to-weight ratios for included items\n            ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            # Remove the item with the lowest ratio\n            remove_idx = included_items[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 3: Objective-specific flips to improve both objectives\n    # Flip items that improve both objectives when added\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 0:\n            if (total_weight + weight_lst[idx]) <= capacity:\n                # Check if adding the item improves both objectives\n                if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    # Step 4: Randomly swap items to diversify the solution\n    if len(new_solution) >= 2:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Final feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If still infeasible, revert to the base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 194,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of randomness and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for idx in excess_items:\n            new_solution[idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight <= capacity:\n                break\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate potential improvement for each remaining item\n        potential_improvements = []\n        for idx in remaining_items:\n            new_weight = total_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_value1 = base_value1 + value1_lst[idx]\n                new_value2 = base_value2 + value2_lst[idx]\n                # Simple heuristic: prioritize items that improve both objectives\n                improvement_score = (new_value1 - base_value1) + (new_value2 - base_value2)\n                potential_improvements.append((improvement_score, idx))\n\n        if potential_improvements:\n            # Select the top 2 items with highest improvement score\n            potential_improvements.sort(reverse=True, key=lambda x: x[0])\n            for score, idx in potential_improvements[:2]:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.44832847444769275,
            1.2686624825000763
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of randomness and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for idx in excess_items:\n            new_solution[idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight <= capacity:\n                break\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate potential improvement for each remaining item\n        potential_improvements = []\n        for idx in remaining_items:\n            new_weight = total_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_value1 = base_value1 + value1_lst[idx]\n                new_value2 = base_value2 + value2_lst[idx]\n                # Simple heuristic: prioritize items that improve both objectives\n                improvement_score = (new_value1 - base_value1) + (new_value2 - base_value2)\n                potential_improvements.append((improvement_score, idx))\n\n        if potential_improvements:\n            # Select the top 2 items with highest improvement score\n            potential_improvements.sort(reverse=True, key=lambda x: x[0])\n            for score, idx in potential_improvements[:2]:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 195,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution = archive[0][0].copy()\n    selected_value1, selected_value2 = archive[0][1]\n\n    # Calculate the total weight of the selected solution\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Identify items that could be swapped (not in the solution) with high potential\n    not_in_solution = np.where(selected_solution == 0)[0]\n    in_solution = np.where(selected_solution == 1)[0]\n\n    # Calculate the \"margin\" for each item (difference in value per unit weight)\n    margin1 = value1_lst / weight_lst\n    margin2 = value2_lst / weight_lst\n\n    # Sort items by their combined margin (normalized to prioritize both objectives)\n    combined_margin = (margin1 + margin2) / 2\n    sorted_items = np.argsort(combined_margin)[::-1]  # Descending order\n\n    # Apply a hybrid local search: prioritize high-margin swaps, then random swaps\n    new_solution = selected_solution.copy()\n\n    # First, try to add high-margin items not in the solution\n    for item in sorted_items:\n        if item in not_in_solution and (current_weight + weight_lst[item]) <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n            break  # Only one addition to maintain diversity\n\n    # Then, try to remove low-margin items in the solution\n    for item in sorted_items[::-1]:  # Reverse order to prioritize low-margin items\n        if item in in_solution:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            break  # Only one removal to maintain diversity\n\n    # If no significant changes, perform a random swap\n    if np.array_equal(new_solution, selected_solution):\n        if len(not_in_solution) > 0 and len(in_solution) > 0:\n            # Select a random item to remove and a random item to add\n            remove_item = np.random.choice(in_solution)\n            add_item = np.random.choice(not_in_solution)\n\n            # Ensure the swap is feasible\n            if (current_weight - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.852592555942367,
            5.248071253299713
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution = archive[0][0].copy()\n    selected_value1, selected_value2 = archive[0][1]\n\n    # Calculate the total weight of the selected solution\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Identify items that could be swapped (not in the solution) with high potential\n    not_in_solution = np.where(selected_solution == 0)[0]\n    in_solution = np.where(selected_solution == 1)[0]\n\n    # Calculate the \"margin\" for each item (difference in value per unit weight)\n    margin1 = value1_lst / weight_lst\n    margin2 = value2_lst / weight_lst\n\n    # Sort items by their combined margin (normalized to prioritize both objectives)\n    combined_margin = (margin1 + margin2) / 2\n    sorted_items = np.argsort(combined_margin)[::-1]  # Descending order\n\n    # Apply a hybrid local search: prioritize high-margin swaps, then random swaps\n    new_solution = selected_solution.copy()\n\n    # First, try to add high-margin items not in the solution\n    for item in sorted_items:\n        if item in not_in_solution and (current_weight + weight_lst[item]) <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n            break  # Only one addition to maintain diversity\n\n    # Then, try to remove low-margin items in the solution\n    for item in sorted_items[::-1]:  # Reverse order to prioritize low-margin items\n        if item in in_solution:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            break  # Only one removal to maintain diversity\n\n    # If no significant changes, perform a random swap\n    if np.array_equal(new_solution, selected_solution):\n        if len(not_in_solution) > 0 and len(in_solution) > 0:\n            # Select a random item to remove and a random item to add\n            remove_item = np.random.choice(in_solution)\n            add_item = np.random.choice(not_in_solution)\n\n            # Ensure the swap is feasible\n            if (current_weight - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 196,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligently select a solution with potential for improvement\n    # Prioritize solutions that are not too crowded in the objective space\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (1 + i) for i in range(len(archive))], k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: Random flip + Greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip phase: flip a random subset of items\n    flip_mask = np.random.rand(len(weight_lst)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items randomly until feasible\n        while excess > 0:\n            items_in_knapsack = np.where(new_solution == 1)[0]\n            if len(items_in_knapsack) == 0:\n                break\n            remove_idx = np.random.choice(items_in_knapsack)\n            new_solution[remove_idx] = 0\n            excess -= weight_lst[remove_idx]\n\n    # Greedy improvement phase: try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves both objectives\n            # (Simplified approximation - could be enhanced with more sophisticated criteria)\n            if (value1_lst[item] > 0 and value2_lst[item] > 0):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.5068386950340974,
            3.073499381542206
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligently select a solution with potential for improvement\n    # Prioritize solutions that are not too crowded in the objective space\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (1 + i) for i in range(len(archive))], k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: Random flip + Greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip phase: flip a random subset of items\n    flip_mask = np.random.rand(len(weight_lst)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items randomly until feasible\n        while excess > 0:\n            items_in_knapsack = np.where(new_solution == 1)[0]\n            if len(items_in_knapsack) == 0:\n                break\n            remove_idx = np.random.choice(items_in_knapsack)\n            new_solution[remove_idx] = 0\n            excess -= weight_lst[remove_idx]\n\n    # Greedy improvement phase: try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves both objectives\n            # (Simplified approximation - could be enhanced with more sophisticated criteria)\n            if (value1_lst[item] > 0 and value2_lst[item] > 0):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 197,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on a hybrid criterion (e.g., high value in one objective and moderate in the other)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Randomly perturb the solution (flip a few bits)\n    num_perturbations = min(3, len(new_solution))  # Limit the number of perturbations\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing excess weight if any\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items in a way that prioritizes those with the highest ratio of marginal contribution to weight\n        marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n        sorted_indices = np.argsort(marginal_contributions[new_solution == 1])[::-1]  # Descending order\n        for idx in sorted_indices:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    # Greedy improvement step: add items that improve both objectives without exceeding capacity\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal contributions for items not in the solution\n        marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        candidate_indices = np.where(new_solution == 0)[0]\n        candidate_contributions = marginal_contributions[candidate_indices]\n        sorted_indices = np.argsort(candidate_contributions)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            if remaining_capacity <= 0:\n                break\n            item_idx = candidate_indices[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.32513706232996414,
            1.271729737520218
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on a hybrid criterion (e.g., high value in one objective and moderate in the other)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Randomly perturb the solution (flip a few bits)\n    num_perturbations = min(3, len(new_solution))  # Limit the number of perturbations\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing excess weight if any\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items in a way that prioritizes those with the highest ratio of marginal contribution to weight\n        marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n        sorted_indices = np.argsort(marginal_contributions[new_solution == 1])[::-1]  # Descending order\n        for idx in sorted_indices:\n            if excess_weight <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n\n    # Greedy improvement step: add items that improve both objectives without exceeding capacity\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal contributions for items not in the solution\n        marginal_contributions = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        candidate_indices = np.where(new_solution == 0)[0]\n        candidate_contributions = marginal_contributions[candidate_indices]\n        sorted_indices = np.argsort(candidate_contributions)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            if remaining_capacity <= 0:\n                break\n            item_idx = candidate_indices[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 198,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on the highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_objectives.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random swaps and objective-driven flips\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random swaps (exploration)\n    for _ in range(min(3, n_items // 2)):\n        i, j = np.random.choice(n_items, size=2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Objective-driven flips (exploitation)\n    for _ in range(min(5, n_items)):\n        i = np.random.randint(0, n_items)\n        if new_solution[i] == 1:\n            # Try to remove item if it doesn't improve both objectives\n            if np.sum(value1_lst * new_solution) - value1_lst[i] > 0 and np.sum(value2_lst * new_solution) - value2_lst[i] > 0:\n                new_solution[i] = 0\n        else:\n            # Try to add item if it doesn't exceed capacity and improves at least one objective\n            if current_weight + weight_lst[i] <= capacity:\n                if value1_lst[i] > 0 or value2_lst[i] > 0:\n                    new_solution[i] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    while current_weight > capacity:\n        # Remove the item with the smallest ratio of (value1 + value2) / weight\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        worst_item = included_items[np.argmin(ratios)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.2857477575149728,
            1.5051011741161346
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on the highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_objectives.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random swaps and objective-driven flips\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random swaps (exploration)\n    for _ in range(min(3, n_items // 2)):\n        i, j = np.random.choice(n_items, size=2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Objective-driven flips (exploitation)\n    for _ in range(min(5, n_items)):\n        i = np.random.randint(0, n_items)\n        if new_solution[i] == 1:\n            # Try to remove item if it doesn't improve both objectives\n            if np.sum(value1_lst * new_solution) - value1_lst[i] > 0 and np.sum(value2_lst * new_solution) - value2_lst[i] > 0:\n                new_solution[i] = 0\n        else:\n            # Try to add item if it doesn't exceed capacity and improves at least one objective\n            if current_weight + weight_lst[i] <= capacity:\n                if value1_lst[i] > 0 or value2_lst[i] > 0:\n                    new_solution[i] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    while current_weight > capacity:\n        # Remove the item with the smallest ratio of (value1 + value2) / weight\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        worst_item = included_items[np.argmin(ratios)]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 199,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a bias towards higher total value (sum of both objectives)\n    total_values = [sum(obj) for _, obj in archive]\n    probabilities = [val / sum(total_values) for val in total_values]\n    selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high value-to-weight ratio and random flips\n    n_items = len(weight_lst)\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Flip items with highest value-to-weight ratio first (greedy part)\n    sorted_indices = np.argsort(-value_ratios)\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n\n    # Randomly flip some items to escape local optima\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        if np.dot(temp_solution, weight_lst) <= capacity:\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.7375985861522967,
            4.022941887378693
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a bias towards higher total value (sum of both objectives)\n    total_values = [sum(obj) for _, obj in archive]\n    probabilities = [val / sum(total_values) for val in total_values]\n    selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high value-to-weight ratio and random flips\n    n_items = len(weight_lst)\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Flip items with highest value-to-weight ratio first (greedy part)\n    sorted_indices = np.argsort(-value_ratios)\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n\n    # Randomly flip some items to escape local optima\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n        if np.dot(temp_solution, weight_lst) <= capacity:\n            new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 200,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst[sol == 1])\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Intelligent selection: prioritize solutions with high value-to-weight ratios\n    selected = None\n    max_ratio = -1\n    for sol in candidates:\n        total_value1 = np.sum(value1_lst[sol == 1])\n        total_value2 = np.sum(value2_lst[sol == 1])\n        total_weight = np.sum(weight_lst[sol == 1])\n        ratio = (total_value1 + total_value2) / total_weight if total_weight > 0 else 0\n        if ratio > max_ratio:\n            max_ratio = ratio\n            selected = sol\n\n    base_solution = selected.copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    for i in range(len(new_solution)):\n        if random.random() < 0.5:  # 50% chance to consider flipping\n            # Calculate value-to-weight ratio for the item\n            item_ratio = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            # If item is in solution, flip it out if ratio is low or random chance\n            if new_solution[i] == 1:\n                if (item_ratio < max_ratio * 0.8) or (random.random() < 0.2):\n                    new_solution[i] = 0\n            # If item is out, flip it in if ratio is high or random chance\n            else:\n                if (item_ratio > max_ratio * 1.2) or (random.random() < 0.2):\n                    temp_solution = new_solution.copy()\n                    temp_solution[i] = 1\n                    temp_weight = np.sum(weight_lst[temp_solution == 1])\n                    if temp_weight <= capacity:\n                        new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3914029652046664,
            2.062452495098114
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst[sol == 1])\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Intelligent selection: prioritize solutions with high value-to-weight ratios\n    selected = None\n    max_ratio = -1\n    for sol in candidates:\n        total_value1 = np.sum(value1_lst[sol == 1])\n        total_value2 = np.sum(value2_lst[sol == 1])\n        total_weight = np.sum(weight_lst[sol == 1])\n        ratio = (total_value1 + total_value2) / total_weight if total_weight > 0 else 0\n        if ratio > max_ratio:\n            max_ratio = ratio\n            selected = sol\n\n    base_solution = selected.copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    for i in range(len(new_solution)):\n        if random.random() < 0.5:  # 50% chance to consider flipping\n            # Calculate value-to-weight ratio for the item\n            item_ratio = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n            # If item is in solution, flip it out if ratio is low or random chance\n            if new_solution[i] == 1:\n                if (item_ratio < max_ratio * 0.8) or (random.random() < 0.2):\n                    new_solution[i] = 0\n            # If item is out, flip it in if ratio is high or random chance\n            else:\n                if (item_ratio > max_ratio * 1.2) or (random.random() < 0.2):\n                    temp_solution = new_solution.copy()\n                    temp_solution[i] = 1\n                    temp_weight = np.sum(weight_lst[temp_solution == 1])\n                    if temp_weight <= capacity:\n                        new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 201,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those that are not too crowded in the objective space\n    # This helps in exploring less-explored regions\n    def selection_probability(solution):\n        # Simple crowding distance approximation based on the number of items (higher diversity)\n        return len(np.where(solution[0] == 1)[0])\n\n    solutions = [sol_obj[0] for sol_obj in archive]\n    weights = [selection_probability(sol) for sol in solutions]\n    weights = np.array(weights) / sum(weights) if sum(weights) > 0 else np.ones(len(solutions)) / len(solutions)\n    base_solution = random.choices(solutions, weights=weights, k=1)[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: Random item swaps followed by greedy improvement\n    for _ in range(3):  # Number of swap attempts\n        # Randomly select two items to swap\n        i, j = random.sample(range(n_items), 2)\n\n        # Check if swapping improves at least one objective\n        current_value1 = np.dot(new_solution, value1_lst)\n        current_value2 = np.dot(new_solution, value2_lst)\n        current_weight = np.dot(new_solution, weight_lst)\n\n        # Swap items i and j\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n        temp_weight = np.dot(temp_solution, weight_lst)\n\n        if temp_weight <= capacity:\n            # If feasible, accept the swap\n            new_solution = temp_solution\n        else:\n            # If not feasible, try to remove one of the items to make it feasible\n            if new_solution[i] == 1:\n                temp_solution[i] = 0\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n            elif new_solution[j] == 1:\n                temp_solution[j] = 0\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n\n    # Greedy improvement step: Add items that improve the most in either objective\n    for _ in range(2):  # Number of greedy improvement steps\n        # Calculate marginal gains for each item not in the solution\n        marginal_value1 = value1_lst - np.dot(new_solution, value1_lst * value1_lst) / (np.dot(new_solution, value1_lst) + 1e-10)\n        marginal_value2 = value2_lst - np.dot(new_solution, value2_lst * value2_lst) / (np.dot(new_solution, value2_lst) + 1e-10)\n        marginal_weight = weight_lst\n\n        # Find items that can be added without exceeding capacity\n        feasible_items = np.where((new_solution == 0) & (marginal_weight <= capacity - np.dot(new_solution, weight_lst)))[0]\n\n        if len(feasible_items) > 0:\n            # Select the item with the highest marginal gain in either objective\n            gains = marginal_value1 + marginal_value2\n            best_item = feasible_items[np.argmax(gains[feasible_items])]\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.21669870427807034,
            10.002706736326218
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those that are not too crowded in the objective space\n    # This helps in exploring less-explored regions\n    def selection_probability(solution):\n        # Simple crowding distance approximation based on the number of items (higher diversity)\n        return len(np.where(solution[0] == 1)[0])\n\n    solutions = [sol_obj[0] for sol_obj in archive]\n    weights = [selection_probability(sol) for sol in solutions]\n    weights = np.array(weights) / sum(weights) if sum(weights) > 0 else np.ones(len(solutions)) / len(solutions)\n    base_solution = random.choices(solutions, weights=weights, k=1)[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search: Random item swaps followed by greedy improvement\n    for _ in range(3):  # Number of swap attempts\n        # Randomly select two items to swap\n        i, j = random.sample(range(n_items), 2)\n\n        # Check if swapping improves at least one objective\n        current_value1 = np.dot(new_solution, value1_lst)\n        current_value2 = np.dot(new_solution, value2_lst)\n        current_weight = np.dot(new_solution, weight_lst)\n\n        # Swap items i and j\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n        temp_weight = np.dot(temp_solution, weight_lst)\n\n        if temp_weight <= capacity:\n            # If feasible, accept the swap\n            new_solution = temp_solution\n        else:\n            # If not feasible, try to remove one of the items to make it feasible\n            if new_solution[i] == 1:\n                temp_solution[i] = 0\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n            elif new_solution[j] == 1:\n                temp_solution[j] = 0\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n\n    # Greedy improvement step: Add items that improve the most in either objective\n    for _ in range(2):  # Number of greedy improvement steps\n        # Calculate marginal gains for each item not in the solution\n        marginal_value1 = value1_lst - np.dot(new_solution, value1_lst * value1_lst) / (np.dot(new_solution, value1_lst) + 1e-10)\n        marginal_value2 = value2_lst - np.dot(new_solution, value2_lst * value2_lst) / (np.dot(new_solution, value2_lst) + 1e-10)\n        marginal_weight = weight_lst\n\n        # Find items that can be added without exceeding capacity\n        feasible_items = np.where((new_solution == 0) & (marginal_weight <= capacity - np.dot(new_solution, weight_lst)))[0]\n\n        if len(feasible_items) > 0:\n            # Select the item with the highest marginal gain in either objective\n            gains = marginal_value1 + marginal_value2\n            best_item = feasible_items[np.argmax(gains[feasible_items])]\n            new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 202,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        potential = (capacity - total_weight) / capacity  # Higher potential if closer to capacity\n        candidates.append((sol, potential))\n\n    # Sort by potential and select top 20% for random selection\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 5)]\n    base_solution = random.choice(top_candidates)[0].copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # 1. Random flip of a small subset of items (1-3 items)\n    flip_indices = random.sample(range(len(new_solution)), random.randint(1, 3))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedy improvement for one objective while maintaining feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - current_weight\n\n    # Try to add items that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and weight_lst[i] <= available_weight:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            available_weight = capacity - current_weight\n\n    # 3. Randomly remove items if over capacity\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        remove_indices = np.where(new_solution == 1)[0]\n        np.random.shuffle(remove_indices)\n        for idx in remove_indices:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.376956980998792,
            1.6915287375450134
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        potential = (capacity - total_weight) / capacity  # Higher potential if closer to capacity\n        candidates.append((sol, potential))\n\n    # Sort by potential and select top 20% for random selection\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 5)]\n    base_solution = random.choice(top_candidates)[0].copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # 1. Random flip of a small subset of items (1-3 items)\n    flip_indices = random.sample(range(len(new_solution)), random.randint(1, 3))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedy improvement for one objective while maintaining feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - current_weight\n\n    # Try to add items that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and weight_lst[i] <= available_weight:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n            available_weight = capacity - current_weight\n\n    # 3. Randomly remove items if over capacity\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        remove_indices = np.where(new_solution == 1)[0]\n        np.random.shuffle(remove_indices)\n        for idx in remove_indices:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 203,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions that are not too crowded and have high potential for improvement\n    # Here, we randomly select a solution but with a bias towards those with higher values\n    # This is a simple but effective way to introduce diversity\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n\n    # Step 2: Generate a neighbor solution using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Strategy 1: Flip a random item (standard local search)\n    if random.random() < 0.5:\n        flip_idx = random.randint(0, n_items - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        current_weight = np.sum(weight_lst * new_solution)\n\n        # If the flip makes the solution infeasible, undo it\n        if current_weight > capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Strategy 2: Swap two items (more aggressive local search)\n    else:\n        # Select two distinct items to swap\n        idx1, idx2 = random.sample(range(n_items), 2)\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n        current_weight = np.sum(weight_lst * new_solution)\n\n        # If the swap makes the solution infeasible, undo it\n        if current_weight > capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Strategy 3: Add a new item if possible (expansion)\n    if random.random() < 0.3:\n        # Find items not in the current solution\n        zero_indices = np.where(new_solution == 0)[0]\n        if len(zero_indices) > 0:\n            candidate_idx = random.choice(zero_indices)\n            if np.sum(weight_lst * new_solution) + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n\n    # Strategy 4: Remove an item if the solution is over-capacity (repair)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Find items to remove until the solution is feasible\n        one_indices = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(one_indices) > 0:\n            remove_idx = random.choice(one_indices)\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n            one_indices = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.3436190799561255,
            2.147906333208084
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions that are not too crowded and have high potential for improvement\n    # Here, we randomly select a solution but with a bias towards those with higher values\n    # This is a simple but effective way to introduce diversity\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n\n    # Step 2: Generate a neighbor solution using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Strategy 1: Flip a random item (standard local search)\n    if random.random() < 0.5:\n        flip_idx = random.randint(0, n_items - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        current_weight = np.sum(weight_lst * new_solution)\n\n        # If the flip makes the solution infeasible, undo it\n        if current_weight > capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Strategy 2: Swap two items (more aggressive local search)\n    else:\n        # Select two distinct items to swap\n        idx1, idx2 = random.sample(range(n_items), 2)\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n        current_weight = np.sum(weight_lst * new_solution)\n\n        # If the swap makes the solution infeasible, undo it\n        if current_weight > capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Strategy 3: Add a new item if possible (expansion)\n    if random.random() < 0.3:\n        # Find items not in the current solution\n        zero_indices = np.where(new_solution == 0)[0]\n        if len(zero_indices) > 0:\n            candidate_idx = random.choice(zero_indices)\n            if np.sum(weight_lst * new_solution) + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n\n    # Strategy 4: Remove an item if the solution is over-capacity (repair)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Find items to remove until the solution is feasible\n        one_indices = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(one_indices) > 0:\n            remove_idx = random.choice(one_indices)\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n            one_indices = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 204,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(weight_lst[solution[0] == 1]) for solution in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy: combine swap and addition/removal\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap two items (if possible)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) >= 2:\n        i, j = np.random.choice(candidates, 2, replace=False)\n        if (current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Randomly add an item not in the solution (if possible)\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        i = np.random.choice(not_in_solution)\n        if (current_weight + weight_lst[i] <= capacity):\n            new_solution[i] = 1\n\n    # Step 3: Randomly remove an item from the solution (if possible)\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        i = np.random.choice(in_solution)\n        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8746836596144114,
            1.840759515762329
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(weight_lst[solution[0] == 1]) for solution in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy: combine swap and addition/removal\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap two items (if possible)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) >= 2:\n        i, j = np.random.choice(candidates, 2, replace=False)\n        if (current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Randomly add an item not in the solution (if possible)\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        i = np.random.choice(not_in_solution)\n        if (current_weight + weight_lst[i] <= capacity):\n            new_solution[i] = 1\n\n    # Step 3: Randomly remove an item from the solution (if possible)\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        i = np.random.choice(in_solution)\n        new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 205,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not on the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        # Calculate the ratio of unused capacity\n        total_weight = np.sum(weight_lst * sol)\n        unused_capacity = capacity - total_weight\n        # Calculate the potential for improvement (e.g., items not in the solution that could fit)\n        potential_items = (weight_lst <= unused_capacity) & (sol == 0)\n        potential_improvement = np.sum(value1_lst * potential_items) + np.sum(value2_lst * potential_items)\n        candidates.append((sol, potential_improvement))\n\n    # Sort candidates by potential improvement and select the top 30% with some randomness\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 3)]\n    selected_sol, _ = random.choice(top_candidates)\n\n    # Hybrid local search: flip items to improve both objectives\n    new_solution = selected_sol.copy()\n    n_items = len(new_solution)\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Flip items with high value-to-weight ratio in both objectives\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n\n    # Sort items by combined ratio (highest first)\n    sorted_indices = np.argsort(-combined_ratio)\n\n    for i in sorted_indices:\n        if new_solution[i] == 0 and (total_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n        elif new_solution[i] == 1 and (total_weight - weight_lst[i]) >= 0:\n            # Optionally flip out items with low combined ratio\n            if combined_ratio[i] < np.mean(combined_ratio[new_solution == 1]):\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    # Strategy 2: Randomly flip items to escape local optima\n    if random.random() < 0.3:  # 30% chance to perform a random flip\n        flip_indices = np.where(new_solution == 1)[0]\n        if len(flip_indices) > 0:\n            i = random.choice(flip_indices)\n            if (total_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7964504489091102,
            8.207582533359528
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not on the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        # Calculate the ratio of unused capacity\n        total_weight = np.sum(weight_lst * sol)\n        unused_capacity = capacity - total_weight\n        # Calculate the potential for improvement (e.g., items not in the solution that could fit)\n        potential_items = (weight_lst <= unused_capacity) & (sol == 0)\n        potential_improvement = np.sum(value1_lst * potential_items) + np.sum(value2_lst * potential_items)\n        candidates.append((sol, potential_improvement))\n\n    # Sort candidates by potential improvement and select the top 30% with some randomness\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 3)]\n    selected_sol, _ = random.choice(top_candidates)\n\n    # Hybrid local search: flip items to improve both objectives\n    new_solution = selected_sol.copy()\n    n_items = len(new_solution)\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Flip items with high value-to-weight ratio in both objectives\n    value1_ratio = value1_lst / weight_lst\n    value2_ratio = value2_lst / weight_lst\n    combined_ratio = value1_ratio + value2_ratio\n\n    # Sort items by combined ratio (highest first)\n    sorted_indices = np.argsort(-combined_ratio)\n\n    for i in sorted_indices:\n        if new_solution[i] == 0 and (total_weight + weight_lst[i]) <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n        elif new_solution[i] == 1 and (total_weight - weight_lst[i]) >= 0:\n            # Optionally flip out items with low combined ratio\n            if combined_ratio[i] < np.mean(combined_ratio[new_solution == 1]):\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    # Strategy 2: Randomly flip items to escape local optima\n    if random.random() < 0.3:  # 30% chance to perform a random flip\n        flip_indices = np.where(new_solution == 1)[0]\n        if len(flip_indices) > 0:\n            i = random.choice(flip_indices)\n            if (total_weight - weight_lst[i]) >= 0:\n                new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 206,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We select solutions that are not dominated and have potential for improvement\n    # Here we use a simple approach: select a random solution with weight < capacity\n    # In practice, you might want a more sophisticated selection strategy\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate a neighbor solution using a hybrid local search operator\n    new_solution = base_solution.copy()\n\n    # Novel local search operator: Multi-objective flip with weight balancing\n    # We consider flipping items that have high value/weight ratios for both objectives\n    # We also consider the current load of the knapsack to make smarter flips\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios using a weight balancing factor (0.5 gives equal importance)\n    combined_ratio = 0.5 * ratio1 + 0.5 * ratio2\n\n    # Sort items by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Try flipping items in order of their combined ratio\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = temp_weight\n                # Check if this flip improves both objectives\n                new_val1 = base_val1 - value1_lst[idx]\n                new_val2 = base_val2 - value2_lst[idx]\n                # If it doesn't improve, flip back\n                if new_val1 <= base_val1 and new_val2 <= base_val2:\n                    new_solution[idx] = 1\n                    current_weight = temp_weight + weight_lst[idx]\n        else:\n            # Try adding the item\n            temp_weight = current_weight + weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = temp_weight\n                # Check if this flip improves both objectives\n                new_val1 = base_val1 + value1_lst[idx]\n                new_val2 = base_val2 + value2_lst[idx]\n                # If it doesn't improve, flip back\n                if new_val1 <= base_val1 and new_val2 <= base_val2:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight - weight_lst[idx]\n\n    # If no improvement was found, perform a random flip among feasible items\n    if np.array_equal(new_solution, base_solution):\n        feasible_indices = np.where((base_solution == 1) |\n                                  ((current_weight + weight_lst) <= capacity))[0]\n        if len(feasible_indices) > 0:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8681062542560792,
            1.229336142539978
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We select solutions that are not dominated and have potential for improvement\n    # Here we use a simple approach: select a random solution with weight < capacity\n    # In practice, you might want a more sophisticated selection strategy\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate a neighbor solution using a hybrid local search operator\n    new_solution = base_solution.copy()\n\n    # Novel local search operator: Multi-objective flip with weight balancing\n    # We consider flipping items that have high value/weight ratios for both objectives\n    # We also consider the current load of the knapsack to make smarter flips\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios using a weight balancing factor (0.5 gives equal importance)\n    combined_ratio = 0.5 * ratio1 + 0.5 * ratio2\n\n    # Sort items by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Try flipping items in order of their combined ratio\n    for idx in sorted_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = temp_weight\n                # Check if this flip improves both objectives\n                new_val1 = base_val1 - value1_lst[idx]\n                new_val2 = base_val2 - value2_lst[idx]\n                # If it doesn't improve, flip back\n                if new_val1 <= base_val1 and new_val2 <= base_val2:\n                    new_solution[idx] = 1\n                    current_weight = temp_weight + weight_lst[idx]\n        else:\n            # Try adding the item\n            temp_weight = current_weight + weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = temp_weight\n                # Check if this flip improves both objectives\n                new_val1 = base_val1 + value1_lst[idx]\n                new_val2 = base_val2 + value2_lst[idx]\n                # If it doesn't improve, flip back\n                if new_val1 <= base_val1 and new_val2 <= base_val2:\n                    new_solution[idx] = 0\n                    current_weight = temp_weight - weight_lst[idx]\n\n    # If no improvement was found, perform a random flip among feasible items\n    if np.array_equal(new_solution, base_solution):\n        feasible_indices = np.where((base_solution == 1) |\n                                  ((current_weight + weight_lst) <= capacity))[0]\n        if len(feasible_indices) > 0:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 207,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values for further exploration\n    candidates = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(3, len(candidates) - 1)  # Select from top 3 candidates\n    base_solution, _ = candidates[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items that can be flipped (0 to 1 or 1 to 0) while maintaining feasibility\n    # For items not in the solution, prioritize those with high value-to-weight ratio\n    not_in_solution = np.where(new_solution == 0)[0]\n    in_solution = np.where(new_solution == 1)[0]\n\n    # Calculate value-to-weight ratios for not-in-solution items\n    if len(not_in_solution) > 0:\n        v1_ratios = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n        v2_ratios = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n        combined_ratios = v1_ratios + v2_ratios  # Simple combination, can be adjusted\n\n        # Select top 20% of items with highest combined ratio that can be added without exceeding capacity\n        top_items = not_in_solution[np.argsort(combined_ratios)[-max(1, len(not_in_solution) // 5):]]\n        feasible_top_items = [item for item in top_items if weight_lst[item] <= remaining_capacity]\n\n        if feasible_top_items:\n            # Randomly select one of the top feasible items to add\n            item_to_add = random.choice(feasible_top_items)\n            new_solution[item_to_add] = 1\n            remaining_capacity -= weight_lst[item_to_add]\n\n    # Randomly flip items currently in the solution to explore other regions\n    if len(in_solution) > 0:\n        # Randomly select a subset of items to flip (up to 3)\n        flip_candidates = random.sample(list(in_solution), min(3, len(in_solution)))\n        for item in flip_candidates:\n            if random.random() < 0.5:  # 50% chance to flip\n                new_solution[item] = 0\n                remaining_capacity += weight_lst[item]\n\n    # Ensure feasibility by removing items if necessary\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items with lowest combined value-to-weight ratio until feasible\n        while excess_weight > 0:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            v1_ratios = value1_lst[in_solution] / weight_lst[in_solution]\n            v2_ratios = value2_lst[in_solution] / weight_lst[in_solution]\n            combined_ratios = v1_ratios + v2_ratios\n            item_to_remove = in_solution[np.argmin(combined_ratios)]\n            new_solution[item_to_remove] = 0\n            excess_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.8484009668584034,
            0.9450075924396515
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high objective values for further exploration\n    candidates = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(3, len(candidates) - 1)  # Select from top 3 candidates\n    base_solution, _ = candidates[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items that can be flipped (0 to 1 or 1 to 0) while maintaining feasibility\n    # For items not in the solution, prioritize those with high value-to-weight ratio\n    not_in_solution = np.where(new_solution == 0)[0]\n    in_solution = np.where(new_solution == 1)[0]\n\n    # Calculate value-to-weight ratios for not-in-solution items\n    if len(not_in_solution) > 0:\n        v1_ratios = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n        v2_ratios = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n        combined_ratios = v1_ratios + v2_ratios  # Simple combination, can be adjusted\n\n        # Select top 20% of items with highest combined ratio that can be added without exceeding capacity\n        top_items = not_in_solution[np.argsort(combined_ratios)[-max(1, len(not_in_solution) // 5):]]\n        feasible_top_items = [item for item in top_items if weight_lst[item] <= remaining_capacity]\n\n        if feasible_top_items:\n            # Randomly select one of the top feasible items to add\n            item_to_add = random.choice(feasible_top_items)\n            new_solution[item_to_add] = 1\n            remaining_capacity -= weight_lst[item_to_add]\n\n    # Randomly flip items currently in the solution to explore other regions\n    if len(in_solution) > 0:\n        # Randomly select a subset of items to flip (up to 3)\n        flip_candidates = random.sample(list(in_solution), min(3, len(in_solution)))\n        for item in flip_candidates:\n            if random.random() < 0.5:  # 50% chance to flip\n                new_solution[item] = 0\n                remaining_capacity += weight_lst[item]\n\n    # Ensure feasibility by removing items if necessary\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Remove items with lowest combined value-to-weight ratio until feasible\n        while excess_weight > 0:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            v1_ratios = value1_lst[in_solution] / weight_lst[in_solution]\n            v2_ratios = value2_lst[in_solution] / weight_lst[in_solution]\n            combined_ratios = v1_ratios + v2_ratios\n            item_to_remove = in_solution[np.argmin(combined_ratios)]\n            new_solution[item_to_remove] = 0\n            excess_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 208,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly biased towards high-value solutions)\n    weights = [np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    values1 = [sol[1][0] for sol in archive]\n    values2 = [sol[1][1] for sol in archive]\n\n    # Normalize values for selection probability\n    norm_values1 = np.array(values1) / max(values1) if max(values1) > 0 else np.ones(len(values1))\n    norm_values2 = np.array(values2) / max(values2) if max(values2) > 0 else np.ones(len(values2))\n    combined_scores = norm_values1 + norm_values2\n\n    # Select a solution with probability proportional to its combined normalized score\n    selected_idx = random.choices(range(len(archive)), weights=combined_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with size based on solution density)\n    density = np.sum(base_solution) / len(base_solution)\n    flip_size = max(1, int(density * len(base_solution) * 0.3))  # Flip 30% of the current items\n    flip_indices = random.sample(range(len(base_solution)), flip_size)\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Remove item if it doesn't violate capacity\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Add item if it doesn't violate capacity\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: Add high-value items not currently in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Sort remaining items by combined value/weight ratio\n        value_ratios = (value1_lst[remaining_items] + value2_lst[remaining_items]) / weight_lst[remaining_items]\n        sorted_items = remaining_items[np.argsort(value_ratios)[::-1]]\n\n        # Try to add up to 3 best items that fit\n        for item in sorted_items[:3]:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n            else:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.3844940284207118,
            2.3578028976917267
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly biased towards high-value solutions)\n    weights = [np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    values1 = [sol[1][0] for sol in archive]\n    values2 = [sol[1][1] for sol in archive]\n\n    # Normalize values for selection probability\n    norm_values1 = np.array(values1) / max(values1) if max(values1) > 0 else np.ones(len(values1))\n    norm_values2 = np.array(values2) / max(values2) if max(values2) > 0 else np.ones(len(values2))\n    combined_scores = norm_values1 + norm_values2\n\n    # Select a solution with probability proportional to its combined normalized score\n    selected_idx = random.choices(range(len(archive)), weights=combined_scores, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with size based on solution density)\n    density = np.sum(base_solution) / len(base_solution)\n    flip_size = max(1, int(density * len(base_solution) * 0.3))  # Flip 30% of the current items\n    flip_indices = random.sample(range(len(base_solution)), flip_size)\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Remove item if it doesn't violate capacity\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Add item if it doesn't violate capacity\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: Add high-value items not currently in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Sort remaining items by combined value/weight ratio\n        value_ratios = (value1_lst[remaining_items] + value2_lst[remaining_items]) / weight_lst[remaining_items]\n        sorted_items = remaining_items[np.argsort(value_ratios)[::-1]]\n\n        # Try to add up to 3 best items that fit\n        for item in sorted_items[:3]:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n            else:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 209,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high marginal improvement potential\n    # Calculate marginal improvement potential for each solution\n    potentials = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate potential improvement by considering items not in the solution\n        potential_improvement = 0\n        for i in range(len(sol)):\n            if sol[i] == 0 and weight_lst[i] <= remaining_capacity:\n                potential_improvement += (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n\n        potentials.append(potential_improvement)\n\n    # Select solutions with top 30% potential\n    top_indices = np.argsort(potentials)[-max(1, len(potentials) // 3):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios for all items\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Identify candidate items for swap\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Sort candidates by value ratio (descending)\n    in_items_sorted = sorted(in_items, key=lambda x: -value_ratios[x])\n    out_items_sorted = sorted(out_items, key=lambda x: -value_ratios[x])\n\n    # Try to swap high-value items in with low-value items out\n    for in_item in in_items_sorted:\n        for out_item in out_items_sorted:\n            delta_weight = weight_lst[out_item] - weight_lst[in_item]\n            if current_weight + delta_weight <= capacity:\n                # Perform the swap\n                new_solution[in_item] = 0\n                new_solution[out_item] = 1\n                current_weight += delta_weight\n                break  # Only perform one swap per iteration\n\n    # If no swap was made, try to add a high-value item if possible\n    if np.array_equal(new_solution, base_solution):\n        for item in out_items_sorted:\n            if weight_lst[item] <= capacity - current_weight:\n                new_solution[item] = 1\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.8230617297140579,
            8.4361871778965
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high marginal improvement potential\n    # Calculate marginal improvement potential for each solution\n    potentials = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate potential improvement by considering items not in the solution\n        potential_improvement = 0\n        for i in range(len(sol)):\n            if sol[i] == 0 and weight_lst[i] <= remaining_capacity:\n                potential_improvement += (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n\n        potentials.append(potential_improvement)\n\n    # Select solutions with top 30% potential\n    top_indices = np.argsort(potentials)[-max(1, len(potentials) // 3):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate value-to-weight ratios for all items\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Identify candidate items for swap\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Sort candidates by value ratio (descending)\n    in_items_sorted = sorted(in_items, key=lambda x: -value_ratios[x])\n    out_items_sorted = sorted(out_items, key=lambda x: -value_ratios[x])\n\n    # Try to swap high-value items in with low-value items out\n    for in_item in in_items_sorted:\n        for out_item in out_items_sorted:\n            delta_weight = weight_lst[out_item] - weight_lst[in_item]\n            if current_weight + delta_weight <= capacity:\n                # Perform the swap\n                new_solution[in_item] = 0\n                new_solution[out_item] = 1\n                current_weight += delta_weight\n                break  # Only perform one swap per iteration\n\n    # If no swap was made, try to add a high-value item if possible\n    if np.array_equal(new_solution, base_solution):\n        for item in out_items_sorted:\n            if weight_lst[item] <= capacity - current_weight:\n                new_solution[item] = 1\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 210,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a base solution: prioritize solutions with higher total value sums\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_k = min(5, len(archive_sorted))  # Consider top 5 solutions or all if archive is small\n    selected_idx = random.randint(0, top_k - 1)\n    base_solution, _ = archive_sorted[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (standard perturbation)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Biased selection: flip items that have high marginal contribution to either objective\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal contributions with a bias towards the objective with lower current value\n    current_value1, current_value2 = archive_sorted[selected_idx][1]\n    bias1 = 1.0 if current_value1 < current_value2 else 0.5\n    bias2 = 1.0 if current_value2 < current_value1 else 0.5\n    combined_marginal = bias1 * marginal1 + bias2 * marginal2\n\n    # Select top items by combined marginal contribution\n    top_items = np.argsort(combined_marginal)[-5:]  # Consider top 5 items\n    for idx in top_items:\n        if random.random() < 0.7:  # 70% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break  # No items left to remove\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.45705158635766874,
            0.8917843103408813
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a base solution: prioritize solutions with higher total value sums\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    top_k = min(5, len(archive_sorted))  # Consider top 5 solutions or all if archive is small\n    selected_idx = random.randint(0, top_k - 1)\n    base_solution, _ = archive_sorted[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (standard perturbation)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Biased selection: flip items that have high marginal contribution to either objective\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal contributions with a bias towards the objective with lower current value\n    current_value1, current_value2 = archive_sorted[selected_idx][1]\n    bias1 = 1.0 if current_value1 < current_value2 else 0.5\n    bias2 = 1.0 if current_value2 < current_value1 else 0.5\n    combined_marginal = bias1 * marginal1 + bias2 * marginal2\n\n    # Select top items by combined marginal contribution\n    top_items = np.argsort(combined_marginal)[-5:]  # Consider top 5 items\n    for idx in top_items:\n        if random.random() < 0.7:  # 70% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break  # No items left to remove\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 211,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a random solution from the archive with preference for those near the Pareto front\n    if len(archive) > 1:\n        # Sort solutions by a combined score (higher value1 + value2)\n        sorted_archive = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 20% or at least 1 solution\n        top_k = max(1, len(archive) // 5)\n        selected_solutions = sorted_archive[:top_k]\n        base_solution, _ = random.choice(selected_solutions)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random perturbation: flip a small number of bits (1-3)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedy improvement: add items that improve at least one objective without violating capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for each item\n    marginal_value1 = value1_lst * (1 - new_solution)\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_weight = weight_lst * (1 - new_solution)\n\n    # Potential candidates: items not in solution that can be added without exceeding capacity\n    candidates = np.where((marginal_weight <= remaining_capacity) &\n                         ((marginal_value1 > 0) | (marginal_value2 > 0)))[0]\n\n    if len(candidates) > 0:\n        # Sort candidates by combined marginal gain (normalized)\n        combined_gain = marginal_value1 + marginal_value2\n        combined_gain[candidates] /= marginal_weight[candidates]  # normalize by weight\n        best_candidate = candidates[np.argmax(combined_gain[candidates])]\n        new_solution[best_candidate] = 1\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            remove_indices = np.where(new_solution)[0]\n            if len(remove_indices) == 0:\n                break\n            idx_to_remove = random.choice(remove_indices)\n            new_solution[idx_to_remove] = 0\n            excess -= weight_lst[idx_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.3198891032640754,
            1.3583606779575348
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a random solution from the archive with preference for those near the Pareto front\n    if len(archive) > 1:\n        # Sort solutions by a combined score (higher value1 + value2)\n        sorted_archive = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 20% or at least 1 solution\n        top_k = max(1, len(archive) // 5)\n        selected_solutions = sorted_archive[:top_k]\n        base_solution, _ = random.choice(selected_solutions)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random perturbation: flip a small number of bits (1-3)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedy improvement: add items that improve at least one objective without violating capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for each item\n    marginal_value1 = value1_lst * (1 - new_solution)\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_weight = weight_lst * (1 - new_solution)\n\n    # Potential candidates: items not in solution that can be added without exceeding capacity\n    candidates = np.where((marginal_weight <= remaining_capacity) &\n                         ((marginal_value1 > 0) | (marginal_value2 > 0)))[0]\n\n    if len(candidates) > 0:\n        # Sort candidates by combined marginal gain (normalized)\n        combined_gain = marginal_value1 + marginal_value2\n        combined_gain[candidates] /= marginal_weight[candidates]  # normalize by weight\n        best_candidate = candidates[np.argmax(combined_gain[candidates])]\n        new_solution[best_candidate] = 1\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            remove_indices = np.where(new_solution)[0]\n            if len(remove_indices) == 0:\n                break\n            idx_to_remove = random.choice(remove_indices)\n            new_solution[idx_to_remove] = 0\n            excess -= weight_lst[idx_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 212,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly flip a subset of items to explore the neighborhood\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        if new_solution[idx] == 1:\n            # If the item is currently included, try removing it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # If the item is currently excluded, try adding it\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Perform a greedy improvement step to maximize the sum of normalized values\n    # Normalize the values to balance both objectives\n    normalized_value1 = value1_lst / np.max(value1_lst) if np.max(value1_lst) != 0 else value1_lst\n    normalized_value2 = value2_lst / np.max(value2_lst) if np.max(value2_lst) != 0 else value2_lst\n    combined_value = normalized_value1 + normalized_value2\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 0:\n            # Try adding the item if it fits\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate the potential improvement\n                improvement = combined_value[idx]\n                # If adding the item improves the combined value, do it\n                if improvement > 0:\n                    new_solution[idx] = 1\n                    current_weight = new_weight\n        else:\n            # Try removing the item to see if it can be improved\n            new_weight = current_weight - weight_lst[idx]\n            # Calculate the potential improvement if we remove the item\n            improvement = -combined_value[idx]\n            # If removing the item improves the combined value, do it\n            if improvement > 0:\n                new_solution[idx] = 0\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.39481599104833326,
            1.5072413980960846
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly flip a subset of items to explore the neighborhood\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        # Try flipping the item\n        if new_solution[idx] == 1:\n            # If the item is currently included, try removing it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # If the item is currently excluded, try adding it\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Perform a greedy improvement step to maximize the sum of normalized values\n    # Normalize the values to balance both objectives\n    normalized_value1 = value1_lst / np.max(value1_lst) if np.max(value1_lst) != 0 else value1_lst\n    normalized_value2 = value2_lst / np.max(value2_lst) if np.max(value2_lst) != 0 else value2_lst\n    combined_value = normalized_value1 + normalized_value2\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 0:\n            # Try adding the item if it fits\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate the potential improvement\n                improvement = combined_value[idx]\n                # If adding the item improves the combined value, do it\n                if improvement > 0:\n                    new_solution[idx] = 1\n                    current_weight = new_weight\n        else:\n            # Try removing the item to see if it can be improved\n            new_weight = current_weight - weight_lst[idx]\n            # Calculate the potential improvement if we remove the item\n            improvement = -combined_value[idx]\n            # If removing the item improves the combined value, do it\n            if improvement > 0:\n                new_solution[idx] = 0\n                current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 213,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select top 30% solutions in either objective\n    sorted_archive = sorted(archive, key=lambda x: (-x[1][0], -x[1][1]))\n    top_idx = max(1, int(0.3 * len(sorted_archive)))\n    selected = random.choice(sorted_archive[:top_idx])\n    base_solution = selected[0].copy()\n\n    # Create neighbor using swap and flip operator\n    new_solution = base_solution.copy()\n\n    # Flip a random subset of items\n    flip_mask = np.random.rand(len(new_solution)) < 0.3\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Perform limited swaps (3-5 swaps)\n    num_swaps = random.randint(3, 5)\n    for _ in range(num_swaps):\n        # Find a random item to swap out\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        out_item = random.choice(in_items)\n\n        # Find a random item to swap in\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) == 0:\n            break\n\n        # Filter out items that would make the solution infeasible\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        target_weight = current_weight - weight_lst[out_item]\n\n        feasible_in_items = [i for i in out_items if target_weight + weight_lst[i] <= capacity]\n        if not feasible_in_items:\n            continue\n\n        in_item = random.choice(feasible_in_items)\n\n        # Perform the swap\n        new_solution[out_item], new_solution[in_item] = new_solution[in_item], new_solution[out_item]\n\n    # Ensure feasibility (though swaps should already handle this)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        items_to_remove = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_to_remove)\n        for item in items_to_remove:\n            if excess <= 0:\n                break\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                excess -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.39823396100529573,
            1.7440279424190521
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select top 30% solutions in either objective\n    sorted_archive = sorted(archive, key=lambda x: (-x[1][0], -x[1][1]))\n    top_idx = max(1, int(0.3 * len(sorted_archive)))\n    selected = random.choice(sorted_archive[:top_idx])\n    base_solution = selected[0].copy()\n\n    # Create neighbor using swap and flip operator\n    new_solution = base_solution.copy()\n\n    # Flip a random subset of items\n    flip_mask = np.random.rand(len(new_solution)) < 0.3\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Perform limited swaps (3-5 swaps)\n    num_swaps = random.randint(3, 5)\n    for _ in range(num_swaps):\n        # Find a random item to swap out\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        out_item = random.choice(in_items)\n\n        # Find a random item to swap in\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) == 0:\n            break\n\n        # Filter out items that would make the solution infeasible\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        target_weight = current_weight - weight_lst[out_item]\n\n        feasible_in_items = [i for i in out_items if target_weight + weight_lst[i] <= capacity]\n        if not feasible_in_items:\n            continue\n\n        in_item = random.choice(feasible_in_items)\n\n        # Perform the swap\n        new_solution[out_item], new_solution[in_item] = new_solution[in_item], new_solution[out_item]\n\n    # Ensure feasibility (though swaps should already handle this)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        items_to_remove = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_to_remove)\n        for item in items_to_remove:\n            if excess <= 0:\n                break\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                excess -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 214,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, (current_value1, current_value2) = archive[selected_idx]\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Number of local search iterations\n        # Randomly select a subset of items to consider for swap\n        candidate_items = np.where(base_solution == 1)[0]\n        if len(candidate_items) == 0:\n            candidate_items = np.arange(len(base_solution))\n\n        # Select two items to swap (one from selected, one from unselected)\n        if random.random() < 0.7:  # 70% chance to use ratio-based selection\n            # Select item to remove based on high ratio in both objectives\n            remove_candidates = np.where(base_solution == 1)[0]\n            if len(remove_candidates) > 0:\n                remove_idx = remove_candidates[np.argmax(ratio1[remove_candidates] + ratio2[remove_candidates])]\n\n                # Select item to add based on high ratio and low weight\n                add_candidates = np.where(base_solution == 0)[0]\n                if len(add_candidates) > 0:\n                    add_idx = add_candidates[np.argmax(ratio1[add_candidates] + ratio2[add_candidates])]\n\n                    # Check feasibility before swapping\n                    current_weight = np.sum(weight_lst[base_solution == 1])\n                    new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                    if new_weight <= capacity:\n                        new_solution[remove_idx], new_solution[add_idx] = 0, 1\n        else:\n            # Random swap as fallback\n            remove_idx = random.choice(np.where(base_solution == 1)[0]) if len(np.where(base_solution == 1)[0]) > 0 else None\n            add_idx = random.choice(np.where(base_solution == 0)[0]) if len(np.where(base_solution == 0)[0]) > 0 else None\n\n            if remove_idx is not None and add_idx is not None:\n                current_weight = np.sum(weight_lst[base_solution == 1])\n                new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                if new_weight <= capacity:\n                    new_solution[remove_idx], new_solution[add_idx] = 0, 1\n\n    return new_solution\n\n",
        "score": [
            -0.5126178316964191,
            2.210635393857956
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, (current_value1, current_value2) = archive[selected_idx]\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Number of local search iterations\n        # Randomly select a subset of items to consider for swap\n        candidate_items = np.where(base_solution == 1)[0]\n        if len(candidate_items) == 0:\n            candidate_items = np.arange(len(base_solution))\n\n        # Select two items to swap (one from selected, one from unselected)\n        if random.random() < 0.7:  # 70% chance to use ratio-based selection\n            # Select item to remove based on high ratio in both objectives\n            remove_candidates = np.where(base_solution == 1)[0]\n            if len(remove_candidates) > 0:\n                remove_idx = remove_candidates[np.argmax(ratio1[remove_candidates] + ratio2[remove_candidates])]\n\n                # Select item to add based on high ratio and low weight\n                add_candidates = np.where(base_solution == 0)[0]\n                if len(add_candidates) > 0:\n                    add_idx = add_candidates[np.argmax(ratio1[add_candidates] + ratio2[add_candidates])]\n\n                    # Check feasibility before swapping\n                    current_weight = np.sum(weight_lst[base_solution == 1])\n                    new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                    if new_weight <= capacity:\n                        new_solution[remove_idx], new_solution[add_idx] = 0, 1\n        else:\n            # Random swap as fallback\n            remove_idx = random.choice(np.where(base_solution == 1)[0]) if len(np.where(base_solution == 1)[0]) > 0 else None\n            add_idx = random.choice(np.where(base_solution == 0)[0]) if len(np.where(base_solution == 0)[0]) > 0 else None\n\n            if remove_idx is not None and add_idx is not None:\n                current_weight = np.sum(weight_lst[base_solution == 1])\n                new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n                if new_weight <= capacity:\n                    new_solution[remove_idx], new_solution[add_idx] = 0, 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 215,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest sum of normalized objectives as the base\n    normalized_objs = np.array([(obj[0] / np.max(value1_lst), obj[1] / np.max(value2_lst)) for _, obj in archive])\n    scores = np.sum(normalized_objs, axis=1)\n    base_idx = np.argmax(scores)\n    base_solution = archive[base_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (intensification)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Strategy 2: Add items with high marginal utility (diversification)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utility = (value1_lst + value2_lst) / weight_lst\n        candidate_items = np.where(new_solution == 0)[0]\n\n        if len(candidate_items) > 0:\n            # Sort candidates by marginal utility\n            sorted_candidates = candidate_items[np.argsort(marginal_utility[candidate_items])[::-1]]\n\n            # Add items until capacity is reached\n            for item in sorted_candidates:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n                else:\n                    break\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the lowest marginal utility\n        in_solution_items = np.where(new_solution == 1)[0]\n        if len(in_solution_items) == 0:\n            break  # No items to remove, solution is empty\n        marginal_utility = (value1_lst + value2_lst) / weight_lst\n        item_to_remove = in_solution_items[np.argmin(marginal_utility[in_solution_items])]\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3229670415843366,
            1.951579213142395
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the solution with the highest sum of normalized objectives as the base\n    normalized_objs = np.array([(obj[0] / np.max(value1_lst), obj[1] / np.max(value2_lst)) for _, obj in archive])\n    scores = np.sum(normalized_objs, axis=1)\n    base_idx = np.argmax(scores)\n    base_solution = archive[base_idx][0].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (intensification)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Strategy 2: Add items with high marginal utility (diversification)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utility = (value1_lst + value2_lst) / weight_lst\n        candidate_items = np.where(new_solution == 0)[0]\n\n        if len(candidate_items) > 0:\n            # Sort candidates by marginal utility\n            sorted_candidates = candidate_items[np.argsort(marginal_utility[candidate_items])[::-1]]\n\n            # Add items until capacity is reached\n            for item in sorted_candidates:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n                else:\n                    break\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the lowest marginal utility\n        in_solution_items = np.where(new_solution == 1)[0]\n        if len(in_solution_items) == 0:\n            break  # No items to remove, solution is empty\n        marginal_utility = (value1_lst + value2_lst) / weight_lst\n        item_to_remove = in_solution_items[np.argmin(marginal_utility[in_solution_items])]\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 216,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not fully packed and have high potential for improvement\n    # in either objective, considering their current weight and value ratios\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential_val1 = np.sum(value1_lst * (1 - sol))\n        potential_val2 = np.sum(value2_lst * (1 - sol))\n        # Score based on remaining capacity and potential improvement\n        score = (potential_val1 + potential_val2) / (capacity - current_weight + 1e-6)\n        candidates.append((score, sol))\n\n    # Sort candidates by score (descending) and select top 3\n    candidates.sort(reverse=True, key=lambda x: x[0])\n    selected = candidates[:min(3, len(candidates))]\n    if not selected:\n        selected = candidates\n\n    # Randomly select one of the top candidates\n    _, base_solution = selected[np.random.randint(len(selected))]\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (with probability based on their value/weight ratio)\n    for i in range(n_items):\n        if np.random.rand() < 0.2:  # 20% chance to consider flipping\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # If item is included, consider removing it if it's not critical\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n            else:\n                # If item is excluded, consider adding it if it fits\n                if current_weight + weight_lst[i] <= capacity:\n                    # Add with probability proportional to value/weight ratio\n                    val_ratio = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n                    if np.random.rand() < val_ratio / (np.max(value1_lst) + np.max(value2_lst) + 1e-6):\n                        new_solution[i] = 1\n\n    # Step 2: Apply a novel local search operator that considers both objectives\n    # We'll use a \"value-balanced\" swap: swap items where one improves one objective while minimally affecting the other\n    for _ in range(5):  # Limit iterations to avoid excessive computation\n        # Find items that are currently included and could be swapped\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) == 0 or len(excluded) == 0:\n            break\n\n        # Randomly select a pair of items to consider swapping\n        i = np.random.choice(included)\n        j = np.random.choice(excluded)\n\n        current_weight = np.sum(weight_lst * new_solution)\n        new_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n        if new_weight <= capacity:\n            # Calculate the change in both objectives\n            delta_val1 = value1_lst[j] - value1_lst[i]\n            delta_val2 = value2_lst[j] - value2_lst[i]\n\n            # Accept the swap if it improves at least one objective or maintains both\n            if delta_val1 > 0 or delta_val2 > 0:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4952628364446305,
            4.749484270811081
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not fully packed and have high potential for improvement\n    # in either objective, considering their current weight and value ratios\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential_val1 = np.sum(value1_lst * (1 - sol))\n        potential_val2 = np.sum(value2_lst * (1 - sol))\n        # Score based on remaining capacity and potential improvement\n        score = (potential_val1 + potential_val2) / (capacity - current_weight + 1e-6)\n        candidates.append((score, sol))\n\n    # Sort candidates by score (descending) and select top 3\n    candidates.sort(reverse=True, key=lambda x: x[0])\n    selected = candidates[:min(3, len(candidates))]\n    if not selected:\n        selected = candidates\n\n    # Randomly select one of the top candidates\n    _, base_solution = selected[np.random.randint(len(selected))]\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (with probability based on their value/weight ratio)\n    for i in range(n_items):\n        if np.random.rand() < 0.2:  # 20% chance to consider flipping\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # If item is included, consider removing it if it's not critical\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n            else:\n                # If item is excluded, consider adding it if it fits\n                if current_weight + weight_lst[i] <= capacity:\n                    # Add with probability proportional to value/weight ratio\n                    val_ratio = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n                    if np.random.rand() < val_ratio / (np.max(value1_lst) + np.max(value2_lst) + 1e-6):\n                        new_solution[i] = 1\n\n    # Step 2: Apply a novel local search operator that considers both objectives\n    # We'll use a \"value-balanced\" swap: swap items where one improves one objective while minimally affecting the other\n    for _ in range(5):  # Limit iterations to avoid excessive computation\n        # Find items that are currently included and could be swapped\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) == 0 or len(excluded) == 0:\n            break\n\n        # Randomly select a pair of items to consider swapping\n        i = np.random.choice(included)\n        j = np.random.choice(excluded)\n\n        current_weight = np.sum(weight_lst * new_solution)\n        new_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n        if new_weight <= capacity:\n            # Calculate the change in both objectives\n            delta_val1 = value1_lst[j] - value1_lst[i]\n            delta_val2 = value2_lst[j] - value2_lst[i]\n\n            # Accept the swap if it improves at least one objective or maintains both\n            if delta_val1 > 0 or delta_val2 > 0:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 217,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(len(archive_sorted) // 2, len(archive_sorted) - 1)\n    base_solution, _ = archive_sorted[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search: Random flip followed by greedy improvement\n    for _ in range(2):  # Number of flip attempts\n        # Random flip\n        flip_idx = np.random.randint(0, n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Check feasibility\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        if current_weight > capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            continue\n\n        # Greedy improvement: Add items with highest marginal profit ratio\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate marginal profit ratios for objective 1 and 2\n            marginal_ratio1 = (value1_lst - np.sum(value1_lst[new_solution == 1])) / weight_lst\n            marginal_ratio2 = (value2_lst - np.sum(value2_lst[new_solution == 1])) / weight_lst\n            combined_ratio = marginal_ratio1 + marginal_ratio2  # Balance both objectives\n\n            # Sort items by combined ratio and add feasible ones\n            sorted_indices = np.argsort(combined_ratio)[::-1]\n            for idx in sorted_indices:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7126738729447188,
            0.9136686623096466
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(len(archive_sorted) // 2, len(archive_sorted) - 1)\n    base_solution, _ = archive_sorted[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search: Random flip followed by greedy improvement\n    for _ in range(2):  # Number of flip attempts\n        # Random flip\n        flip_idx = np.random.randint(0, n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Check feasibility\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        if current_weight > capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            continue\n\n        # Greedy improvement: Add items with highest marginal profit ratio\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate marginal profit ratios for objective 1 and 2\n            marginal_ratio1 = (value1_lst - np.sum(value1_lst[new_solution == 1])) / weight_lst\n            marginal_ratio2 = (value2_lst - np.sum(value2_lst[new_solution == 1])) / weight_lst\n            combined_ratio = marginal_ratio1 + marginal_ratio2  # Balance both objectives\n\n            # Sort items by combined ratio and add feasible ones\n            sorted_indices = np.argsort(combined_ratio)[::-1]\n            for idx in sorted_indices:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 218,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (randomly weighted by objective values)\n    total_value1 = sum(obj[0] for _, obj in archive)\n    total_value2 = sum(obj[1] for _, obj in archive)\n    weights = [obj[0] / total_value1 + obj[1] / total_value2 for _, obj in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and marginal contributions\n    current_weight = np.sum(weight_lst * new_solution)\n    marginal_value1 = value1_lst * (1 - new_solution)  # Marginal value if item is added\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_weight = weight_lst * (1 - new_solution)\n\n    # Identify items that can be added without exceeding capacity\n    feasible_mask = (marginal_weight <= (capacity - current_weight)) & (new_solution == 0)\n\n    if np.any(feasible_mask):\n        # Hybrid local search: flip items with high marginal contribution to either objective\n        # Combine marginal contributions for both objectives (normalized)\n        combined_marginal = (marginal_value1 + marginal_value2) * feasible_mask\n        top_k = min(3, np.sum(feasible_mask))  # Flip up to 3 items\n        if top_k > 0:\n            top_indices = np.argpartition(combined_marginal, -top_k)[-top_k:]\n            new_solution[top_indices] = 1\n\n    # Also consider flipping items with negative marginal contribution (if they can be removed)\n    removable_mask = (new_solution == 1)\n    if np.any(removable_mask):\n        # Check if removing these items would not make the solution worse in either objective\n        for i in np.where(removable_mask)[0]:\n            if (value1_lst[i] <= 0 and value2_lst[i] <= 0) or random.random() < 0.2:  # 20% chance to flip anyway\n                new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -1.0593467041309688,
            0.752679854631424
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (randomly weighted by objective values)\n    total_value1 = sum(obj[0] for _, obj in archive)\n    total_value2 = sum(obj[1] for _, obj in archive)\n    weights = [obj[0] / total_value1 + obj[1] / total_value2 for _, obj in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and marginal contributions\n    current_weight = np.sum(weight_lst * new_solution)\n    marginal_value1 = value1_lst * (1 - new_solution)  # Marginal value if item is added\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_weight = weight_lst * (1 - new_solution)\n\n    # Identify items that can be added without exceeding capacity\n    feasible_mask = (marginal_weight <= (capacity - current_weight)) & (new_solution == 0)\n\n    if np.any(feasible_mask):\n        # Hybrid local search: flip items with high marginal contribution to either objective\n        # Combine marginal contributions for both objectives (normalized)\n        combined_marginal = (marginal_value1 + marginal_value2) * feasible_mask\n        top_k = min(3, np.sum(feasible_mask))  # Flip up to 3 items\n        if top_k > 0:\n            top_indices = np.argpartition(combined_marginal, -top_k)[-top_k:]\n            new_solution[top_indices] = 1\n\n    # Also consider flipping items with negative marginal contribution (if they can be removed)\n    removable_mask = (new_solution == 1)\n    if np.any(removable_mask):\n        # Check if removing these items would not make the solution worse in either objective\n        for i in np.where(removable_mask)[0]:\n            if (value1_lst[i] <= 0 and value2_lst[i] <= 0) or random.random() < 0.2:  # 20% chance to flip anyway\n                new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 218,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (randomly weighted by objective values)\n    total_value1 = sum(obj[0] for _, obj in archive)\n    total_value2 = sum(obj[1] for _, obj in archive)\n    weights = [obj[0] / total_value1 + obj[1] / total_value2 for _, obj in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and marginal contributions\n    current_weight = np.sum(weight_lst * new_solution)\n    marginal_value1 = value1_lst * (1 - new_solution)  # Marginal value if item is added\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_weight = weight_lst * (1 - new_solution)\n\n    # Identify items that can be added without exceeding capacity\n    feasible_mask = (marginal_weight <= (capacity - current_weight)) & (new_solution == 0)\n\n    if np.any(feasible_mask):\n        # Hybrid local search: flip items with high marginal contribution to either objective\n        # Combine marginal contributions for both objectives (normalized)\n        combined_marginal = (marginal_value1 + marginal_value2) * feasible_mask\n        top_k = min(3, np.sum(feasible_mask))  # Flip up to 3 items\n        if top_k > 0:\n            top_indices = np.argpartition(combined_marginal, -top_k)[-top_k:]\n            new_solution[top_indices] = 1\n\n    # Also consider flipping items with negative marginal contribution (if they can be removed)\n    removable_mask = (new_solution == 1)\n    if np.any(removable_mask):\n        # Check if removing these items would not make the solution worse in either objective\n        for i in np.where(removable_mask)[0]:\n            if (value1_lst[i] <= 0 and value2_lst[i] <= 0) or random.random() < 0.2:  # 20% chance to flip anyway\n                new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -1.0593467041309688,
            0.752679854631424
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (randomly weighted by objective values)\n    total_value1 = sum(obj[0] for _, obj in archive)\n    total_value2 = sum(obj[1] for _, obj in archive)\n    weights = [obj[0] / total_value1 + obj[1] / total_value2 for _, obj in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and marginal contributions\n    current_weight = np.sum(weight_lst * new_solution)\n    marginal_value1 = value1_lst * (1 - new_solution)  # Marginal value if item is added\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_weight = weight_lst * (1 - new_solution)\n\n    # Identify items that can be added without exceeding capacity\n    feasible_mask = (marginal_weight <= (capacity - current_weight)) & (new_solution == 0)\n\n    if np.any(feasible_mask):\n        # Hybrid local search: flip items with high marginal contribution to either objective\n        # Combine marginal contributions for both objectives (normalized)\n        combined_marginal = (marginal_value1 + marginal_value2) * feasible_mask\n        top_k = min(3, np.sum(feasible_mask))  # Flip up to 3 items\n        if top_k > 0:\n            top_indices = np.argpartition(combined_marginal, -top_k)[-top_k:]\n            new_solution[top_indices] = 1\n\n    # Also consider flipping items with negative marginal contribution (if they can be removed)\n    removable_mask = (new_solution == 1)\n    if np.any(removable_mask):\n        # Check if removing these items would not make the solution worse in either objective\n        for i in np.where(removable_mask)[0]:\n            if (value1_lst[i] <= 0 and value2_lst[i] <= 0) or random.random() < 0.2:  # 20% chance to flip anyway\n                new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 219,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution (lowest crowding distance or least dominated)\n    def crowding_distance(sol_idx):\n        left = archive[sol_idx - 1][1] if sol_idx > 0 else None\n        right = archive[sol_idx + 1][1] if sol_idx < len(archive) - 1 else None\n        if left is None or right is None:\n            return float('inf')\n        dist1 = abs(archive[sol_idx][1][0] - left[0]) + abs(archive[sol_idx][1][0] - right[0])\n        dist2 = abs(archive[sol_idx][1][1] - left[1]) + abs(archive[sol_idx][1][1] - right[1])\n        return dist1 + dist2\n\n    # Sort solutions by crowding distance (ascending) and pick the one with smallest distance\n    sorted_indices = sorted(range(len(archive)), key=lambda i: crowding_distance(i))\n    base_idx = sorted_indices[0]\n    base_solution = archive[base_idx][0].copy()\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Diversification: Randomly flip a subset of items\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each bit\n    for i in np.where(flip_mask)[0]:\n        if new_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Intensification: Greedily add items with best marginal gain in either objective\n    # Calculate marginal gains for each item not in the solution\n    not_included = np.where(new_solution == 0)[0]\n    marginal_gain1 = value1_lst[not_included] / weight_lst[not_included]\n    marginal_gain2 = value2_lst[not_included] / weight_lst[not_included]\n\n    # Combine gains and sort by combined score (alternating objectives for balance)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_items = not_included[np.argsort(-combined_gain)]\n\n    for i in sorted_items:\n        if current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.35706268496774396,
            1.1608339250087738
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution (lowest crowding distance or least dominated)\n    def crowding_distance(sol_idx):\n        left = archive[sol_idx - 1][1] if sol_idx > 0 else None\n        right = archive[sol_idx + 1][1] if sol_idx < len(archive) - 1 else None\n        if left is None or right is None:\n            return float('inf')\n        dist1 = abs(archive[sol_idx][1][0] - left[0]) + abs(archive[sol_idx][1][0] - right[0])\n        dist2 = abs(archive[sol_idx][1][1] - left[1]) + abs(archive[sol_idx][1][1] - right[1])\n        return dist1 + dist2\n\n    # Sort solutions by crowding distance (ascending) and pick the one with smallest distance\n    sorted_indices = sorted(range(len(archive)), key=lambda i: crowding_distance(i))\n    base_idx = sorted_indices[0]\n    base_solution = archive[base_idx][0].copy()\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Diversification: Randomly flip a subset of items\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each bit\n    for i in np.where(flip_mask)[0]:\n        if new_solution[i] == 1:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n        else:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Intensification: Greedily add items with best marginal gain in either objective\n    # Calculate marginal gains for each item not in the solution\n    not_included = np.where(new_solution == 0)[0]\n    marginal_gain1 = value1_lst[not_included] / weight_lst[not_included]\n    marginal_gain2 = value2_lst[not_included] / weight_lst[not_included]\n\n    # Combine gains and sort by combined score (alternating objectives for balance)\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_items = not_included[np.argsort(-combined_gain)]\n\n    for i in sorted_items:\n        if current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 220,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        # Compute the \"distance\" to the Pareto front (simplified heuristic)\n        # Here, we consider solutions that are not too close to the extreme points\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        # If no candidates, pick a random solution and try to improve it\n        sol, _ = random.choice(archive)\n        candidates.append((sol, (0, 0)))\n\n    # Select the solution with the highest potential for improvement\n    # (Here, we use a simple heuristic: pick the solution with the lowest total weight)\n    selected_sol, _ = min(candidates, key=lambda x: np.sum(x[0] * weight_lst))\n\n    # Generate a neighbor solution using a hybrid local search strategy\n    new_solution = selected_sol.copy()\n    n_items = len(new_solution)\n\n    # Strategy 1: Randomly flip a subset of items (like mutation in genetic algorithms)\n    for _ in range(random.randint(1, min(3, n_items))):\n        idx = random.randint(0, n_items - 1)\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Strategy 2: Try to add an item if possible (greedy improvement)\n    for idx in np.where(new_solution == 0)[0]:\n        if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            break\n\n    # Strategy 3: Try to remove an item if it doesn't hurt the objectives too much\n    for idx in np.where(new_solution == 1)[0]:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 0\n        if np.sum(temp_solution * weight_lst) <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.617735097691453,
            7.101117342710495
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        # Compute the \"distance\" to the Pareto front (simplified heuristic)\n        # Here, we consider solutions that are not too close to the extreme points\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        # If no candidates, pick a random solution and try to improve it\n        sol, _ = random.choice(archive)\n        candidates.append((sol, (0, 0)))\n\n    # Select the solution with the highest potential for improvement\n    # (Here, we use a simple heuristic: pick the solution with the lowest total weight)\n    selected_sol, _ = min(candidates, key=lambda x: np.sum(x[0] * weight_lst))\n\n    # Generate a neighbor solution using a hybrid local search strategy\n    new_solution = selected_sol.copy()\n    n_items = len(new_solution)\n\n    # Strategy 1: Randomly flip a subset of items (like mutation in genetic algorithms)\n    for _ in range(random.randint(1, min(3, n_items))):\n        idx = random.randint(0, n_items - 1)\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Strategy 2: Try to add an item if possible (greedy improvement)\n    for idx in np.where(new_solution == 0)[0]:\n        if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            break\n\n    # Strategy 3: Try to remove an item if it doesn't hurt the objectives too much\n    for idx in np.where(new_solution == 1)[0]:\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 0\n        if np.sum(temp_solution * weight_lst) <= capacity:\n            new_solution = temp_solution\n            break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 221,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with higher probability for solutions with higher total value\n    total_values = np.array([sum(obj) for _, obj in archive])\n    probabilities = total_values / total_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items that can be flipped (either included or excluded without violating capacity)\n    included_items = np.where(base_solution == 1)[0]\n    excluded_items = np.where(base_solution == 0)[0]\n\n    # Hybrid local search: flip items based on value density and randomness\n    for item in included_items:\n        if np.random.rand() < 0.3:  # 30% chance to consider flipping an included item\n            if current_weight - weight_lst[item] + np.random.choice(weight_lst[excluded_items]) <= capacity:\n                new_solution[item] = 0\n                # Add a random excluded item if possible\n                candidates = [i for i in excluded_items if current_weight + weight_lst[i] <= capacity]\n                if candidates:\n                    new_item = np.random.choice(candidates)\n                    new_solution[new_item] = 1\n                    current_weight += weight_lst[new_item] - weight_lst[item]\n\n    # Randomly flip some excluded items to explore new combinations\n    for item in excluded_items:\n        if np.random.rand() < 0.1:  # 10% chance to consider adding an excluded item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8132252154157131,
            4.405137538909912
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with higher probability for solutions with higher total value\n    total_values = np.array([sum(obj) for _, obj in archive])\n    probabilities = total_values / total_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items that can be flipped (either included or excluded without violating capacity)\n    included_items = np.where(base_solution == 1)[0]\n    excluded_items = np.where(base_solution == 0)[0]\n\n    # Hybrid local search: flip items based on value density and randomness\n    for item in included_items:\n        if np.random.rand() < 0.3:  # 30% chance to consider flipping an included item\n            if current_weight - weight_lst[item] + np.random.choice(weight_lst[excluded_items]) <= capacity:\n                new_solution[item] = 0\n                # Add a random excluded item if possible\n                candidates = [i for i in excluded_items if current_weight + weight_lst[i] <= capacity]\n                if candidates:\n                    new_item = np.random.choice(candidates)\n                    new_solution[new_item] = 1\n                    current_weight += weight_lst[new_item] - weight_lst[item]\n\n    # Randomly flip some excluded items to explore new combinations\n    for item in excluded_items:\n        if np.random.rand() < 0.1:  # 10% chance to consider adding an excluded item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 222,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = np.array([np.sum(weight_lst[sol == 1]) for sol in archive_solutions])\n    archive_values = np.array([(np.sum(value1_lst[sol == 1]), np.sum(value2_lst[sol == 1])) for sol in archive_solutions])\n\n    # Identify solutions with potential for improvement (not at capacity and not too close to the Pareto front)\n    potential_indices = [\n        i for i in range(len(archive_solutions))\n        if archive_weights[i] < capacity * 0.95  # Not too close to capacity\n    ]\n\n    if not potential_indices:\n        potential_indices = list(range(len(archive_solutions)))  # Fallback to all solutions\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.choice(potential_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    n_items = len(weight_lst)\n    n_perturb = max(1, int(n_items * 0.1))  # Perturb 10% of items\n\n    # Random perturbation: Flip a few bits\n    perturb_indices = random.sample(range(n_items), n_perturb)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess_weight = total_weight - capacity\n        excess_items = new_solution.copy()\n        while excess_weight > 0 and np.any(excess_items):\n            # Remove the item with the smallest ratio of (value1 + value2) / weight\n            item_values = value1_lst + value2_lst\n            item_ratios = np.where(excess_items, item_values / weight_lst, -1)\n            worst_item = np.argmax(item_ratios)\n            if item_ratios[worst_item] >= 0:\n                excess_weight -= weight_lst[worst_item]\n                excess_items[worst_item] = 0\n            else:\n                break\n        new_solution = excess_items\n\n    # Greedy improvement: Add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    available_capacity = capacity - current_weight\n\n    for item in remaining_items:\n        if weight_lst[item] <= available_capacity:\n            # Check if adding the item improves both objectives\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.38811528910701804,
            3.949872672557831
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = np.array([np.sum(weight_lst[sol == 1]) for sol in archive_solutions])\n    archive_values = np.array([(np.sum(value1_lst[sol == 1]), np.sum(value2_lst[sol == 1])) for sol in archive_solutions])\n\n    # Identify solutions with potential for improvement (not at capacity and not too close to the Pareto front)\n    potential_indices = [\n        i for i in range(len(archive_solutions))\n        if archive_weights[i] < capacity * 0.95  # Not too close to capacity\n    ]\n\n    if not potential_indices:\n        potential_indices = list(range(len(archive_solutions)))  # Fallback to all solutions\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.choice(potential_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    n_items = len(weight_lst)\n    n_perturb = max(1, int(n_items * 0.1))  # Perturb 10% of items\n\n    # Random perturbation: Flip a few bits\n    perturb_indices = random.sample(range(n_items), n_perturb)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess_weight = total_weight - capacity\n        excess_items = new_solution.copy()\n        while excess_weight > 0 and np.any(excess_items):\n            # Remove the item with the smallest ratio of (value1 + value2) / weight\n            item_values = value1_lst + value2_lst\n            item_ratios = np.where(excess_items, item_values / weight_lst, -1)\n            worst_item = np.argmax(item_ratios)\n            if item_ratios[worst_item] >= 0:\n                excess_weight -= weight_lst[worst_item]\n                excess_items[worst_item] = 0\n            else:\n                break\n        new_solution = excess_items\n\n    # Greedy improvement: Add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    available_capacity = capacity - current_weight\n\n    for item in remaining_items:\n        if weight_lst[item] <= available_capacity:\n            # Check if adding the item improves both objectives\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 223,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly flip a subset of items to create perturbation\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items with the lowest marginal contribution to both objectives\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Compute marginal contribution (value/weight) for both objectives\n            marginal_v1 = value1_lst[included_items] / weight_lst[included_items]\n            marginal_v2 = value2_lst[included_items] / weight_lst[included_items]\n            # Remove item with the smallest combined marginal contribution\n            combined_marginal = marginal_v1 + marginal_v2\n            remove_idx = included_items[np.argmin(combined_marginal)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement: add items with highest marginal contribution to both objectives\n    excluded_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for idx in excluded_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3555845687108178,
            2.4653400182724
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly flip a subset of items to create perturbation\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items with the lowest marginal contribution to both objectives\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Compute marginal contribution (value/weight) for both objectives\n            marginal_v1 = value1_lst[included_items] / weight_lst[included_items]\n            marginal_v2 = value2_lst[included_items] / weight_lst[included_items]\n            # Remove item with the smallest combined marginal contribution\n            combined_marginal = marginal_v1 + marginal_v2\n            remove_idx = included_items[np.argmin(combined_marginal)]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement: add items with highest marginal contribution to both objectives\n    excluded_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for idx in excluded_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding the item improves both objectives\n            if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 224,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objective values (indicating potential for improvement)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% solutions for higher chance of selection\n        top_solutions = archive_sorted[:max(1, len(archive) // 3)]\n        selected_idx = random.randint(0, len(top_solutions) - 1)\n        base_solution = top_solutions[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    # Flip operation: randomly flip a small number of items (1-3)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure the solution is feasible after flips\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_item_weights = weight_lst[excess_items]\n        # Sort excess items by value density (value1 + value2)/weight\n        item_densities = (value1_lst[excess_items] + value2_lst[excess_items]) / excess_item_weights\n        sorted_indices = np.argsort(item_densities)\n        # Remove least valuable items first\n        for i in sorted_indices:\n            if excess_weight <= 0:\n                break\n            item_idx = excess_items[i]\n            new_solution[item_idx] = 0\n            excess_weight -= weight_lst[item_idx]\n\n    # Swap operation: randomly swap two items (if possible)\n    if len(new_solution) >= 2:\n        swap_indices = random.sample(range(len(new_solution)), 2)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n        # Ensure feasibility after swap\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        if current_weight > capacity:\n            # If swap makes it infeasible, revert it\n            new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.349561243853298,
            1.8382858335971832
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objective values (indicating potential for improvement)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% solutions for higher chance of selection\n        top_solutions = archive_sorted[:max(1, len(archive) // 3)]\n        selected_idx = random.randint(0, len(top_solutions) - 1)\n        base_solution = top_solutions[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    # Flip operation: randomly flip a small number of items (1-3)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure the solution is feasible after flips\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_item_weights = weight_lst[excess_items]\n        # Sort excess items by value density (value1 + value2)/weight\n        item_densities = (value1_lst[excess_items] + value2_lst[excess_items]) / excess_item_weights\n        sorted_indices = np.argsort(item_densities)\n        # Remove least valuable items first\n        for i in sorted_indices:\n            if excess_weight <= 0:\n                break\n            item_idx = excess_items[i]\n            new_solution[item_idx] = 0\n            excess_weight -= weight_lst[item_idx]\n\n    # Swap operation: randomly swap two items (if possible)\n    if len(new_solution) >= 2:\n        swap_indices = random.sample(range(len(new_solution)), 2)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n        # Ensure feasibility after swap\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        if current_weight > capacity:\n            # If swap makes it infeasible, revert it\n            new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 225,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    # Prefer solutions that are not too close to the Pareto front or have high diversity\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[1 / (1 + np.sum(sol[0])) for sol in archive],  # Prefer sparser solutions\n        k=1\n    )[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_score = marginal_value1 + marginal_value2  # Combined score\n\n    # Sort items by marginal score (descending)\n    sorted_indices = np.argsort(marginal_score)[::-1]\n\n    # Hybrid local search: flip a subset of items based on their marginal contributions\n    new_solution = base_solution.copy()\n    num_flips = min(3, len(sorted_indices))  # Limit the number of flips for efficiency\n    for idx in sorted_indices[:num_flips]:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # If no improvement, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = random.choice(candidate_indices)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.817263225939308,
            10.178510308265686
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    # Prefer solutions that are not too close to the Pareto front or have high diversity\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[1 / (1 + np.sum(sol[0])) for sol in archive],  # Prefer sparser solutions\n        k=1\n    )[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_score = marginal_value1 + marginal_value2  # Combined score\n\n    # Sort items by marginal score (descending)\n    sorted_indices = np.argsort(marginal_score)[::-1]\n\n    # Hybrid local search: flip a subset of items based on their marginal contributions\n    new_solution = base_solution.copy()\n    num_flips = min(3, len(sorted_indices))  # Limit the number of flips for efficiency\n    for idx in sorted_indices[:num_flips]:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # If no improvement, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        candidate_indices = np.where(base_solution == 1)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = random.choice(candidate_indices)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 226,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total value in either objective\n    objectives = np.array([obj for _, obj in archive])\n    total_values = objectives.sum(axis=0)\n    if total_values[0] > total_values[1]:\n        weights = objectives[:, 0] / total_values[0]\n    else:\n        weights = objectives[:, 1] / total_values[1]\n    selected_idx = np.random.choice(len(archive), p=weights/weights.sum())\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: flip items with high marginal improvement or random flips\n    for _ in range(min(5, len(new_solution))):  # Limit the number of flips to avoid excessive computation\n        # Calculate marginal improvements for each item\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        marginal_weight = weight_lst * (1 - new_solution) - weight_lst * new_solution\n\n        # Combine marginal improvements with weights\n        combined_marginal = marginal1 + marginal2\n        feasible_mask = (current_weight + marginal_weight <= capacity) | (new_solution == 1)\n        combined_marginal[~feasible_mask] = -np.inf  # Penalize infeasible flips\n\n        # Select items to flip: prioritize high marginal improvements or random selection\n        if np.random.random() < 0.7:  # 70% chance to select based on marginal improvements\n            candidate_items = np.argsort(combined_marginal)[-3:]  # Top 3 items\n            if len(candidate_items) > 0:\n                flip_idx = np.random.choice(candidate_items)\n            else:\n                break  # No feasible flips available\n        else:  # 30% chance to select randomly\n            candidate_items = np.where(feasible_mask)[0]\n            if len(candidate_items) > 0:\n                flip_idx = np.random.choice(candidate_items)\n            else:\n                break  # No feasible flips available\n\n        # Perform the flip\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        current_weight += marginal_weight[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3482814233183154,
            2.487173944711685
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total value in either objective\n    objectives = np.array([obj for _, obj in archive])\n    total_values = objectives.sum(axis=0)\n    if total_values[0] > total_values[1]:\n        weights = objectives[:, 0] / total_values[0]\n    else:\n        weights = objectives[:, 1] / total_values[1]\n    selected_idx = np.random.choice(len(archive), p=weights/weights.sum())\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: flip items with high marginal improvement or random flips\n    for _ in range(min(5, len(new_solution))):  # Limit the number of flips to avoid excessive computation\n        # Calculate marginal improvements for each item\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        marginal_weight = weight_lst * (1 - new_solution) - weight_lst * new_solution\n\n        # Combine marginal improvements with weights\n        combined_marginal = marginal1 + marginal2\n        feasible_mask = (current_weight + marginal_weight <= capacity) | (new_solution == 1)\n        combined_marginal[~feasible_mask] = -np.inf  # Penalize infeasible flips\n\n        # Select items to flip: prioritize high marginal improvements or random selection\n        if np.random.random() < 0.7:  # 70% chance to select based on marginal improvements\n            candidate_items = np.argsort(combined_marginal)[-3:]  # Top 3 items\n            if len(candidate_items) > 0:\n                flip_idx = np.random.choice(candidate_items)\n            else:\n                break  # No feasible flips available\n        else:  # 30% chance to select randomly\n            candidate_items = np.where(feasible_mask)[0]\n            if len(candidate_items) > 0:\n                flip_idx = np.random.choice(candidate_items)\n            else:\n                break  # No feasible flips available\n\n        # Perform the flip\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        current_weight += marginal_weight[flip_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 227,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random flips with objective-aware flips\n    n_items = len(weight_lst)\n    n_flips = min(3, n_items)  # Limit number of flips to maintain feasibility\n\n    for _ in range(n_flips):\n        # Randomly select a candidate item to flip\n        candidate_idx = np.random.randint(0, n_items)\n        current_status = new_solution[candidate_idx]\n\n        # Calculate potential new weight\n        if current_status == 1:\n            new_weight = current_weight - weight_lst[candidate_idx]\n        else:\n            new_weight = current_weight + weight_lst[candidate_idx]\n\n        # Only consider feasible flips\n        if new_weight <= capacity:\n            # Objective-aware flip: prefer flips that improve both objectives\n            if current_status == 1:\n                # If item is included, consider removing it (only if it doesn't hurt objectives)\n                if (value1_lst[candidate_idx] <= 0 and value2_lst[candidate_idx] <= 0) or \\\n                   (np.random.random() < 0.3):  # Small probability to remove even if negative\n                    new_solution[candidate_idx] = 0\n                    current_weight = new_weight\n            else:\n                # If item is excluded, consider adding it (only if it improves at least one objective)\n                if (value1_lst[candidate_idx] > 0 or value2_lst[candidate_idx] > 0) or \\\n                   (np.random.random() < 0.2):  # Small probability to add even if neutral\n                    new_solution[candidate_idx] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.43957431374259337,
            1.746657818555832
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random flips with objective-aware flips\n    n_items = len(weight_lst)\n    n_flips = min(3, n_items)  # Limit number of flips to maintain feasibility\n\n    for _ in range(n_flips):\n        # Randomly select a candidate item to flip\n        candidate_idx = np.random.randint(0, n_items)\n        current_status = new_solution[candidate_idx]\n\n        # Calculate potential new weight\n        if current_status == 1:\n            new_weight = current_weight - weight_lst[candidate_idx]\n        else:\n            new_weight = current_weight + weight_lst[candidate_idx]\n\n        # Only consider feasible flips\n        if new_weight <= capacity:\n            # Objective-aware flip: prefer flips that improve both objectives\n            if current_status == 1:\n                # If item is included, consider removing it (only if it doesn't hurt objectives)\n                if (value1_lst[candidate_idx] <= 0 and value2_lst[candidate_idx] <= 0) or \\\n                   (np.random.random() < 0.3):  # Small probability to remove even if negative\n                    new_solution[candidate_idx] = 0\n                    current_weight = new_weight\n            else:\n                # If item is excluded, consider adding it (only if it improves at least one objective)\n                if (value1_lst[candidate_idx] > 0 or value2_lst[candidate_idx] > 0) or \\\n                   (np.random.random() < 0.2):  # Small probability to add even if neutral\n                    new_solution[candidate_idx] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 228,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    non_dominated = [sol for sol, obj in archive]\n    if not non_dominated:\n        return np.zeros_like(weight_lst)\n\n    # Select a solution with the lowest total weight (to allow more room for improvement)\n    selected_solution = min(non_dominated, key=lambda x: np.sum(weight_lst[x == 1]))\n\n    # Create a neighbor by flipping a subset of items based on a hybrid strategy\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid strategy: Randomly flip a small subset of items (for diversity) and then apply a greedy improvement\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove the heaviest items until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            # Remove the item with the highest weight (or random if weights are equal)\n            remove_idx = np.argmax(weight_lst[excess_items])\n            new_solution[excess_items[remove_idx]] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Apply a greedy improvement: add items that improve at least one objective without violating capacity\n    remaining_weight = capacity - total_weight\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if weight_lst[idx] <= remaining_weight:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                remaining_weight = capacity - total_weight\n\n    return new_solution\n\n",
        "score": [
            -0.21349507964870884,
            3.6009525060653687
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    non_dominated = [sol for sol, obj in archive]\n    if not non_dominated:\n        return np.zeros_like(weight_lst)\n\n    # Select a solution with the lowest total weight (to allow more room for improvement)\n    selected_solution = min(non_dominated, key=lambda x: np.sum(weight_lst[x == 1]))\n\n    # Create a neighbor by flipping a subset of items based on a hybrid strategy\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid strategy: Randomly flip a small subset of items (for diversity) and then apply a greedy improvement\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove the heaviest items until feasible\n        while total_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            # Remove the item with the highest weight (or random if weights are equal)\n            remove_idx = np.argmax(weight_lst[excess_items])\n            new_solution[excess_items[remove_idx]] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Apply a greedy improvement: add items that improve at least one objective without violating capacity\n    remaining_weight = capacity - total_weight\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if weight_lst[idx] <= remaining_weight:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                remaining_weight = capacity - total_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 229,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot generate a neighbor solution.\")\n\n    # Select a solution with high potential for improvement: solutions with low crowding distance or non-dominated\n    # Here, we select a solution randomly but prioritize those with higher total value (sum of both objectives)\n    scores = [sum(obj) for _, obj in archive]\n    selected_idx = np.random.choice(len(archive), p=np.array(scores) / sum(scores))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swap + greedy improvement\n    n_items = len(base_solution)\n    if n_items < 2:\n        return new_solution  # No possible swaps\n\n    # Randomly select two items to swap\n    i, j = np.random.choice(n_items, size=2, replace=False)\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, revert the swap and perform a greedy improvement step\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        # Greedy improvement: flip the item that reduces the weight the most while improving at least one objective\n        current_weight = np.sum(weight_lst * base_solution)\n        for idx in range(n_items):\n            if base_solution[idx] == 1:\n                # Try removing the item\n                new_solution = base_solution.copy()\n                new_solution[idx] = 0\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    return new_solution\n            else:\n                # Try adding the item\n                new_solution = base_solution.copy()\n                new_solution[idx] = 1\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    # Check if it improves at least one objective\n                    delta_value1 = value1_lst[idx]\n                    delta_value2 = value2_lst[idx]\n                    if delta_value1 > 0 or delta_value2 > 0:\n                        return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.47251092338719525,
            1.5098077356815338
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot generate a neighbor solution.\")\n\n    # Select a solution with high potential for improvement: solutions with low crowding distance or non-dominated\n    # Here, we select a solution randomly but prioritize those with higher total value (sum of both objectives)\n    scores = [sum(obj) for _, obj in archive]\n    selected_idx = np.random.choice(len(archive), p=np.array(scores) / sum(scores))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swap + greedy improvement\n    n_items = len(base_solution)\n    if n_items < 2:\n        return new_solution  # No possible swaps\n\n    # Randomly select two items to swap\n    i, j = np.random.choice(n_items, size=2, replace=False)\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, revert the swap and perform a greedy improvement step\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        # Greedy improvement: flip the item that reduces the weight the most while improving at least one objective\n        current_weight = np.sum(weight_lst * base_solution)\n        for idx in range(n_items):\n            if base_solution[idx] == 1:\n                # Try removing the item\n                new_solution = base_solution.copy()\n                new_solution[idx] = 0\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    return new_solution\n            else:\n                # Try adding the item\n                new_solution = base_solution.copy()\n                new_solution[idx] = 1\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    # Check if it improves at least one objective\n                    delta_value1 = value1_lst[idx]\n                    delta_value2 = value2_lst[idx]\n                    if delta_value1 > 0 or delta_value2 > 0:\n                        return new_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 230,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (not dominated by others in the archive)\n    candidate_solutions = []\n    for sol, _ in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight <= capacity:\n            candidate_solutions.append(sol)\n\n    if not candidate_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select a solution with high potential for improvement (randomly among top 30% by value)\n    candidate_solutions.sort(key=lambda x: np.sum(x * value1_lst) + np.sum(x * value2_lst), reverse=True)\n    top_candidates = candidate_solutions[:max(1, len(candidate_solutions) // 3)]\n    base_solution = random.choice(top_candidates).copy()\n\n    # Create a neighbor by flipping items with high marginal improvement\n    new_solution = base_solution.copy()\n    total_weight = np.sum(new_solution * weight_lst)\n\n    # Calculate marginal gains for each item\n    marginal_gains = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # For included items, consider removing if it's not too heavy\n            marginal_gain = (value1_lst[i] + value2_lst[i]) * -1  # Negative gain for removal\n        else:\n            # For excluded items, consider adding if it fits\n            if total_weight + weight_lst[i] <= capacity:\n                marginal_gain = value1_lst[i] + value2_lst[i]\n            else:\n                marginal_gain = -np.inf  # Cannot add\n\n        marginal_gains.append(marginal_gain)\n\n    # Select top 20% of items with highest marginal gains\n    num_candidates = max(1, len(marginal_gains) // 5)\n    top_indices = np.argsort(marginal_gains)[-num_candidates:]\n    selected_index = random.choice(top_indices)\n\n    # Flip the selected item\n    new_solution[selected_index] = 1 - new_solution[selected_index]\n\n    # Ensure feasibility by removing items if necessary\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items with lowest value/weight ratio until feasible\n        while current_weight > capacity:\n            included_indices = np.where(new_solution == 1)[0]\n            if len(included_indices) == 0:\n                break  # No items left to remove\n            # Select item with lowest value/weight ratio\n            ratios = (value1_lst[included_indices] + value2_lst[included_indices]) / weight_lst[included_indices]\n            remove_index = included_indices[np.argmin(ratios)]\n            new_solution[remove_index] = 0\n            current_weight = np.sum(new_solution * weight_lst)\n\n    return new_solution\n\n",
        "score": [
            -0.8427755363967384,
            2.7515567243099213
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (not dominated by others in the archive)\n    candidate_solutions = []\n    for sol, _ in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight <= capacity:\n            candidate_solutions.append(sol)\n\n    if not candidate_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select a solution with high potential for improvement (randomly among top 30% by value)\n    candidate_solutions.sort(key=lambda x: np.sum(x * value1_lst) + np.sum(x * value2_lst), reverse=True)\n    top_candidates = candidate_solutions[:max(1, len(candidate_solutions) // 3)]\n    base_solution = random.choice(top_candidates).copy()\n\n    # Create a neighbor by flipping items with high marginal improvement\n    new_solution = base_solution.copy()\n    total_weight = np.sum(new_solution * weight_lst)\n\n    # Calculate marginal gains for each item\n    marginal_gains = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # For included items, consider removing if it's not too heavy\n            marginal_gain = (value1_lst[i] + value2_lst[i]) * -1  # Negative gain for removal\n        else:\n            # For excluded items, consider adding if it fits\n            if total_weight + weight_lst[i] <= capacity:\n                marginal_gain = value1_lst[i] + value2_lst[i]\n            else:\n                marginal_gain = -np.inf  # Cannot add\n\n        marginal_gains.append(marginal_gain)\n\n    # Select top 20% of items with highest marginal gains\n    num_candidates = max(1, len(marginal_gains) // 5)\n    top_indices = np.argsort(marginal_gains)[-num_candidates:]\n    selected_index = random.choice(top_indices)\n\n    # Flip the selected item\n    new_solution[selected_index] = 1 - new_solution[selected_index]\n\n    # Ensure feasibility by removing items if necessary\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items with lowest value/weight ratio until feasible\n        while current_weight > capacity:\n            included_indices = np.where(new_solution == 1)[0]\n            if len(included_indices) == 0:\n                break  # No items left to remove\n            # Select item with lowest value/weight ratio\n            ratios = (value1_lst[included_indices] + value2_lst[included_indices]) / weight_lst[included_indices]\n            remove_index = included_indices[np.argmin(ratios)]\n            new_solution[remove_index] = 0\n            current_weight = np.sum(new_solution * weight_lst)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 231,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort([obj[i] for obj in archive_objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (archive_objectives[sorted_indices[j + 1]][i] - archive_objectives[sorted_indices[j - 1]][i])\n\n    # Select a solution with low crowding distance (promising for improvement)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate a neighbor by flipping a random subset of items\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)  # Flip up to 3 items\n    new_solution = base_solution.copy()\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]  # Flip selected bits\n\n    # Ensure feasibility by removing excess weight if needed\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedily remove items with the lowest ratio of (value1 + value2)/weight\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and total_weight > capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7802016360634678,
            1.2429251670837402
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort([obj[i] for obj in archive_objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (archive_objectives[sorted_indices[j + 1]][i] - archive_objectives[sorted_indices[j - 1]][i])\n\n    # Select a solution with low crowding distance (promising for improvement)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate a neighbor by flipping a random subset of items\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)  # Flip up to 3 items\n    new_solution = base_solution.copy()\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]  # Flip selected bits\n\n    # Ensure feasibility by removing excess weight if needed\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedily remove items with the lowest ratio of (value1 + value2)/weight\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and total_weight > capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 232,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine random flips with value-based swaps\n    # Step 1: Randomly flip a small number of items\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Try to remove the item if it doesn't violate capacity\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item if it doesn't exceed capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Value-based swap - replace low-value items with high-value alternatives\n    # Calculate value ratios for each objective\n    value1_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value2_ratio = value2_lst / (weight_lst + 1e-10)\n\n    # Find items to potentially swap out (currently in knapsack)\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        # Find items to potentially swap in (currently not in knapsack)\n        out_of_knapsack = np.where(new_solution == 0)[0]\n\n        if len(out_of_knapsack) > 0:\n            # Select a random item to consider removing\n            remove_idx = np.random.choice(in_knapsack)\n            # Find potential items to add that would improve both objectives\n            potential_add = out_of_knapsack[\n                (weight_lst[out_of_knapsack] <= weight_lst[remove_idx]) &\n                (value1_ratio[out_of_knapsack] > value1_ratio[remove_idx]) &\n                (value2_ratio[out_of_knapsack] > value2_ratio[remove_idx])\n            ]\n\n            if len(potential_add) > 0:\n                add_idx = np.random.choice(potential_add)\n                # Check if the swap is feasible\n                if current_weight - weight_lst[remove_idx] + weight_lst[add_idx] <= capacity:\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.36786926485376736,
            0.9126192629337311
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine random flips with value-based swaps\n    # Step 1: Randomly flip a small number of items\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Try to remove the item if it doesn't violate capacity\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item if it doesn't exceed capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Value-based swap - replace low-value items with high-value alternatives\n    # Calculate value ratios for each objective\n    value1_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value2_ratio = value2_lst / (weight_lst + 1e-10)\n\n    # Find items to potentially swap out (currently in knapsack)\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        # Find items to potentially swap in (currently not in knapsack)\n        out_of_knapsack = np.where(new_solution == 0)[0]\n\n        if len(out_of_knapsack) > 0:\n            # Select a random item to consider removing\n            remove_idx = np.random.choice(in_knapsack)\n            # Find potential items to add that would improve both objectives\n            potential_add = out_of_knapsack[\n                (weight_lst[out_of_knapsack] <= weight_lst[remove_idx]) &\n                (value1_ratio[out_of_knapsack] > value1_ratio[remove_idx]) &\n                (value2_ratio[out_of_knapsack] > value2_ratio[remove_idx])\n            ]\n\n            if len(potential_add) > 0:\n                add_idx = np.random.choice(potential_add)\n                # Check if the swap is feasible\n                if current_weight - weight_lst[remove_idx] + weight_lst[add_idx] <= capacity:\n                    new_solution[remove_idx] = 0\n                    new_solution[add_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 233,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (promising candidates)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 50% of solutions\n        top_candidates = archive_sorted[:max(1, len(archive_sorted) // 2)]\n        # Randomly select one from top candidates\n        selected_solution, _ = random.choice(top_candidates)\n    else:\n        selected_solution = archive[0][0]\n\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search strategy: combination of flip, swap, and shift operations\n    operation = random.choice(['flip', 'swap', 'shift'])\n\n    if operation == 'flip':\n        # Flip a random item (0 to 1 or 1 to 0)\n        idx = random.randint(0, n_items - 1)\n        new_solution[idx] = 1 - new_solution[idx]\n        # Ensure feasibility\n        if np.sum(weight_lst * new_solution) > capacity:\n            # If infeasible, flip back\n            new_solution[idx] = 1 - new_solution[idx]\n\n    elif operation == 'swap':\n        # Swap two random items\n        idx1, idx2 = random.sample(range(n_items), 2)\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n        # Ensure feasibility\n        if np.sum(weight_lst * new_solution) > capacity:\n            # If infeasible, swap back\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    elif operation == 'shift':\n        # Shift a random segment of items\n        if n_items > 1:\n            start = random.randint(0, n_items - 2)\n            end = random.randint(start + 1, n_items - 1)\n            segment = new_solution[start:end]\n            # Rotate the segment by one position\n            new_solution[start:end] = np.roll(segment, 1)\n            # Ensure feasibility\n            if np.sum(weight_lst * new_solution) > capacity:\n                # If infeasible, rotate back\n                new_solution[start:end] = np.roll(segment, -1)\n\n    return new_solution\n\n",
        "score": [
            -0.28856218540356426,
            2.5862798392772675
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (promising candidates)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 50% of solutions\n        top_candidates = archive_sorted[:max(1, len(archive_sorted) // 2)]\n        # Randomly select one from top candidates\n        selected_solution, _ = random.choice(top_candidates)\n    else:\n        selected_solution = archive[0][0]\n\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search strategy: combination of flip, swap, and shift operations\n    operation = random.choice(['flip', 'swap', 'shift'])\n\n    if operation == 'flip':\n        # Flip a random item (0 to 1 or 1 to 0)\n        idx = random.randint(0, n_items - 1)\n        new_solution[idx] = 1 - new_solution[idx]\n        # Ensure feasibility\n        if np.sum(weight_lst * new_solution) > capacity:\n            # If infeasible, flip back\n            new_solution[idx] = 1 - new_solution[idx]\n\n    elif operation == 'swap':\n        # Swap two random items\n        idx1, idx2 = random.sample(range(n_items), 2)\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n        # Ensure feasibility\n        if np.sum(weight_lst * new_solution) > capacity:\n            # If infeasible, swap back\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    elif operation == 'shift':\n        # Shift a random segment of items\n        if n_items > 1:\n            start = random.randint(0, n_items - 2)\n            end = random.randint(start + 1, n_items - 1)\n            segment = new_solution[start:end]\n            # Rotate the segment by one position\n            new_solution[start:end] = np.roll(segment, 1)\n            # Ensure feasibility\n            if np.sum(weight_lst * new_solution) > capacity:\n                # If infeasible, rotate back\n                new_solution[start:end] = np.roll(segment, -1)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 234,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Random swap of two items (if feasible)\n    if len(new_solution) >= 2:\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if (new_solution[i] != new_solution[j] and\n            current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high value-to-weight ratio in one objective\n    if np.random.rand() < 0.5:\n        # Choose objective to prioritize (alternate between objectives)\n        if np.random.rand() < 0.5:\n            values = value1_lst\n        else:\n            values = value2_lst\n\n        # Calculate value-to-weight ratios\n        vw_ratios = values / (weight_lst + 1e-10)  # Avoid division by zero\n\n        # Identify items not in solution with high v/w ratio\n        candidate_items = np.where((new_solution == 0) & (vw_ratios > np.percentile(vw_ratios, 75)))[0]\n\n        if len(candidate_items) > 0:\n            # Select top 20% candidates by v/w ratio\n            top_candidates = candidate_items[np.argsort(vw_ratios[candidate_items])[-max(1, len(candidate_items)//5):]]\n\n            for item in top_candidates:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    # 3. Capacity-aware adjustment\n    while current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio in both objectives\n        combined_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) > 0:\n            worst_item = removable_items[np.argmin(combined_ratios[removable_items])]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.27794121591229237,
            3.2098356783390045
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Random swap of two items (if feasible)\n    if len(new_solution) >= 2:\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if (new_solution[i] != new_solution[j] and\n            current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high value-to-weight ratio in one objective\n    if np.random.rand() < 0.5:\n        # Choose objective to prioritize (alternate between objectives)\n        if np.random.rand() < 0.5:\n            values = value1_lst\n        else:\n            values = value2_lst\n\n        # Calculate value-to-weight ratios\n        vw_ratios = values / (weight_lst + 1e-10)  # Avoid division by zero\n\n        # Identify items not in solution with high v/w ratio\n        candidate_items = np.where((new_solution == 0) & (vw_ratios > np.percentile(vw_ratios, 75)))[0]\n\n        if len(candidate_items) > 0:\n            # Select top 20% candidates by v/w ratio\n            top_candidates = candidate_items[np.argsort(vw_ratios[candidate_items])[-max(1, len(candidate_items)//5):]]\n\n            for item in top_candidates:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    # 3. Capacity-aware adjustment\n    while current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio in both objectives\n        combined_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        removable_items = np.where(new_solution == 1)[0]\n\n        if len(removable_items) > 0:\n            worst_item = removable_items[np.argmin(combined_ratios[removable_items])]\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 235,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of non-dominated status and objective values\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n        base_solution = archive_sorted[0][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip\n    # 2. Evaluate the impact on both objectives\n    # 3. Apply a weighted random selection to decide which items to flip\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select 10% of items to consider for flipping\n    n_items = len(new_solution)\n    n_candidates = max(1, int(0.1 * n_items))\n    candidate_indices = np.random.choice(n_items, size=n_candidates, replace=False)\n\n    # Evaluate each candidate flip\n    best_improvement = -float('inf')\n    best_index = -1\n    best_flip = None\n\n    for idx in candidate_indices:\n        # Flip the item\n        flipped = new_solution.copy()\n        flipped[idx] = 1 - flipped[idx]\n\n        # Calculate new weight and values\n        new_weight = current_weight + (flipped[idx] - new_solution[idx]) * weight_lst[idx]\n        new_value1 = current_value1 + (flipped[idx] - new_solution[idx]) * value1_lst[idx]\n        new_value2 = current_value2 + (flipped[idx] - new_solution[idx]) * value2_lst[idx]\n\n        # Check feasibility\n        if new_weight <= capacity:\n            # Calculate improvement score (weighted sum of both objectives)\n            improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_index = idx\n                best_flip = flipped\n\n    # Apply the best flip if found\n    if best_index != -1:\n        new_solution = best_flip\n    else:\n        # If no improvement found, try a random flip that maintains feasibility\n        feasible_indices = [i for i in range(n_items) if (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity) or\n                          (new_solution[i] == 1 and current_weight - weight_lst[i] >= 0)]\n        if feasible_indices:\n            idx = np.random.choice(feasible_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9621740466177965,
            1.251669555902481
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of non-dominated status and objective values\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n        base_solution = archive_sorted[0][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip\n    # 2. Evaluate the impact on both objectives\n    # 3. Apply a weighted random selection to decide which items to flip\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select 10% of items to consider for flipping\n    n_items = len(new_solution)\n    n_candidates = max(1, int(0.1 * n_items))\n    candidate_indices = np.random.choice(n_items, size=n_candidates, replace=False)\n\n    # Evaluate each candidate flip\n    best_improvement = -float('inf')\n    best_index = -1\n    best_flip = None\n\n    for idx in candidate_indices:\n        # Flip the item\n        flipped = new_solution.copy()\n        flipped[idx] = 1 - flipped[idx]\n\n        # Calculate new weight and values\n        new_weight = current_weight + (flipped[idx] - new_solution[idx]) * weight_lst[idx]\n        new_value1 = current_value1 + (flipped[idx] - new_solution[idx]) * value1_lst[idx]\n        new_value2 = current_value2 + (flipped[idx] - new_solution[idx]) * value2_lst[idx]\n\n        # Check feasibility\n        if new_weight <= capacity:\n            # Calculate improvement score (weighted sum of both objectives)\n            improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_index = idx\n                best_flip = flipped\n\n    # Apply the best flip if found\n    if best_index != -1:\n        new_solution = best_flip\n    else:\n        # If no improvement found, try a random flip that maintains feasibility\n        feasible_indices = [i for i in range(n_items) if (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity) or\n                          (new_solution[i] == 1 and current_weight - weight_lst[i] >= 0)]\n        if feasible_indices:\n            idx = np.random.choice(feasible_indices)\n            new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 236,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution from the archive\n    # Prefer solutions with higher total value (sum of both objectives)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    total_values = [obj[0] + obj[1] for obj in archive_objectives]\n\n    # Select top 20% of solutions by total value\n    top_k = max(1, len(archive) // 5)\n    top_indices = np.argsort(total_values)[-top_k:]\n\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (exploration)\n    # 2. Greedily improve the solution (exploitation)\n\n    # Step 1: Random flip (exploration)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(5, n_items))  # Flip up to 5 items\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is in solution, try to remove it\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If item is not in solution, try to add it\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Greedy improvement (exploitation)\n    # Calculate current total weights and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to improve by adding items that provide the best marginal gain\n    # in either objective (alternating between objectives)\n    for _ in range(5):  # Limit improvement steps\n        # Calculate marginal gains for adding items\n        marginal_gains = []\n        for i in range(n_items):\n            if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                # Calculate marginal gain for each objective\n                gain1 = value1_lst[i] / (weight_lst[i] + 1e-6)  # Avoid division by zero\n                gain2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n                marginal_gains.append((i, gain1, gain2))\n\n        if not marginal_gains:\n            break\n\n        # Alternate between improving objective 1 and 2\n        if random.random() < 0.5:\n            # Improve objective 1\n            best_item = max(marginal_gains, key=lambda x: x[1])\n        else:\n            # Improve objective 2\n            best_item = max(marginal_gains, key=lambda x: x[2])\n\n        # Add the best item\n        new_solution[best_item[0]] = 1\n        current_weight += weight_lst[best_item[0]]\n        current_value1 += value1_lst[best_item[0]]\n        current_value2 += value2_lst[best_item[0]]\n\n    return new_solution\n\n",
        "score": [
            -0.328086082936619,
            6.135779231786728
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution from the archive\n    # Prefer solutions with higher total value (sum of both objectives)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    total_values = [obj[0] + obj[1] for obj in archive_objectives]\n\n    # Select top 20% of solutions by total value\n    top_k = max(1, len(archive) // 5)\n    top_indices = np.argsort(total_values)[-top_k:]\n\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (exploration)\n    # 2. Greedily improve the solution (exploitation)\n\n    # Step 1: Random flip (exploration)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(5, n_items))  # Flip up to 5 items\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is in solution, try to remove it\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If item is not in solution, try to add it\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Greedy improvement (exploitation)\n    # Calculate current total weights and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to improve by adding items that provide the best marginal gain\n    # in either objective (alternating between objectives)\n    for _ in range(5):  # Limit improvement steps\n        # Calculate marginal gains for adding items\n        marginal_gains = []\n        for i in range(n_items):\n            if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                # Calculate marginal gain for each objective\n                gain1 = value1_lst[i] / (weight_lst[i] + 1e-6)  # Avoid division by zero\n                gain2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n                marginal_gains.append((i, gain1, gain2))\n\n        if not marginal_gains:\n            break\n\n        # Alternate between improving objective 1 and 2\n        if random.random() < 0.5:\n            # Improve objective 1\n            best_item = max(marginal_gains, key=lambda x: x[1])\n        else:\n            # Improve objective 2\n            best_item = max(marginal_gains, key=lambda x: x[2])\n\n        # Add the best item\n        new_solution[best_item[0]] = 1\n        current_weight += weight_lst[best_item[0]]\n        current_value1 += value1_lst[best_item[0]]\n        current_value2 += value2_lst[best_item[0]]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 237,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (one with potential for improvement)\n    def calculate_potential(sol):\n        included = np.where(sol == 1)[0]\n        excluded = np.where(sol == 0)[0]\n\n        # Calculate potential marginal gains\n        if len(included) > 0:\n            in_weights = weight_lst[included]\n            in_value1 = value1_lst[included]\n            in_value2 = value2_lst[included]\n            avg_in_weight = np.mean(in_weights)\n            avg_in_value1 = np.mean(in_value1)\n            avg_in_value2 = np.mean(in_value2)\n        else:\n            avg_in_weight = 0\n            avg_in_value1 = 0\n            avg_in_value2 = 0\n\n        if len(excluded) > 0:\n            ex_weights = weight_lst[excluded]\n            ex_value1 = value1_lst[excluded]\n            ex_value2 = value2_lst[excluded]\n            avg_ex_weight = np.mean(ex_weights)\n            avg_ex_value1 = np.mean(ex_value1)\n            avg_ex_value2 = np.mean(ex_value2)\n        else:\n            avg_ex_weight = 0\n            avg_ex_value1 = 0\n            avg_ex_value2 = 0\n\n        # Potential is higher if we can swap out low-value items for higher-value ones\n        potential = (avg_ex_value1 + avg_ex_value2) - (avg_in_value1 + avg_in_value2)\n        return potential\n\n    # Select top 3 solutions with highest potential\n    potentials = [calculate_potential(sol[0]) for sol in archive]\n    top_indices = np.argsort(potentials)[-min(3, len(archive)):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2.1: Randomized bit flips (to escape local optima)\n    flip_candidates = []\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Consider removing this item\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append((i, -1))  # -1 means remove\n        else:\n            # Consider adding this item\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append((i, 1))  # 1 means add\n\n    # Perform random flips (up to 3)\n    random.shuffle(flip_candidates)\n    for i in range(min(3, len(flip_candidates))):\n        idx, action = flip_candidates[i]\n        new_solution[idx] = action == 1\n        current_weight += action * weight_lst[idx]\n\n    # Step 2.2: Greedy swaps (between included and excluded items)\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Calculate value ratios for potential swaps\n    if len(included) > 0 and len(excluded) > 0:\n        in_weights = weight_lst[included]\n        in_value1 = value1_lst[included]\n        in_value2 = value2_lst[included]\n        ex_weights = weight_lst[excluded]\n        ex_value1 = value1_lst[excluded]\n        ex_value2 = value2_lst[excluded]\n\n        # Calculate normalized value (sum of both objectives)\n        in_values = in_value1 + in_value2\n        ex_values = ex_value1 + ex_value2\n\n        # Find best possible swaps (where we gain more value by swapping)\n        for i in range(len(included)):\n            for j in range(len(excluded)):\n                delta_weight = ex_weights[j] - in_weights[i]\n                if abs(delta_weight) < 1e-6:  # nearly same weight\n                    if ex_values[j] > in_values[i]:\n                        new_solution[included[i]] = 0\n                        new_solution[excluded[j]] = 1\n                        break\n                elif delta_weight > 0:  # adding heavier item\n                    if current_weight + delta_weight <= capacity and ex_values[j] > in_values[i]:\n                        new_solution[included[i]] = 0\n                        new_solution[excluded[j]] = 1\n                        current_weight += delta_weight\n                        break\n                else:  # adding lighter item\n                    if ex_values[j] > in_values[i]:\n                        new_solution[included[i]] = 0\n                        new_solution[excluded[j]] = 1\n                        current_weight += delta_weight\n                        break\n\n    # Ensure solution is feasible (in case of rounding errors)\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If not feasible, remove heaviest items until feasible\n        included = np.where(new_solution == 1)[0]\n        included_weights = weight_lst[included]\n        included_values = value1_lst[included] + value2_lst[included]\n\n        # Sort by value-to-weight ratio (remove least valuable first)\n        ratios = included_values / (included_weights + 1e-6)\n        sorted_indices = np.argsort(ratios)\n\n        current_weight = np.sum(included_weights)\n        for i in sorted_indices:\n            if current_weight <= capacity:\n                break\n            current_weight -= included_weights[i]\n            new_solution[included[i]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8751135682381361,
            7.077544450759888
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (one with potential for improvement)\n    def calculate_potential(sol):\n        included = np.where(sol == 1)[0]\n        excluded = np.where(sol == 0)[0]\n\n        # Calculate potential marginal gains\n        if len(included) > 0:\n            in_weights = weight_lst[included]\n            in_value1 = value1_lst[included]\n            in_value2 = value2_lst[included]\n            avg_in_weight = np.mean(in_weights)\n            avg_in_value1 = np.mean(in_value1)\n            avg_in_value2 = np.mean(in_value2)\n        else:\n            avg_in_weight = 0\n            avg_in_value1 = 0\n            avg_in_value2 = 0\n\n        if len(excluded) > 0:\n            ex_weights = weight_lst[excluded]\n            ex_value1 = value1_lst[excluded]\n            ex_value2 = value2_lst[excluded]\n            avg_ex_weight = np.mean(ex_weights)\n            avg_ex_value1 = np.mean(ex_value1)\n            avg_ex_value2 = np.mean(ex_value2)\n        else:\n            avg_ex_weight = 0\n            avg_ex_value1 = 0\n            avg_ex_value2 = 0\n\n        # Potential is higher if we can swap out low-value items for higher-value ones\n        potential = (avg_ex_value1 + avg_ex_value2) - (avg_in_value1 + avg_in_value2)\n        return potential\n\n    # Select top 3 solutions with highest potential\n    potentials = [calculate_potential(sol[0]) for sol in archive]\n    top_indices = np.argsort(potentials)[-min(3, len(archive)):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2.1: Randomized bit flips (to escape local optima)\n    flip_candidates = []\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Consider removing this item\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append((i, -1))  # -1 means remove\n        else:\n            # Consider adding this item\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append((i, 1))  # 1 means add\n\n    # Perform random flips (up to 3)\n    random.shuffle(flip_candidates)\n    for i in range(min(3, len(flip_candidates))):\n        idx, action = flip_candidates[i]\n        new_solution[idx] = action == 1\n        current_weight += action * weight_lst[idx]\n\n    # Step 2.2: Greedy swaps (between included and excluded items)\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Calculate value ratios for potential swaps\n    if len(included) > 0 and len(excluded) > 0:\n        in_weights = weight_lst[included]\n        in_value1 = value1_lst[included]\n        in_value2 = value2_lst[included]\n        ex_weights = weight_lst[excluded]\n        ex_value1 = value1_lst[excluded]\n        ex_value2 = value2_lst[excluded]\n\n        # Calculate normalized value (sum of both objectives)\n        in_values = in_value1 + in_value2\n        ex_values = ex_value1 + ex_value2\n\n        # Find best possible swaps (where we gain more value by swapping)\n        for i in range(len(included)):\n            for j in range(len(excluded)):\n                delta_weight = ex_weights[j] - in_weights[i]\n                if abs(delta_weight) < 1e-6:  # nearly same weight\n                    if ex_values[j] > in_values[i]:\n                        new_solution[included[i]] = 0\n                        new_solution[excluded[j]] = 1\n                        break\n                elif delta_weight > 0:  # adding heavier item\n                    if current_weight + delta_weight <= capacity and ex_values[j] > in_values[i]:\n                        new_solution[included[i]] = 0\n                        new_solution[excluded[j]] = 1\n                        current_weight += delta_weight\n                        break\n                else:  # adding lighter item\n                    if ex_values[j] > in_values[i]:\n                        new_solution[included[i]] = 0\n                        new_solution[excluded[j]] = 1\n                        current_weight += delta_weight\n                        break\n\n    # Ensure solution is feasible (in case of rounding errors)\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If not feasible, remove heaviest items until feasible\n        included = np.where(new_solution == 1)[0]\n        included_weights = weight_lst[included]\n        included_values = value1_lst[included] + value2_lst[included]\n\n        # Sort by value-to-weight ratio (remove least valuable first)\n        ratios = included_values / (included_weights + 1e-6)\n        sorted_indices = np.argsort(ratios)\n\n        current_weight = np.sum(included_weights)\n        for i in sorted_indices:\n            if current_weight <= capacity:\n                break\n            current_weight -= included_weights[i]\n            new_solution[included[i]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 238,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on a combination of randomness and objective diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to explore the neighborhood\n    num_flips = min(5, len(weight_lst))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n\n    # Apply flips and ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove the item if it's in the solution\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            # Add the item if it fits within capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Greedy improvement: Try to add items that improve both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate the \"utility\" of each item as a combination of both objectives\n        utility1 = value1_lst / weight_lst\n        utility2 = value2_lst / weight_lst\n        combined_utility = utility1 + utility2  # Simple weighted sum\n\n        # Sort items by combined utility in descending order\n        sorted_indices = np.argsort(-combined_utility)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3507590750600904,
            6.032165914773941
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on a combination of randomness and objective diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to explore the neighborhood\n    num_flips = min(5, len(weight_lst))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n\n    # Apply flips and ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove the item if it's in the solution\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            # Add the item if it fits within capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Greedy improvement: Try to add items that improve both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate the \"utility\" of each item as a combination of both objectives\n        utility1 = value1_lst / weight_lst\n        utility2 = value2_lst / weight_lst\n        combined_utility = utility1 + utility2  # Simple weighted sum\n\n        # Sort items by combined utility in descending order\n        sorted_indices = np.argsort(-combined_utility)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 239,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., one with low dominance count or high crowding distance)\n    # Here, we randomly select from the top 20% of solutions by objective values\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selection_pool = sorted_archive[:max(1, len(sorted_archive) // 5)]\n    base_solution, _ = random.choice(selection_pool)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine item swaps and flips with value-based perturbations\n    # Step 1: Identify items with high value ratios (value1/weight and value2/weight)\n    value1_ratios = value1_lst / weight_lst\n    value2_ratios = value2_lst / weight_lst\n\n    # Step 2: Perform a value-based flip (toggle items with high ratios)\n    high_value_items = np.where((value1_ratios > np.percentile(value1_ratios, 75)) |\n                                (value2_ratios > np.percentile(value2_ratios, 75)))[0]\n\n    for item in high_value_items:\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            new_solution[item] = 1 - new_solution[item]\n\n    # Step 3: Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value ratios until feasible\n        while current_weight > capacity:\n            # Identify items to remove (lowest value ratios)\n            item_ratios = (value1_lst + value2_lst) / weight_lst\n            item_ratios[new_solution == 0] = np.inf  # Ignore items not in solution\n            item_to_remove = np.argmin(item_ratios)\n            new_solution[item_to_remove] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 4: Perform a value-based swap (swap items with high ratios)\n    if len(high_value_items) >= 2:\n        item1, item2 = random.sample(list(high_value_items), 2)\n        if new_solution[item1] != new_solution[item2]:\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n",
        "score": [
            -0.4564246708236702,
            1.96341010928154
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., one with low dominance count or high crowding distance)\n    # Here, we randomly select from the top 20% of solutions by objective values\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selection_pool = sorted_archive[:max(1, len(sorted_archive) // 5)]\n    base_solution, _ = random.choice(selection_pool)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine item swaps and flips with value-based perturbations\n    # Step 1: Identify items with high value ratios (value1/weight and value2/weight)\n    value1_ratios = value1_lst / weight_lst\n    value2_ratios = value2_lst / weight_lst\n\n    # Step 2: Perform a value-based flip (toggle items with high ratios)\n    high_value_items = np.where((value1_ratios > np.percentile(value1_ratios, 75)) |\n                                (value2_ratios > np.percentile(value2_ratios, 75)))[0]\n\n    for item in high_value_items:\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            new_solution[item] = 1 - new_solution[item]\n\n    # Step 3: Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value ratios until feasible\n        while current_weight > capacity:\n            # Identify items to remove (lowest value ratios)\n            item_ratios = (value1_lst + value2_lst) / weight_lst\n            item_ratios[new_solution == 0] = np.inf  # Ignore items not in solution\n            item_to_remove = np.argmin(item_ratios)\n            new_solution[item_to_remove] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 4: Perform a value-based swap (swap items with high ratios)\n    if len(high_value_items) >= 2:\n        item1, item2 = random.sample(list(high_value_items), 2)\n        if new_solution[item1] != new_solution[item2]:\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 240,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score (e.g., sum of normalized objective values)\n        normalized_scores = []\n        for sol, obj in archive:\n            norm_obj1 = obj[0] / np.max([o[0] for _, o in archive]) if np.max([o[0] for _, o in archive]) != 0 else 0\n            norm_obj2 = obj[1] / np.max([o[1] for _, o in archive]) if np.max([o[1] for _, o in archive]) != 0 else 0\n            normalized_scores.append(norm_obj1 + norm_obj2)\n\n        # Select solutions in the middle of the Pareto front\n        middle_idx = len(normalized_scores) // 2\n        selected_idx = random.choice([i for i in range(len(normalized_scores)) if abs(i - middle_idx) <= len(normalized_scores) // 4])\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (intensification)\n    # 2. If feasible, apply a greedy improvement for one objective\n    # 3. If still feasible, apply a greedy improvement for the other objective\n\n    # Step 1: Random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove excess items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            item_to_remove = np.random.choice(excess_items)\n            new_solution[item_to_remove] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n            excess_items = np.where(new_solution == 1)[0]\n\n    # Step 2: Greedy improvement for objective 1\n    if current_weight <= capacity:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        for item in candidate_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Add the item that improves objective 1 the most\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item at a time to maintain diversity\n\n    # Step 3: Greedy improvement for objective 2\n    if current_weight <= capacity:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        for item in candidate_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Add the item that improves objective 2 the most\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item at a time to maintain diversity\n\n    return new_solution\n\n",
        "score": [
            -0.3681106763386651,
            3.2177192866802216
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score (e.g., sum of normalized objective values)\n        normalized_scores = []\n        for sol, obj in archive:\n            norm_obj1 = obj[0] / np.max([o[0] for _, o in archive]) if np.max([o[0] for _, o in archive]) != 0 else 0\n            norm_obj2 = obj[1] / np.max([o[1] for _, o in archive]) if np.max([o[1] for _, o in archive]) != 0 else 0\n            normalized_scores.append(norm_obj1 + norm_obj2)\n\n        # Select solutions in the middle of the Pareto front\n        middle_idx = len(normalized_scores) // 2\n        selected_idx = random.choice([i for i in range(len(normalized_scores)) if abs(i - middle_idx) <= len(normalized_scores) // 4])\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (intensification)\n    # 2. If feasible, apply a greedy improvement for one objective\n    # 3. If still feasible, apply a greedy improvement for the other objective\n\n    # Step 1: Random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove excess items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            item_to_remove = np.random.choice(excess_items)\n            new_solution[item_to_remove] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n            excess_items = np.where(new_solution == 1)[0]\n\n    # Step 2: Greedy improvement for objective 1\n    if current_weight <= capacity:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        for item in candidate_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Add the item that improves objective 1 the most\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item at a time to maintain diversity\n\n    # Step 3: Greedy improvement for objective 2\n    if current_weight <= capacity:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        for item in candidate_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Add the item that improves objective 2 the most\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item at a time to maintain diversity\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 241,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of their objectives (normalized)\n        objectives = np.array([obj for _, obj in archive])\n        max_values = objectives.max(axis=0)\n        normalized = objectives / max_values\n        scores = normalized.sum(axis=1)\n        # Select a solution with probability proportional to its score\n        selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    new_solution = base_solution.copy()\n\n    # First, try to flip a single bit (add or remove an item)\n    flip_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    if flip_candidates:\n        flip_idx = random.choice(flip_candidates)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # If no flip is possible, try a swap (exchange two items)\n    swap_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            for j in range(len(base_solution)):\n                if base_solution[j] == 0:\n                    # Check if swapping i and j keeps the solution feasible\n                    if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                        swap_candidates.append((i, j))\n\n    if swap_candidates:\n        i, j = random.choice(swap_candidates)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # If no swap is possible, try a more aggressive move: remove two items and add two new ones\n    remove_candidates = [i for i in range(len(base_solution)) if base_solution[i] == 1]\n    add_candidates = [i for i in range(len(base_solution)) if base_solution[i] == 0]\n\n    if len(remove_candidates) >= 2 and len(add_candidates) >= 2:\n        # Select two items to remove and two to add\n        i1, i2 = random.sample(remove_candidates, 2)\n        j1, j2 = random.sample(add_candidates, 2)\n\n        # Check feasibility\n        new_weight = current_weight - weight_lst[i1] - weight_lst[i2] + weight_lst[j1] + weight_lst[j2]\n        if new_weight <= capacity:\n            new_solution[i1] = 0\n            new_solution[i2] = 0\n            new_solution[j1] = 1\n            new_solution[j2] = 1\n            return new_solution\n\n    # If all else fails, return the base solution (no change)\n    return base_solution\n\n",
        "score": [
            -0.8192159585787779,
            0.9674059152603149
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of their objectives (normalized)\n        objectives = np.array([obj for _, obj in archive])\n        max_values = objectives.max(axis=0)\n        normalized = objectives / max_values\n        scores = normalized.sum(axis=1)\n        # Select a solution with probability proportional to its score\n        selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    new_solution = base_solution.copy()\n\n    # First, try to flip a single bit (add or remove an item)\n    flip_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    if flip_candidates:\n        flip_idx = random.choice(flip_candidates)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # If no flip is possible, try a swap (exchange two items)\n    swap_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            for j in range(len(base_solution)):\n                if base_solution[j] == 0:\n                    # Check if swapping i and j keeps the solution feasible\n                    if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                        swap_candidates.append((i, j))\n\n    if swap_candidates:\n        i, j = random.choice(swap_candidates)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # If no swap is possible, try a more aggressive move: remove two items and add two new ones\n    remove_candidates = [i for i in range(len(base_solution)) if base_solution[i] == 1]\n    add_candidates = [i for i in range(len(base_solution)) if base_solution[i] == 0]\n\n    if len(remove_candidates) >= 2 and len(add_candidates) >= 2:\n        # Select two items to remove and two to add\n        i1, i2 = random.sample(remove_candidates, 2)\n        j1, j2 = random.sample(add_candidates, 2)\n\n        # Check feasibility\n        new_weight = current_weight - weight_lst[i1] - weight_lst[i2] + weight_lst[j1] + weight_lst[j2]\n        if new_weight <= capacity:\n            new_solution[i1] = 0\n            new_solution[i2] = 0\n            new_solution[j1] = 1\n            new_solution[j2] = 1\n            return new_solution\n\n    # If all else fails, return the base solution (no change)\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 242,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Randomly select a subset of items to consider for flipping\n    flip_candidates = np.where(new_solution == 1)[0] if np.random.rand() < 0.5 else np.where(new_solution == 0)[0]\n    if len(flip_candidates) == 0:\n        return new_solution\n\n    # Step 2: Perform a flip operation (add or remove an item)\n    flip_idx = random.choice(flip_candidates)\n    if new_solution[flip_idx] == 1:\n        # Remove item if it doesn't make the solution infeasible\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n    else:\n        # Add item if it doesn't exceed capacity\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    # Step 3: Perform a swap operation (exchange two items)\n    if n_items > 1:\n        item1, item2 = random.sample(range(n_items), 2)\n        # Check if swap is feasible\n        delta_weight = weight_lst[item2] - weight_lst[item1]\n        if (new_solution[item1] == 1 and new_solution[item2] == 0 and current_weight + delta_weight <= capacity) or \\\n           (new_solution[item1] == 0 and new_solution[item2] == 1 and current_weight + delta_weight <= capacity):\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n",
        "score": [
            -0.3156259894104023,
            1.0815629065036774
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Randomly select a subset of items to consider for flipping\n    flip_candidates = np.where(new_solution == 1)[0] if np.random.rand() < 0.5 else np.where(new_solution == 0)[0]\n    if len(flip_candidates) == 0:\n        return new_solution\n\n    # Step 2: Perform a flip operation (add or remove an item)\n    flip_idx = random.choice(flip_candidates)\n    if new_solution[flip_idx] == 1:\n        # Remove item if it doesn't make the solution infeasible\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n    else:\n        # Add item if it doesn't exceed capacity\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    # Step 3: Perform a swap operation (exchange two items)\n    if n_items > 1:\n        item1, item2 = random.sample(range(n_items), 2)\n        # Check if swap is feasible\n        delta_weight = weight_lst[item2] - weight_lst[item1]\n        if (new_solution[item1] == 1 and new_solution[item2] == 0 and current_weight + delta_weight <= capacity) or \\\n           (new_solution[item1] == 0 and new_solution[item2] == 1 and current_weight + delta_weight <= capacity):\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 243,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Intelligent selection of a promising solution\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(weight_lst[archive[i][0] == 1]) / capacity for i in range(len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # Strategy 1: Randomly flip a subset of items to explore new regions\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, min(5, len(new_solution))), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess items if needed\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 2: Remove items with the lowest marginal contribution to both objectives\n        while current_weight > capacity:\n            # Calculate marginal contributions\n            marginal_contrib = (value1_lst + value2_lst) * new_solution\n            # Remove the item with the smallest marginal contribution\n            remove_idx = np.argmax(marginal_contrib == np.min(marginal_contrib[marginal_contrib > 0]))\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Strategy 3: Add items with high marginal contribution if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate potential marginal contributions for items not in the solution\n        potential_contrib = (value1_lst + value2_lst) * (1 - new_solution)\n        # Select items to add based on marginal contribution and remaining capacity\n        candidate_indices = np.where((1 - new_solution) == 1)[0]\n        candidate_weights = weight_lst[candidate_indices]\n        candidate_contribs = potential_contrib[candidate_indices]\n\n        # Sort by marginal contribution and select items that fit\n        sorted_indices = np.argsort(candidate_contribs)[::-1]\n        for idx in sorted_indices:\n            if candidate_weights[idx] <= remaining_capacity:\n                new_solution[candidate_indices[idx]] = 1\n                remaining_capacity -= candidate_weights[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.3551463361917149,
            4.960403144359589
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Intelligent selection of a promising solution\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(weight_lst[archive[i][0] == 1]) / capacity for i in range(len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # Strategy 1: Randomly flip a subset of items to explore new regions\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, min(5, len(new_solution))), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess items if needed\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 2: Remove items with the lowest marginal contribution to both objectives\n        while current_weight > capacity:\n            # Calculate marginal contributions\n            marginal_contrib = (value1_lst + value2_lst) * new_solution\n            # Remove the item with the smallest marginal contribution\n            remove_idx = np.argmax(marginal_contrib == np.min(marginal_contrib[marginal_contrib > 0]))\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Strategy 3: Add items with high marginal contribution if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate potential marginal contributions for items not in the solution\n        potential_contrib = (value1_lst + value2_lst) * (1 - new_solution)\n        # Select items to add based on marginal contribution and remaining capacity\n        candidate_indices = np.where((1 - new_solution) == 1)[0]\n        candidate_weights = weight_lst[candidate_indices]\n        candidate_contribs = potential_contrib[candidate_indices]\n\n        # Sort by marginal contribution and select items that fit\n        sorted_indices = np.argsort(candidate_contribs)[::-1]\n        for idx in sorted_indices:\n            if candidate_weights[idx] <= remaining_capacity:\n                new_solution[candidate_indices[idx]] = 1\n                remaining_capacity -= candidate_weights[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 244,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate potential improvement in both objectives\n            potential_value1 = np.sum(value1_lst * (1 - sol))  # Items not in solution\n            potential_value2 = np.sum(value2_lst * (1 - sol))\n            candidates.append((sol, obj, potential_value1, potential_value2))\n\n    if not candidates:\n        # If no candidates with remaining capacity, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select solution with highest combined potential improvement\n        base_solution, _, potential1, potential2 = max(candidates, key=lambda x: x[2] + x[3])\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    if np.random.rand() < 0.7:  # 70% chance for flip operation\n        # Flip operation: toggle a random item\n        flip_idx = np.random.randint(0, len(new_solution))\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight > capacity:\n            # Remove items randomly until feasible\n            while current_weight > capacity:\n                remove_candidates = np.where(new_solution == 1)[0]\n                if len(remove_candidates) == 0:\n                    break\n                remove_idx = np.random.choice(remove_candidates)\n                new_solution[remove_idx] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n    else:  # 30% chance for swap operation\n        # Swap operation: swap two items\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight > capacity:\n            # Remove items with lowest value-to-weight ratio until feasible\n            while current_weight > capacity:\n                included_items = np.where(new_solution == 1)[0]\n                if len(included_items) == 0:\n                    break\n                # Calculate value-to-weight ratios for included items\n                ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n                remove_idx = included_items[np.argmin(ratios)]\n                new_solution[remove_idx] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.8215477005119491,
            3.3074557185173035
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate potential improvement in both objectives\n            potential_value1 = np.sum(value1_lst * (1 - sol))  # Items not in solution\n            potential_value2 = np.sum(value2_lst * (1 - sol))\n            candidates.append((sol, obj, potential_value1, potential_value2))\n\n    if not candidates:\n        # If no candidates with remaining capacity, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select solution with highest combined potential improvement\n        base_solution, _, potential1, potential2 = max(candidates, key=lambda x: x[2] + x[3])\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    if np.random.rand() < 0.7:  # 70% chance for flip operation\n        # Flip operation: toggle a random item\n        flip_idx = np.random.randint(0, len(new_solution))\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight > capacity:\n            # Remove items randomly until feasible\n            while current_weight > capacity:\n                remove_candidates = np.where(new_solution == 1)[0]\n                if len(remove_candidates) == 0:\n                    break\n                remove_idx = np.random.choice(remove_candidates)\n                new_solution[remove_idx] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n    else:  # 30% chance for swap operation\n        # Swap operation: swap two items\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight > capacity:\n            # Remove items with lowest value-to-weight ratio until feasible\n            while current_weight > capacity:\n                included_items = np.where(new_solution == 1)[0]\n                if len(included_items) == 0:\n                    break\n                # Calculate value-to-weight ratios for included items\n                ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n                remove_idx = included_items[np.argmin(ratios)]\n                new_solution[remove_idx] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 245,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = random.choice(archive)\n    current_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    new_solution = current_solution.copy()\n\n    # Random swap: flip a random subset of items\n    num_swaps = min(3, len(new_solution))  # Limit the number of swaps\n    swap_indices = random.sample(range(len(new_solution)), num_swaps)\n\n    for idx in swap_indices:\n        # Flip the item and check feasibility\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement: try to add/remove items to improve both objectives\n    improved = True\n    while improved:\n        improved = False\n        # Try to add items that improve both objectives\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0 and (current_weight + weight_lst[i] <= capacity):\n                # Check if adding this item improves both objectives\n                if (value1_lst[i] > 0) and (value2_lst[i] > 0):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    improved = True\n                    break\n\n        # Try to remove items that are not improving both objectives\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Check if removing this item does not worsen both objectives\n                if (value1_lst[i] <= 0) and (value2_lst[i] <= 0):\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    improved = True\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.3663327661207617,
            2.0562231242656708
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = random.choice(archive)\n    current_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    new_solution = current_solution.copy()\n\n    # Random swap: flip a random subset of items\n    num_swaps = min(3, len(new_solution))  # Limit the number of swaps\n    swap_indices = random.sample(range(len(new_solution)), num_swaps)\n\n    for idx in swap_indices:\n        # Flip the item and check feasibility\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement: try to add/remove items to improve both objectives\n    improved = True\n    while improved:\n        improved = False\n        # Try to add items that improve both objectives\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0 and (current_weight + weight_lst[i] <= capacity):\n                # Check if adding this item improves both objectives\n                if (value1_lst[i] > 0) and (value2_lst[i] > 0):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    improved = True\n                    break\n\n        # Try to remove items that are not improving both objectives\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Check if removing this item does not worsen both objectives\n                if (value1_lst[i] <= 0) and (value2_lst[i] <= 0):\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    improved = True\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 246,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    potentials = []\n    for sol, (v1, v2) in archive:\n        # Simple heuristic: solutions with lower values have higher potential\n        max_v1 = max(obj[1][0] for obj in archive)\n        max_v2 = max(obj[1][1] for obj in archive)\n        potential = (max_v1 - v1) + (max_v2 - v2)\n        potentials.append(potential)\n\n    # Normalize potentials for selection probability\n    total_potential = sum(potentials)\n    if total_potential == 0:\n        probs = [1.0 / len(archive)] * len(archive)\n    else:\n        probs = [p / total_potential for p in potentials]\n\n    # Select base solution based on potential\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Random flip with probability based on potential\n    # 2. Targeted swap between items with high value ratios\n    new_solution = base_solution.copy()\n\n    # Random flip phase (higher probability for lower potential solutions)\n    flip_prob = min(0.5, 0.1 + (1 - probs[base_idx]) * 0.4)\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Targeted swap phase (swap items with high value ratios)\n    # Calculate value ratios for each objective\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Find items to consider for swap (those not in current solution)\n    candidate_items = np.where(new_solution == 0)[0]\n    if len(candidate_items) > 0:\n        # Select a candidate with high value ratio\n        candidate_ratios = ratio1[candidate_items] + ratio2[candidate_items]\n        selected_candidate = candidate_items[np.argmax(candidate_ratios)]\n\n        # Find item in solution to swap with\n        in_solution_items = np.where(new_solution == 1)[0]\n        if len(in_solution_items) > 0:\n            # Prefer items with lower value ratios to improve both objectives\n            in_solution_ratios = ratio1[in_solution_items] + ratio2[in_solution_items]\n            swap_item = in_solution_items[np.argmin(in_solution_ratios)]\n\n            # Check if swap is feasible\n            delta_weight = weight_lst[selected_candidate] - weight_lst[swap_item]\n            if current_weight + delta_weight <= capacity:\n                new_solution[swap_item] = 0\n                new_solution[selected_candidate] = 1\n                current_weight += delta_weight\n\n    return new_solution\n\n",
        "score": [
            -0.41038252597254354,
            1.1607472002506256
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    potentials = []\n    for sol, (v1, v2) in archive:\n        # Simple heuristic: solutions with lower values have higher potential\n        max_v1 = max(obj[1][0] for obj in archive)\n        max_v2 = max(obj[1][1] for obj in archive)\n        potential = (max_v1 - v1) + (max_v2 - v2)\n        potentials.append(potential)\n\n    # Normalize potentials for selection probability\n    total_potential = sum(potentials)\n    if total_potential == 0:\n        probs = [1.0 / len(archive)] * len(archive)\n    else:\n        probs = [p / total_potential for p in potentials]\n\n    # Select base solution based on potential\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Random flip with probability based on potential\n    # 2. Targeted swap between items with high value ratios\n    new_solution = base_solution.copy()\n\n    # Random flip phase (higher probability for lower potential solutions)\n    flip_prob = min(0.5, 0.1 + (1 - probs[base_idx]) * 0.4)\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Targeted swap phase (swap items with high value ratios)\n    # Calculate value ratios for each objective\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Find items to consider for swap (those not in current solution)\n    candidate_items = np.where(new_solution == 0)[0]\n    if len(candidate_items) > 0:\n        # Select a candidate with high value ratio\n        candidate_ratios = ratio1[candidate_items] + ratio2[candidate_items]\n        selected_candidate = candidate_items[np.argmax(candidate_ratios)]\n\n        # Find item in solution to swap with\n        in_solution_items = np.where(new_solution == 1)[0]\n        if len(in_solution_items) > 0:\n            # Prefer items with lower value ratios to improve both objectives\n            in_solution_ratios = ratio1[in_solution_items] + ratio2[in_solution_items]\n            swap_item = in_solution_items[np.argmin(in_solution_ratios)]\n\n            # Check if swap is feasible\n            delta_weight = weight_lst[selected_candidate] - weight_lst[swap_item]\n            if current_weight + delta_weight <= capacity:\n                new_solution[swap_item] = 0\n                new_solution[selected_candidate] = 1\n                current_weight += delta_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 247,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the boundary (avoid overfitting)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip items based on value ratios and weight adjustments\n    # Step 1: Randomly select a subset of items to consider flipping\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_idx = np.random.choice(flip_candidates)\n        # Flip the selected item (remove it)\n        new_solution[flip_idx] = 0\n        current_weight -= weight_lst[flip_idx]\n\n        # Step 2: Add items with high value-to-weight ratios that fit the remaining capacity\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate value-to-weight ratios for items not in the solution\n            value_ratio1 = value1_lst / weight_lst\n            value_ratio2 = value2_lst / weight_lst\n            combined_ratio = value_ratio1 + value_ratio2  # Balance both objectives\n\n            # Filter items that can fit and have the highest combined ratio\n            available_items = np.where(new_solution == 0)[0]\n            feasible_items = available_items[weight_lst[available_items] <= remaining_capacity]\n\n            if len(feasible_items) > 0:\n                best_item = feasible_items[np.argmax(combined_ratio[feasible_items])]\n                new_solution[best_item] = 1\n\n    # Ensure feasibility (should not be necessary due to construction, but safe)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If over capacity, remove items with lowest value-to-weight ratio\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove (should not happen due to initial checks)\n            # Remove the item with the lowest combined value-to-weight ratio\n            remove_idx = included_items[np.argmin(combined_ratio[included_items])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4407003646205198,
            8.038973808288574
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the boundary (avoid overfitting)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip items based on value ratios and weight adjustments\n    # Step 1: Randomly select a subset of items to consider flipping\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_idx = np.random.choice(flip_candidates)\n        # Flip the selected item (remove it)\n        new_solution[flip_idx] = 0\n        current_weight -= weight_lst[flip_idx]\n\n        # Step 2: Add items with high value-to-weight ratios that fit the remaining capacity\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate value-to-weight ratios for items not in the solution\n            value_ratio1 = value1_lst / weight_lst\n            value_ratio2 = value2_lst / weight_lst\n            combined_ratio = value_ratio1 + value_ratio2  # Balance both objectives\n\n            # Filter items that can fit and have the highest combined ratio\n            available_items = np.where(new_solution == 0)[0]\n            feasible_items = available_items[weight_lst[available_items] <= remaining_capacity]\n\n            if len(feasible_items) > 0:\n                best_item = feasible_items[np.argmax(combined_ratio[feasible_items])]\n                new_solution[best_item] = 1\n\n    # Ensure feasibility (should not be necessary due to construction, but safe)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If over capacity, remove items with lowest value-to-weight ratio\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove (should not happen due to initial checks)\n            # Remove the item with the lowest combined value-to-weight ratio\n            remove_idx = included_items[np.argmin(combined_ratio[included_items])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 248,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty\")\n\n    # Select a solution with high potential (top 30% by objective sum)\n    sorted_archive = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selection_pool = sorted_archive[:max(1, len(sorted_archive) // 3)]\n    base_solution, _ = random.choice(selection_pool)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: swap-and-flip operator\n    n_items = len(weight_lst)\n    if n_items <= 1:\n        return new_solution\n\n    # Randomly select a subset of items to flip\n    flip_mask = np.random.choice([0, 1], size=n_items, p=[0.7, 0.3])\n    candidate = new_solution ^ flip_mask\n\n    # Calculate current and candidate weights\n    current_weight = np.sum(weight_lst * new_solution)\n    candidate_weight = np.sum(weight_lst * candidate)\n\n    # If feasible, return candidate\n    if candidate_weight <= capacity:\n        return candidate\n\n    # If not feasible, perform a swap to restore feasibility\n    excess = candidate_weight - capacity\n    # Find items that are in candidate but not in original (flipped items)\n    flipped_items = np.where(flip_mask == 1)[0]\n\n    # Try to remove items from the flipped subset until feasible\n    for item in np.random.permutation(flipped_items):\n        if candidate[item] == 1 and (current_weight - weight_lst[item]) <= capacity:\n            candidate[item] = 0\n            if np.sum(weight_lst * candidate) <= capacity:\n                return candidate\n\n    # If still not feasible, try to swap with another item\n    for item in np.random.permutation(flipped_items):\n        if candidate[item] == 1:\n            # Find a candidate to swap with (not in solution)\n            swap_candidates = np.where((new_solution == 0) &\n                                     (weight_lst <= weight_lst[item] + excess))[0]\n            if len(swap_candidates) > 0:\n                swap_item = np.random.choice(swap_candidates)\n                candidate[item] = 0\n                candidate[swap_item] = 1\n                if np.sum(weight_lst * candidate) <= capacity:\n                    return candidate\n\n    # If all else fails, return the original solution\n    return new_solution\n\n",
        "score": [
            -0.32141592068748065,
            1.7565708458423615
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty\")\n\n    # Select a solution with high potential (top 30% by objective sum)\n    sorted_archive = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n    selection_pool = sorted_archive[:max(1, len(sorted_archive) // 3)]\n    base_solution, _ = random.choice(selection_pool)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: swap-and-flip operator\n    n_items = len(weight_lst)\n    if n_items <= 1:\n        return new_solution\n\n    # Randomly select a subset of items to flip\n    flip_mask = np.random.choice([0, 1], size=n_items, p=[0.7, 0.3])\n    candidate = new_solution ^ flip_mask\n\n    # Calculate current and candidate weights\n    current_weight = np.sum(weight_lst * new_solution)\n    candidate_weight = np.sum(weight_lst * candidate)\n\n    # If feasible, return candidate\n    if candidate_weight <= capacity:\n        return candidate\n\n    # If not feasible, perform a swap to restore feasibility\n    excess = candidate_weight - capacity\n    # Find items that are in candidate but not in original (flipped items)\n    flipped_items = np.where(flip_mask == 1)[0]\n\n    # Try to remove items from the flipped subset until feasible\n    for item in np.random.permutation(flipped_items):\n        if candidate[item] == 1 and (current_weight - weight_lst[item]) <= capacity:\n            candidate[item] = 0\n            if np.sum(weight_lst * candidate) <= capacity:\n                return candidate\n\n    # If still not feasible, try to swap with another item\n    for item in np.random.permutation(flipped_items):\n        if candidate[item] == 1:\n            # Find a candidate to swap with (not in solution)\n            swap_candidates = np.where((new_solution == 0) &\n                                     (weight_lst <= weight_lst[item] + excess))[0]\n            if len(swap_candidates) > 0:\n                swap_item = np.random.choice(swap_candidates)\n                candidate[item] = 0\n                candidate[swap_item] = 1\n                if np.sum(weight_lst * candidate) <= capacity:\n                    return candidate\n\n    # If all else fails, return the original solution\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 249,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a higher probability of being non-dominated\n    # Here, we use a simple heuristic: select a solution with a balanced objective trade-off\n    # Alternatively, you could use other criteria like diversity or crowding distance\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (1 + i) for i in range(len(archive))])[0]\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly swap a subset of items\n    if len(new_solution) > 1:\n        num_swaps = min(3, len(new_solution) - 1)\n        indices = random.sample(range(len(new_solution)), num_swaps)\n        for i in indices:\n            new_solution[i] = 1 - new_solution[i]\n\n    # 2. Swap items with high value-to-weight ratios for both objectives\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Select items with high value-to-weight ratio in either objective\n    high_value_items1 = np.where(value_weight_ratio1 > np.percentile(value_weight_ratio1, 75))[0]\n    high_value_items2 = np.where(value_weight_ratio2 > np.percentile(value_weight_ratio2, 75))[0]\n\n    # Swap items in high-value categories\n    if len(high_value_items1) > 0 and len(high_value_items2) > 0:\n        item1 = random.choice(high_value_items1)\n        item2 = random.choice(high_value_items2)\n        new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    # 3. Adjust weight to stay within capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items with low value-to-weight ratio until feasible\n        low_value_items = np.argsort(value_weight_ratio1 + value_weight_ratio2)\n        for item in low_value_items:\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                new_weight -= weight_lst[item]\n                if new_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.334686273484623,
            1.8700880706310272
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a higher probability of being non-dominated\n    # Here, we use a simple heuristic: select a solution with a balanced objective trade-off\n    # Alternatively, you could use other criteria like diversity or crowding distance\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (1 + i) for i in range(len(archive))])[0]\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly swap a subset of items\n    if len(new_solution) > 1:\n        num_swaps = min(3, len(new_solution) - 1)\n        indices = random.sample(range(len(new_solution)), num_swaps)\n        for i in indices:\n            new_solution[i] = 1 - new_solution[i]\n\n    # 2. Swap items with high value-to-weight ratios for both objectives\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Select items with high value-to-weight ratio in either objective\n    high_value_items1 = np.where(value_weight_ratio1 > np.percentile(value_weight_ratio1, 75))[0]\n    high_value_items2 = np.where(value_weight_ratio2 > np.percentile(value_weight_ratio2, 75))[0]\n\n    # Swap items in high-value categories\n    if len(high_value_items1) > 0 and len(high_value_items2) > 0:\n        item1 = random.choice(high_value_items1)\n        item2 = random.choice(high_value_items2)\n        new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    # 3. Adjust weight to stay within capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items with low value-to-weight ratio until feasible\n        low_value_items = np.argsort(value_weight_ratio1 + value_weight_ratio2)\n        for item in low_value_items:\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                new_weight -= weight_lst[item]\n                if new_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 250,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select the solution with the highest potential for improvement (e.g., low value but high weight margin)\n    def potential_score(sol_obj_pair):\n        sol, (val1, val2) = sol_obj_pair\n        total_weight = np.sum(weight_lst * sol)\n        weight_margin = capacity - total_weight\n        # Prefer solutions with high weight margin and low value (potential to add more items)\n        return weight_margin - 0.5 * (val1 + val2)\n\n    # Sort archive by potential score and select top candidates\n    sorted_archive = sorted(archive, key=potential_score, reverse=True)\n    candidates = sorted_archive[:max(3, len(archive) // 3)]  # Top 1/3 or 3, whichever is larger\n    base_solution, _ = random.choice(candidates)\n\n    # Hybrid local search strategy: combination of single-bit flip and multi-bit flip\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # First, try a single-bit flip (add or remove an item)\n    for _ in range(10):  # Try up to 10 random single-bit flips\n        idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[idx] == 1:\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                break\n        else:\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                break\n\n    # Then, try a multi-bit flip (add/remove multiple items)\n    if random.random() < 0.3:  # 30% chance to perform multi-bit flip\n        num_flips = min(3, len(weight_lst) // 2)  # Flip up to 3 or half the items\n        for _ in range(num_flips):\n            idx = random.randint(0, len(weight_lst) - 1)\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7382590307619018,
            1.1899296343326569
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select the solution with the highest potential for improvement (e.g., low value but high weight margin)\n    def potential_score(sol_obj_pair):\n        sol, (val1, val2) = sol_obj_pair\n        total_weight = np.sum(weight_lst * sol)\n        weight_margin = capacity - total_weight\n        # Prefer solutions with high weight margin and low value (potential to add more items)\n        return weight_margin - 0.5 * (val1 + val2)\n\n    # Sort archive by potential score and select top candidates\n    sorted_archive = sorted(archive, key=potential_score, reverse=True)\n    candidates = sorted_archive[:max(3, len(archive) // 3)]  # Top 1/3 or 3, whichever is larger\n    base_solution, _ = random.choice(candidates)\n\n    # Hybrid local search strategy: combination of single-bit flip and multi-bit flip\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # First, try a single-bit flip (add or remove an item)\n    for _ in range(10):  # Try up to 10 random single-bit flips\n        idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[idx] == 1:\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                break\n        else:\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                break\n\n    # Then, try a multi-bit flip (add/remove multiple items)\n    if random.random() < 0.3:  # 30% chance to perform multi-bit flip\n        num_flips = min(3, len(weight_lst) // 2)  # Flip up to 3 or half the items\n        for _ in range(num_flips):\n            idx = random.randint(0, len(weight_lst) - 1)\n            if new_solution[idx] == 1:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n            else:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 251,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        # If all solutions are dominated, fall back to random selection\n        selected = random.choice(archive)[0]\n    else:\n        # Select a random non-dominated solution\n        selected = random.choice(non_dominated)[0]\n\n    base_solution = selected.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    # Try to add items that improve both objectives\n    excluded_items = np.where(new_solution == 0)[0]\n    for item in excluded_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[item]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[item]\n            if (new_value1 > np.sum(value1_lst * new_solution) and\n                new_value2 > np.sum(value2_lst * new_solution)):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item per iteration to maintain diversity\n\n    # If no addition was made, try to remove items that are least critical\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate criticality for each included item (lower criticality is better to remove)\n            criticality = []\n            for item in included_items:\n                # Criticality is based on how much we lose in both objectives if we remove this item\n                criticality_value = (value1_lst[item] + value2_lst[item]) / weight_lst[item]\n                criticality.append((criticality_value, item))\n\n            # Remove the item with lowest criticality\n            if criticality:\n                _, worst_item = min(criticality)\n                new_solution[worst_item] = 0\n\n    # If still no change, perform a random swap\n    if np.array_equal(new_solution, base_solution):\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Randomly select one item to remove and one to add\n            remove_item = random.choice(included)\n            add_item = random.choice(excluded)\n\n            # Check if the swap is feasible\n            if current_weight - weight_lst[remove_item] + weight_lst[add_item] <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8780178064889497,
            1.146210789680481
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        # If all solutions are dominated, fall back to random selection\n        selected = random.choice(archive)[0]\n    else:\n        # Select a random non-dominated solution\n        selected = random.choice(non_dominated)[0]\n\n    base_solution = selected.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    # Try to add items that improve both objectives\n    excluded_items = np.where(new_solution == 0)[0]\n    for item in excluded_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[item]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[item]\n            if (new_value1 > np.sum(value1_lst * new_solution) and\n                new_value2 > np.sum(value2_lst * new_solution)):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item per iteration to maintain diversity\n\n    # If no addition was made, try to remove items that are least critical\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate criticality for each included item (lower criticality is better to remove)\n            criticality = []\n            for item in included_items:\n                # Criticality is based on how much we lose in both objectives if we remove this item\n                criticality_value = (value1_lst[item] + value2_lst[item]) / weight_lst[item]\n                criticality.append((criticality_value, item))\n\n            # Remove the item with lowest criticality\n            if criticality:\n                _, worst_item = min(criticality)\n                new_solution[worst_item] = 0\n\n    # If still no change, perform a random swap\n    if np.array_equal(new_solution, base_solution):\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Randomly select one item to remove and one to add\n            remove_item = random.choice(included)\n            add_item = random.choice(excluded)\n\n            # Check if the swap is feasible\n            if current_weight - weight_lst[remove_item] + weight_lst[add_item] <= capacity:\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 252,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty\")\n\n    # Step 1: Select a promising solution (high diversity in objectives)\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Normalize objectives to select solutions with high diversity\n        normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        diversity_scores = np.sum(normalized, axis=1)\n        selected_idx = np.argmax(diversity_scores)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Novel local search operator\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst - np.mean(value1_lst)\n    marginal_value2 = value2_lst - np.mean(value2_lst)\n    combined_marginal = marginal_value1 + marginal_value2  # Simple combination for this example\n\n    # Select items to flip based on marginal contribution and current solution\n    candidate_indices = np.where(new_solution == 1)[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.arange(len(weight_lst))\n\n    # Randomly select a subset of items to consider for flipping\n    subset_size = min(5, len(candidate_indices))\n    selected_indices = np.random.choice(candidate_indices, size=subset_size, replace=False)\n\n    for idx in selected_indices:\n        # Try flipping the item\n        if new_solution[idx] == 1:\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight <= capacity:\n                # Accept the flip if it improves at least one objective\n                new_solution[idx] = 0\n                current_weight = temp_weight\n        else:\n            temp_weight = current_weight + weight_lst[idx]\n            if temp_weight <= capacity:\n                # Accept the flip if it improves at least one objective\n                new_solution[idx] = 1\n                current_weight = temp_weight\n\n    # Step 3: Ensure feasibility (redundant but safe)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, randomly remove items until feasible\n        while total_weight > capacity:\n            included = np.where(new_solution == 1)[0]\n            if len(included) == 0:\n                break\n            remove_idx = np.random.choice(included)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7698579985048454,
            1.2723955512046814
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive cannot be empty\")\n\n    # Step 1: Select a promising solution (high diversity in objectives)\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Normalize objectives to select solutions with high diversity\n        normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        diversity_scores = np.sum(normalized, axis=1)\n        selected_idx = np.argmax(diversity_scores)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Novel local search operator\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst - np.mean(value1_lst)\n    marginal_value2 = value2_lst - np.mean(value2_lst)\n    combined_marginal = marginal_value1 + marginal_value2  # Simple combination for this example\n\n    # Select items to flip based on marginal contribution and current solution\n    candidate_indices = np.where(new_solution == 1)[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.arange(len(weight_lst))\n\n    # Randomly select a subset of items to consider for flipping\n    subset_size = min(5, len(candidate_indices))\n    selected_indices = np.random.choice(candidate_indices, size=subset_size, replace=False)\n\n    for idx in selected_indices:\n        # Try flipping the item\n        if new_solution[idx] == 1:\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight <= capacity:\n                # Accept the flip if it improves at least one objective\n                new_solution[idx] = 0\n                current_weight = temp_weight\n        else:\n            temp_weight = current_weight + weight_lst[idx]\n            if temp_weight <= capacity:\n                # Accept the flip if it improves at least one objective\n                new_solution[idx] = 1\n                current_weight = temp_weight\n\n    # Step 3: Ensure feasibility (redundant but safe)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, randomly remove items until feasible\n        while total_weight > capacity:\n            included = np.where(new_solution == 1)[0]\n            if len(included) == 0:\n                break\n            remove_idx = np.random.choice(included)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 253,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their total value (sum of both objectives) to find the most promising one\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        base_solution = archive_sorted[0][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on a combination of value-to-weight ratio and randomness\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.5:  # 50% chance to consider flipping\n            if new_solution[i] == 1:\n                # Remove item if it's not critical (low value-to-weight ratio)\n                value_ratio1 = value1_lst[i] / weight_lst[i]\n                value_ratio2 = value2_lst[i] / weight_lst[i]\n                if value_ratio1 < 0.5 or value_ratio2 < 0.5:\n                    new_solution[i] = 0\n            else:\n                # Add item if it fits and has high value-to-weight ratio\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    value_ratio1 = value1_lst[i] / weight_lst[i]\n                    value_ratio2 = value2_lst[i] / weight_lst[i]\n                    if value_ratio1 > 1.0 or value_ratio2 > 1.0:\n                        new_solution[i] = 1\n\n    # Additional local search: swap two items if it improves both objectives\n    if len(new_solution) >= 2:\n        for _ in range(5):  # Try up to 5 random swaps\n            i, j = np.random.choice(len(new_solution), 2, replace=False)\n            if new_solution[i] != new_solution[j]:\n                temp = new_solution.copy()\n                temp[i], temp[j] = temp[j], temp[i]\n                if np.sum(weight_lst[temp == 1]) <= capacity:\n                    # Check if swap improves both objectives\n                    old_value1 = np.sum(value1_lst[new_solution == 1])\n                    old_value2 = np.sum(value2_lst[new_solution == 1])\n                    new_value1 = np.sum(value1_lst[temp == 1])\n                    new_value2 = np.sum(value2_lst[temp == 1])\n                    if (new_value1 > old_value1 and new_value2 > old_value2) or \\\n                       (new_value1 >= old_value1 and new_value2 > old_value2) or \\\n                       (new_value1 > old_value1 and new_value2 >= old_value2):\n                        new_solution = temp\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.33734972869251967,
            8.058798730373383
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their total value (sum of both objectives) to find the most promising one\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        base_solution = archive_sorted[0][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on a combination of value-to-weight ratio and randomness\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.5:  # 50% chance to consider flipping\n            if new_solution[i] == 1:\n                # Remove item if it's not critical (low value-to-weight ratio)\n                value_ratio1 = value1_lst[i] / weight_lst[i]\n                value_ratio2 = value2_lst[i] / weight_lst[i]\n                if value_ratio1 < 0.5 or value_ratio2 < 0.5:\n                    new_solution[i] = 0\n            else:\n                # Add item if it fits and has high value-to-weight ratio\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    value_ratio1 = value1_lst[i] / weight_lst[i]\n                    value_ratio2 = value2_lst[i] / weight_lst[i]\n                    if value_ratio1 > 1.0 or value_ratio2 > 1.0:\n                        new_solution[i] = 1\n\n    # Additional local search: swap two items if it improves both objectives\n    if len(new_solution) >= 2:\n        for _ in range(5):  # Try up to 5 random swaps\n            i, j = np.random.choice(len(new_solution), 2, replace=False)\n            if new_solution[i] != new_solution[j]:\n                temp = new_solution.copy()\n                temp[i], temp[j] = temp[j], temp[i]\n                if np.sum(weight_lst[temp == 1]) <= capacity:\n                    # Check if swap improves both objectives\n                    old_value1 = np.sum(value1_lst[new_solution == 1])\n                    old_value2 = np.sum(value2_lst[new_solution == 1])\n                    new_value1 = np.sum(value1_lst[temp == 1])\n                    new_value2 = np.sum(value2_lst[temp == 1])\n                    if (new_value1 > old_value1 and new_value2 > old_value2) or \\\n                       (new_value1 >= old_value1 and new_value2 > old_value2) or \\\n                       (new_value1 > old_value1 and new_value2 >= old_value2):\n                        new_solution = temp\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 254,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Prioritize solutions with high marginal potential\n            marginal_v1 = np.sum(value1_lst * (1 - sol))\n            marginal_v2 = np.sum(value2_lst * (1 - sol))\n            candidates.append((sol, v1, v2, marginal_v1, marginal_v2))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select a candidate with high marginal potential\n    candidate = max(candidates, key=lambda x: (x[3] + x[4]) / (1e-6 + np.sum(weight_lst * (1 - x[0]))))\n    base_solution = candidate[0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal value-to-weight ratio\n    for _ in range(min(5, len(weight_lst))):  # Limit the number of flips\n        # Calculate marginal value-to-weight ratios for excluded items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) == 0:\n            break\n\n        ratios_v1 = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        ratios_v2 = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Combine ratios for both objectives\n        combined_ratios = (ratios_v1 + ratios_v2) / 2\n\n        # Select items to flip based on combined ratio and randomness\n        item_to_flip = random.choices(\n            excluded_items,\n            weights=combined_ratios,\n            k=1\n        )[0]\n\n        # Check feasibility of adding the item\n        if np.sum(weight_lst * new_solution) + weight_lst[item_to_flip] <= capacity:\n            new_solution[item_to_flip] = 1\n\n    # Optional: Randomly flip some included items to escape local optima\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0 and random.random() < 0.3:\n        item_to_remove = random.choice(included_items)\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7747928532765063,
            5.305067092180252
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Prioritize solutions with high marginal potential\n            marginal_v1 = np.sum(value1_lst * (1 - sol))\n            marginal_v2 = np.sum(value2_lst * (1 - sol))\n            candidates.append((sol, v1, v2, marginal_v1, marginal_v2))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select a candidate with high marginal potential\n    candidate = max(candidates, key=lambda x: (x[3] + x[4]) / (1e-6 + np.sum(weight_lst * (1 - x[0]))))\n    base_solution = candidate[0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal value-to-weight ratio\n    for _ in range(min(5, len(weight_lst))):  # Limit the number of flips\n        # Calculate marginal value-to-weight ratios for excluded items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) == 0:\n            break\n\n        ratios_v1 = value1_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n        ratios_v2 = value2_lst[excluded_items] / (weight_lst[excluded_items] + 1e-6)\n\n        # Combine ratios for both objectives\n        combined_ratios = (ratios_v1 + ratios_v2) / 2\n\n        # Select items to flip based on combined ratio and randomness\n        item_to_flip = random.choices(\n            excluded_items,\n            weights=combined_ratios,\n            k=1\n        )[0]\n\n        # Check feasibility of adding the item\n        if np.sum(weight_lst * new_solution) + weight_lst[item_to_flip] <= capacity:\n            new_solution[item_to_flip] = 1\n\n    # Optional: Randomly flip some included items to escape local optima\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0 and random.random() < 0.3:\n        item_to_remove = random.choice(included_items)\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 255,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution from the crowded region\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Find the most crowded region (using simple grid-based approach)\n        min_vals = np.min(objectives, axis=0)\n        max_vals = np.max(objectives, axis=0)\n        grid_size = 5  # Adjust based on problem size\n        grid_counts = np.zeros((grid_size, grid_size))\n\n        for obj in objectives:\n            x_idx = min(int((obj[0] - min_vals[0]) / (max_vals[0] - min_vals[0] + 1e-6) * grid_size), grid_size - 1)\n            y_idx = min(int((obj[1] - min_vals[1]) / (max_vals[1] - min_vals[1] + 1e-6) * grid_size), grid_size - 1)\n            grid_counts[x_idx, y_idx] += 1\n\n        # Select from the most crowded cell\n        crowded_cells = np.argwhere(grid_counts == np.max(grid_counts))\n        if len(crowded_cells) > 0:\n            cell = random.choice(crowded_cells)\n            candidates = [sol for sol, obj in archive\n                         if (int((obj[0] - min_vals[0]) / (max_vals[0] - min_vals[0] + 1e-6) * grid_size) == cell[0] and\n                             int((obj[1] - min_vals[1]) / (max_vals[1] - min_vals[1] + 1e-6) * grid_size) == cell[1])]\n            if candidates:\n                base_solution = random.choice(candidates)\n            else:\n                base_solution = random.choice(archive)[0]\n        else:\n            base_solution = random.choice(archive)[0]\n    else:\n        base_solution = archive[0][0]\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Calculate value-to-weight ratios for all items\n    value_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_ratio1 + value_ratio2  # Simple combination of both objectives\n\n    # Sort items by combined ratio (descending)\n    sorted_items = np.argsort(-combined_ratio)\n\n    # Try to add items with highest combined ratio first\n    for item in sorted_items:\n        if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n            current_value1 += value1_lst[item]\n            current_value2 += value2_lst[item]\n\n    # Then try to remove items with lowest combined ratio\n    for item in reversed(sorted_items):\n        if new_solution[item] == 1:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            current_value1 -= value1_lst[item]\n            current_value2 -= value2_lst[item]\n\n    # Random flip with probability based on crowding\n    for _ in range(min(5, len(new_solution))):  # Limit number of flips\n        item = random.randint(0, len(new_solution) - 1)\n        if new_solution[item] == 1:\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8234246506564318,
            2.30629625916481
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution from the crowded region\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) > 1:\n        # Find the most crowded region (using simple grid-based approach)\n        min_vals = np.min(objectives, axis=0)\n        max_vals = np.max(objectives, axis=0)\n        grid_size = 5  # Adjust based on problem size\n        grid_counts = np.zeros((grid_size, grid_size))\n\n        for obj in objectives:\n            x_idx = min(int((obj[0] - min_vals[0]) / (max_vals[0] - min_vals[0] + 1e-6) * grid_size), grid_size - 1)\n            y_idx = min(int((obj[1] - min_vals[1]) / (max_vals[1] - min_vals[1] + 1e-6) * grid_size), grid_size - 1)\n            grid_counts[x_idx, y_idx] += 1\n\n        # Select from the most crowded cell\n        crowded_cells = np.argwhere(grid_counts == np.max(grid_counts))\n        if len(crowded_cells) > 0:\n            cell = random.choice(crowded_cells)\n            candidates = [sol for sol, obj in archive\n                         if (int((obj[0] - min_vals[0]) / (max_vals[0] - min_vals[0] + 1e-6) * grid_size) == cell[0] and\n                             int((obj[1] - min_vals[1]) / (max_vals[1] - min_vals[1] + 1e-6) * grid_size) == cell[1])]\n            if candidates:\n                base_solution = random.choice(candidates)\n            else:\n                base_solution = random.choice(archive)[0]\n        else:\n            base_solution = random.choice(archive)[0]\n    else:\n        base_solution = archive[0][0]\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Calculate value-to-weight ratios for all items\n    value_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_ratio1 + value_ratio2  # Simple combination of both objectives\n\n    # Sort items by combined ratio (descending)\n    sorted_items = np.argsort(-combined_ratio)\n\n    # Try to add items with highest combined ratio first\n    for item in sorted_items:\n        if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n            current_value1 += value1_lst[item]\n            current_value2 += value2_lst[item]\n\n    # Then try to remove items with lowest combined ratio\n    for item in reversed(sorted_items):\n        if new_solution[item] == 1:\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            current_value1 -= value1_lst[item]\n            current_value2 -= value2_lst[item]\n\n    # Random flip with probability based on crowding\n    for _ in range(min(5, len(new_solution))):  # Limit number of flips\n        item = random.randint(0, len(new_solution) - 1)\n        if new_solution[item] == 1:\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 256,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, obj in archive:\n        # Calculate the total weight and values\n        total_weight = np.sum(sol * weight_lst)\n        total_value1 = np.sum(sol * value1_lst)\n        total_value2 = np.sum(sol * value2_lst)\n\n        # Check if the solution is feasible and has potential for improvement\n        if total_weight <= capacity:\n            # Calculate the \"improvement potential\" as the sum of the marginal values\n            marginal_value1 = np.sum((1 - sol) * value1_lst)\n            marginal_value2 = np.sum((1 - sol) * value2_lst)\n            potential = marginal_value1 + marginal_value2\n            candidates.append((sol, potential))\n\n    if not candidates:\n        # If no candidates, return a random solution from the archive\n        return archive[np.random.randint(len(archive))][0].copy()\n\n    # Sort candidates by potential and select the top 20% with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 5)]\n    base_solution = top_candidates[np.random.randint(len(top_candidates))][0].copy()\n\n    # Hybrid local search: combine flip-based and swap-based moves\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Flip-based move (add/remove one item)\n    for _ in range(5):  # Try up to 5 random flips\n        idx = np.random.randint(n_items)\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n        else:\n            # Try to add the item\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Swap-based move (swap two items)\n    for _ in range(3):  # Try up to 3 random swaps\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            # Calculate the change in weight\n            weight_diff = (weight_lst[idx2] - weight_lst[idx1]) if new_solution[idx1] else (weight_lst[idx1] - weight_lst[idx2])\n            if np.sum(new_solution * weight_lst) + weight_diff <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Step 3: Objective-biased move (try to improve one objective while keeping the other stable)\n    if np.random.random() < 0.3:  # 30% chance for this move\n        # Choose which objective to prioritize\n        if np.random.random() < 0.5:\n            # Prioritize value1\n            candidate_items = np.where((1 - new_solution) * value1_lst > 0)[0]\n        else:\n            # Prioritize value2\n            candidate_items = np.where((1 - new_solution) * value2_lst > 0)[0]\n\n        if len(candidate_items) > 0:\n            # Select the best candidate item to add\n            best_item = candidate_items[np.argmax((1 - new_solution)[candidate_items] *\n                                                (value1_lst[candidate_items] + value2_lst[candidate_items]))]\n            if np.sum(new_solution * weight_lst) + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8126266983794097,
            5.621484190225601
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, obj in archive:\n        # Calculate the total weight and values\n        total_weight = np.sum(sol * weight_lst)\n        total_value1 = np.sum(sol * value1_lst)\n        total_value2 = np.sum(sol * value2_lst)\n\n        # Check if the solution is feasible and has potential for improvement\n        if total_weight <= capacity:\n            # Calculate the \"improvement potential\" as the sum of the marginal values\n            marginal_value1 = np.sum((1 - sol) * value1_lst)\n            marginal_value2 = np.sum((1 - sol) * value2_lst)\n            potential = marginal_value1 + marginal_value2\n            candidates.append((sol, potential))\n\n    if not candidates:\n        # If no candidates, return a random solution from the archive\n        return archive[np.random.randint(len(archive))][0].copy()\n\n    # Sort candidates by potential and select the top 20% with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 5)]\n    base_solution = top_candidates[np.random.randint(len(top_candidates))][0].copy()\n\n    # Hybrid local search: combine flip-based and swap-based moves\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Flip-based move (add/remove one item)\n    for _ in range(5):  # Try up to 5 random flips\n        idx = np.random.randint(n_items)\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n        else:\n            # Try to add the item\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Swap-based move (swap two items)\n    for _ in range(3):  # Try up to 3 random swaps\n        idx1, idx2 = np.random.choice(n_items, 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            # Calculate the change in weight\n            weight_diff = (weight_lst[idx2] - weight_lst[idx1]) if new_solution[idx1] else (weight_lst[idx1] - weight_lst[idx2])\n            if np.sum(new_solution * weight_lst) + weight_diff <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Step 3: Objective-biased move (try to improve one objective while keeping the other stable)\n    if np.random.random() < 0.3:  # 30% chance for this move\n        # Choose which objective to prioritize\n        if np.random.random() < 0.5:\n            # Prioritize value1\n            candidate_items = np.where((1 - new_solution) * value1_lst > 0)[0]\n        else:\n            # Prioritize value2\n            candidate_items = np.where((1 - new_solution) * value2_lst > 0)[0]\n\n        if len(candidate_items) > 0:\n            # Select the best candidate item to add\n            best_item = candidate_items[np.argmax((1 - new_solution)[candidate_items] *\n                                                (value1_lst[candidate_items] + value2_lst[candidate_items]))]\n            if np.sum(new_solution * weight_lst) + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 257,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too close to the Pareto front\n    # This encourages exploration of less-explored regions\n    base_solution, _ = random.choice(archive)\n    current_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Determine the number of items to consider for flipping (between 1 and 10% of items)\n    n_items = len(weight_lst)\n    max_flips = max(1, int(0.1 * n_items))\n    num_flips = random.randint(1, max_flips)\n\n    # Create a candidate list of items to flip (either included or excluded)\n    candidate_indices = np.where(current_solution == 1)[0] if random.random() < 0.5 else np.where(current_solution == 0)[0]\n\n    # If no candidates, just flip a random item\n    if len(candidate_indices) == 0:\n        candidate_indices = np.arange(n_items)\n\n    # Select items to flip based on a combination of randomness and value-to-weight ratio\n    flip_indices = random.sample(list(candidate_indices), min(num_flips, len(candidate_indices)))\n\n    # Calculate the potential change in weight and values\n    for idx in flip_indices:\n        if current_solution[idx] == 1:\n            # If item is included, try to exclude it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                current_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[idx] <= capacity:\n                current_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a value-based greedy improvement step\n    # For each item, consider flipping it if it improves either objective\n    for idx in range(n_items):\n        if current_solution[idx] == 1:\n            # Try excluding the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate the change in objectives\n                delta_value1 = -value1_lst[idx]\n                delta_value2 = -value2_lst[idx]\n\n                # Only flip if it doesn't worsen both objectives\n                if not (delta_value1 < 0 and delta_value2 < 0):\n                    current_solution[idx] = 0\n                    current_weight = new_weight\n        else:\n            # Try including the item\n            if current_weight + weight_lst[idx] <= capacity:\n                # Calculate the change in objectives\n                delta_value1 = value1_lst[idx]\n                delta_value2 = value2_lst[idx]\n\n                # Only flip if it improves at least one objective\n                if delta_value1 > 0 or delta_value2 > 0:\n                    current_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return current_solution\n\n",
        "score": [
            -0.4438774972739147,
            4.7439627051353455
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too close to the Pareto front\n    # This encourages exploration of less-explored regions\n    base_solution, _ = random.choice(archive)\n    current_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Determine the number of items to consider for flipping (between 1 and 10% of items)\n    n_items = len(weight_lst)\n    max_flips = max(1, int(0.1 * n_items))\n    num_flips = random.randint(1, max_flips)\n\n    # Create a candidate list of items to flip (either included or excluded)\n    candidate_indices = np.where(current_solution == 1)[0] if random.random() < 0.5 else np.where(current_solution == 0)[0]\n\n    # If no candidates, just flip a random item\n    if len(candidate_indices) == 0:\n        candidate_indices = np.arange(n_items)\n\n    # Select items to flip based on a combination of randomness and value-to-weight ratio\n    flip_indices = random.sample(list(candidate_indices), min(num_flips, len(candidate_indices)))\n\n    # Calculate the potential change in weight and values\n    for idx in flip_indices:\n        if current_solution[idx] == 1:\n            # If item is included, try to exclude it\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                current_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try to include it\n            if current_weight + weight_lst[idx] <= capacity:\n                current_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a value-based greedy improvement step\n    # For each item, consider flipping it if it improves either objective\n    for idx in range(n_items):\n        if current_solution[idx] == 1:\n            # Try excluding the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                # Calculate the change in objectives\n                delta_value1 = -value1_lst[idx]\n                delta_value2 = -value2_lst[idx]\n\n                # Only flip if it doesn't worsen both objectives\n                if not (delta_value1 < 0 and delta_value2 < 0):\n                    current_solution[idx] = 0\n                    current_weight = new_weight\n        else:\n            # Try including the item\n            if current_weight + weight_lst[idx] <= capacity:\n                # Calculate the change in objectives\n                delta_value1 = value1_lst[idx]\n                delta_value2 = value2_lst[idx]\n\n                # Only flip if it improves at least one objective\n                if delta_value1 > 0 or delta_value2 > 0:\n                    current_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return current_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 258,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a higher probability for those with higher combined value\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor by performing a random swap with value-based consideration\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped (either in or out)\n    candidates_in = np.where(base_solution == 0)[0]\n    candidates_out = np.where(base_solution == 1)[0]\n\n    # If no candidates for swap, return the base solution\n    if len(candidates_in) == 0 or len(candidates_out) == 0:\n        return base_solution\n\n    # Select items to swap: one from candidates_in and one from candidates_out\n    item_in = np.random.choice(candidates_in)\n    item_out = np.random.choice(candidates_out)\n\n    # Check if swapping is feasible\n    delta_weight = weight_lst[item_in] - weight_lst[item_out]\n    if current_weight + delta_weight <= capacity:\n        new_solution[item_in] = 1\n        new_solution[item_out] = 0\n\n        # Perform value-based local improvement\n        improved = True\n        while improved:\n            improved = False\n            # Try to add items that improve both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            for item in remaining_items:\n                if current_weight + weight_lst[item] <= capacity:\n                    # Calculate potential new objectives\n                    new_value1 = current_obj[0] + value1_lst[item]\n                    new_value2 = current_obj[1] + value2_lst[item]\n                    # If both objectives improve, add the item\n                    if new_value1 > current_obj[0] and new_value2 > current_obj[1]:\n                        new_solution[item] = 1\n                        current_obj = (new_value1, new_value2)\n                        current_weight += weight_lst[item]\n                        improved = True\n                        break\n            # Try to remove items that don't contribute to both objectives\n            selected_items = np.where(new_solution == 1)[0]\n            for item in selected_items:\n                # Check if removing this item would keep both objectives non-worse\n                if (current_obj[0] - value1_lst[item] >= current_obj[0] and\n                    current_obj[1] - value2_lst[item] >= current_obj[1]):\n                    new_solution[item] = 0\n                    current_obj = (current_obj[0] - value1_lst[item],\n                                 current_obj[1] - value2_lst[item])\n                    current_weight -= weight_lst[item]\n                    improved = True\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.3195376251303344,
            2.827159732580185
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a higher probability for those with higher combined value\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor by performing a random swap with value-based consideration\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped (either in or out)\n    candidates_in = np.where(base_solution == 0)[0]\n    candidates_out = np.where(base_solution == 1)[0]\n\n    # If no candidates for swap, return the base solution\n    if len(candidates_in) == 0 or len(candidates_out) == 0:\n        return base_solution\n\n    # Select items to swap: one from candidates_in and one from candidates_out\n    item_in = np.random.choice(candidates_in)\n    item_out = np.random.choice(candidates_out)\n\n    # Check if swapping is feasible\n    delta_weight = weight_lst[item_in] - weight_lst[item_out]\n    if current_weight + delta_weight <= capacity:\n        new_solution[item_in] = 1\n        new_solution[item_out] = 0\n\n        # Perform value-based local improvement\n        improved = True\n        while improved:\n            improved = False\n            # Try to add items that improve both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            for item in remaining_items:\n                if current_weight + weight_lst[item] <= capacity:\n                    # Calculate potential new objectives\n                    new_value1 = current_obj[0] + value1_lst[item]\n                    new_value2 = current_obj[1] + value2_lst[item]\n                    # If both objectives improve, add the item\n                    if new_value1 > current_obj[0] and new_value2 > current_obj[1]:\n                        new_solution[item] = 1\n                        current_obj = (new_value1, new_value2)\n                        current_weight += weight_lst[item]\n                        improved = True\n                        break\n            # Try to remove items that don't contribute to both objectives\n            selected_items = np.where(new_solution == 1)[0]\n            for item in selected_items:\n                # Check if removing this item would keep both objectives non-worse\n                if (current_obj[0] - value1_lst[item] >= current_obj[0] and\n                    current_obj[1] - value2_lst[item] >= current_obj[1]):\n                    new_solution[item] = 0\n                    current_obj = (current_obj[0] - value1_lst[item],\n                                 current_obj[1] - value2_lst[item])\n                    current_weight -= weight_lst[item]\n                    improved = True\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 259,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    # Here, we select a solution that is not too close to the Pareto front\n    # and has a good balance between the two objectives\n    base_solution, (obj1, obj2) = max(archive, key=lambda x: min(x[1][0], x[1][1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (exploration)\n    # 2. Selectively flip items with high value-to-weight ratio (exploitation)\n    # 3. Adjust to stay within capacity\n\n    # Step 1: Random flips (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Value-based selection (exploitation)\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios and select top items\n    combined_ratio = ratio1 + ratio2\n    top_items = np.argsort(combined_ratio)[-5:]  # Top 5 items by combined ratio\n\n    # Flip items that are not in the solution but have high ratio\n    for idx in top_items:\n        if new_solution[idx] == 0:\n            new_solution[idx] = 1\n\n    # Step 3: Adjust to stay within capacity\n    # If weight exceeds capacity, remove items with lowest combined ratio\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Get indices of items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        # Sort items by combined ratio (ascending to remove worst items first)\n        sorted_items = sorted(in_solution, key=lambda x: combined_ratio[x])\n        for idx in sorted_items:\n            new_solution[idx] = 0\n            new_weight -= weight_lst[idx]\n            if new_weight <= capacity:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.32747592429962324,
            1.4157953560352325
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    # Here, we select a solution that is not too close to the Pareto front\n    # and has a good balance between the two objectives\n    base_solution, (obj1, obj2) = max(archive, key=lambda x: min(x[1][0], x[1][1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (exploration)\n    # 2. Selectively flip items with high value-to-weight ratio (exploitation)\n    # 3. Adjust to stay within capacity\n\n    # Step 1: Random flips (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Value-based selection (exploitation)\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios and select top items\n    combined_ratio = ratio1 + ratio2\n    top_items = np.argsort(combined_ratio)[-5:]  # Top 5 items by combined ratio\n\n    # Flip items that are not in the solution but have high ratio\n    for idx in top_items:\n        if new_solution[idx] == 0:\n            new_solution[idx] = 1\n\n    # Step 3: Adjust to stay within capacity\n    # If weight exceeds capacity, remove items with lowest combined ratio\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Get indices of items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        # Sort items by combined ratio (ascending to remove worst items first)\n        sorted_items = sorted(in_solution, key=lambda x: combined_ratio[x])\n        for idx in sorted_items:\n            new_solution[idx] = 0\n            new_weight -= weight_lst[idx]\n            if new_weight <= capacity:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 260,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions that have high potential for improvement by considering their dominance and diversity\n    # Here, we use a simple heuristic: select a solution that is not too close to the Pareto front\n    # and has a good balance between the two objectives\n\n    # Calculate the normalized objectives for all solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_values = np.max(objectives, axis=0)\n    min_values = np.min(objectives, axis=0)\n\n    # Normalize objectives to [0, 1] range\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-10)\n\n    # Calculate a score for each solution: balance between the two objectives and distance from the Pareto front\n    scores = np.abs(normalized[:, 0] - normalized[:, 1]) * np.mean(normalized, axis=1)\n\n    # Select the solution with the highest score (most promising for improvement)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor solution using a hybrid local search approach\n    # We combine two strategies:\n    # 1. Random flip of a subset of items (exploration)\n    # 2. Greedy addition of items that improve both objectives (exploitation)\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Random flip of a subset of items (exploration)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            remove_idx = np.random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 2: Greedy addition of items that improve both objectives (exploitation)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for idx in remaining_items:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Calculate potential improvement in both objectives\n            potential_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            potential_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n\n            # Only add if it improves both objectives\n            if (potential_value1 > np.sum(value1_lst * new_solution) and\n                potential_value2 > np.sum(value2_lst * new_solution)):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5347836833967012,
            1.733799546957016
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions that have high potential for improvement by considering their dominance and diversity\n    # Here, we use a simple heuristic: select a solution that is not too close to the Pareto front\n    # and has a good balance between the two objectives\n\n    # Calculate the normalized objectives for all solutions\n    objectives = np.array([obj for _, obj in archive])\n    max_values = np.max(objectives, axis=0)\n    min_values = np.min(objectives, axis=0)\n\n    # Normalize objectives to [0, 1] range\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-10)\n\n    # Calculate a score for each solution: balance between the two objectives and distance from the Pareto front\n    scores = np.abs(normalized[:, 0] - normalized[:, 1]) * np.mean(normalized, axis=1)\n\n    # Select the solution with the highest score (most promising for improvement)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor solution using a hybrid local search approach\n    # We combine two strategies:\n    # 1. Random flip of a subset of items (exploration)\n    # 2. Greedy addition of items that improve both objectives (exploitation)\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Random flip of a subset of items (exploration)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            remove_idx = np.random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 2: Greedy addition of items that improve both objectives (exploitation)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for idx in remaining_items:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Calculate potential improvement in both objectives\n            potential_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            potential_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n\n            # Only add if it improves both objectives\n            if (potential_value1 > np.sum(value1_lst * new_solution) and\n                potential_value2 > np.sum(value2_lst * new_solution)):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 261,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (i + 1) for i in range(len(archive))])[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    for _ in range(min(5, len(base_solution))):  # Limit the number of flips to avoid excessive changes\n        # Identify items that can be flipped without violating capacity\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        candidate_items = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Check if removing this item would keep the solution feasible\n                if current_weight - weight_lst[i] <= capacity:\n                    candidate_items.append((i, -1))  # Mark for removal\n            else:\n                # Check if adding this item would keep the solution feasible\n                if current_weight + weight_lst[i] <= capacity:\n                    candidate_items.append((i, 1))  # Mark for addition\n\n        if not candidate_items:\n            break\n\n        # Select a candidate item based on value improvement\n        best_candidate = None\n        best_improvement = -float('inf')\n\n        for i, flip in candidate_items:\n            if flip == 1:\n                # Calculate potential improvement for addition\n                improvement = value1_lst[i] + value2_lst[i]\n            else:\n                # Calculate potential improvement for removal\n                improvement = - (value1_lst[i] + value2_lst[i])\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = (i, flip)\n\n        if best_candidate:\n            i, flip = best_candidate\n            new_solution[i] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
        "score": [
            -0.31727689186755176,
            3.598930060863495
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.choices(range(len(archive)), weights=[1.0 / (i + 1) for i in range(len(archive))])[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    for _ in range(min(5, len(base_solution))):  # Limit the number of flips to avoid excessive changes\n        # Identify items that can be flipped without violating capacity\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        candidate_items = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Check if removing this item would keep the solution feasible\n                if current_weight - weight_lst[i] <= capacity:\n                    candidate_items.append((i, -1))  # Mark for removal\n            else:\n                # Check if adding this item would keep the solution feasible\n                if current_weight + weight_lst[i] <= capacity:\n                    candidate_items.append((i, 1))  # Mark for addition\n\n        if not candidate_items:\n            break\n\n        # Select a candidate item based on value improvement\n        best_candidate = None\n        best_improvement = -float('inf')\n\n        for i, flip in candidate_items:\n            if flip == 1:\n                # Calculate potential improvement for addition\n                improvement = value1_lst[i] + value2_lst[i]\n            else:\n                # Calculate potential improvement for removal\n                improvement = - (value1_lst[i] + value2_lst[i])\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = (i, flip)\n\n        if best_candidate:\n            i, flip = best_candidate\n            new_solution[i] = 1 if flip == 1 else 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 262,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (not on the Pareto front)\n    candidates = [sol for sol, _ in archive]\n    if len(candidates) > 1:\n        # Prefer solutions with lower total weight to have more room for improvement\n        weights = [np.sum(weight_lst * sol) for sol in candidates]\n        min_weight = min(weights)\n        promising_indices = [i for i, w in enumerate(weights) if w <= min_weight + 0.2 * capacity]\n        if promising_indices:\n            base_solution = random.choice([candidates[i] for i in promising_indices])\n        else:\n            base_solution = random.choice(candidates)\n    else:\n        base_solution = candidates[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: probabilistic flip + value-based swap\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Probabilistic flip: flip items with low value-to-weight ratio\n    value1_per_weight = value1_lst / (weight_lst + 1e-10)\n    value2_per_weight = value2_lst / (weight_lst + 1e-10)\n    flip_prob = 0.3  # Probability of flipping a low-value item\n\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # More likely to remove low-value items\n            if random.random() < flip_prob and (value1_per_weight[i] < np.median(value1_per_weight) or value2_per_weight[i] < np.median(value2_per_weight)):\n                new_solution[i] = 0\n        else:\n            # More likely to add items with high value-to-weight ratio\n            if remaining_capacity >= weight_lst[i] and random.random() < 0.7:\n                if value1_per_weight[i] > np.median(value1_per_weight) and value2_per_weight[i] > np.median(value2_per_weight):\n                    new_solution[i] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        while current_weight > capacity:\n            item_values = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            worst_item = np.argmax(new_solution * item_values)\n            if new_solution[worst_item] == 1:\n                new_solution[worst_item] = 0\n                current_weight -= weight_lst[worst_item]\n            else:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.891459052574748,
            4.787500858306885
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (not on the Pareto front)\n    candidates = [sol for sol, _ in archive]\n    if len(candidates) > 1:\n        # Prefer solutions with lower total weight to have more room for improvement\n        weights = [np.sum(weight_lst * sol) for sol in candidates]\n        min_weight = min(weights)\n        promising_indices = [i for i, w in enumerate(weights) if w <= min_weight + 0.2 * capacity]\n        if promising_indices:\n            base_solution = random.choice([candidates[i] for i in promising_indices])\n        else:\n            base_solution = random.choice(candidates)\n    else:\n        base_solution = candidates[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: probabilistic flip + value-based swap\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Probabilistic flip: flip items with low value-to-weight ratio\n    value1_per_weight = value1_lst / (weight_lst + 1e-10)\n    value2_per_weight = value2_lst / (weight_lst + 1e-10)\n    flip_prob = 0.3  # Probability of flipping a low-value item\n\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # More likely to remove low-value items\n            if random.random() < flip_prob and (value1_per_weight[i] < np.median(value1_per_weight) or value2_per_weight[i] < np.median(value2_per_weight)):\n                new_solution[i] = 0\n        else:\n            # More likely to add items with high value-to-weight ratio\n            if remaining_capacity >= weight_lst[i] and random.random() < 0.7:\n                if value1_per_weight[i] > np.median(value1_per_weight) and value2_per_weight[i] > np.median(value2_per_weight):\n                    new_solution[i] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        while current_weight > capacity:\n            item_values = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            worst_item = np.argmax(new_solution * item_values)\n            if new_solution[worst_item] == 1:\n                new_solution[worst_item] = 0\n                current_weight -= weight_lst[worst_item]\n            else:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 263,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the boundary (not too full or too empty)\n    selected_idx = random.choices(range(len(archive)), weights=[np.sum(sol[0]) / len(sol[0]) * (1 - np.sum(sol[0]) / len(sol[0])) for sol in archive])[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Determine which objective to prioritize based on current solution's performance\n    # If the solution is weak in both objectives, prioritize the objective with higher potential\n    obj1, obj2 = archive[selected_idx][1]\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Calculate potential improvement for each objective\n    potential1 = total_value1 - obj1\n    potential2 = total_value2 - obj2\n\n    # Decide which objective to prioritize (higher potential)\n    prioritize_obj1 = potential1 > potential2\n\n    # Hybrid local search: flip a subset of items based on the prioritized objective\n    new_solution = base_solution.copy()\n    candidates = np.where(base_solution == 1)[0] if prioritize_obj1 else np.where(base_solution == 0)[0]\n\n    if len(candidates) > 0:\n        # Flip a random subset of candidates (1-3 items)\n        flip_count = min(3, len(candidates))\n        flip_indices = random.sample(list(candidates), flip_count)\n\n        for idx in flip_indices:\n            if base_solution[idx] == 1:\n                # Try to remove the item if it doesn't violate capacity\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                # Try to add the item if it doesn't violate capacity\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # If no improvement possible, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        non_zero = np.where(base_solution == 1)[0]\n        zero = np.where(base_solution == 0)[0]\n\n        if len(non_zero) > 0 and len(zero) > 0:\n            # Randomly flip one item from each group\n            flip_non_zero = random.choice(non_zero)\n            flip_zero = random.choice(zero)\n\n            if current_weight - weight_lst[flip_non_zero] + weight_lst[flip_zero] <= capacity:\n                new_solution[flip_non_zero] = 0\n                new_solution[flip_zero] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.24893876228634831,
            8.429605484008789
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the boundary (not too full or too empty)\n    selected_idx = random.choices(range(len(archive)), weights=[np.sum(sol[0]) / len(sol[0]) * (1 - np.sum(sol[0]) / len(sol[0])) for sol in archive])[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Determine which objective to prioritize based on current solution's performance\n    # If the solution is weak in both objectives, prioritize the objective with higher potential\n    obj1, obj2 = archive[selected_idx][1]\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Calculate potential improvement for each objective\n    potential1 = total_value1 - obj1\n    potential2 = total_value2 - obj2\n\n    # Decide which objective to prioritize (higher potential)\n    prioritize_obj1 = potential1 > potential2\n\n    # Hybrid local search: flip a subset of items based on the prioritized objective\n    new_solution = base_solution.copy()\n    candidates = np.where(base_solution == 1)[0] if prioritize_obj1 else np.where(base_solution == 0)[0]\n\n    if len(candidates) > 0:\n        # Flip a random subset of candidates (1-3 items)\n        flip_count = min(3, len(candidates))\n        flip_indices = random.sample(list(candidates), flip_count)\n\n        for idx in flip_indices:\n            if base_solution[idx] == 1:\n                # Try to remove the item if it doesn't violate capacity\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                # Try to add the item if it doesn't violate capacity\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # If no improvement possible, perform a random flip to escape local optima\n    if np.array_equal(new_solution, base_solution):\n        non_zero = np.where(base_solution == 1)[0]\n        zero = np.where(base_solution == 0)[0]\n\n        if len(non_zero) > 0 and len(zero) > 0:\n            # Randomly flip one item from each group\n            flip_non_zero = random.choice(non_zero)\n            flip_zero = random.choice(zero)\n\n            if current_weight - weight_lst[flip_non_zero] + weight_lst[flip_zero] <= capacity:\n                new_solution[flip_non_zero] = 0\n                new_solution[flip_zero] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 264,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (not on the Pareto front)\n    # Here, we select a solution that is not dominated by any other in the archive\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        is_dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Randomly select a solution from the non-dominated set\n    selected_idx = np.random.randint(0, len(non_dominated))\n    selected_sol, _ = non_dominated[selected_idx]\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator: flip a random subset of items with high marginal utility\n    # Calculate marginal utility for each item (weighted sum of both objectives)\n    marginal_utility = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n\n    # Identify items that are in the solution and have high marginal utility\n    candidate_indices = np.where((new_solution == 1) & (marginal_utility > np.percentile(marginal_utility, 75)))[0]\n\n    # If no candidates, flip a random item\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(new_solution))\n\n    # Flip a random subset of the candidates (with probability 0.3)\n    for idx in candidate_indices:\n        if np.random.rand() < 0.3:\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility: if weight exceeds capacity, remove highest-weight items\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Sort items in the solution by weight in descending order\n        sorted_indices = np.argsort(-weight_lst * new_solution)\n        for idx in sorted_indices:\n            if current_weight <= capacity:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5070678535449811,
            1.2158903777599335
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (not on the Pareto front)\n    # Here, we select a solution that is not dominated by any other in the archive\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        is_dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] >= obj[0] and other_obj[1] >= obj[1] and (other_obj[0] > obj[0] or other_obj[1] > obj[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Randomly select a solution from the non-dominated set\n    selected_idx = np.random.randint(0, len(non_dominated))\n    selected_sol, _ = non_dominated[selected_idx]\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator: flip a random subset of items with high marginal utility\n    # Calculate marginal utility for each item (weighted sum of both objectives)\n    marginal_utility = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n\n    # Identify items that are in the solution and have high marginal utility\n    candidate_indices = np.where((new_solution == 1) & (marginal_utility > np.percentile(marginal_utility, 75)))[0]\n\n    # If no candidates, flip a random item\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(new_solution))\n\n    # Flip a random subset of the candidates (with probability 0.3)\n    for idx in candidate_indices:\n        if np.random.rand() < 0.3:\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility: if weight exceeds capacity, remove highest-weight items\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Sort items in the solution by weight in descending order\n        sorted_indices = np.argsort(-weight_lst * new_solution)\n        for idx in sorted_indices:\n            if current_weight <= capacity:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 265,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with a bias towards those closer to the ideal point\n    ideal_point = (max(obj[0] for _, obj in archive), max(obj[1] for _, obj in archive))\n    candidates = []\n    for sol, obj in archive:\n        # Calculate distance to ideal point\n        distance = np.sqrt((ideal_point[0] - obj[0])**2 + (ideal_point[1] - obj[1])**2)\n        candidates.append((sol, obj, distance))\n\n    # Select top 30% of solutions with smallest distance to ideal point\n    candidates.sort(key=lambda x: x[2])\n    top_k = max(1, int(0.3 * len(candidates)))\n    selected = random.choice(candidates[:top_k])[0]\n    base_solution = selected.copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # First, try to improve both objectives by flipping items that have high value-to-weight ratio\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_ratio = value_to_weight1 + value_to_weight2\n\n    # Sort items by combined value-to-weight ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Second, perform random flips to escape local optima\n    num_flips = min(3, len(new_solution))\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.6552857588401746,
            1.5643326342105865
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with a bias towards those closer to the ideal point\n    ideal_point = (max(obj[0] for _, obj in archive), max(obj[1] for _, obj in archive))\n    candidates = []\n    for sol, obj in archive:\n        # Calculate distance to ideal point\n        distance = np.sqrt((ideal_point[0] - obj[0])**2 + (ideal_point[1] - obj[1])**2)\n        candidates.append((sol, obj, distance))\n\n    # Select top 30% of solutions with smallest distance to ideal point\n    candidates.sort(key=lambda x: x[2])\n    top_k = max(1, int(0.3 * len(candidates)))\n    selected = random.choice(candidates[:top_k])[0]\n    base_solution = selected.copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # First, try to improve both objectives by flipping items that have high value-to-weight ratio\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_ratio = value_to_weight1 + value_to_weight2\n\n    # Sort items by combined value-to-weight ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Second, perform random flips to escape local optima\n    num_flips = min(3, len(new_solution))\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 266,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a promising solution based on its potential for improvement\n    # Here, we select a solution with high value in at least one objective\n    max_value = -1\n    selected_solution = None\n    for sol, (v1, v2) in archive:\n        if max(v1, v2) > max_value:\n            max_value = max(v1, v2)\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = archive[0][0]\n\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation - flip a random subset of items\n    num_items = len(weight_lst)\n    perturbation_size = min(3, num_items)  # Limit perturbation size for efficiency\n    perturbation_indices = random.sample(range(num_items), perturbation_size)\n    for idx in perturbation_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Step 2: Greedy improvement - add items that improve at least one objective\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    for idx in range(num_items):\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            delta_v1 = value1_lst[idx]\n            delta_v2 = value2_lst[idx]\n            if delta_v1 > 0 or delta_v2 > 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.34455797347257766,
            0.6245601177215576
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a promising solution based on its potential for improvement\n    # Here, we select a solution with high value in at least one objective\n    max_value = -1\n    selected_solution = None\n    for sol, (v1, v2) in archive:\n        if max(v1, v2) > max_value:\n            max_value = max(v1, v2)\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = archive[0][0]\n\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation - flip a random subset of items\n    num_items = len(weight_lst)\n    perturbation_size = min(3, num_items)  # Limit perturbation size for efficiency\n    perturbation_indices = random.sample(range(num_items), perturbation_size)\n    for idx in perturbation_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Step 2: Greedy improvement - add items that improve at least one objective\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    for idx in range(num_items):\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            delta_v1 = value1_lst[idx]\n            delta_v2 = value2_lst[idx]\n            if delta_v1 > 0 or delta_v2 > 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 266,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a promising solution based on its potential for improvement\n    # Here, we select a solution with high value in at least one objective\n    max_value = -1\n    selected_solution = None\n    for sol, (v1, v2) in archive:\n        if max(v1, v2) > max_value:\n            max_value = max(v1, v2)\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = archive[0][0]\n\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation - flip a random subset of items\n    num_items = len(weight_lst)\n    perturbation_size = min(3, num_items)  # Limit perturbation size for efficiency\n    perturbation_indices = random.sample(range(num_items), perturbation_size)\n    for idx in perturbation_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Step 2: Greedy improvement - add items that improve at least one objective\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    for idx in range(num_items):\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            delta_v1 = value1_lst[idx]\n            delta_v2 = value2_lst[idx]\n            if delta_v1 > 0 or delta_v2 > 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.34455797347257766,
            0.6245601177215576
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot select a neighbor.\")\n\n    # Select a promising solution based on its potential for improvement\n    # Here, we select a solution with high value in at least one objective\n    max_value = -1\n    selected_solution = None\n    for sol, (v1, v2) in archive:\n        if max(v1, v2) > max_value:\n            max_value = max(v1, v2)\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = archive[0][0]\n\n    current_solution = selected_solution.copy()\n    new_solution = current_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation - flip a random subset of items\n    num_items = len(weight_lst)\n    perturbation_size = min(3, num_items)  # Limit perturbation size for efficiency\n    perturbation_indices = random.sample(range(num_items), perturbation_size)\n    for idx in perturbation_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Step 2: Greedy improvement - add items that improve at least one objective\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    for idx in range(num_items):\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            delta_v1 = value1_lst[idx]\n            delta_v2 = value2_lst[idx]\n            if delta_v1 > 0 or delta_v2 > 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 267,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with high potential for improvement\n    # Potential is defined as the ratio of the solution's objective values to the maximum possible values\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potentials = []\n    for sol, obj in archive:\n        potential = (obj[0] / max_value1 + obj[1] / max_value2) / 2\n        potentials.append(potential)\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: Combine random perturbation with greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a random subset of items)\n    num_perturb = min(3, len(new_solution))  # Perturb up to 3 items\n    perturb_indices = random.sample(range(len(new_solution)), num_perturb)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        excess_items = np.where(new_solution)[0]\n        np.random.shuffle(excess_items)\n        for idx in excess_items:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    # Step 2: Greedy improvement (add items that improve both objectives)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if (new_solution[idx] == 0 and\n            np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity):\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            temp_value1 = np.sum(temp_solution * value1_lst)\n            temp_value2 = np.sum(temp_solution * value2_lst)\n\n            # Check if both objectives improve or at least one improves without hurting the other too much\n            current_value1 = np.sum(new_solution * value1_lst)\n            current_value2 = np.sum(new_solution * value2_lst)\n\n            if ((temp_value1 >= current_value1 and temp_value2 >= current_value2) or\n                (temp_value1 > current_value1 and temp_value2 >= current_value2 - 0.1 * max_value2) or\n                (temp_value2 > current_value2 and temp_value1 >= current_value1 - 0.1 * max_value1)):\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.3487929663043783,
            4.841085314750671
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with high potential for improvement\n    # Potential is defined as the ratio of the solution's objective values to the maximum possible values\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potentials = []\n    for sol, obj in archive:\n        potential = (obj[0] / max_value1 + obj[1] / max_value2) / 2\n        potentials.append(potential)\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: Combine random perturbation with greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a random subset of items)\n    num_perturb = min(3, len(new_solution))  # Perturb up to 3 items\n    perturb_indices = random.sample(range(len(new_solution)), num_perturb)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        excess_items = np.where(new_solution)[0]\n        np.random.shuffle(excess_items)\n        for idx in excess_items:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    # Step 2: Greedy improvement (add items that improve both objectives)\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if (new_solution[idx] == 0 and\n            np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity):\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            temp_value1 = np.sum(temp_solution * value1_lst)\n            temp_value2 = np.sum(temp_solution * value2_lst)\n\n            # Check if both objectives improve or at least one improves without hurting the other too much\n            current_value1 = np.sum(new_solution * value1_lst)\n            current_value2 = np.sum(new_solution * value2_lst)\n\n            if ((temp_value1 >= current_value1 and temp_value2 >= current_value2) or\n                (temp_value1 > current_value1 and temp_value2 >= current_value2 - 0.1 * max_value2) or\n                (temp_value2 > current_value2 and temp_value1 >= current_value1 - 0.1 * max_value1)):\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 268,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher-value solutions\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight <= capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in the archive.\")\n\n    # Sort candidates by the sum of normalized objectives to prioritize high-value solutions\n    normalized = []\n    max_obj1 = max(obj[0] for _, obj in candidates)\n    max_obj2 = max(obj[1] for _, obj in candidates)\n    for sol, obj in candidates:\n        norm_obj = (obj[0] / max_obj1 if max_obj1 else 0, obj[1] / max_obj2 if max_obj2 else 0)\n        normalized.append((sol, obj, norm_obj))\n\n    # Select top 20% of solutions by normalized sum of objectives\n    normalized.sort(key=lambda x: -(x[2][0] + x[2][1]))\n    top_candidates = normalized[:max(1, len(normalized) // 5)]\n\n    # Randomly select a base solution from top candidates\n    base_sol, _, _ = random.choice(top_candidates)\n    new_solution = base_sol.copy()\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    for _ in range(3):  # Perform 3 iterations of local search\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Combine ratios and add randomness\n        combined_ratio = v1_ratio + v2_ratio + np.random.rand(len(weight_lst)) * 0.1\n\n        # Sort items by combined ratio in descending order\n        sorted_items = np.argsort(-combined_ratio)\n\n        # Try to flip items in a way that maintains feasibility\n        for item in sorted_items:\n            if new_solution[item] == 1:\n                # Try removing the item\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 0\n                temp_weight = np.sum(temp_sol * weight_lst)\n                if temp_weight <= capacity:\n                    new_solution = temp_sol\n                    break\n            else:\n                # Try adding the item\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 1\n                temp_weight = np.sum(temp_sol * weight_lst)\n                if temp_weight <= capacity:\n                    new_solution = temp_sol\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8575467313134326,
            1.7384877502918243
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher-value solutions\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight <= capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in the archive.\")\n\n    # Sort candidates by the sum of normalized objectives to prioritize high-value solutions\n    normalized = []\n    max_obj1 = max(obj[0] for _, obj in candidates)\n    max_obj2 = max(obj[1] for _, obj in candidates)\n    for sol, obj in candidates:\n        norm_obj = (obj[0] / max_obj1 if max_obj1 else 0, obj[1] / max_obj2 if max_obj2 else 0)\n        normalized.append((sol, obj, norm_obj))\n\n    # Select top 20% of solutions by normalized sum of objectives\n    normalized.sort(key=lambda x: -(x[2][0] + x[2][1]))\n    top_candidates = normalized[:max(1, len(normalized) // 5)]\n\n    # Randomly select a base solution from top candidates\n    base_sol, _, _ = random.choice(top_candidates)\n    new_solution = base_sol.copy()\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    for _ in range(3):  # Perform 3 iterations of local search\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Combine ratios and add randomness\n        combined_ratio = v1_ratio + v2_ratio + np.random.rand(len(weight_lst)) * 0.1\n\n        # Sort items by combined ratio in descending order\n        sorted_items = np.argsort(-combined_ratio)\n\n        # Try to flip items in a way that maintains feasibility\n        for item in sorted_items:\n            if new_solution[item] == 1:\n                # Try removing the item\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 0\n                temp_weight = np.sum(temp_sol * weight_lst)\n                if temp_weight <= capacity:\n                    new_solution = temp_sol\n                    break\n            else:\n                # Try adding the item\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 1\n                temp_weight = np.sum(temp_sol * weight_lst)\n                if temp_weight <= capacity:\n                    new_solution = temp_sol\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 269,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flips and greedy selection\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to flip (1 to 3 items)\n    flip_indices = np.random.choice(n_items, size=np.random.randint(1, 4), replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_weight = total_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                total_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = total_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                total_weight = new_weight\n\n    # Greedy improvement: add items that improve both objectives if possible\n    for idx in np.random.permutation(n_items):\n        if new_solution[idx] == 0 and (total_weight + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n            # Approximate Pareto dominance check (simplified for efficiency)\n            if (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                current_value1, current_value2 = new_value1, new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.4070002978315918,
            2.183038681745529
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flips and greedy selection\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to flip (1 to 3 items)\n    flip_indices = np.random.choice(n_items, size=np.random.randint(1, 4), replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_weight = total_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                total_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = total_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                total_weight = new_weight\n\n    # Greedy improvement: add items that improve both objectives if possible\n    for idx in np.random.permutation(n_items):\n        if new_solution[idx] == 0 and (total_weight + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n            # Approximate Pareto dominance check (simplified for efficiency)\n            if (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n                current_value1, current_value2 = new_value1, new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 270,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    num_items = len(weight_lst)\n    indices = np.arange(num_items)\n    np.random.shuffle(indices)\n\n    for i in indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n        else:\n            # Try adding item i\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n\n    # Additional refinement: flip a random item if no improvement is made\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = np.random.choice(num_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5442166519421698,
            1.513161689043045
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    num_items = len(weight_lst)\n    indices = np.arange(num_items)\n    np.random.shuffle(indices)\n\n    for i in indices:\n        if new_solution[i] == 1:\n            # Try removing item i\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = temp_weight\n        else:\n            # Try adding item i\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = temp_weight\n\n    # Additional refinement: flip a random item if no improvement is made\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = np.random.choice(num_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 271,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = max(archive, key=lambda x: np.sum(x[0]))\n\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Determine the number of items to perturb (adaptive based on solution density)\n    density = np.sum(new_solution) / n_items\n    num_perturbations = max(1, int(density * n_items * 0.3))  # 30% of items if dense, otherwise more\n\n    # Apply hybrid local search: random swap, flip, and adaptive perturbation\n    for _ in range(num_perturbations):\n        # Randomly select two distinct items\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Randomly choose between swap, flip, or adaptive perturbation\n        operation = np.random.choice(['swap', 'flip', 'adaptive'])\n\n        if operation == 'swap':\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        elif operation == 'flip':\n            new_solution[i] = 1 - new_solution[i]\n        else:  # adaptive\n            # Flip based on marginal contribution (higher marginal value items are more likely to be flipped)\n            marginal_value1 = value1_lst[i] / (weight_lst[i] + 1e-6)  # Avoid division by zero\n            marginal_value2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            if np.random.rand() < (marginal_value1 + marginal_value2) / (np.max(value1_lst) + np.max(value2_lst) + 1e-6):\n                new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility (repair if necessary)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with the smallest marginal contribution until feasible\n        while total_weight > capacity:\n            # Identify items that are currently in the knapsack\n            in_knapsack = np.where(new_solution == 1)[0]\n            if len(in_knapsack) == 0:\n                break  # No items left to remove (edge case)\n            # Remove the item with the smallest marginal contribution\n            marginal_contributions = (value1_lst[in_knapsack] + value2_lst[in_knapsack]) / (weight_lst[in_knapsack] + 1e-6)\n            idx_to_remove = in_knapsack[np.argmin(marginal_contributions)]\n            new_solution[idx_to_remove] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.3560127022543401,
            5.9560345113277435
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = max(archive, key=lambda x: np.sum(x[0]))\n\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Determine the number of items to perturb (adaptive based on solution density)\n    density = np.sum(new_solution) / n_items\n    num_perturbations = max(1, int(density * n_items * 0.3))  # 30% of items if dense, otherwise more\n\n    # Apply hybrid local search: random swap, flip, and adaptive perturbation\n    for _ in range(num_perturbations):\n        # Randomly select two distinct items\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Randomly choose between swap, flip, or adaptive perturbation\n        operation = np.random.choice(['swap', 'flip', 'adaptive'])\n\n        if operation == 'swap':\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        elif operation == 'flip':\n            new_solution[i] = 1 - new_solution[i]\n        else:  # adaptive\n            # Flip based on marginal contribution (higher marginal value items are more likely to be flipped)\n            marginal_value1 = value1_lst[i] / (weight_lst[i] + 1e-6)  # Avoid division by zero\n            marginal_value2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            if np.random.rand() < (marginal_value1 + marginal_value2) / (np.max(value1_lst) + np.max(value2_lst) + 1e-6):\n                new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility (repair if necessary)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with the smallest marginal contribution until feasible\n        while total_weight > capacity:\n            # Identify items that are currently in the knapsack\n            in_knapsack = np.where(new_solution == 1)[0]\n            if len(in_knapsack) == 0:\n                break  # No items left to remove (edge case)\n            # Remove the item with the smallest marginal contribution\n            marginal_contributions = (value1_lst[in_knapsack] + value2_lst[in_knapsack]) / (weight_lst[in_knapsack] + 1e-6)\n            idx_to_remove = in_knapsack[np.argmin(marginal_contributions)]\n            new_solution[idx_to_remove] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 272,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (lowest crowding distance or random if archive is small)\n    if len(archive) <= 3:\n        selected_idx = np.random.randint(0, len(archive))\n    else:\n        # Calculate crowding distance for each solution in the archive\n        objectives = np.array([obj for _, obj in archive])\n        normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        crowding_dist = np.zeros(len(archive))\n\n        for m in range(2):\n            sorted_idx = np.argsort(normalized_obj[:, m])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for i in range(1, len(archive)-1):\n                crowding_dist[sorted_idx[i]] += normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]\n\n        # Select solution with lowest crowding distance (most crowded area)\n        selected_idx = np.argmin(crowding_dist)\n\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (up to 20% of items)\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. If solution is infeasible, perform a repair operation\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with lowest value density until feasible\n        value_density = (value1_lst + value2_lst) / weight_lst\n        while total_weight > capacity:\n            candidate_indices = np.where(new_solution == 1)[0]\n            if len(candidate_indices) == 0:\n                break\n            remove_idx = candidate_indices[np.argmin(value_density[candidate_indices])]\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # 3. If solution is still feasible, perform a weighted flip based on potential improvement\n    if np.sum(weight_lst[new_solution == 1]) <= capacity:\n        # Calculate potential improvement for each item\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        potential_improvement = np.zeros(n_items)\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    potential_improvement[i] = value1_lst[i] + value2_lst[i]\n            else:\n                potential_improvement[i] = - (value1_lst[i] + value2_lst[i])\n\n        # Flip items with highest potential improvement (up to 2 items)\n        top_improvement_indices = np.argsort(-potential_improvement)[:2]\n        for idx in top_improvement_indices:\n            if potential_improvement[idx] > 0:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.34245276394525226,
            4.520864248275757
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (lowest crowding distance or random if archive is small)\n    if len(archive) <= 3:\n        selected_idx = np.random.randint(0, len(archive))\n    else:\n        # Calculate crowding distance for each solution in the archive\n        objectives = np.array([obj for _, obj in archive])\n        normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        crowding_dist = np.zeros(len(archive))\n\n        for m in range(2):\n            sorted_idx = np.argsort(normalized_obj[:, m])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for i in range(1, len(archive)-1):\n                crowding_dist[sorted_idx[i]] += normalized_obj[sorted_idx[i+1], m] - normalized_obj[sorted_idx[i-1], m]\n\n        # Select solution with lowest crowding distance (most crowded area)\n        selected_idx = np.argmin(crowding_dist)\n\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (up to 20% of items)\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. If solution is infeasible, perform a repair operation\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with lowest value density until feasible\n        value_density = (value1_lst + value2_lst) / weight_lst\n        while total_weight > capacity:\n            candidate_indices = np.where(new_solution == 1)[0]\n            if len(candidate_indices) == 0:\n                break\n            remove_idx = candidate_indices[np.argmin(value_density[candidate_indices])]\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # 3. If solution is still feasible, perform a weighted flip based on potential improvement\n    if np.sum(weight_lst[new_solution == 1]) <= capacity:\n        # Calculate potential improvement for each item\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        potential_improvement = np.zeros(n_items)\n        for i in range(n_items):\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    potential_improvement[i] = value1_lst[i] + value2_lst[i]\n            else:\n                potential_improvement[i] = - (value1_lst[i] + value2_lst[i])\n\n        # Flip items with highest potential improvement (up to 2 items)\n        top_improvement_indices = np.argsort(-potential_improvement)[:2]\n        for idx in top_improvement_indices:\n            if potential_improvement[idx] > 0:\n                new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 273,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of their values (higher is better)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution with probability inversely proportional to its rank\n        ranks = np.arange(1, len(archive) + 1)\n        probs = 1 / ranks\n        probs = probs / probs.sum()\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution, _ = archive_sorted[selected_idx]\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily add high-value items (exploitation)\n\n    # Step 1: Random flipping\n    flip_indices = np.where(np.random.rand(len(new_solution)) < 0.3)[0]  # 30% chance to flip each item\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight > weight_lst[idx]:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedy addition of high-value items\n    # Calculate value-to-weight ratios for both objectives\n    v1_ratios = value1_lst / weight_lst\n    v2_ratios = value2_lst / weight_lst\n\n    # Combine ratios to prioritize items that improve both objectives\n    combined_ratios = v1_ratios + v2_ratios\n\n    # Sort items by combined ratio (descending)\n    sorted_indices = np.argsort(-combined_ratios)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Ensure solution is feasible (should be already, but double-check)\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Remove the least valuable item in the solution\n        solution_items = np.where(new_solution == 1)[0]\n        if len(solution_items) == 0:\n            break  # empty solution\n        # Remove item with smallest combined value\n        item_to_remove = min(solution_items, key=lambda i: value1_lst[i] + value2_lst[i])\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.4546496278606192,
            1.6900096237659454
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score of their values (higher is better)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution with probability inversely proportional to its rank\n        ranks = np.arange(1, len(archive) + 1)\n        probs = 1 / ranks\n        probs = probs / probs.sum()\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution, _ = archive_sorted[selected_idx]\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily add high-value items (exploitation)\n\n    # Step 1: Random flipping\n    flip_indices = np.where(np.random.rand(len(new_solution)) < 0.3)[0]  # 30% chance to flip each item\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight > weight_lst[idx]:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedy addition of high-value items\n    # Calculate value-to-weight ratios for both objectives\n    v1_ratios = value1_lst / weight_lst\n    v2_ratios = value2_lst / weight_lst\n\n    # Combine ratios to prioritize items that improve both objectives\n    combined_ratios = v1_ratios + v2_ratios\n\n    # Sort items by combined ratio (descending)\n    sorted_indices = np.argsort(-combined_ratios)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Ensure solution is feasible (should be already, but double-check)\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Remove the least valuable item in the solution\n        solution_items = np.where(new_solution == 1)[0]\n        if len(solution_items) == 0:\n            break  # empty solution\n        # Remove item with smallest combined value\n        item_to_remove = min(solution_items, key=lambda i: value1_lst[i] + value2_lst[i])\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 274,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(solution * weight_lst) for solution, _ in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Hybrid local search strategy: flip a random subset of items with high marginal utility\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate marginal utility for each item (difference in objective values if flipped)\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_weight = weight_lst - (base_solution * weight_lst)\n\n    # Prioritize items with high marginal utility and small weight\n    score = (marginal_value1 + marginal_value2) / (marginal_weight + 1e-6)\n    top_items = np.argsort(score)[-max(1, n_items // 5):]  # Select top 20% of items\n\n    # Flip a random subset of top items\n    flip_indices = np.random.choice(top_items, size=min(3, len(top_items)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess weight\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_items = np.where(new_solution)[0]\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7906749668076504,
            1.7299275994300842
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([np.sum(solution * weight_lst) for solution, _ in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Hybrid local search strategy: flip a random subset of items with high marginal utility\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate marginal utility for each item (difference in objective values if flipped)\n    marginal_value1 = value1_lst - (base_solution * value1_lst)\n    marginal_value2 = value2_lst - (base_solution * value2_lst)\n    marginal_weight = weight_lst - (base_solution * weight_lst)\n\n    # Prioritize items with high marginal utility and small weight\n    score = (marginal_value1 + marginal_value2) / (marginal_weight + 1e-6)\n    top_items = np.argsort(score)[-max(1, n_items // 5):]  # Select top 20% of items\n\n    # Flip a random subset of top items\n    flip_indices = np.random.choice(top_items, size=min(3, len(top_items)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing excess weight\n    while np.sum(new_solution * weight_lst) > capacity:\n        excess_items = np.where(new_solution)[0]\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 275,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. Flip a random bit and check feasibility\n    # 2. If infeasible, try to swap with another item\n    # 3. If still infeasible, try to remove the heaviest item\n\n    # Step 1: Random bit flip\n    flip_idx = np.random.randint(0, len(base_solution))\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n    new_weight = np.sum(weight_lst * new_solution)\n\n    if new_weight <= capacity:\n        return new_solution\n\n    # Step 2: If infeasible, try to swap with another item\n    if new_solution[flip_idx] == 1:\n        # Try to remove the flipped item and add a lighter one\n        candidates = np.where((base_solution == 1) & (weight_lst <= weight_lst[flip_idx]))[0]\n        if len(candidates) > 0:\n            swap_idx = np.random.choice(candidates)\n            new_solution[swap_idx] = 0\n            new_weight = np.sum(weight_lst * new_solution)\n            if new_weight <= capacity:\n                return new_solution\n    else:\n        # Try to add a lighter item\n        candidates = np.where((base_solution == 0) & (weight_lst <= capacity - current_weight + weight_lst[flip_idx]))[0]\n        if len(candidates) > 0:\n            swap_idx = np.random.choice(candidates)\n            new_solution[swap_idx] = 1\n            new_weight = np.sum(weight_lst * new_solution)\n            if new_weight <= capacity:\n                return new_solution\n\n    # Step 3: If still infeasible, remove the heaviest item\n    if new_weight > capacity:\n        heaviest_idx = np.argmax(weight_lst * base_solution)\n        new_solution[heaviest_idx] = 0\n        new_weight = np.sum(weight_lst * new_solution)\n        if new_weight <= capacity:\n            return new_solution\n\n    # If all else fails, return the original solution\n    return base_solution.copy()\n\n",
        "score": [
            -0.46038663936949914,
            0.8354862034320831
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. Flip a random bit and check feasibility\n    # 2. If infeasible, try to swap with another item\n    # 3. If still infeasible, try to remove the heaviest item\n\n    # Step 1: Random bit flip\n    flip_idx = np.random.randint(0, len(base_solution))\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n    new_weight = np.sum(weight_lst * new_solution)\n\n    if new_weight <= capacity:\n        return new_solution\n\n    # Step 2: If infeasible, try to swap with another item\n    if new_solution[flip_idx] == 1:\n        # Try to remove the flipped item and add a lighter one\n        candidates = np.where((base_solution == 1) & (weight_lst <= weight_lst[flip_idx]))[0]\n        if len(candidates) > 0:\n            swap_idx = np.random.choice(candidates)\n            new_solution[swap_idx] = 0\n            new_weight = np.sum(weight_lst * new_solution)\n            if new_weight <= capacity:\n                return new_solution\n    else:\n        # Try to add a lighter item\n        candidates = np.where((base_solution == 0) & (weight_lst <= capacity - current_weight + weight_lst[flip_idx]))[0]\n        if len(candidates) > 0:\n            swap_idx = np.random.choice(candidates)\n            new_solution[swap_idx] = 1\n            new_weight = np.sum(weight_lst * new_solution)\n            if new_weight <= capacity:\n                return new_solution\n\n    # Step 3: If still infeasible, remove the heaviest item\n    if new_weight > capacity:\n        heaviest_idx = np.argmax(weight_lst * base_solution)\n        new_solution[heaviest_idx] = 0\n        new_weight = np.sum(weight_lst * new_solution)\n        if new_weight <= capacity:\n            return new_solution\n\n    # If all else fails, return the original solution\n    return base_solution.copy()\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 276,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the Pareto front\n    # and have a good balance between the two objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight <= capacity:\n            # Calculate a score based on the distance to the Pareto front and objective balance\n            # Here we use a simple heuristic: prioritize solutions with higher total weight and balanced objectives\n            score = (total_weight / capacity) * (1 - abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6))\n            candidates.append((score, sol))\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the highest score\n        candidates.sort(key=lambda x: -x[0])\n        base_solution = candidates[0][1].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (with probability based on their value-to-weight ratio)\n    # 2. Perform a greedy improvement step\n    # 3. Apply a weighted random flip based on objective importance\n\n    # Step 1: Random flip with value-weighted probability\n    for i in range(len(new_solution)):\n        if random.random() < 0.2:  # 20% chance to consider flipping\n            # Calculate value-to-weight ratio for both objectives\n            v1_ratio = value1_lst[i] / (weight_lst[i] + 1e-6)\n            v2_ratio = value2_lst[i] / (weight_lst[i] + 1e-6)\n            flip_prob = 0.5 * (v1_ratio + v2_ratio)  # Combined probability\n\n            if random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_items)\n        for i in removable_items:\n            if excess <= 0:\n                break\n            new_solution[i] = 0\n            excess -= weight_lst[i]\n\n    # Step 2: Greedy improvement step\n    # Try to add the most valuable items not currently in the knapsack\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Calculate value-to-weight ratios for items not in the knapsack\n        candidate_items = np.where(new_solution == 0)[0]\n        v1_ratios = value1_lst[candidate_items] / (weight_lst[candidate_items] + 1e-6)\n        v2_ratios = value2_lst[candidate_items] / (weight_lst[candidate_items] + 1e-6)\n        combined_ratios = v1_ratios + v2_ratios\n\n        # Sort by combined ratio in descending order\n        sorted_indices = np.argsort(-combined_ratios)\n        for idx in sorted_indices:\n            i = candidate_items[idx]\n            if weight_lst[i] <= remaining_weight:\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    # Step 3: Weighted random flip based on objective importance\n    # This step helps explore different parts of the Pareto front\n    if random.random() < 0.3:  # 30% chance to perform this step\n        # Determine which objective to prioritize (randomly)\n        prioritize_v1 = random.random() < 0.5\n\n        # Calculate value-to-weight ratios for the prioritized objective\n        if prioritize_v1:\n            ratios = value1_lst / (weight_lst + 1e-6)\n        else:\n            ratios = value2_lst / (weight_lst + 1e-6)\n\n        # Flip items with high ratio with higher probability\n        for i in range(len(new_solution)):\n            flip_prob = ratios[i] * 0.5  # Scale probability\n            if random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n        # Ensure feasibility\n        current_weight = np.sum(new_solution * weight_lst)\n        if current_weight > capacity:\n            # Remove items with lowest ratio in the prioritized objective\n            excess = current_weight - capacity\n            removable_items = np.where(new_solution == 1)[0]\n            if prioritize_v1:\n                removable_ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-6)\n            else:\n                removable_ratios = value2_lst[removable_items] / (weight_lst[removable_items] + 1e-6)\n            sorted_indices = np.argsort(removable_ratios)\n            for idx in sorted_indices:\n                i = removable_items[idx]\n                if excess <= 0:\n                    break\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.27581230964262415,
            1.9246729016304016
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the Pareto front\n    # and have a good balance between the two objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight <= capacity:\n            # Calculate a score based on the distance to the Pareto front and objective balance\n            # Here we use a simple heuristic: prioritize solutions with higher total weight and balanced objectives\n            score = (total_weight / capacity) * (1 - abs(obj[0] - obj[1]) / (obj[0] + obj[1] + 1e-6))\n            candidates.append((score, sol))\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the highest score\n        candidates.sort(key=lambda x: -x[0])\n        base_solution = candidates[0][1].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (with probability based on their value-to-weight ratio)\n    # 2. Perform a greedy improvement step\n    # 3. Apply a weighted random flip based on objective importance\n\n    # Step 1: Random flip with value-weighted probability\n    for i in range(len(new_solution)):\n        if random.random() < 0.2:  # 20% chance to consider flipping\n            # Calculate value-to-weight ratio for both objectives\n            v1_ratio = value1_lst[i] / (weight_lst[i] + 1e-6)\n            v2_ratio = value2_lst[i] / (weight_lst[i] + 1e-6)\n            flip_prob = 0.5 * (v1_ratio + v2_ratio)  # Combined probability\n\n            if random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess = current_weight - capacity\n        removable_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(removable_items)\n        for i in removable_items:\n            if excess <= 0:\n                break\n            new_solution[i] = 0\n            excess -= weight_lst[i]\n\n    # Step 2: Greedy improvement step\n    # Try to add the most valuable items not currently in the knapsack\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Calculate value-to-weight ratios for items not in the knapsack\n        candidate_items = np.where(new_solution == 0)[0]\n        v1_ratios = value1_lst[candidate_items] / (weight_lst[candidate_items] + 1e-6)\n        v2_ratios = value2_lst[candidate_items] / (weight_lst[candidate_items] + 1e-6)\n        combined_ratios = v1_ratios + v2_ratios\n\n        # Sort by combined ratio in descending order\n        sorted_indices = np.argsort(-combined_ratios)\n        for idx in sorted_indices:\n            i = candidate_items[idx]\n            if weight_lst[i] <= remaining_weight:\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    # Step 3: Weighted random flip based on objective importance\n    # This step helps explore different parts of the Pareto front\n    if random.random() < 0.3:  # 30% chance to perform this step\n        # Determine which objective to prioritize (randomly)\n        prioritize_v1 = random.random() < 0.5\n\n        # Calculate value-to-weight ratios for the prioritized objective\n        if prioritize_v1:\n            ratios = value1_lst / (weight_lst + 1e-6)\n        else:\n            ratios = value2_lst / (weight_lst + 1e-6)\n\n        # Flip items with high ratio with higher probability\n        for i in range(len(new_solution)):\n            flip_prob = ratios[i] * 0.5  # Scale probability\n            if random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n        # Ensure feasibility\n        current_weight = np.sum(new_solution * weight_lst)\n        if current_weight > capacity:\n            # Remove items with lowest ratio in the prioritized objective\n            excess = current_weight - capacity\n            removable_items = np.where(new_solution == 1)[0]\n            if prioritize_v1:\n                removable_ratios = value1_lst[removable_items] / (weight_lst[removable_items] + 1e-6)\n            else:\n                removable_ratios = value2_lst[removable_items] / (weight_lst[removable_items] + 1e-6)\n            sorted_indices = np.argsort(removable_ratios)\n            for idx in sorted_indices:\n                i = removable_items[idx]\n                if excess <= 0:\n                    break\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 277,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded\n    # (assuming archive is sorted by dominance, we pick a solution near the middle)\n    base_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution, (base_val1, base_val2) = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap items (50% chance) to introduce diversity\n    # 2. Greedily add items with highest value-to-weight ratio for both objectives\n    # 3. Remove items with lowest value-to-weight ratio to free up capacity\n\n    # Step 1: Random swaps\n    if np.random.rand() < 0.5:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Step 2: Greedy addition based on value-to-weight ratio\n    # Calculate value-to-weight ratios for both objectives\n    vw_ratio1 = value1_lst / weight_lst\n    vw_ratio2 = value2_lst / weight_lst\n\n    # Combine ratios using a weighted sum (could be tuned)\n    combined_ratio = 0.5 * vw_ratio1 + 0.5 * vw_ratio2\n\n    # Sort items by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Try to add items with highest combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Step 3: Remove items with lowest ratio if capacity is still tight\n    if total_weight > capacity:\n        # Calculate new combined ratio for items in the knapsack\n        in_knapsack = new_solution == 1\n        combined_ratio_in = combined_ratio[in_knapsack]\n        sorted_in_indices = np.argsort(combined_ratio_in)\n\n        # Remove items with lowest ratio until feasible\n        for i in sorted_in_indices:\n            idx = np.where(in_knapsack)[0][i]\n            if total_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.9145426672155607,
            1.345736712217331
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded\n    # (assuming archive is sorted by dominance, we pick a solution near the middle)\n    base_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution, (base_val1, base_val2) = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap items (50% chance) to introduce diversity\n    # 2. Greedily add items with highest value-to-weight ratio for both objectives\n    # 3. Remove items with lowest value-to-weight ratio to free up capacity\n\n    # Step 1: Random swaps\n    if np.random.rand() < 0.5:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # Step 2: Greedy addition based on value-to-weight ratio\n    # Calculate value-to-weight ratios for both objectives\n    vw_ratio1 = value1_lst / weight_lst\n    vw_ratio2 = value2_lst / weight_lst\n\n    # Combine ratios using a weighted sum (could be tuned)\n    combined_ratio = 0.5 * vw_ratio1 + 0.5 * vw_ratio2\n\n    # Sort items by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    # Try to add items with highest combined ratio\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Step 3: Remove items with lowest ratio if capacity is still tight\n    if total_weight > capacity:\n        # Calculate new combined ratio for items in the knapsack\n        in_knapsack = new_solution == 1\n        combined_ratio_in = combined_ratio[in_knapsack]\n        sorted_in_indices = np.argsort(combined_ratio_in)\n\n        # Remove items with lowest ratio until feasible\n        for i in sorted_in_indices:\n            idx = np.where(in_knapsack)[0][i]\n            if total_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 278,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their total value (sum of both objectives) to prioritize high-value solutions\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Randomly select from top 50% of solutions to avoid always picking the best\n        selection_pool = archive_sorted[:max(1, len(archive_sorted) // 2)]\n        base_solution, _ = random.choice(selection_pool)\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (10% of the items)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), max(1, n_items // 10))\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it's in the solution\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            # Add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Greedily add items with highest marginal utility (ratio of (value1 + value2)/weight)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utilities = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Small epsilon to avoid division by zero\n        # Get indices of items not in the solution, sorted by marginal utility\n        candidate_indices = np.where(new_solution == 0)[0]\n        sorted_indices = sorted(candidate_indices, key=lambda x: -marginal_utilities[x])\n\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3562639673102771,
            1.1674964725971222
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their total value (sum of both objectives) to prioritize high-value solutions\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Randomly select from top 50% of solutions to avoid always picking the best\n        selection_pool = archive_sorted[:max(1, len(archive_sorted) // 2)]\n        base_solution, _ = random.choice(selection_pool)\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (10% of the items)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), max(1, n_items // 10))\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it's in the solution\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            # Add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Greedily add items with highest marginal utility (ratio of (value1 + value2)/weight)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal utility for each item not in the solution\n        marginal_utilities = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Small epsilon to avoid division by zero\n        # Get indices of items not in the solution, sorted by marginal utility\n        candidate_indices = np.where(new_solution == 0)[0]\n        sorted_indices = sorted(candidate_indices, key=lambda x: -marginal_utilities[x])\n\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 279,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    # Here, we prioritize solutions that are not on the Pareto front or have high potential for trade-offs\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1->0 or 0->1)\n    # 2. Use a greedy approach to select items that improve both objectives\n    # 3. Ensure feasibility by checking capacity constraints\n\n    # Step 1: Random flips (exploration)\n    num_flips = min(3, len(new_solution))  # Limit the number of flips\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    for _ in range(3):  # Limit the number of greedy steps\n        # Calculate current total weight and values\n        current_weight = np.sum(new_solution * weight_lst)\n        current_value1 = np.sum(new_solution * value1_lst)\n        current_value2 = np.sum(new_solution * value2_lst)\n\n        # Find items that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        for item in candidate_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Evaluate potential improvement in both objectives\n                new_value1 = current_value1 + value1_lst[item]\n                new_value2 = current_value2 + value2_lst[item]\n                if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n                   (new_value1 >= current_value1 and new_value2 >= current_value2):\n                    new_solution[item] = 1\n                    break\n\n        # Find items that can be removed to potentially improve both objectives\n        candidate_items = np.where(new_solution == 1)[0]\n        for item in candidate_items:\n            new_weight = current_weight - weight_lst[item]\n            new_value1 = current_value1 - value1_lst[item]\n            new_value2 = current_value2 - value2_lst[item]\n            if new_weight >= 0 and ((new_value1 > current_value1 and new_value2 > current_value2) or \\\n                                  (new_value1 >= current_value1 and new_value2 >= current_value2)):\n                new_solution[item] = 0\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.39182655033649316,
            2.9706229865550995
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    # Here, we prioritize solutions that are not on the Pareto front or have high potential for trade-offs\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1->0 or 0->1)\n    # 2. Use a greedy approach to select items that improve both objectives\n    # 3. Ensure feasibility by checking capacity constraints\n\n    # Step 1: Random flips (exploration)\n    num_flips = min(3, len(new_solution))  # Limit the number of flips\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    for _ in range(3):  # Limit the number of greedy steps\n        # Calculate current total weight and values\n        current_weight = np.sum(new_solution * weight_lst)\n        current_value1 = np.sum(new_solution * value1_lst)\n        current_value2 = np.sum(new_solution * value2_lst)\n\n        # Find items that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        for item in candidate_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Evaluate potential improvement in both objectives\n                new_value1 = current_value1 + value1_lst[item]\n                new_value2 = current_value2 + value2_lst[item]\n                if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n                   (new_value1 >= current_value1 and new_value2 >= current_value2):\n                    new_solution[item] = 1\n                    break\n\n        # Find items that can be removed to potentially improve both objectives\n        candidate_items = np.where(new_solution == 1)[0]\n        for item in candidate_items:\n            new_weight = current_weight - weight_lst[item]\n            new_value1 = current_value1 - value1_lst[item]\n            new_value2 = current_value2 - value2_lst[item]\n            if new_weight >= 0 and ((new_value1 > current_value1 and new_value2 > current_value2) or \\\n                                  (new_value1 >= current_value1 and new_value2 >= current_value2)):\n                new_solution[item] = 0\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 280,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (v1, v2) in archive:\n        current_weight = np.dot(sol, weight_lst)\n        if current_weight >= capacity:\n            continue  # Skip infeasible solutions\n        # Calculate potential improvement: sum of value ratios for items not in solution\n        potential_v1 = np.sum((value1_lst / weight_lst) * (1 - sol))\n        potential_v2 = np.sum((value2_lst / weight_lst) * (1 - sol))\n        candidates.append((sol, v1, v2, potential_v1, potential_v2))\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if all are infeasible\n\n    # Sort candidates by potential improvement (prioritize solutions with high potential)\n    candidates.sort(key=lambda x: -(x[3] + x[4]))\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search: combine random flips with value-density-based selection\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # First, try to add items with high value-density for both objectives\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Then perform random flips to escape local optima\n    for _ in range(min(5, n_items // 2)):  # Limit number of flips\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.942272633418109,
            3.0699973106384277
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (v1, v2) in archive:\n        current_weight = np.dot(sol, weight_lst)\n        if current_weight >= capacity:\n            continue  # Skip infeasible solutions\n        # Calculate potential improvement: sum of value ratios for items not in solution\n        potential_v1 = np.sum((value1_lst / weight_lst) * (1 - sol))\n        potential_v2 = np.sum((value2_lst / weight_lst) * (1 - sol))\n        candidates.append((sol, v1, v2, potential_v1, potential_v2))\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if all are infeasible\n\n    # Sort candidates by potential improvement (prioritize solutions with high potential)\n    candidates.sort(key=lambda x: -(x[3] + x[4]))\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search: combine random flips with value-density-based selection\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # First, try to add items with high value-density for both objectives\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Then perform random flips to escape local optima\n    for _ in range(min(5, n_items // 2)):  # Limit number of flips\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 281,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for those with higher potential for improvement\n    # Here, we use a simple heuristic to select a solution with high total weight utilization\n    base_solution, _ = max(archive, key=lambda x: np.sum(weight_lst[x[0] == 1]) / capacity)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Identify items that can be flipped (either added or removed)\n    # We prioritize items that can improve at least one objective without violating capacity\n    candidate_indices = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if removing the item can improve at least one objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidate_indices.append(i)\n        else:\n            # Check if adding the item can improve at least one objective and not violate capacity\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        # If no candidates, randomly flip one item (ensuring feasibility)\n        feasible_indices = [i for i in range(len(new_solution))\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if not feasible_indices:\n            return new_solution  # No feasible move possible\n        flip_index = random.choice(feasible_indices)\n    else:\n        # Select the best candidate based on marginal improvement in both objectives\n        best_candidate = None\n        best_improvement = -float('inf')\n        for i in candidate_indices:\n            if new_solution[i] == 1:\n                # Calculate marginal improvement if we remove the item\n                delta_value1 = -value1_lst[i]\n                delta_value2 = -value2_lst[i]\n                improvement = delta_value1 + delta_value2  # Simple sum of improvements\n            else:\n                # Calculate marginal improvement if we add the item\n                delta_value1 = value1_lst[i]\n                delta_value2 = value2_lst[i]\n                improvement = delta_value1 + delta_value2\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = i\n\n        flip_index = best_candidate\n\n    # Flip the selected item\n    new_solution[flip_index] = 1 - new_solution[flip_index]\n\n    return new_solution\n\n",
        "score": [
            -0.8230628581851407,
            1.7665463089942932
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a preference for those with higher potential for improvement\n    # Here, we use a simple heuristic to select a solution with high total weight utilization\n    base_solution, _ = max(archive, key=lambda x: np.sum(weight_lst[x[0] == 1]) / capacity)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Identify items that can be flipped (either added or removed)\n    # We prioritize items that can improve at least one objective without violating capacity\n    candidate_indices = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if removing the item can improve at least one objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidate_indices.append(i)\n        else:\n            # Check if adding the item can improve at least one objective and not violate capacity\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        # If no candidates, randomly flip one item (ensuring feasibility)\n        feasible_indices = [i for i in range(len(new_solution))\n                           if (new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if not feasible_indices:\n            return new_solution  # No feasible move possible\n        flip_index = random.choice(feasible_indices)\n    else:\n        # Select the best candidate based on marginal improvement in both objectives\n        best_candidate = None\n        best_improvement = -float('inf')\n        for i in candidate_indices:\n            if new_solution[i] == 1:\n                # Calculate marginal improvement if we remove the item\n                delta_value1 = -value1_lst[i]\n                delta_value2 = -value2_lst[i]\n                improvement = delta_value1 + delta_value2  # Simple sum of improvements\n            else:\n                # Calculate marginal improvement if we add the item\n                delta_value1 = value1_lst[i]\n                delta_value2 = value2_lst[i]\n                improvement = delta_value1 + delta_value2\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = i\n\n        flip_index = best_candidate\n\n    # Flip the selected item\n    new_solution[flip_index] = 1 - new_solution[flip_index]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 282,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    N = len(base_solution)\n\n    # Step 1: Random flip (exploration)\n    flip_idx = np.random.randint(0, N)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]  # Flip the bit\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, undo the flip and try a different approach\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        # Try to remove a random item to make it feasible\n        while total_weight > capacity:\n            remove_idx = np.random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    candidate_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(candidate_items)\n\n    for item in candidate_items:\n        if np.sum(weight_lst * new_solution) + weight_lst[item] <= capacity:\n            # Check if adding this item improves both objectives\n            new_val1 = current_val1 + value1_lst[item]\n            new_val2 = current_val2 + value2_lst[item]\n            if new_val1 > current_val1 and new_val2 > current_val2:\n                new_solution[item] = 1\n                current_val1, current_val2 = new_val1, new_val2\n\n    return new_solution\n\n",
        "score": [
            -0.39584681411094214,
            5.933458209037781
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    N = len(base_solution)\n\n    # Step 1: Random flip (exploration)\n    flip_idx = np.random.randint(0, N)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]  # Flip the bit\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, undo the flip and try a different approach\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        # Try to remove a random item to make it feasible\n        while total_weight > capacity:\n            remove_idx = np.random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    candidate_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(candidate_items)\n\n    for item in candidate_items:\n        if np.sum(weight_lst * new_solution) + weight_lst[item] <= capacity:\n            # Check if adding this item improves both objectives\n            new_val1 = current_val1 + value1_lst[item]\n            new_val2 = current_val2 + value2_lst[item]\n            if new_val1 > current_val1 and new_val2 > current_val2:\n                new_solution[item] = 1\n                current_val1, current_val2 = new_val1, new_val2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 283,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We select a solution that is not too close to the boundary of the capacity\n    selected_idx = 0\n    max_potential = -1\n    for i, (solution, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        remaining_capacity = capacity - current_weight\n        potential = remaining_capacity * (np.sum(value1_lst) + np.sum(value2_lst)) / len(weight_lst)\n        if potential > max_potential:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Randomly select a subset of items to consider for flipping\n    subset_size = max(1, int(0.2 * n_items))\n    candidate_indices = random.sample(range(n_items), subset_size)\n\n    # Evaluate flipping each candidate item\n    best_flip = None\n    best_improvement = 0\n\n    for idx in candidate_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                # Calculate improvement in both objectives\n                improvement1 = value1_lst[idx]\n                improvement2 = value2_lst[idx]\n                total_improvement = improvement1 + improvement2\n                if total_improvement > best_improvement:\n                    best_improvement = total_improvement\n                    best_flip = (idx, 0)\n        else:\n            # Try adding the item\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                improvement1 = value1_lst[idx]\n                improvement2 = value2_lst[idx]\n                total_improvement = improvement1 + improvement2\n                if total_improvement > best_improvement:\n                    best_improvement = total_improvement\n                    best_flip = (idx, 1)\n\n    # Apply the best flip if found\n    if best_flip is not None:\n        idx, value = best_flip\n        new_solution[idx] = value\n\n    # Step 3: Apply a small random perturbation to escape local optima\n    if random.random() < 0.3:  # 30% chance of perturbation\n        perturb_indices = random.sample(range(n_items), min(2, n_items))\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n            else:\n                if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.805235995091643,
            3.137032240629196
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We select a solution that is not too close to the boundary of the capacity\n    selected_idx = 0\n    max_potential = -1\n    for i, (solution, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        remaining_capacity = capacity - current_weight\n        potential = remaining_capacity * (np.sum(value1_lst) + np.sum(value2_lst)) / len(weight_lst)\n        if potential > max_potential:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Randomly select a subset of items to consider for flipping\n    subset_size = max(1, int(0.2 * n_items))\n    candidate_indices = random.sample(range(n_items), subset_size)\n\n    # Evaluate flipping each candidate item\n    best_flip = None\n    best_improvement = 0\n\n    for idx in candidate_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                # Calculate improvement in both objectives\n                improvement1 = value1_lst[idx]\n                improvement2 = value2_lst[idx]\n                total_improvement = improvement1 + improvement2\n                if total_improvement > best_improvement:\n                    best_improvement = total_improvement\n                    best_flip = (idx, 0)\n        else:\n            # Try adding the item\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                improvement1 = value1_lst[idx]\n                improvement2 = value2_lst[idx]\n                total_improvement = improvement1 + improvement2\n                if total_improvement > best_improvement:\n                    best_improvement = total_improvement\n                    best_flip = (idx, 1)\n\n    # Apply the best flip if found\n    if best_flip is not None:\n        idx, value = best_flip\n        new_solution[idx] = value\n\n    # Step 3: Apply a small random perturbation to escape local optima\n    if random.random() < 0.3:  # 30% chance of perturbation\n        perturb_indices = random.sample(range(n_items), min(2, n_items))\n        for idx in perturb_indices:\n            if new_solution[idx] == 1:\n                if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n            else:\n                if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 284,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol_obj[0] for sol_obj in archive]\n    archive_objectives = [sol_obj[1] for sol_obj in archive]\n\n    # Calculate crowding distance to identify less crowded solutions (more potential for improvement)\n    crowding_distances = np.zeros(len(archive))\n    objectives = np.array(archive_objectives)\n\n    for m in range(objectives.shape[1]):\n        sorted_idx = np.argsort(objectives[:, m])\n        sorted_obj = objectives[sorted_idx, m]\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if sorted_obj[-1] - sorted_obj[0] == 0:\n                crowding_distances[sorted_idx[i]] += 0\n            else:\n                crowding_distances[sorted_idx[i]] += (sorted_obj[i+1] - sorted_obj[i-1]) / (sorted_obj[-1] - sorted_obj[0])\n\n    # Select a solution with low crowding distance (promising for improvement)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Strategy 1: Randomly flip a subset of items (exploration)\n    num_flips = min(3, len(weight_lst))  # Limit flips to avoid excessive changes\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n\n    for i in flip_indices:\n        if base_solution[i] == 1:\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n        else:\n            if total_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    # Strategy 2: Value-based flip (exploitation)\n    # Identify items with high marginal value-to-weight ratio\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Flip items with highest marginal value in either objective\n    for i in np.argsort(-marginal_value1)[::-1]:\n        if base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n            break\n\n    for i in np.argsort(-marginal_value2)[::-1]:\n        if base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8886887004155929,
            1.8939094841480255
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol_obj[0] for sol_obj in archive]\n    archive_objectives = [sol_obj[1] for sol_obj in archive]\n\n    # Calculate crowding distance to identify less crowded solutions (more potential for improvement)\n    crowding_distances = np.zeros(len(archive))\n    objectives = np.array(archive_objectives)\n\n    for m in range(objectives.shape[1]):\n        sorted_idx = np.argsort(objectives[:, m])\n        sorted_obj = objectives[sorted_idx, m]\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            if sorted_obj[-1] - sorted_obj[0] == 0:\n                crowding_distances[sorted_idx[i]] += 0\n            else:\n                crowding_distances[sorted_idx[i]] += (sorted_obj[i+1] - sorted_obj[i-1]) / (sorted_obj[-1] - sorted_obj[0])\n\n    # Select a solution with low crowding distance (promising for improvement)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Strategy 1: Randomly flip a subset of items (exploration)\n    num_flips = min(3, len(weight_lst))  # Limit flips to avoid excessive changes\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n\n    for i in flip_indices:\n        if base_solution[i] == 1:\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n        else:\n            if total_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    # Strategy 2: Value-based flip (exploitation)\n    # Identify items with high marginal value-to-weight ratio\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Flip items with highest marginal value in either objective\n    for i in np.argsort(-marginal_value1)[::-1]:\n        if base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n            break\n\n    for i in np.argsort(-marginal_value2)[::-1]:\n        if base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n            break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 285,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement scores for each solution\n    potential_scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        # Potential score is a combination of remaining capacity and objective values\n        score = remaining_capacity * (obj[0] + obj[1]) / (np.sum(value1_lst) + np.sum(value2_lst))\n        potential_scores.append(score)\n\n    # Normalize scores and select a solution with probability proportional to its score\n    total_score = sum(potential_scores)\n    if total_score == 0:\n        selected_idx = np.random.randint(0, len(archive))\n    else:\n        normalized_scores = [score / total_score for score in potential_scores]\n        selected_idx = np.random.choice(len(archive), p=normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (1-3)\n    num_flips = np.random.randint(1, 4)\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n\n    # 2. For each flipped item, consider adding it if it fits, or removing it if it doesn't\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n\n    # 3. If no improvement, perform a biased random walk\n    if np.array_equal(new_solution, base_solution):\n        # Select items with higher marginal value-to-weight ratio\n        value_to_weight1 = value1_lst / weight_lst\n        value_to_weight2 = value2_lst / weight_lst\n        combined_ratio = value_to_weight1 + value_to_weight2\n\n        # Sort indices by combined ratio (descending)\n        sorted_indices = np.argsort(-combined_ratio)\n\n        # Try adding items in order of highest ratio until capacity is reached\n        for idx in sorted_indices:\n            if new_solution[idx] == 0:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_weight = np.sum(weight_lst * temp_solution)\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                else:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.2986062788276763,
            8.778159856796265
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate potential improvement scores for each solution\n    potential_scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        # Potential score is a combination of remaining capacity and objective values\n        score = remaining_capacity * (obj[0] + obj[1]) / (np.sum(value1_lst) + np.sum(value2_lst))\n        potential_scores.append(score)\n\n    # Normalize scores and select a solution with probability proportional to its score\n    total_score = sum(potential_scores)\n    if total_score == 0:\n        selected_idx = np.random.randint(0, len(archive))\n    else:\n        normalized_scores = [score / total_score for score in potential_scores]\n        selected_idx = np.random.choice(len(archive), p=normalized_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (1-3)\n    num_flips = np.random.randint(1, 4)\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n\n    # 2. For each flipped item, consider adding it if it fits, or removing it if it doesn't\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n\n    # 3. If no improvement, perform a biased random walk\n    if np.array_equal(new_solution, base_solution):\n        # Select items with higher marginal value-to-weight ratio\n        value_to_weight1 = value1_lst / weight_lst\n        value_to_weight2 = value2_lst / weight_lst\n        combined_ratio = value_to_weight1 + value_to_weight2\n\n        # Sort indices by combined ratio (descending)\n        sorted_indices = np.argsort(-combined_ratio)\n\n        # Try adding items in order of highest ratio until capacity is reached\n        for idx in sorted_indices:\n            if new_solution[idx] == 0:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                temp_weight = np.sum(weight_lst * temp_solution)\n                if temp_weight <= capacity:\n                    new_solution = temp_solution\n                else:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 286,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    def potential_score(solution, objective):\n        # Score based on the sum of normalized values and the fraction of capacity used\n        total_weight = np.sum(weight_lst * solution)\n        weight_ratio = total_weight / capacity\n        value1_norm = objective[0] / np.sum(value1_lst)\n        value2_norm = objective[1] / np.sum(value2_lst)\n        return (value1_norm + value2_norm) * (1 - weight_ratio)\n\n    # Sort solutions by potential score in descending order\n    scored_solutions = [(potential_score(sol, obj), sol, obj) for sol, obj in archive]\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n\n    # Select top 30% of solutions for consideration\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    candidates = [sol for _, sol, _ in scored_solutions[:top_k]]\n\n    # Randomly select a base solution from top candidates\n    base_solution = random.choice(candidates).copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with probability based on their marginal contribution)\n    for i in range(len(new_solution)):\n        if random.random() < 0.2:  # 20% chance to consider flipping\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # If item is included, decide to remove based on marginal contribution\n                marginal_contrib1 = value1_lst[i] / (current_weight - weight_lst[i])\n                marginal_contrib2 = value2_lst[i] / (current_weight - weight_lst[i])\n                if random.random() < (marginal_contrib1 + marginal_contrib2) / (np.sum(value1_lst) + np.sum(value2_lst)):\n                    new_solution[i] = 0\n            else:\n                # If item is not included, decide to add if it fits\n                if current_weight + weight_lst[i] <= capacity:\n                    marginal_contrib1 = value1_lst[i] / (current_weight + weight_lst[i])\n                    marginal_contrib2 = value2_lst[i] / (current_weight + weight_lst[i])\n                    if random.random() < (marginal_contrib1 + marginal_contrib2) / (np.sum(value1_lst) + np.sum(value2_lst)):\n                        new_solution[i] = 1\n\n    # Strategy 2: Randomly swap two items if it improves at least one objective\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        # Check feasibility\n        if np.sum(weight_lst * temp_solution) <= capacity:\n            # Check if at least one objective improves\n            old_value1 = np.sum(value1_lst * new_solution)\n            old_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            if (new_value1 > old_value1 or new_value2 > old_value2):\n                new_solution = temp_solution\n\n    # Strategy 3: Randomly add or remove items based on their diversity potential\n    if random.random() < 0.3:  # 30% chance to apply this strategy\n        excluded_items = [i for i in range(len(new_solution)) if new_solution[i] == 0]\n        included_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n\n        if excluded_items and included_items:\n            # Select an excluded item with high potential\n            potential_excluded = sorted(excluded_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x], reverse=True)\n            candidate_excluded = potential_excluded[0] if len(potential_excluded) > 0 else random.choice(excluded_items)\n\n            # Select an included item with low potential\n            potential_included = sorted(included_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n            candidate_included = potential_included[0] if len(potential_included) > 0 else random.choice(included_items)\n\n            # Try to swap them if feasible\n            temp_solution = new_solution.copy()\n            temp_solution[candidate_excluded] = 1\n            temp_solution[candidate_included] = 0\n\n            if np.sum(weight_lst * temp_solution) <= capacity:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.42201506076694173,
            10.601821929216385
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    def potential_score(solution, objective):\n        # Score based on the sum of normalized values and the fraction of capacity used\n        total_weight = np.sum(weight_lst * solution)\n        weight_ratio = total_weight / capacity\n        value1_norm = objective[0] / np.sum(value1_lst)\n        value2_norm = objective[1] / np.sum(value2_lst)\n        return (value1_norm + value2_norm) * (1 - weight_ratio)\n\n    # Sort solutions by potential score in descending order\n    scored_solutions = [(potential_score(sol, obj), sol, obj) for sol, obj in archive]\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n\n    # Select top 30% of solutions for consideration\n    top_k = max(1, int(0.3 * len(scored_solutions)))\n    candidates = [sol for _, sol, _ in scored_solutions[:top_k]]\n\n    # Randomly select a base solution from top candidates\n    base_solution = random.choice(candidates).copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with probability based on their marginal contribution)\n    for i in range(len(new_solution)):\n        if random.random() < 0.2:  # 20% chance to consider flipping\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # If item is included, decide to remove based on marginal contribution\n                marginal_contrib1 = value1_lst[i] / (current_weight - weight_lst[i])\n                marginal_contrib2 = value2_lst[i] / (current_weight - weight_lst[i])\n                if random.random() < (marginal_contrib1 + marginal_contrib2) / (np.sum(value1_lst) + np.sum(value2_lst)):\n                    new_solution[i] = 0\n            else:\n                # If item is not included, decide to add if it fits\n                if current_weight + weight_lst[i] <= capacity:\n                    marginal_contrib1 = value1_lst[i] / (current_weight + weight_lst[i])\n                    marginal_contrib2 = value2_lst[i] / (current_weight + weight_lst[i])\n                    if random.random() < (marginal_contrib1 + marginal_contrib2) / (np.sum(value1_lst) + np.sum(value2_lst)):\n                        new_solution[i] = 1\n\n    # Strategy 2: Randomly swap two items if it improves at least one objective\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        # Check feasibility\n        if np.sum(weight_lst * temp_solution) <= capacity:\n            # Check if at least one objective improves\n            old_value1 = np.sum(value1_lst * new_solution)\n            old_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = np.sum(value1_lst * temp_solution)\n            new_value2 = np.sum(value2_lst * temp_solution)\n\n            if (new_value1 > old_value1 or new_value2 > old_value2):\n                new_solution = temp_solution\n\n    # Strategy 3: Randomly add or remove items based on their diversity potential\n    if random.random() < 0.3:  # 30% chance to apply this strategy\n        excluded_items = [i for i in range(len(new_solution)) if new_solution[i] == 0]\n        included_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n\n        if excluded_items and included_items:\n            # Select an excluded item with high potential\n            potential_excluded = sorted(excluded_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x], reverse=True)\n            candidate_excluded = potential_excluded[0] if len(potential_excluded) > 0 else random.choice(excluded_items)\n\n            # Select an included item with low potential\n            potential_included = sorted(included_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n            candidate_included = potential_included[0] if len(potential_included) > 0 else random.choice(included_items)\n\n            # Try to swap them if feasible\n            temp_solution = new_solution.copy()\n            temp_solution[candidate_excluded] = 1\n            temp_solution[candidate_included] = 0\n\n            if np.sum(weight_lst * temp_solution) <= capacity:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 287,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    # Prioritize solutions with high value ratios but not fully packed\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Not too close to capacity\n            value_ratio = (v1 + v2) / (total_weight + 1e-6)\n            candidates.append((sol, value_ratio))\n\n    if not candidates:\n        # If no suitable candidates, pick a random solution\n        base_solution = archive[random.randint(0, len(archive) - 1)][0].copy()\n    else:\n        # Select the solution with highest value ratio\n        base_solution = max(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Probabilistic flip (like bit flip but weighted by value/weight ratio)\n    # 2. If stuck, perform a targeted swap between high-value items\n\n    # Calculate value-to-weight ratios\n    v1_ratio = value1_lst / (weight_lst + 1e-6)\n    v2_ratio = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = v1_ratio + v2_ratio\n\n    # Step 1: Probabilistic flip\n    for i in range(len(new_solution)):\n        if random.random() < 0.1:  # 10% chance to flip each bit\n            if new_solution[i] == 1:\n                # Remove item\n                new_solution[i] = 0\n            else:\n                # Add item if it doesn't exceed capacity\n                total_weight = np.sum(weight_lst * new_solution)\n                if total_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Step 2: If no improvement, perform targeted swap\n    if np.array_equal(new_solution, base_solution):\n        # Find items to swap: one included with low ratio, one excluded with high ratio\n        included_low = [i for i in range(len(new_solution)) if new_solution[i] == 1 and combined_ratio[i] < np.median(combined_ratio)]\n        excluded_high = [i for i in range(len(new_solution)) if new_solution[i] == 0 and combined_ratio[i] > np.median(combined_ratio)]\n\n        if included_low and excluded_high:\n            # Perform the swap\n            i = random.choice(included_low)\n            j = random.choice(excluded_high)\n\n            # Check if swap is feasible\n            total_weight = np.sum(weight_lst * new_solution)\n            if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution is feasible\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value/weight ratio until feasible\n        while total_weight > capacity:\n            # Find included items\n            included = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n            if not included:\n                break  # Shouldn't happen as at least one item is included\n\n            # Remove item with lowest combined ratio\n            i = min(included, key=lambda x: combined_ratio[x])\n            new_solution[i] = 0\n            total_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.341251375691832,
            1.1352128684520721
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    # Prioritize solutions with high value ratios but not fully packed\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Not too close to capacity\n            value_ratio = (v1 + v2) / (total_weight + 1e-6)\n            candidates.append((sol, value_ratio))\n\n    if not candidates:\n        # If no suitable candidates, pick a random solution\n        base_solution = archive[random.randint(0, len(archive) - 1)][0].copy()\n    else:\n        # Select the solution with highest value ratio\n        base_solution = max(candidates, key=lambda x: x[1])[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Probabilistic flip (like bit flip but weighted by value/weight ratio)\n    # 2. If stuck, perform a targeted swap between high-value items\n\n    # Calculate value-to-weight ratios\n    v1_ratio = value1_lst / (weight_lst + 1e-6)\n    v2_ratio = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = v1_ratio + v2_ratio\n\n    # Step 1: Probabilistic flip\n    for i in range(len(new_solution)):\n        if random.random() < 0.1:  # 10% chance to flip each bit\n            if new_solution[i] == 1:\n                # Remove item\n                new_solution[i] = 0\n            else:\n                # Add item if it doesn't exceed capacity\n                total_weight = np.sum(weight_lst * new_solution)\n                if total_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Step 2: If no improvement, perform targeted swap\n    if np.array_equal(new_solution, base_solution):\n        # Find items to swap: one included with low ratio, one excluded with high ratio\n        included_low = [i for i in range(len(new_solution)) if new_solution[i] == 1 and combined_ratio[i] < np.median(combined_ratio)]\n        excluded_high = [i for i in range(len(new_solution)) if new_solution[i] == 0 and combined_ratio[i] > np.median(combined_ratio)]\n\n        if included_low and excluded_high:\n            # Perform the swap\n            i = random.choice(included_low)\n            j = random.choice(excluded_high)\n\n            # Check if swap is feasible\n            total_weight = np.sum(weight_lst * new_solution)\n            if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution is feasible\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value/weight ratio until feasible\n        while total_weight > capacity:\n            # Find included items\n            included = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n            if not included:\n                break  # Shouldn't happen as at least one item is included\n\n            # Remove item with lowest combined ratio\n            i = min(included, key=lambda x: combined_ratio[x])\n            new_solution[i] = 0\n            total_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 288,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Here, we use a simple approach: select a solution with high total value in either objective\n    # More sophisticated selection strategies could be used (e.g., crowding distance, hypervolume)\n    selected_idx = np.argmax([obj[0] + obj[1] for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a list of candidate items to flip\n    candidate_indices = np.where(base_solution == 1)[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 0)[0]\n\n    # Randomly select a subset of candidates to flip\n    np.random.shuffle(candidate_indices)\n    flip_indices = candidate_indices[:max(1, len(candidate_indices) // 3)]\n\n    # Flip the selected items\n    new_solution = base_solution.copy()\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is in the solution, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not in the solution, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a greedy improvement step to maximize marginal contributions\n    # Calculate marginal contributions for all items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    for idx in not_in_solution:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Calculate marginal contribution in both objectives\n            marginal1 = value1_lst[idx]\n            marginal2 = value2_lst[idx]\n            # Simple greedy selection: add item if it improves both objectives\n            if marginal1 > 0 and marginal2 > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5036417168116936,
            2.047939270734787
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Here, we use a simple approach: select a solution with high total value in either objective\n    # More sophisticated selection strategies could be used (e.g., crowding distance, hypervolume)\n    selected_idx = np.argmax([obj[0] + obj[1] for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a list of candidate items to flip\n    candidate_indices = np.where(base_solution == 1)[0]\n    if len(candidate_indices) == 0:\n        candidate_indices = np.where(base_solution == 0)[0]\n\n    # Randomly select a subset of candidates to flip\n    np.random.shuffle(candidate_indices)\n    flip_indices = candidate_indices[:max(1, len(candidate_indices) // 3)]\n\n    # Flip the selected items\n    new_solution = base_solution.copy()\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is in the solution, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not in the solution, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Apply a greedy improvement step to maximize marginal contributions\n    # Calculate marginal contributions for all items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    for idx in not_in_solution:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Calculate marginal contribution in both objectives\n            marginal1 = value1_lst[idx]\n            marginal2 = value2_lst[idx]\n            # Simple greedy selection: add item if it improves both objectives\n            if marginal1 > 0 and marginal2 > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 289,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate potential improvements for each item\n    potential_items = []\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            # Check if removing this item could help (weight reduction)\n            if current_weight - weight_lst[i] <= capacity:\n                potential_items.append((i, -weight_lst[i], -value1_lst[i], -value2_lst[i]))\n        else:\n            # Check if adding this item could help (value increase)\n            if current_weight + weight_lst[i] <= capacity:\n                potential_items.append((i, weight_lst[i], value1_lst[i], value2_lst[i]))\n\n    if not potential_items:\n        return base_solution\n\n    # Sort by combined potential improvement (weight + value)\n    potential_items.sort(key=lambda x: -(x[2] + x[3]))\n\n    # Select top 10% or at least 1 item for modification\n    num_candidates = max(1, len(potential_items) // 10)\n    selected_indices = [x[0] for x in potential_items[:num_candidates]]\n\n    # Apply changes to the solution\n    new_solution = base_solution.copy()\n    for idx in selected_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break\n            # Remove item with smallest ratio of (value1 + value2) / weight\n            ratios = (value1_lst[items_in_solution] + value2_lst[items_in_solution]) / weight_lst[items_in_solution]\n            item_to_remove = items_in_solution[np.argmin(ratios)]\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.8279358249699544,
            1.2731997966766357
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Calculate potential improvements for each item\n    potential_items = []\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            # Check if removing this item could help (weight reduction)\n            if current_weight - weight_lst[i] <= capacity:\n                potential_items.append((i, -weight_lst[i], -value1_lst[i], -value2_lst[i]))\n        else:\n            # Check if adding this item could help (value increase)\n            if current_weight + weight_lst[i] <= capacity:\n                potential_items.append((i, weight_lst[i], value1_lst[i], value2_lst[i]))\n\n    if not potential_items:\n        return base_solution\n\n    # Sort by combined potential improvement (weight + value)\n    potential_items.sort(key=lambda x: -(x[2] + x[3]))\n\n    # Select top 10% or at least 1 item for modification\n    num_candidates = max(1, len(potential_items) // 10)\n    selected_indices = [x[0] for x in potential_items[:num_candidates]]\n\n    # Apply changes to the solution\n    new_solution = base_solution.copy()\n    for idx in selected_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break\n            # Remove item with smallest ratio of (value1 + value2) / weight\n            ratios = (value1_lst[items_in_solution] + value2_lst[items_in_solution]) / weight_lst[items_in_solution]\n            item_to_remove = items_in_solution[np.argmin(ratios)]\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 290,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions that are:\n    # 1. Non-dominated (already filtered in archive)\n    # 2. Have some room for improvement (not fully packed)\n    # 3. Have high potential (high value or diversity)\n\n    # Calculate current total weight and capacity utilization\n    solution_weights = [np.sum(weight_lst[s[0] == 1]) for s in archive]\n    utilization = [w / capacity for w in solution_weights]\n\n    # Score solutions based on potential for improvement (lower utilization is better)\n    scores = [1 - u for u in utilization]\n\n    # Add some randomness to selection to avoid local optima\n    selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    base_solution, (current_v1, current_v2) = archive[selected_idx]\n\n    # Step 2: Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Determine which objective to prioritize for improvement\n    # We alternate between objectives to balance improvement\n    if random.random() < 0.5:\n        # Focus on value1\n        value_lst = value1_lst\n        other_value_lst = value2_lst\n    else:\n        # Focus on value2\n        value_lst = value2_lst\n        other_value_lst = value1_lst\n\n    # Step 2.1: Value-driven swap operator\n    # Identify high-value and low-value items in the current solution\n    in_solution = new_solution == 1\n    out_solution = new_solution == 0\n\n    # Calculate value ratios to identify high-value items\n    value_ratios = value_lst / (other_value_lst + 1e-6)  # Avoid division by zero\n\n    # Identify top 20% high-value items in solution\n    high_value_in = np.where(in_solution)[0]\n    if len(high_value_in) > 0:\n        high_value_threshold = np.percentile(value_ratios[high_value_in], 80)\n        high_value_items = high_value_in[value_ratios[high_value_in] >= high_value_threshold]\n    else:\n        high_value_items = np.array([], dtype=int)\n\n    # Identify bottom 20% low-value items not in solution\n    low_value_out = np.where(out_solution)[0]\n    if len(low_value_out) > 0:\n        low_value_threshold = np.percentile(value_ratios[low_value_out], 20)\n        low_value_items = low_value_out[value_ratios[low_value_out] <= low_value_threshold]\n    else:\n        low_value_items = np.array([], dtype=int)\n\n    # Perform swaps between high-value items in solution and low-value items out\n    if len(high_value_items) > 0 and len(low_value_items) > 0:\n        # Select a random high-value item to remove\n        item_to_remove = random.choice(high_value_items)\n        current_weight = np.sum(weight_lst[new_solution == 1])\n\n        # Find low-value items we can add without exceeding capacity\n        possible_additions = []\n        for item in low_value_items:\n            if (current_weight - weight_lst[item_to_remove] + weight_lst[item]) <= capacity:\n                possible_additions.append(item)\n\n        if possible_additions:\n            # Select a random low-value item to add\n            item_to_add = random.choice(possible_additions)\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # Step 2.2: Random bit flip for diversification\n    # With 10% probability, perform a random bit flip that maintains feasibility\n    if random.random() < 0.1:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Find feasible swaps\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            feasible_swaps = []\n\n            for remove_item in in_items:\n                for add_item in out_items:\n                    if (current_weight - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                        feasible_swaps.append((remove_item, add_item))\n\n            if feasible_swaps:\n                remove_item, add_item = random.choice(feasible_swaps)\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.6793136258684349,
            7.289168030023575
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions that are:\n    # 1. Non-dominated (already filtered in archive)\n    # 2. Have some room for improvement (not fully packed)\n    # 3. Have high potential (high value or diversity)\n\n    # Calculate current total weight and capacity utilization\n    solution_weights = [np.sum(weight_lst[s[0] == 1]) for s in archive]\n    utilization = [w / capacity for w in solution_weights]\n\n    # Score solutions based on potential for improvement (lower utilization is better)\n    scores = [1 - u for u in utilization]\n\n    # Add some randomness to selection to avoid local optima\n    selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    base_solution, (current_v1, current_v2) = archive[selected_idx]\n\n    # Step 2: Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Determine which objective to prioritize for improvement\n    # We alternate between objectives to balance improvement\n    if random.random() < 0.5:\n        # Focus on value1\n        value_lst = value1_lst\n        other_value_lst = value2_lst\n    else:\n        # Focus on value2\n        value_lst = value2_lst\n        other_value_lst = value1_lst\n\n    # Step 2.1: Value-driven swap operator\n    # Identify high-value and low-value items in the current solution\n    in_solution = new_solution == 1\n    out_solution = new_solution == 0\n\n    # Calculate value ratios to identify high-value items\n    value_ratios = value_lst / (other_value_lst + 1e-6)  # Avoid division by zero\n\n    # Identify top 20% high-value items in solution\n    high_value_in = np.where(in_solution)[0]\n    if len(high_value_in) > 0:\n        high_value_threshold = np.percentile(value_ratios[high_value_in], 80)\n        high_value_items = high_value_in[value_ratios[high_value_in] >= high_value_threshold]\n    else:\n        high_value_items = np.array([], dtype=int)\n\n    # Identify bottom 20% low-value items not in solution\n    low_value_out = np.where(out_solution)[0]\n    if len(low_value_out) > 0:\n        low_value_threshold = np.percentile(value_ratios[low_value_out], 20)\n        low_value_items = low_value_out[value_ratios[low_value_out] <= low_value_threshold]\n    else:\n        low_value_items = np.array([], dtype=int)\n\n    # Perform swaps between high-value items in solution and low-value items out\n    if len(high_value_items) > 0 and len(low_value_items) > 0:\n        # Select a random high-value item to remove\n        item_to_remove = random.choice(high_value_items)\n        current_weight = np.sum(weight_lst[new_solution == 1])\n\n        # Find low-value items we can add without exceeding capacity\n        possible_additions = []\n        for item in low_value_items:\n            if (current_weight - weight_lst[item_to_remove] + weight_lst[item]) <= capacity:\n                possible_additions.append(item)\n\n        if possible_additions:\n            # Select a random low-value item to add\n            item_to_add = random.choice(possible_additions)\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # Step 2.2: Random bit flip for diversification\n    # With 10% probability, perform a random bit flip that maintains feasibility\n    if random.random() < 0.1:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Find feasible swaps\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            feasible_swaps = []\n\n            for remove_item in in_items:\n                for add_item in out_items:\n                    if (current_weight - weight_lst[remove_item] + weight_lst[add_item]) <= capacity:\n                        feasible_swaps.append((remove_item, add_item))\n\n            if feasible_swaps:\n                remove_item, add_item = random.choice(feasible_swaps)\n                new_solution[remove_item] = 0\n                new_solution[add_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 291,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards higher-value solutions\n    base_solution, (v1, v2) = random.choices(\n        archive,\n        weights=[(v1 + v2) for (sol, (v1, v2)) in archive],\n        k=1\n    )[0]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly flip a subset of items (with higher probability for lower-weight items)\n    flip_probs = np.exp(-weight_lst / np.max(weight_lst + 1e-6))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_probs * 0.3\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after flips\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove excess weight by removing items with lowest value-to-weight ratio\n        while total_weight > capacity:\n            candidate_indices = np.where(new_solution == 1)[0]\n            if len(candidate_indices) == 0:\n                break\n            # Calculate value-to-weight ratios for both objectives\n            v1_ratios = value1_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n            v2_ratios = value2_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n            combined_ratios = v1_ratios + v2_ratios\n            remove_idx = candidate_indices[np.argmin(combined_ratios)]\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # 2. Add items that improve both objectives if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        candidate_indices = np.where(new_solution == 0)[0]\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratios = value1_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n        v2_ratios = value2_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n        combined_ratios = v1_ratios + v2_ratios\n        # Sort by combined ratio in descending order\n        sorted_indices = candidate_indices[np.argsort(-combined_ratios)]\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.38818648760376817,
            2.3199056684970856
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards higher-value solutions\n    base_solution, (v1, v2) = random.choices(\n        archive,\n        weights=[(v1 + v2) for (sol, (v1, v2)) in archive],\n        k=1\n    )[0]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly flip a subset of items (with higher probability for lower-weight items)\n    flip_probs = np.exp(-weight_lst / np.max(weight_lst + 1e-6))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_probs * 0.3\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after flips\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove excess weight by removing items with lowest value-to-weight ratio\n        while total_weight > capacity:\n            candidate_indices = np.where(new_solution == 1)[0]\n            if len(candidate_indices) == 0:\n                break\n            # Calculate value-to-weight ratios for both objectives\n            v1_ratios = value1_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n            v2_ratios = value2_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n            combined_ratios = v1_ratios + v2_ratios\n            remove_idx = candidate_indices[np.argmin(combined_ratios)]\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # 2. Add items that improve both objectives if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        candidate_indices = np.where(new_solution == 0)[0]\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratios = value1_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n        v2_ratios = value2_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n        combined_ratios = v1_ratios + v2_ratios\n        # Sort by combined ratio in descending order\n        sorted_indices = candidate_indices[np.argsort(-combined_ratios)]\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 292,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # We define potential as solutions that are not too close to the Pareto front's extremes\n    # and have a balance between the two objectives\n    objectives = np.array([obj for _, obj in archive])\n    mean_obj = np.mean(objectives, axis=0)\n    std_obj = np.std(objectives, axis=0)\n\n    # Normalize objectives to compare across scales\n    normalized_obj = (objectives - mean_obj) / (std_obj + 1e-8)\n\n    # Calculate a score for each solution: higher score means more balanced and potentially improvable\n    scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    scores = 1 / (scores + 1e-8)  # Higher score for more balanced solutions\n\n    # Select solution with highest score\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # First, perform random bit flips to explore neighborhood\n    num_flips = min(3, n_items)  # Limit number of flips to avoid excessive changes\n    flip_indices = random.sample(range(n_items), num_flips)\n\n    for idx in flip_indices:\n        # Try flipping the bit\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Check feasibility\n        total_weight = np.sum(weight_lst[temp_solution == 1])\n        if total_weight <= capacity:\n            new_solution = temp_solution\n\n    # Second, perform a greedy improvement step\n    # Evaluate all possible single-bit flips and select the best one that improves at least one objective\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    best_improvement = 0\n    best_candidate = None\n\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            # Try removing item (flip from 1 to 0)\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_value1 = current_value1 - value1_lst[idx]\n                new_value2 = current_value2 - value2_lst[idx]\n\n                # Calculate improvement (we want to maximize both objectives)\n                # We use a simple weighted sum for improvement\n                improvement = 0.5 * (new_value1 - current_value1) + 0.5 * (new_value2 - current_value2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = idx\n        else:\n            # Try adding item (flip from 0 to 1)\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_value1 = current_value1 + value1_lst[idx]\n                new_value2 = current_value2 + value2_lst[idx]\n\n                improvement = 0.5 * (new_value1 - current_value1) + 0.5 * (new_value2 - current_value2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = idx\n\n    # Apply the best improvement if found\n    if best_candidate is not None:\n        new_solution[best_candidate] = 1 - new_solution[best_candidate]\n\n    return new_solution\n\n",
        "score": [
            -0.595577831332317,
            3.668285995721817
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # We define potential as solutions that are not too close to the Pareto front's extremes\n    # and have a balance between the two objectives\n    objectives = np.array([obj for _, obj in archive])\n    mean_obj = np.mean(objectives, axis=0)\n    std_obj = np.std(objectives, axis=0)\n\n    # Normalize objectives to compare across scales\n    normalized_obj = (objectives - mean_obj) / (std_obj + 1e-8)\n\n    # Calculate a score for each solution: higher score means more balanced and potentially improvable\n    scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    scores = 1 / (scores + 1e-8)  # Higher score for more balanced solutions\n\n    # Select solution with highest score\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # First, perform random bit flips to explore neighborhood\n    num_flips = min(3, n_items)  # Limit number of flips to avoid excessive changes\n    flip_indices = random.sample(range(n_items), num_flips)\n\n    for idx in flip_indices:\n        # Try flipping the bit\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]\n\n        # Check feasibility\n        total_weight = np.sum(weight_lst[temp_solution == 1])\n        if total_weight <= capacity:\n            new_solution = temp_solution\n\n    # Second, perform a greedy improvement step\n    # Evaluate all possible single-bit flips and select the best one that improves at least one objective\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    best_improvement = 0\n    best_candidate = None\n\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            # Try removing item (flip from 1 to 0)\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_value1 = current_value1 - value1_lst[idx]\n                new_value2 = current_value2 - value2_lst[idx]\n\n                # Calculate improvement (we want to maximize both objectives)\n                # We use a simple weighted sum for improvement\n                improvement = 0.5 * (new_value1 - current_value1) + 0.5 * (new_value2 - current_value2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = idx\n        else:\n            # Try adding item (flip from 0 to 1)\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_value1 = current_value1 + value1_lst[idx]\n                new_value2 = current_value2 + value2_lst[idx]\n\n                improvement = 0.5 * (new_value1 - current_value1) + 0.5 * (new_value2 - current_value2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = idx\n\n    # Apply the best improvement if found\n    if best_candidate is not None:\n        new_solution[best_candidate] = 1 - new_solution[best_candidate]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 293,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with high potential for improvement\n    def potential_score(solution, objective):\n        # Score based on normalized objective values and solution density\n        total_value1, total_value2 = objective\n        density = np.sum(solution) / len(solution)\n        normalized_value1 = total_value1 / (np.sum(value1_lst) + 1e-10)\n        normalized_value2 = total_value2 / (np.sum(value2_lst) + 1e-10)\n        return (normalized_value1 + normalized_value2) * (1 - density)\n\n    # Sort solutions by potential score (descending)\n    scored_solutions = [(potential_score(sol, obj), sol, obj) for sol, obj in archive]\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n\n    # Select top 20% of solutions with highest potential\n    top_count = max(1, len(scored_solutions) // 5)\n    selected_solutions = [sol for _, sol, _ in scored_solutions[:top_count]]\n\n    if not selected_solutions:\n        selected_solutions = [sol for sol, _ in archive]\n\n    # Randomly select a base solution from the promising ones\n    base_solution = random.choice(selected_solutions).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    def apply_hybrid_search(solution):\n        # Step 1: Random flip (with probability based on solution density)\n        flip_prob = 0.3 if np.sum(solution) / len(solution) > 0.5 else 0.7\n        for i in range(len(solution)):\n            if random.random() < flip_prob:\n                solution[i] = 1 - solution[i]\n\n        # Step 2: Weight-based swapping (swap items with similar weights)\n        if len(solution) > 1:\n            idx1, idx2 = random.sample(range(len(solution)), 2)\n            if abs(weight_lst[idx1] - weight_lst[idx2]) < capacity * 0.1:\n                solution[idx1], solution[idx2] = solution[idx2], solution[idx1]\n\n        # Step 3: Value-based flipping (flip items with high marginal value)\n        total_weight = np.sum(weight_lst[solution == 1])\n        for i in range(len(solution)):\n            if solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n                marginal_value1 = value1_lst[i]\n                marginal_value2 = value2_lst[i]\n                if (marginal_value1 > np.mean(value1_lst) or marginal_value2 > np.mean(value2_lst)) and random.random() < 0.5:\n                    solution[i] = 1\n                    total_weight += weight_lst[i]\n\n        return solution\n\n    # Apply the hybrid search and ensure feasibility\n    new_solution = apply_hybrid_search(new_solution)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Repair infeasible solutions by removing items with lowest marginal value\n    if total_weight > capacity:\n        items_in_solution = np.where(new_solution == 1)[0]\n        # Sort by marginal value (value1 + value2) in ascending order\n        sorted_items = sorted(items_in_solution, key=lambda x: value1_lst[x] + value2_lst[x])\n        for item in sorted_items:\n            if total_weight > capacity:\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3672274647970368,
            2.282461166381836
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with high potential for improvement\n    def potential_score(solution, objective):\n        # Score based on normalized objective values and solution density\n        total_value1, total_value2 = objective\n        density = np.sum(solution) / len(solution)\n        normalized_value1 = total_value1 / (np.sum(value1_lst) + 1e-10)\n        normalized_value2 = total_value2 / (np.sum(value2_lst) + 1e-10)\n        return (normalized_value1 + normalized_value2) * (1 - density)\n\n    # Sort solutions by potential score (descending)\n    scored_solutions = [(potential_score(sol, obj), sol, obj) for sol, obj in archive]\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n\n    # Select top 20% of solutions with highest potential\n    top_count = max(1, len(scored_solutions) // 5)\n    selected_solutions = [sol for _, sol, _ in scored_solutions[:top_count]]\n\n    if not selected_solutions:\n        selected_solutions = [sol for sol, _ in archive]\n\n    # Randomly select a base solution from the promising ones\n    base_solution = random.choice(selected_solutions).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    def apply_hybrid_search(solution):\n        # Step 1: Random flip (with probability based on solution density)\n        flip_prob = 0.3 if np.sum(solution) / len(solution) > 0.5 else 0.7\n        for i in range(len(solution)):\n            if random.random() < flip_prob:\n                solution[i] = 1 - solution[i]\n\n        # Step 2: Weight-based swapping (swap items with similar weights)\n        if len(solution) > 1:\n            idx1, idx2 = random.sample(range(len(solution)), 2)\n            if abs(weight_lst[idx1] - weight_lst[idx2]) < capacity * 0.1:\n                solution[idx1], solution[idx2] = solution[idx2], solution[idx1]\n\n        # Step 3: Value-based flipping (flip items with high marginal value)\n        total_weight = np.sum(weight_lst[solution == 1])\n        for i in range(len(solution)):\n            if solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n                marginal_value1 = value1_lst[i]\n                marginal_value2 = value2_lst[i]\n                if (marginal_value1 > np.mean(value1_lst) or marginal_value2 > np.mean(value2_lst)) and random.random() < 0.5:\n                    solution[i] = 1\n                    total_weight += weight_lst[i]\n\n        return solution\n\n    # Apply the hybrid search and ensure feasibility\n    new_solution = apply_hybrid_search(new_solution)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Repair infeasible solutions by removing items with lowest marginal value\n    if total_weight > capacity:\n        items_in_solution = np.where(new_solution == 1)[0]\n        # Sort by marginal value (value1 + value2) in ascending order\n        sorted_items = sorted(items_in_solution, key=lambda x: value1_lst[x] + value2_lst[x])\n        for item in sorted_items:\n            if total_weight > capacity:\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 294,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a bias towards those with higher total value (sum of both objectives)\n    weights = [sum(obj) for _, obj in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a neighbor by flipping items with high value-to-weight ratios\n    new_solution = base_solution.copy()\n    item_indices = np.arange(len(weight_lst))\n\n    # Calculate value-to-weight ratios for both objectives\n    vw_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    vw_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios and select top candidates\n    combined_ratio = vw_ratio1 + vw_ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Sort in descending order\n\n    # Try flipping top 20% of items with highest combined ratio\n    num_candidates = max(1, len(sorted_indices) // 5)\n    candidate_indices = sorted_indices[:num_candidates]\n\n    # Randomly select a subset of candidates to flip\n    flip_indices = np.random.choice(candidate_indices, size=min(3, len(candidate_indices)), replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try removing it\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try adding it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flip to ensure diversity\n    if random.random() < 0.3:\n        random_idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] >= 0:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.6285164892001509,
            0.931982547044754
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a bias towards those with higher total value (sum of both objectives)\n    weights = [sum(obj) for _, obj in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a neighbor by flipping items with high value-to-weight ratios\n    new_solution = base_solution.copy()\n    item_indices = np.arange(len(weight_lst))\n\n    # Calculate value-to-weight ratios for both objectives\n    vw_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    vw_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios and select top candidates\n    combined_ratio = vw_ratio1 + vw_ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Sort in descending order\n\n    # Try flipping top 20% of items with highest combined ratio\n    num_candidates = max(1, len(sorted_indices) // 5)\n    candidate_indices = sorted_indices[:num_candidates]\n\n    # Randomly select a subset of candidates to flip\n    flip_indices = np.random.choice(candidate_indices, size=min(3, len(candidate_indices)), replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try removing it\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try adding it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flip to ensure diversity\n    if random.random() < 0.3:\n        random_idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] >= 0:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 295,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with higher total value (sum of both objectives)\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Perform a series of random swaps to explore the neighborhood\n    num_swaps = min(3, len(new_solution) // 2)\n    for _ in range(num_swaps):\n        # Randomly select two distinct items\n        i, j = random.sample(range(len(new_solution)), 2)\n        # Swap their inclusion status\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Check feasibility and revert if violated\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Greedy improvement step: add items with the highest marginal value-to-weight ratio\n    remaining_capacity = capacity - np.dot(new_solution, weight_lst)\n    if remaining_capacity > 0:\n        # Calculate marginal value-to-weight ratios for items not in the solution\n        marginal_ratio1 = np.where(new_solution == 0, value1_lst / weight_lst, -np.inf)\n        marginal_ratio2 = np.where(new_solution == 0, value2_lst / weight_lst, -np.inf)\n\n        # Combine ratios using a weighted sum (can be adjusted for different objectives)\n        combined_ratio = 0.5 * marginal_ratio1 + 0.5 * marginal_ratio2\n\n        # Select items to add based on the highest combined ratio\n        candidate_items = np.argsort(combined_ratio)[::-1]\n        for item in candidate_items:\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.31908499484681485,
            9.232540041208267
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with higher total value (sum of both objectives)\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Perform a series of random swaps to explore the neighborhood\n    num_swaps = min(3, len(new_solution) // 2)\n    for _ in range(num_swaps):\n        # Randomly select two distinct items\n        i, j = random.sample(range(len(new_solution)), 2)\n        # Swap their inclusion status\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Check feasibility and revert if violated\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Greedy improvement step: add items with the highest marginal value-to-weight ratio\n    remaining_capacity = capacity - np.dot(new_solution, weight_lst)\n    if remaining_capacity > 0:\n        # Calculate marginal value-to-weight ratios for items not in the solution\n        marginal_ratio1 = np.where(new_solution == 0, value1_lst / weight_lst, -np.inf)\n        marginal_ratio2 = np.where(new_solution == 0, value2_lst / weight_lst, -np.inf)\n\n        # Combine ratios using a weighted sum (can be adjusted for different objectives)\n        combined_ratio = 0.5 * marginal_ratio1 + 0.5 * marginal_ratio2\n\n        # Select items to add based on the highest combined ratio\n        candidate_items = np.argsort(combined_ratio)[::-1]\n        for item in candidate_items:\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 296,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Intelligently select a base solution from the archive\n    # Prefer solutions that are not too close to the Pareto front or have high potential for improvement\n    # Here, we select a random solution with a bias towards those with higher total value in either objective\n    total_values = np.array([sum(obj) for sol, obj in archive])\n    probabilities = total_values / np.sum(total_values) if np.sum(total_values) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    # First, perform a random flip of a subset of items (with a probability based on their marginal contribution)\n    n_items = len(weight_lst)\n    flip_prob = 0.2  # Probability of flipping each item\n    for i in range(n_items):\n        if random.random() < flip_prob:\n            # Flip the item if it fits, otherwise try to replace it with another item\n            if new_solution[i] == 0:\n                current_weight = np.sum(new_solution * weight_lst)\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n            else:\n                new_solution[i] = 0\n\n    # Step 3: Greedy improvement step - try to add items that improve both objectives\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Sort items by combined marginal contribution (weighted sum of both objectives)\n    combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Try to add the most promising items that fit\n    for i in sorted_indices:\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            new_solution[i] = 1\n            remaining_capacity -= weight_lst[i]\n\n    # Step 4: Ensure feasibility (should already be enforced, but double-check)\n    if np.sum(new_solution * weight_lst) > capacity:\n        # If not feasible, remove items until it is\n        for i in np.where(new_solution == 1)[0]:\n            new_solution[i] = 0\n            if np.sum(new_solution * weight_lst) <= capacity:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.4050698760872946,
            2.0365550220012665
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Intelligently select a base solution from the archive\n    # Prefer solutions that are not too close to the Pareto front or have high potential for improvement\n    # Here, we select a random solution with a bias towards those with higher total value in either objective\n    total_values = np.array([sum(obj) for sol, obj in archive])\n    probabilities = total_values / np.sum(total_values) if np.sum(total_values) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    # First, perform a random flip of a subset of items (with a probability based on their marginal contribution)\n    n_items = len(weight_lst)\n    flip_prob = 0.2  # Probability of flipping each item\n    for i in range(n_items):\n        if random.random() < flip_prob:\n            # Flip the item if it fits, otherwise try to replace it with another item\n            if new_solution[i] == 0:\n                current_weight = np.sum(new_solution * weight_lst)\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n            else:\n                new_solution[i] = 0\n\n    # Step 3: Greedy improvement step - try to add items that improve both objectives\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Sort items by combined marginal contribution (weighted sum of both objectives)\n    combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Try to add the most promising items that fit\n    for i in sorted_indices:\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            new_solution[i] = 1\n            remaining_capacity -= weight_lst[i]\n\n    # Step 4: Ensure feasibility (should already be enforced, but double-check)\n    if np.sum(new_solution * weight_lst) > capacity:\n        # If not feasible, remove items until it is\n        for i in np.where(new_solution == 1)[0]:\n            new_solution[i] = 0\n            if np.sum(new_solution * weight_lst) <= capacity:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 297,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, (current_val1, current_val2) = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))\n\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with higher probability for items with high value-to-weight ratio)\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n\n    # Combine both objectives' value-to-weight ratios\n    combined_value_to_weight = (value_to_weight1 + value_to_weight2) / 2\n\n    # Probability of flipping each item is proportional to its combined value-to-weight ratio\n    flip_probs = combined_value_to_weight / np.sum(combined_value_to_weight)\n    flip_mask = np.random.rand(n_items) < flip_probs\n\n    # Flip selected items (with feasibility check)\n    for i in range(n_items):\n        if flip_mask[i]:\n            if new_solution[i] == 1:\n                # Try removing item\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n            else:\n                # Try adding item\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Additional improvement: Add or remove items based on marginal gains\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal gains for adding items (not currently in solution)\n    add_candidates = np.where(new_solution == 0)[0]\n    add_gains1 = value1_lst[add_candidates] / weight_lst[add_candidates]\n    add_gains2 = value2_lst[add_candidates] / weight_lst[add_candidates]\n\n    # Calculate marginal gains for removing items (currently in solution)\n    remove_candidates = np.where(new_solution == 1)[0]\n    remove_gains1 = -value1_lst[remove_candidates] / weight_lst[remove_candidates]\n    remove_gains2 = -value2_lst[remove_candidates] / weight_lst[remove_candidates]\n\n    # Combine gains for both objectives\n    combined_add_gains = (add_gains1 + add_gains2) / 2\n    combined_remove_gains = (remove_gains1 + remove_gains2) / 2\n\n    # Add items with highest combined gain that fit\n    for i in np.argsort(-combined_add_gains):\n        idx = add_candidates[i]\n        if current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Remove items with lowest combined gain\n    for i in np.argsort(combined_remove_gains):\n        idx = remove_candidates[i]\n        if current_weight - weight_lst[idx] >= 0:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.876627215741144,
            2.130982607603073
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, (current_val1, current_val2) = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))\n\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with higher probability for items with high value-to-weight ratio)\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n\n    # Combine both objectives' value-to-weight ratios\n    combined_value_to_weight = (value_to_weight1 + value_to_weight2) / 2\n\n    # Probability of flipping each item is proportional to its combined value-to-weight ratio\n    flip_probs = combined_value_to_weight / np.sum(combined_value_to_weight)\n    flip_mask = np.random.rand(n_items) < flip_probs\n\n    # Flip selected items (with feasibility check)\n    for i in range(n_items):\n        if flip_mask[i]:\n            if new_solution[i] == 1:\n                # Try removing item\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n            else:\n                # Try adding item\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Additional improvement: Add or remove items based on marginal gains\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal gains for adding items (not currently in solution)\n    add_candidates = np.where(new_solution == 0)[0]\n    add_gains1 = value1_lst[add_candidates] / weight_lst[add_candidates]\n    add_gains2 = value2_lst[add_candidates] / weight_lst[add_candidates]\n\n    # Calculate marginal gains for removing items (currently in solution)\n    remove_candidates = np.where(new_solution == 1)[0]\n    remove_gains1 = -value1_lst[remove_candidates] / weight_lst[remove_candidates]\n    remove_gains2 = -value2_lst[remove_candidates] / weight_lst[remove_candidates]\n\n    # Combine gains for both objectives\n    combined_add_gains = (add_gains1 + add_gains2) / 2\n    combined_remove_gains = (remove_gains1 + remove_gains2) / 2\n\n    # Add items with highest combined gain that fit\n    for i in np.argsort(-combined_add_gains):\n        idx = add_candidates[i]\n        if current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Remove items with lowest combined gain\n    for i in np.argsort(combined_remove_gains):\n        idx = remove_candidates[i]\n        if current_weight - weight_lst[idx] >= 0:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 298,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    new_solution = base_solution.copy()\n\n    # Randomly flip a few items to introduce diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Perform weight-based swaps: replace a heavy item with a lighter one if beneficial\n    heavy_items = np.where((new_solution == 1) & (weight_lst > np.median(weight_lst)))[0]\n    if len(heavy_items) > 0:\n        heavy_idx = random.choice(heavy_items)\n        light_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(light_items) > 0:\n            light_idx = random.choice(light_items)\n            new_solution[heavy_idx] = 0\n            new_solution[light_idx] = 1\n\n    # Perform value-based swaps: replace a low-value item with a high-value one if beneficial\n    low_value_items = np.where((new_solution == 1) & (value1_lst + value2_lst < np.median(value1_lst + value2_lst)))[0]\n    if len(low_value_items) > 0:\n        low_idx = random.choice(low_value_items)\n        high_value_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(high_value_items) > 0:\n            high_idx = random.choice(high_value_items)\n            new_solution[low_idx] = 0\n            new_solution[high_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.6323906780135176,
            4.370532065629959
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    new_solution = base_solution.copy()\n\n    # Randomly flip a few items to introduce diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n        else:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Perform weight-based swaps: replace a heavy item with a lighter one if beneficial\n    heavy_items = np.where((new_solution == 1) & (weight_lst > np.median(weight_lst)))[0]\n    if len(heavy_items) > 0:\n        heavy_idx = random.choice(heavy_items)\n        light_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(light_items) > 0:\n            light_idx = random.choice(light_items)\n            new_solution[heavy_idx] = 0\n            new_solution[light_idx] = 1\n\n    # Perform value-based swaps: replace a low-value item with a high-value one if beneficial\n    low_value_items = np.where((new_solution == 1) & (value1_lst + value2_lst < np.median(value1_lst + value2_lst)))[0]\n    if len(low_value_items) > 0:\n        low_idx = random.choice(low_value_items)\n        high_value_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n        if len(high_value_items) > 0:\n            high_idx = random.choice(high_value_items)\n            new_solution[low_idx] = 0\n            new_solution[high_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 299,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not Pareto-optimal in the archive)\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and objective values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: combine random swaps and objective-aware flips\n    for _ in range(10):  # Number of local search steps\n        # Randomly select two items to swap\n        i, j = random.sample(range(len(new_solution)), 2)\n\n        # Calculate new weight if we swap i and j\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] != new_solution[j] else 0\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            # Accept the swap if feasible\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight = new_weight\n            current_value1 += (value1_lst[j] - value1_lst[i]) if new_solution[i] != new_solution[j] else 0\n            current_value2 += (value2_lst[j] - value2_lst[i]) if new_solution[i] != new_solution[j] else 0\n        else:\n            # If swap is infeasible, try flipping one item to improve objectives\n            for k in random.sample(range(len(new_solution)), min(5, len(new_solution))):\n                if new_solution[k] == 1:\n                    # Try removing item k\n                    if current_weight - weight_lst[k] <= capacity:\n                        new_solution[k] = 0\n                        current_weight -= weight_lst[k]\n                        current_value1 -= value1_lst[k]\n                        current_value2 -= value2_lst[k]\n                        break\n                else:\n                    # Try adding item k\n                    if current_weight + weight_lst[k] <= capacity:\n                        new_solution[k] = 1\n                        current_weight += weight_lst[k]\n                        current_value1 += value1_lst[k]\n                        current_value2 += value2_lst[k]\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.5108115175120358,
            0.8851116597652435
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not Pareto-optimal in the archive)\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and objective values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: combine random swaps and objective-aware flips\n    for _ in range(10):  # Number of local search steps\n        # Randomly select two items to swap\n        i, j = random.sample(range(len(new_solution)), 2)\n\n        # Calculate new weight if we swap i and j\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] != new_solution[j] else 0\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            # Accept the swap if feasible\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight = new_weight\n            current_value1 += (value1_lst[j] - value1_lst[i]) if new_solution[i] != new_solution[j] else 0\n            current_value2 += (value2_lst[j] - value2_lst[i]) if new_solution[i] != new_solution[j] else 0\n        else:\n            # If swap is infeasible, try flipping one item to improve objectives\n            for k in random.sample(range(len(new_solution)), min(5, len(new_solution))):\n                if new_solution[k] == 1:\n                    # Try removing item k\n                    if current_weight - weight_lst[k] <= capacity:\n                        new_solution[k] = 0\n                        current_weight -= weight_lst[k]\n                        current_value1 -= value1_lst[k]\n                        current_value2 -= value2_lst[k]\n                        break\n                else:\n                    # Try adding item k\n                    if current_weight + weight_lst[k] <= capacity:\n                        new_solution[k] = 1\n                        current_weight += weight_lst[k]\n                        current_value1 += value1_lst[k]\n                        current_value2 += value2_lst[k]\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 300,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # (assumes archive is pre-filtered to non-dominated solutions)\n    base_solution = random.choice(archive)[0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip bits with a probability that depends on the item's potential to improve both objectives\n    # 2. Use a threshold-based approach to ensure feasibility\n    new_solution = base_solution.copy()\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            # Probability to remove item based on how much it contributes to both objectives\n            prob_remove = 0.5 * (1 - (ratio1[i] * ratio2[i]) / (np.max(ratio1) * np.max(ratio2)))\n            if random.random() < prob_remove and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                current_value1 -= value1_lst[i]\n                current_value2 -= value2_lst[i]\n        else:\n            # Probability to add item based on its value-to-weight ratio for both objectives\n            prob_add = 0.5 * (ratio1[i] * ratio2[i]) / (np.max(ratio1) * np.max(ratio2))\n            if random.random() < prob_add and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_value1 += value1_lst[i]\n                current_value2 += value2_lst[i]\n\n    # Additional random bit flip to ensure diversity\n    if random.random() < 0.3:\n        idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9127131975660241,
            10.075952470302582
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # (assumes archive is pre-filtered to non-dominated solutions)\n    base_solution = random.choice(archive)[0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip bits with a probability that depends on the item's potential to improve both objectives\n    # 2. Use a threshold-based approach to ensure feasibility\n    new_solution = base_solution.copy()\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 1:\n            # Probability to remove item based on how much it contributes to both objectives\n            prob_remove = 0.5 * (1 - (ratio1[i] * ratio2[i]) / (np.max(ratio1) * np.max(ratio2)))\n            if random.random() < prob_remove and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                current_value1 -= value1_lst[i]\n                current_value2 -= value2_lst[i]\n        else:\n            # Probability to add item based on its value-to-weight ratio for both objectives\n            prob_add = 0.5 * (ratio1[i] * ratio2[i]) / (np.max(ratio1) * np.max(ratio2))\n            if random.random() < prob_add and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_value1 += value1_lst[i]\n                current_value2 += value2_lst[i]\n\n    # Additional random bit flip to ensure diversity\n    if random.random() < 0.3:\n        idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    }
]