[
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 1,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = np.array([(v1 + v2) for (sol, (v1, v2)) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_swaps = min(3, len(base_solution) // 2)\n    swap_indices = np.random.choice(len(base_solution), size=n_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high marginal value (exploitation)\n    # Calculate marginal values for each item\n    marginal_value1 = value1_lst - np.sum(value1_lst * base_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * base_solution)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top-k items with highest marginal value\n    k = min(5, len(base_solution) // 3)\n    top_indices = np.argsort(combined_marginal)[-k:]\n\n    for idx in top_indices:\n        if weight_lst[idx] <= remaining_capacity and not new_solution[idx]:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # 3. Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with lowest combined marginal value\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break\n        remove_idx = np.argmin(combined_marginal[included_indices])\n        new_solution[included_indices[remove_idx]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3932824201997357,
            2.0257696509361267
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = np.array([(v1 + v2) for (sol, (v1, v2)) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_swaps = min(3, len(base_solution) // 2)\n    swap_indices = np.random.choice(len(base_solution), size=n_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high marginal value (exploitation)\n    # Calculate marginal values for each item\n    marginal_value1 = value1_lst - np.sum(value1_lst * base_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * base_solution)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top-k items with highest marginal value\n    k = min(5, len(base_solution) // 3)\n    top_indices = np.argsort(combined_marginal)[-k:]\n\n    for idx in top_indices:\n        if weight_lst[idx] <= remaining_capacity and not new_solution[idx]:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # 3. Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with lowest combined marginal value\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break\n        remove_idx = np.argmin(combined_marginal[included_indices])\n        new_solution[included_indices[remove_idx]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 1,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = np.array([(v1 + v2) for (sol, (v1, v2)) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_swaps = min(3, len(base_solution) // 2)\n    swap_indices = np.random.choice(len(base_solution), size=n_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high marginal value (exploitation)\n    # Calculate marginal values for each item\n    marginal_value1 = value1_lst - np.sum(value1_lst * base_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * base_solution)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top-k items with highest marginal value\n    k = min(5, len(base_solution) // 3)\n    top_indices = np.argsort(combined_marginal)[-k:]\n\n    for idx in top_indices:\n        if weight_lst[idx] <= remaining_capacity and not new_solution[idx]:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # 3. Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with lowest combined marginal value\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break\n        remove_idx = np.argmin(combined_marginal[included_indices])\n        new_solution[included_indices[remove_idx]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3932824201997357,
            2.0257696509361267
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = np.array([(v1 + v2) for (sol, (v1, v2)) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_swaps = min(3, len(base_solution) // 2)\n    swap_indices = np.random.choice(len(base_solution), size=n_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high marginal value (exploitation)\n    # Calculate marginal values for each item\n    marginal_value1 = value1_lst - np.sum(value1_lst * base_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * base_solution)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top-k items with highest marginal value\n    k = min(5, len(base_solution) // 3)\n    top_indices = np.argsort(combined_marginal)[-k:]\n\n    for idx in top_indices:\n        if weight_lst[idx] <= remaining_capacity and not new_solution[idx]:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # 3. Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with lowest combined marginal value\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break\n        remove_idx = np.argmin(combined_marginal[included_indices])\n        new_solution[included_indices[remove_idx]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 1,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = np.array([(v1 + v2) for (sol, (v1, v2)) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_swaps = min(3, len(base_solution) // 2)\n    swap_indices = np.random.choice(len(base_solution), size=n_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high marginal value (exploitation)\n    # Calculate marginal values for each item\n    marginal_value1 = value1_lst - np.sum(value1_lst * base_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * base_solution)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top-k items with highest marginal value\n    k = min(5, len(base_solution) // 3)\n    top_indices = np.argsort(combined_marginal)[-k:]\n\n    for idx in top_indices:\n        if weight_lst[idx] <= remaining_capacity and not new_solution[idx]:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # 3. Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with lowest combined marginal value\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break\n        remove_idx = np.argmin(combined_marginal[included_indices])\n        new_solution[included_indices[remove_idx]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3932824201997357,
            2.0257696509361267
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = np.array([(v1 + v2) for (sol, (v1, v2)) in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, (v1, v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items (exploration)\n    n_swaps = min(3, len(base_solution) // 2)\n    swap_indices = np.random.choice(len(base_solution), size=n_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with high marginal value (exploitation)\n    # Calculate marginal values for each item\n    marginal_value1 = value1_lst - np.sum(value1_lst * base_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * base_solution)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top-k items with highest marginal value\n    k = min(5, len(base_solution) // 3)\n    top_indices = np.argsort(combined_marginal)[-k:]\n\n    for idx in top_indices:\n        if weight_lst[idx] <= remaining_capacity and not new_solution[idx]:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # 3. Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with lowest combined marginal value\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break\n        remove_idx = np.argmin(combined_marginal[included_indices])\n        new_solution[included_indices[remove_idx]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 2,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_objectives.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high value-to-weight ratio in a random subset\n    n_items = len(weight_lst)\n    subset_size = max(1, min(n_items // 4, 10))  # Dynamically adjust subset size\n    random_indices = random.sample(range(n_items), subset_size)\n\n    for i in random_indices:\n        # Calculate value-to-weight ratio for both objectives\n        v1_ratio = value1_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n        v2_ratio = value2_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n\n        # Flip the item if it has high value-to-weight ratio in either objective\n        if v1_ratio > 0.5 * value1_lst.mean() or v2_ratio > 0.5 * value2_lst.mean():\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # If item is included, try to remove it\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n            else:\n                # If item is excluded, try to add it\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Additional check to ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, perform a greedy repair\n        items_sorted = np.argsort((value1_lst + value2_lst) / weight_lst)\n        for i in reversed(items_sorted):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.3261619562671908,
            2.2487597167491913
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_objectives.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high value-to-weight ratio in a random subset\n    n_items = len(weight_lst)\n    subset_size = max(1, min(n_items // 4, 10))  # Dynamically adjust subset size\n    random_indices = random.sample(range(n_items), subset_size)\n\n    for i in random_indices:\n        # Calculate value-to-weight ratio for both objectives\n        v1_ratio = value1_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n        v2_ratio = value2_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n\n        # Flip the item if it has high value-to-weight ratio in either objective\n        if v1_ratio > 0.5 * value1_lst.mean() or v2_ratio > 0.5 * value2_lst.mean():\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # If item is included, try to remove it\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n            else:\n                # If item is excluded, try to add it\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Additional check to ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, perform a greedy repair\n        items_sorted = np.argsort((value1_lst + value2_lst) / weight_lst)\n        for i in reversed(items_sorted):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 3,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized scores for each solution\n    scores = []\n    max_val1 = max(obj[0] for _, obj in archive)\n    max_val2 = max(obj[1] for _, obj in archive)\n\n    for sol, obj in archive:\n        # Normalize objectives and combine them\n        norm_val1 = obj[0] / max_val1 if max_val1 > 0 else 0\n        norm_val2 = obj[1] / max_val2 if max_val2 > 0 else 0\n        scores.append(norm_val1 + norm_val2)\n\n    # Select a solution with probability proportional to its score\n    selected_idx = np.random.choice(len(archive), p=np.array(scores)/sum(scores))\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_val1 = base_obj[0]\n    current_val2 = base_obj[1]\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability 0.3)\n    # 2. Greedily add items that improve both objectives (if feasible)\n\n    # Step 1: Random flips\n    flip_mask = np.random.rand(len(new_solution)) < 0.3\n    for i in np.where(flip_mask)[0]:\n        if new_solution[i] == 1:\n            # Remove item if it would not violate capacity\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                current_val1 -= value1_lst[i]\n                current_val2 -= value2_lst[i]\n        else:\n            # Add item if it would not violate capacity\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_val1 += value1_lst[i]\n                current_val2 += value2_lst[i]\n\n    # Step 2: Greedy addition of items that improve both objectives\n    # Calculate marginal gains for each item not in the solution\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Calculate normalized marginal gains\n        marginal_gains1 = value1_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)  # Avoid division by zero\n        marginal_gains2 = value2_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n\n        # Normalize gains\n        max_gain1 = np.max(marginal_gains1) if len(marginal_gains1) > 0 else 1.0\n        max_gain2 = np.max(marginal_gains2) if len(marginal_gains2) > 0 else 1.0\n\n        norm_gains1 = marginal_gains1 / max_gain1 if max_gain1 > 0 else marginal_gains1\n        norm_gains2 = marginal_gains2 / max_gain2 if max_gain2 > 0 else marginal_gains2\n\n        # Combined score for each candidate\n        combined_scores = norm_gains1 + norm_gains2\n\n        # Sort candidates by combined score in descending order\n        sorted_indices = candidate_indices[np.argsort(-combined_scores)]\n\n        # Try to add items in order of their combined score\n        for i in sorted_indices:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_val1 += value1_lst[i]\n                current_val2 += value2_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.37050373184857055,
            2.495403528213501
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized scores for each solution\n    scores = []\n    max_val1 = max(obj[0] for _, obj in archive)\n    max_val2 = max(obj[1] for _, obj in archive)\n\n    for sol, obj in archive:\n        # Normalize objectives and combine them\n        norm_val1 = obj[0] / max_val1 if max_val1 > 0 else 0\n        norm_val2 = obj[1] / max_val2 if max_val2 > 0 else 0\n        scores.append(norm_val1 + norm_val2)\n\n    # Select a solution with probability proportional to its score\n    selected_idx = np.random.choice(len(archive), p=np.array(scores)/sum(scores))\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_val1 = base_obj[0]\n    current_val2 = base_obj[1]\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability 0.3)\n    # 2. Greedily add items that improve both objectives (if feasible)\n\n    # Step 1: Random flips\n    flip_mask = np.random.rand(len(new_solution)) < 0.3\n    for i in np.where(flip_mask)[0]:\n        if new_solution[i] == 1:\n            # Remove item if it would not violate capacity\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                current_val1 -= value1_lst[i]\n                current_val2 -= value2_lst[i]\n        else:\n            # Add item if it would not violate capacity\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_val1 += value1_lst[i]\n                current_val2 += value2_lst[i]\n\n    # Step 2: Greedy addition of items that improve both objectives\n    # Calculate marginal gains for each item not in the solution\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Calculate normalized marginal gains\n        marginal_gains1 = value1_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)  # Avoid division by zero\n        marginal_gains2 = value2_lst[candidate_indices] / (weight_lst[candidate_indices] + 1e-6)\n\n        # Normalize gains\n        max_gain1 = np.max(marginal_gains1) if len(marginal_gains1) > 0 else 1.0\n        max_gain2 = np.max(marginal_gains2) if len(marginal_gains2) > 0 else 1.0\n\n        norm_gains1 = marginal_gains1 / max_gain1 if max_gain1 > 0 else marginal_gains1\n        norm_gains2 = marginal_gains2 / max_gain2 if max_gain2 > 0 else marginal_gains2\n\n        # Combined score for each candidate\n        combined_scores = norm_gains1 + norm_gains2\n\n        # Sort candidates by combined score in descending order\n        sorted_indices = candidate_indices[np.argsort(-combined_scores)]\n\n        # Try to add items in order of their combined score\n        for i in sorted_indices:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_val1 += value1_lst[i]\n                current_val2 += value2_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 4,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select a solution that is not already on the Pareto front (for simplicity)\n    # In practice, you might use more sophisticated selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to add items that improve both objectives\n    # 2. If no such items exist, try to add items that improve one objective while not significantly hurting the other\n    # 3. If still no improvement, perform a random swap\n\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Add items that improve both objectives\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve both objectives\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 2: Add items that improve one objective while not significantly hurting the other\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve one objective while not hurting the other too much\n            if (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 3: Perform a random swap if no immediate improvement is possible\n    # Find all items that can be added without exceeding capacity\n    candidate_items = [i for i in range(len(weight_lst))\n                      if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity]\n\n    if candidate_items:\n        # Randomly select an item to add\n        item_to_add = random.choice(candidate_items)\n        new_solution[item_to_add] = 1\n    else:\n        # If no items can be added, try removing items to free up space\n        candidate_items = [i for i in range(len(weight_lst)) if base_solution[i] == 1]\n        if candidate_items:\n            # Randomly select an item to remove\n            item_to_remove = random.choice(candidate_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8171229586985924,
            2.8044958412647247
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select a solution that is not already on the Pareto front (for simplicity)\n    # In practice, you might use more sophisticated selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to add items that improve both objectives\n    # 2. If no such items exist, try to add items that improve one objective while not significantly hurting the other\n    # 3. If still no improvement, perform a random swap\n\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Add items that improve both objectives\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve both objectives\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 2: Add items that improve one objective while not significantly hurting the other\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve one objective while not hurting the other too much\n            if (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 3: Perform a random swap if no immediate improvement is possible\n    # Find all items that can be added without exceeding capacity\n    candidate_items = [i for i in range(len(weight_lst))\n                      if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity]\n\n    if candidate_items:\n        # Randomly select an item to add\n        item_to_add = random.choice(candidate_items)\n        new_solution[item_to_add] = 1\n    else:\n        # If no items can be added, try removing items to free up space\n        candidate_items = [i for i in range(len(weight_lst)) if base_solution[i] == 1]\n        if candidate_items:\n            # Randomly select an item to remove\n            item_to_remove = random.choice(candidate_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 4,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select a solution that is not already on the Pareto front (for simplicity)\n    # In practice, you might use more sophisticated selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to add items that improve both objectives\n    # 2. If no such items exist, try to add items that improve one objective while not significantly hurting the other\n    # 3. If still no improvement, perform a random swap\n\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Add items that improve both objectives\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve both objectives\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 2: Add items that improve one objective while not significantly hurting the other\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve one objective while not hurting the other too much\n            if (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 3: Perform a random swap if no immediate improvement is possible\n    # Find all items that can be added without exceeding capacity\n    candidate_items = [i for i in range(len(weight_lst))\n                      if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity]\n\n    if candidate_items:\n        # Randomly select an item to add\n        item_to_add = random.choice(candidate_items)\n        new_solution[item_to_add] = 1\n    else:\n        # If no items can be added, try removing items to free up space\n        candidate_items = [i for i in range(len(weight_lst)) if base_solution[i] == 1]\n        if candidate_items:\n            # Randomly select an item to remove\n            item_to_remove = random.choice(candidate_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8171229586985924,
            2.8044958412647247
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select a solution that is not already on the Pareto front (for simplicity)\n    # In practice, you might use more sophisticated selection criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy:\n    # 1. First, try to add items that improve both objectives\n    # 2. If no such items exist, try to add items that improve one objective while not significantly hurting the other\n    # 3. If still no improvement, perform a random swap\n\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Add items that improve both objectives\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve both objectives\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 2: Add items that improve one objective while not significantly hurting the other\n    for i in range(len(weight_lst)):\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item would improve one objective while not hurting the other too much\n            if (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n                return new_solution\n\n    # Strategy 3: Perform a random swap if no immediate improvement is possible\n    # Find all items that can be added without exceeding capacity\n    candidate_items = [i for i in range(len(weight_lst))\n                      if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity]\n\n    if candidate_items:\n        # Randomly select an item to add\n        item_to_add = random.choice(candidate_items)\n        new_solution[item_to_add] = 1\n    else:\n        # If no items can be added, try removing items to free up space\n        candidate_items = [i for i in range(len(weight_lst)) if base_solution[i] == 1]\n        if candidate_items:\n            # Randomly select an item to remove\n            item_to_remove = random.choice(candidate_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 5,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions that are not too close to the edge of the capacity\n    # or solutions with high marginal gains\n    candidate_indices = []\n    for idx, (solution, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        if current_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    # Randomly select a candidate solution\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (diversification)\n    # 2. Apply a greedy improvement step (intensification)\n    # 3. Ensure feasibility\n\n    # Step 1: Randomly flip a subset of items (20% chance for each item)\n    flip_mask = np.random.rand(len(base_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess <= 0:\n                break\n            new_solution[item] = 0\n            excess -= weight_lst[item]\n\n    # Step 2: Greedy improvement - add items with highest marginal gain\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate marginal gain for both objectives\n            marginal_gain1 = value1_lst[item]\n            marginal_gain2 = value2_lst[item]\n\n            # Simple greedy criterion: prioritize items with high combined marginal gain\n            if marginal_gain1 + marginal_gain2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.453915938102982,
            2.0250668227672577
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions that are not too close to the edge of the capacity\n    # or solutions with high marginal gains\n    candidate_indices = []\n    for idx, (solution, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        if current_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    # Randomly select a candidate solution\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (diversification)\n    # 2. Apply a greedy improvement step (intensification)\n    # 3. Ensure feasibility\n\n    # Step 1: Randomly flip a subset of items (20% chance for each item)\n    flip_mask = np.random.rand(len(base_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess <= 0:\n                break\n            new_solution[item] = 0\n            excess -= weight_lst[item]\n\n    # Step 2: Greedy improvement - add items with highest marginal gain\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate marginal gain for both objectives\n            marginal_gain1 = value1_lst[item]\n            marginal_gain2 = value2_lst[item]\n\n            # Simple greedy criterion: prioritize items with high combined marginal gain\n            if marginal_gain1 + marginal_gain2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 5,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions that are not too close to the edge of the capacity\n    # or solutions with high marginal gains\n    candidate_indices = []\n    for idx, (solution, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        if current_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    # Randomly select a candidate solution\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (diversification)\n    # 2. Apply a greedy improvement step (intensification)\n    # 3. Ensure feasibility\n\n    # Step 1: Randomly flip a subset of items (20% chance for each item)\n    flip_mask = np.random.rand(len(base_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess <= 0:\n                break\n            new_solution[item] = 0\n            excess -= weight_lst[item]\n\n    # Step 2: Greedy improvement - add items with highest marginal gain\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate marginal gain for both objectives\n            marginal_gain1 = value1_lst[item]\n            marginal_gain2 = value2_lst[item]\n\n            # Simple greedy criterion: prioritize items with high combined marginal gain\n            if marginal_gain1 + marginal_gain2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.453915938102982,
            2.0250668227672577
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions that are not too close to the edge of the capacity\n    # or solutions with high marginal gains\n    candidate_indices = []\n    for idx, (solution, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        if current_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n\n    # Randomly select a candidate solution\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (diversification)\n    # 2. Apply a greedy improvement step (intensification)\n    # 3. Ensure feasibility\n\n    # Step 1: Randomly flip a subset of items (20% chance for each item)\n    flip_mask = np.random.rand(len(base_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess <= 0:\n                break\n            new_solution[item] = 0\n            excess -= weight_lst[item]\n\n    # Step 2: Greedy improvement - add items with highest marginal gain\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate marginal gain for both objectives\n            marginal_gain1 = value1_lst[item]\n            marginal_gain2 = value2_lst[item]\n\n            # Simple greedy criterion: prioritize items with high combined marginal gain\n            if marginal_gain1 + marginal_gain2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 6,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Calculate the current total weight of each solution in the archive\n    solution_weights = [np.sum(weight_lst[solution[0] == 1]) for solution in archive]\n\n    # Identify solutions that are not at full capacity (promising for improvement)\n    promising_indices = [i for i, (solution, _) in enumerate(archive)\n                         if np.sum(weight_lst[solution == 1]) < capacity * 0.95]\n\n    if not promising_indices:\n        # If no promising solutions, select randomly from the archive\n        promising_indices = list(range(len(archive)))\n\n    # Select a base solution from the promising ones\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    current_weight = solution_weights[selected_idx]\n\n    # Calculate value-to-weight ratios for both objectives\n    value1_ratios = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value2_ratios = value2_lst / (weight_lst + 1e-10)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Flip items with high value-to-weight ratios (exploitation)\n    new_solution = base_solution.copy()\n\n    # Random flips (exploration)\n    num_random_flips = min(3, len(new_solution))\n    random_indices = random.sample(range(len(new_solution)), num_random_flips)\n    for idx in random_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Check feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If overweight, remove the heaviest item(s)\n        while total_weight > capacity:\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Value-to-weight ratio flips (exploitation)\n    # Select top 5% items by value-to-weight ratio for each objective\n    top_value1_items = np.argsort(value1_ratios)[-max(1, len(value1_ratios) // 20):]\n    top_value2_items = np.argsort(value2_ratios)[-max(1, len(value2_ratios) // 20):]\n\n    # Combine and flip items with high ratios\n    candidate_items = np.union1d(top_value1_items, top_value2_items)\n    for idx in candidate_items:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3513534287508541,
            4.918847411870956
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Calculate the current total weight of each solution in the archive\n    solution_weights = [np.sum(weight_lst[solution[0] == 1]) for solution in archive]\n\n    # Identify solutions that are not at full capacity (promising for improvement)\n    promising_indices = [i for i, (solution, _) in enumerate(archive)\n                         if np.sum(weight_lst[solution == 1]) < capacity * 0.95]\n\n    if not promising_indices:\n        # If no promising solutions, select randomly from the archive\n        promising_indices = list(range(len(archive)))\n\n    # Select a base solution from the promising ones\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    current_weight = solution_weights[selected_idx]\n\n    # Calculate value-to-weight ratios for both objectives\n    value1_ratios = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value2_ratios = value2_lst / (weight_lst + 1e-10)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Flip items with high value-to-weight ratios (exploitation)\n    new_solution = base_solution.copy()\n\n    # Random flips (exploration)\n    num_random_flips = min(3, len(new_solution))\n    random_indices = random.sample(range(len(new_solution)), num_random_flips)\n    for idx in random_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Check feasibility after random flips\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If overweight, remove the heaviest item(s)\n        while total_weight > capacity:\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Value-to-weight ratio flips (exploitation)\n    # Select top 5% items by value-to-weight ratio for each objective\n    top_value1_items = np.argsort(value1_ratios)[-max(1, len(value1_ratios) // 20):]\n    top_value2_items = np.argsort(value2_ratios)[-max(1, len(value2_ratios) // 20):]\n\n    # Combine and flip items with high ratios\n    candidate_items = np.union1d(top_value1_items, top_value2_items)\n    for idx in candidate_items:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 7,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the archive)\n    # Here, we select a solution with the lowest crowding distance (simplified for this example)\n    crowding_distances = []\n    for i, (sol, _) in enumerate(archive):\n        # Simplified crowding distance: sum of differences with neighbors\n        left = archive[i-1][1] if i > 0 else (0, 0)\n        right = archive[i+1][1] if i < len(archive)-1 else (0, 0)\n        dist = (abs(sol[0] - left[0]) + abs(sol[1] - left[1]) +\n                abs(sol[0] - right[0]) + abs(sol[1] - right[1]))\n        crowding_distances.append(dist)\n\n    # Select the solution with the smallest crowding distance (most crowded)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with weight check)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it doesn't cause infeasibility\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add item if it doesn't exceed capacity\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: If no changes, perform a more aggressive flip (swap two items)\n    if np.array_equal(new_solution, base_solution):\n        available_indices = np.where(new_solution == 1)[0]\n        if len(available_indices) >= 2:\n            i, j = np.random.choice(available_indices, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility (fallback if needed)\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove random items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6988867398475083,
            1.963521033525467
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the archive)\n    # Here, we select a solution with the lowest crowding distance (simplified for this example)\n    crowding_distances = []\n    for i, (sol, _) in enumerate(archive):\n        # Simplified crowding distance: sum of differences with neighbors\n        left = archive[i-1][1] if i > 0 else (0, 0)\n        right = archive[i+1][1] if i < len(archive)-1 else (0, 0)\n        dist = (abs(sol[0] - left[0]) + abs(sol[1] - left[1]) +\n                abs(sol[0] - right[0]) + abs(sol[1] - right[1]))\n        crowding_distances.append(dist)\n\n    # Select the solution with the smallest crowding distance (most crowded)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with weight check)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it doesn't cause infeasibility\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add item if it doesn't exceed capacity\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: If no changes, perform a more aggressive flip (swap two items)\n    if np.array_equal(new_solution, base_solution):\n        available_indices = np.where(new_solution == 1)[0]\n        if len(available_indices) >= 2:\n            i, j = np.random.choice(available_indices, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility (fallback if needed)\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove random items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 7,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the archive)\n    # Here, we select a solution with the lowest crowding distance (simplified for this example)\n    crowding_distances = []\n    for i, (sol, _) in enumerate(archive):\n        # Simplified crowding distance: sum of differences with neighbors\n        left = archive[i-1][1] if i > 0 else (0, 0)\n        right = archive[i+1][1] if i < len(archive)-1 else (0, 0)\n        dist = (abs(sol[0] - left[0]) + abs(sol[1] - left[1]) +\n                abs(sol[0] - right[0]) + abs(sol[1] - right[1]))\n        crowding_distances.append(dist)\n\n    # Select the solution with the smallest crowding distance (most crowded)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with weight check)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it doesn't cause infeasibility\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add item if it doesn't exceed capacity\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: If no changes, perform a more aggressive flip (swap two items)\n    if np.array_equal(new_solution, base_solution):\n        available_indices = np.where(new_solution == 1)[0]\n        if len(available_indices) >= 2:\n            i, j = np.random.choice(available_indices, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility (fallback if needed)\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove random items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6988867398475083,
            1.963521033525467
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the archive)\n    # Here, we select a solution with the lowest crowding distance (simplified for this example)\n    crowding_distances = []\n    for i, (sol, _) in enumerate(archive):\n        # Simplified crowding distance: sum of differences with neighbors\n        left = archive[i-1][1] if i > 0 else (0, 0)\n        right = archive[i+1][1] if i < len(archive)-1 else (0, 0)\n        dist = (abs(sol[0] - left[0]) + abs(sol[1] - left[1]) +\n                abs(sol[0] - right[0]) + abs(sol[1] - right[1]))\n        crowding_distances.append(dist)\n\n    # Select the solution with the smallest crowding distance (most crowded)\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items (with weight check)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item if it doesn't cause infeasibility\n            if np.sum(new_solution * weight_lst) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add item if it doesn't exceed capacity\n            if np.sum(new_solution * weight_lst) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: If no changes, perform a more aggressive flip (swap two items)\n    if np.array_equal(new_solution, base_solution):\n        available_indices = np.where(new_solution == 1)[0]\n        if len(available_indices) >= 2:\n            i, j = np.random.choice(available_indices, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility (fallback if needed)\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove random items until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) == 0:\n            break\n        remove_idx = np.random.choice(excess_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 8,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in archive.\")\n\n    # Select a solution with the highest potential for improvement (e.g., not fully packed)\n    base_solution = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal value-to-weight ratio\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Sort items by combined marginal value (descending)\n    sorted_items = np.argsort(-combined_marginal)\n\n    # Flip top-k items with the highest marginal value (k is a small random number)\n    k = min(3, len(sorted_items))\n    for i in sorted_items[:k]:\n        if np.random.rand() < 0.5:  # Randomly decide to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility by removing excess items if needed\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        excess_weight = total_weight - capacity\n        # Remove items with lowest marginal value until feasible\n        for i in sorted_items[::-1]:\n            if excess_weight <= 0:\n                break\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                excess_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7046986046681877,
            8.1203091442585
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in archive.\")\n\n    # Select a solution with the highest potential for improvement (e.g., not fully packed)\n    base_solution = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal value-to-weight ratio\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Sort items by combined marginal value (descending)\n    sorted_items = np.argsort(-combined_marginal)\n\n    # Flip top-k items with the highest marginal value (k is a small random number)\n    k = min(3, len(sorted_items))\n    for i in sorted_items[:k]:\n        if np.random.rand() < 0.5:  # Randomly decide to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility by removing excess items if needed\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        excess_weight = total_weight - capacity\n        # Remove items with lowest marginal value until feasible\n        for i in sorted_items[::-1]:\n            if excess_weight <= 0:\n                break\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                excess_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 9,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution (randomly from top 30% of archive)\n    top_k = max(1, len(archive) // 3)\n    candidates = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)[:top_k]\n    selected_idx = np.random.randint(0, len(candidates))\n    base_solution, _ = candidates[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 3: Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_score = marginal_value1 + marginal_value2\n\n    # Step 4: Identify items to flip (prioritize low-weight, high-marginal items)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) == 0:\n        flip_candidates = np.where(new_solution == 0)[0]\n\n    # Sort by marginal score (descending) and weight (ascending)\n    sorted_indices = np.lexsort((weight_lst[flip_candidates], -marginal_score[flip_candidates]))\n    flip_indices = flip_candidates[sorted_indices]\n\n    # Step 5: Try to flip items while maintaining feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try to add item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Step 6: If no changes made, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = np.random.choice(np.arange(len(new_solution)))\n        if new_solution[flip_idx] == 1:\n            new_weight = current_weight - weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            new_weight = current_weight + weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7401806470202265,
            1.1594519317150116
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution (randomly from top 30% of archive)\n    top_k = max(1, len(archive) // 3)\n    candidates = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)[:top_k]\n    selected_idx = np.random.randint(0, len(candidates))\n    base_solution, _ = candidates[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 3: Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_score = marginal_value1 + marginal_value2\n\n    # Step 4: Identify items to flip (prioritize low-weight, high-marginal items)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) == 0:\n        flip_candidates = np.where(new_solution == 0)[0]\n\n    # Sort by marginal score (descending) and weight (ascending)\n    sorted_indices = np.lexsort((weight_lst[flip_candidates], -marginal_score[flip_candidates]))\n    flip_indices = flip_candidates[sorted_indices]\n\n    # Step 5: Try to flip items while maintaining feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try to add item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Step 6: If no changes made, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = np.random.choice(np.arange(len(new_solution)))\n        if new_solution[flip_idx] == 1:\n            new_weight = current_weight - weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            new_weight = current_weight + weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 9,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution (randomly from top 30% of archive)\n    top_k = max(1, len(archive) // 3)\n    candidates = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)[:top_k]\n    selected_idx = np.random.randint(0, len(candidates))\n    base_solution, _ = candidates[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 3: Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_score = marginal_value1 + marginal_value2\n\n    # Step 4: Identify items to flip (prioritize low-weight, high-marginal items)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) == 0:\n        flip_candidates = np.where(new_solution == 0)[0]\n\n    # Sort by marginal score (descending) and weight (ascending)\n    sorted_indices = np.lexsort((weight_lst[flip_candidates], -marginal_score[flip_candidates]))\n    flip_indices = flip_candidates[sorted_indices]\n\n    # Step 5: Try to flip items while maintaining feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try to add item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Step 6: If no changes made, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = np.random.choice(np.arange(len(new_solution)))\n        if new_solution[flip_idx] == 1:\n            new_weight = current_weight - weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            new_weight = current_weight + weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7401806470202265,
            1.1594519317150116
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution (randomly from top 30% of archive)\n    top_k = max(1, len(archive) // 3)\n    candidates = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)[:top_k]\n    selected_idx = np.random.randint(0, len(candidates))\n    base_solution, _ = candidates[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 3: Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n    marginal_score = marginal_value1 + marginal_value2\n\n    # Step 4: Identify items to flip (prioritize low-weight, high-marginal items)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) == 0:\n        flip_candidates = np.where(new_solution == 0)[0]\n\n    # Sort by marginal score (descending) and weight (ascending)\n    sorted_indices = np.lexsort((weight_lst[flip_candidates], -marginal_score[flip_candidates]))\n    flip_indices = flip_candidates[sorted_indices]\n\n    # Step 5: Try to flip items while maintaining feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try to add item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Step 6: If no changes made, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        flip_idx = np.random.choice(np.arange(len(new_solution)))\n        if new_solution[flip_idx] == 1:\n            new_weight = current_weight - weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            new_weight = current_weight + weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 10,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps and value-based flips\n    num_items = len(weight_lst)\n    if num_items < 2:\n        return new_solution  # No swaps possible\n\n    # Random swap: exchange two items\n    i, j = np.random.choice(num_items, size=2, replace=False)\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, revert the swap and try a value-based flip\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        # Flip the item with the highest marginal value in either objective\n        marginal_value1 = value1_lst - current_value1\n        marginal_value2 = value2_lst - current_value2\n        # Combine marginal values (normalized) to prioritize items that improve both objectives\n        combined_marginal = (marginal_value1 / np.max(marginal_value1 + 1e-10)) + (marginal_value2 / np.max(marginal_value2 + 1e-10))\n        flip_candidate = np.argmax(combined_marginal)\n        new_solution[flip_candidate] = 1 - new_solution[flip_candidate]\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            new_solution[flip_candidate] = 1 - new_solution[flip_candidate]\n\n    return new_solution\n\n",
        "score": [
            -0.44215936165444747,
            1.871090680360794
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps and value-based flips\n    num_items = len(weight_lst)\n    if num_items < 2:\n        return new_solution  # No swaps possible\n\n    # Random swap: exchange two items\n    i, j = np.random.choice(num_items, size=2, replace=False)\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, revert the swap and try a value-based flip\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        # Flip the item with the highest marginal value in either objective\n        marginal_value1 = value1_lst - current_value1\n        marginal_value2 = value2_lst - current_value2\n        # Combine marginal values (normalized) to prioritize items that improve both objectives\n        combined_marginal = (marginal_value1 / np.max(marginal_value1 + 1e-10)) + (marginal_value2 / np.max(marginal_value2 + 1e-10))\n        flip_candidate = np.argmax(combined_marginal)\n        new_solution[flip_candidate] = 1 - new_solution[flip_candidate]\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            new_solution[flip_candidate] = 1 - new_solution[flip_candidate]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 11,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest combined objective value\n    best_solution = max(archive, key=lambda x: sum(x[1]))[0]\n    base_solution = best_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: random flip followed by greedy improvement\n    # Step 1: Randomly flip a subset of bits (intelligent selection)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item would exceed capacity\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Greedy improvement - add the best remaining item if feasible\n    remaining_items = np.where(new_solution == 0)[0]\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    if len(remaining_items) > 0:\n        # Calculate the combined value-to-weight ratio for remaining items\n        ratios = (value1_lst[remaining_items] + value2_lst[remaining_items]) / weight_lst[remaining_items]\n        best_item_idx = remaining_items[np.argmax(ratios)]\n\n        if total_weight + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    # Step 3: Randomly remove an item if the solution is too heavy\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        heavy_items = np.where(new_solution == 1)[0]\n        remove_idx = random.choice(heavy_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3144289564304338,
            8.15700176358223
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest combined objective value\n    best_solution = max(archive, key=lambda x: sum(x[1]))[0]\n    base_solution = best_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: random flip followed by greedy improvement\n    # Step 1: Randomly flip a subset of bits (intelligent selection)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item would exceed capacity\n            total_weight = np.sum(weight_lst[new_solution == 1])\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Greedy improvement - add the best remaining item if feasible\n    remaining_items = np.where(new_solution == 0)[0]\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    if len(remaining_items) > 0:\n        # Calculate the combined value-to-weight ratio for remaining items\n        ratios = (value1_lst[remaining_items] + value2_lst[remaining_items]) / weight_lst[remaining_items]\n        best_item_idx = remaining_items[np.argmax(ratios)]\n\n        if total_weight + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    # Step 3: Randomly remove an item if the solution is too heavy\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        heavy_items = np.where(new_solution == 1)[0]\n        remove_idx = random.choice(heavy_items)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 12,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with probability proportional to its dominance rank (higher value solutions are more likely)\n    total_values = np.array([sum(obj) for _, obj in archive])\n    probs = total_values / np.sum(total_values) if np.sum(total_values) > 0 else np.ones(len(archive)) / len(archive)\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: value-weighted random swaps with feasibility check\n    num_swaps = random.randint(1, min(5, len(weight_lst) // 2))  # Limit swaps to avoid excessive changes\n    for _ in range(num_swaps):\n        # Select items to swap based on their value contribution\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Weighted selection of items to remove (higher value items are more likely)\n            remove_weights = value1_lst[included] + value2_lst[included]\n            remove_weights = remove_weights / np.sum(remove_weights)\n            item_to_remove = np.random.choice(included, p=remove_weights)\n\n            # Weighted selection of items to add (higher value items are more likely)\n            add_weights = value1_lst[excluded] + value2_lst[excluded]\n            add_weights = add_weights / np.sum(add_weights)\n            item_to_add = np.random.choice(excluded, p=add_weights)\n\n            # Check feasibility of the swap\n            new_weight = current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]\n            if new_weight <= capacity:\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.5575641430247126,
            3.1940804421901703
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with probability proportional to its dominance rank (higher value solutions are more likely)\n    total_values = np.array([sum(obj) for _, obj in archive])\n    probs = total_values / np.sum(total_values) if np.sum(total_values) > 0 else np.ones(len(archive)) / len(archive)\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: value-weighted random swaps with feasibility check\n    num_swaps = random.randint(1, min(5, len(weight_lst) // 2))  # Limit swaps to avoid excessive changes\n    for _ in range(num_swaps):\n        # Select items to swap based on their value contribution\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Weighted selection of items to remove (higher value items are more likely)\n            remove_weights = value1_lst[included] + value2_lst[included]\n            remove_weights = remove_weights / np.sum(remove_weights)\n            item_to_remove = np.random.choice(included, p=remove_weights)\n\n            # Weighted selection of items to add (higher value items are more likely)\n            add_weights = value1_lst[excluded] + value2_lst[excluded]\n            add_weights = add_weights / np.sum(add_weights)\n            item_to_add = np.random.choice(excluded, p=add_weights)\n\n            # Check feasibility of the swap\n            new_weight = current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]\n            if new_weight <= capacity:\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 13,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a random solution from the archive\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Perform random flips to explore the neighborhood\n    num_flips = min(3, len(new_solution))  # Flip up to 3 items\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        # Temporarily flip the item\n        new_solution[idx] = 1 - new_solution[idx]\n\n        # Check feasibility\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If infeasible, revert the flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Apply a greedy improvement step to maximize both objectives\n    # Evaluate the current solution\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Try to add or remove items to improve both objectives\n    for _ in range(5):  # Limit the number of improvement attempts\n        improved = False\n\n        # Try adding items not in the solution\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 + value1_lst[i]\n                    new_value2 = current_value2 + value2_lst[i]\n\n                    # Check if both objectives improve\n                    if (new_value1 > current_value1) and (new_value2 > current_value2):\n                        new_solution[i] = 1\n                        current_value1 = new_value1\n                        current_value2 = new_value2\n                        current_weight = new_weight\n                        improved = True\n                        break\n\n        # Try removing items in the solution\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i]\n                new_value1 = current_value1 - value1_lst[i]\n                new_value2 = current_value2 - value2_lst[i]\n\n                # Check if both objectives can be improved or at least one is not worsened\n                if (new_value1 >= current_value1 - 1e-6) and (new_value2 >= current_value2 - 1e-6):\n                    new_solution[i] = 0\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n                    current_weight = new_weight\n                    improved = True\n                    break\n\n        if not improved:\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.3722973848401132,
            5.2236462235450745
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a random solution from the archive\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Perform random flips to explore the neighborhood\n    num_flips = min(3, len(new_solution))  # Flip up to 3 items\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        # Temporarily flip the item\n        new_solution[idx] = 1 - new_solution[idx]\n\n        # Check feasibility\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If infeasible, revert the flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Apply a greedy improvement step to maximize both objectives\n    # Evaluate the current solution\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Try to add or remove items to improve both objectives\n    for _ in range(5):  # Limit the number of improvement attempts\n        improved = False\n\n        # Try adding items not in the solution\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                new_weight = current_weight + weight_lst[i]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 + value1_lst[i]\n                    new_value2 = current_value2 + value2_lst[i]\n\n                    # Check if both objectives improve\n                    if (new_value1 > current_value1) and (new_value2 > current_value2):\n                        new_solution[i] = 1\n                        current_value1 = new_value1\n                        current_value2 = new_value2\n                        current_weight = new_weight\n                        improved = True\n                        break\n\n        # Try removing items in the solution\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i]\n                new_value1 = current_value1 - value1_lst[i]\n                new_value2 = current_value2 - value2_lst[i]\n\n                # Check if both objectives can be improved or at least one is not worsened\n                if (new_value1 >= current_value1 - 1e-6) and (new_value2 >= current_value2 - 1e-6):\n                    new_solution[i] = 0\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n                    current_weight = new_weight\n                    improved = True\n                    break\n\n        if not improved:\n            break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 14,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% of solutions)\n    selected_idx = random.choice(range(min(3, len(archive))))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded without exceeding capacity)\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if excluding this item would keep the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if including this item would keep the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    # If no candidates, return the base solution\n    if not flip_candidates:\n        return new_solution\n\n    # Select a subset of candidates to flip (up to 3 items)\n    num_flips = min(3, len(flip_candidates))\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    # Flip the selected items\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility (in case of multiple flips)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove the heaviest flipped item\n        for i in sorted(flip_indices, key=lambda x: weight_lst[x], reverse=True):\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 1 - new_solution[i]\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.8925215180110103,
            1.550609052181244
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% of solutions)\n    selected_idx = random.choice(range(min(3, len(archive))))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded without exceeding capacity)\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if excluding this item would keep the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if including this item would keep the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    # If no candidates, return the base solution\n    if not flip_candidates:\n        return new_solution\n\n    # Select a subset of candidates to flip (up to 3 items)\n    num_flips = min(3, len(flip_candidates))\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    # Flip the selected items\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility (in case of multiple flips)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove the heaviest flipped item\n        for i in sorted(flip_indices, key=lambda x: weight_lst[x], reverse=True):\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 1 - new_solution[i]\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 14,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% of solutions)\n    selected_idx = random.choice(range(min(3, len(archive))))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded without exceeding capacity)\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if excluding this item would keep the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if including this item would keep the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    # If no candidates, return the base solution\n    if not flip_candidates:\n        return new_solution\n\n    # Select a subset of candidates to flip (up to 3 items)\n    num_flips = min(3, len(flip_candidates))\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    # Flip the selected items\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility (in case of multiple flips)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove the heaviest flipped item\n        for i in sorted(flip_indices, key=lambda x: weight_lst[x], reverse=True):\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 1 - new_solution[i]\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.8925215180110103,
            1.550609052181244
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly from top 30% of solutions)\n    selected_idx = random.choice(range(min(3, len(archive))))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: flip a subset of items based on their marginal contribution\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded without exceeding capacity)\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if excluding this item would keep the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if including this item would keep the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(i)\n\n    # If no candidates, return the base solution\n    if not flip_candidates:\n        return new_solution\n\n    # Select a subset of candidates to flip (up to 3 items)\n    num_flips = min(3, len(flip_candidates))\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    # Flip the selected items\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility (in case of multiple flips)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove the heaviest flipped item\n        for i in sorted(flip_indices, key=lambda x: weight_lst[x], reverse=True):\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 1 - new_solution[i]\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 15,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability inversely proportional to its objective values\n    # This encourages selecting solutions that are not too dominated by others\n    objectives = np.array([obj for (_, obj) in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / (max_obj + 1e-10)  # Avoid division by zero\n    scores = np.prod(normalized_obj, axis=1)  # Product of normalized objectives\n    selection_probs = (1 - scores) / np.sum(1 - scores)  # Higher score -> lower probability\n    base_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Random flip with objective-balanced selection\n    # 2. Greedy improvement for both objectives\n    # 3. Final perturbation to escape local optima\n\n    # Step 1: Random flip with objective-balanced selection\n    # Select items to flip based on their potential to improve both objectives\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        # Calculate potential improvement for each candidate\n        potential_improvement = (value1_lst[flip_candidates] + value2_lst[flip_candidates]) / weight_lst[flip_candidates]\n        flip_probs = potential_improvement / np.sum(potential_improvement)\n        flip_idx = np.random.choice(flip_candidates, p=flip_probs)\n\n        # Flip the selected item if it doesn't violate capacity\n        if new_solution[flip_idx] == 1 and current_weight - weight_lst[flip_idx] >= 0:\n            new_solution[flip_idx] = 0\n            current_weight -= weight_lst[flip_idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Try to add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate potential improvement for each available item\n        potential_improvement = (value1_lst[available_items] + value2_lst[available_items]) / weight_lst[available_items]\n        sorted_items = available_items[np.argsort(-potential_improvement)]\n\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item per iteration to maintain diversity\n\n    # Step 3: Final perturbation to escape local optima\n    # Randomly flip a small number of items (1-3) to introduce diversity\n    num_perturbations = random.randint(1, 3)\n    for _ in range(num_perturbations):\n        perturb_candidates = np.where(new_solution == 1)[0]\n        if len(perturb_candidates) > 0:\n            perturb_idx = random.choice(perturb_candidates)\n            # Flip the item if it doesn't violate capacity\n            if new_solution[perturb_idx] == 1 and current_weight - weight_lst[perturb_idx] >= 0:\n                new_solution[perturb_idx] = 0\n                current_weight -= weight_lst[perturb_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6297832268063945,
            1.9993395507335663
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability inversely proportional to its objective values\n    # This encourages selecting solutions that are not too dominated by others\n    objectives = np.array([obj for (_, obj) in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = objectives / (max_obj + 1e-10)  # Avoid division by zero\n    scores = np.prod(normalized_obj, axis=1)  # Product of normalized objectives\n    selection_probs = (1 - scores) / np.sum(1 - scores)  # Higher score -> lower probability\n    base_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Random flip with objective-balanced selection\n    # 2. Greedy improvement for both objectives\n    # 3. Final perturbation to escape local optima\n\n    # Step 1: Random flip with objective-balanced selection\n    # Select items to flip based on their potential to improve both objectives\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        # Calculate potential improvement for each candidate\n        potential_improvement = (value1_lst[flip_candidates] + value2_lst[flip_candidates]) / weight_lst[flip_candidates]\n        flip_probs = potential_improvement / np.sum(potential_improvement)\n        flip_idx = np.random.choice(flip_candidates, p=flip_probs)\n\n        # Flip the selected item if it doesn't violate capacity\n        if new_solution[flip_idx] == 1 and current_weight - weight_lst[flip_idx] >= 0:\n            new_solution[flip_idx] = 0\n            current_weight -= weight_lst[flip_idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Try to add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    if len(available_items) > 0:\n        # Calculate potential improvement for each available item\n        potential_improvement = (value1_lst[available_items] + value2_lst[available_items]) / weight_lst[available_items]\n        sorted_items = available_items[np.argsort(-potential_improvement)]\n\n        for item in sorted_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break  # Only add one item per iteration to maintain diversity\n\n    # Step 3: Final perturbation to escape local optima\n    # Randomly flip a small number of items (1-3) to introduce diversity\n    num_perturbations = random.randint(1, 3)\n    for _ in range(num_perturbations):\n        perturb_candidates = np.where(new_solution == 1)[0]\n        if len(perturb_candidates) > 0:\n            perturb_idx = random.choice(perturb_candidates)\n            # Flip the item if it doesn't violate capacity\n            if new_solution[perturb_idx] == 1 and current_weight - weight_lst[perturb_idx] >= 0:\n                new_solution[perturb_idx] = 0\n                current_weight -= weight_lst[perturb_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 16,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (to avoid extreme solutions)\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1])\n        # Select a solution from the middle 50% to avoid extreme cases\n        start_idx = max(0, len(archive_sorted) // 4)\n        end_idx = min(len(archive_sorted), 3 * len(archive_sorted) // 4)\n        base_solution, _ = random.choice(archive_sorted[start_idx:end_idx])\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small subset of items (1-3 items)\n    flip_indices = random.sample(range(len(new_solution)), random.randint(1, min(3, len(new_solution))))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Ensure feasibility by removing the worst item(s) if capacity is exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Find items that are currently included\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break  # No items to remove, solution is infeasible\n\n        # Calculate the \"cost\" of each included item (weight / (value1 + value2))\n        costs = weight_lst[included_indices] / (value1_lst[included_indices] + value2_lst[included_indices])\n        worst_item = included_indices[np.argmax(costs)]\n        new_solution[worst_item] = 0\n\n    # 3. Add the best feasible item not currently in the solution\n    excluded_indices = np.where(new_solution == 0)[0]\n    if len(excluded_indices) > 0:\n        # Calculate potential improvement for each excluded item\n        improvements = (value1_lst[excluded_indices] + value2_lst[excluded_indices]) / weight_lst[excluded_indices]\n        best_candidate = excluded_indices[np.argmax(improvements)]\n\n        # Check if adding this item keeps the solution feasible\n        if np.sum(weight_lst * new_solution) + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.2446456619498502,
            8.636138617992401
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (to avoid extreme solutions)\n        archive_sorted = sorted(archive, key=lambda x: x[1][0] + x[1][1])\n        # Select a solution from the middle 50% to avoid extreme cases\n        start_idx = max(0, len(archive_sorted) // 4)\n        end_idx = min(len(archive_sorted), 3 * len(archive_sorted) // 4)\n        base_solution, _ = random.choice(archive_sorted[start_idx:end_idx])\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small subset of items (1-3 items)\n    flip_indices = random.sample(range(len(new_solution)), random.randint(1, min(3, len(new_solution))))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Ensure feasibility by removing the worst item(s) if capacity is exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Find items that are currently included\n        included_indices = np.where(new_solution == 1)[0]\n        if len(included_indices) == 0:\n            break  # No items to remove, solution is infeasible\n\n        # Calculate the \"cost\" of each included item (weight / (value1 + value2))\n        costs = weight_lst[included_indices] / (value1_lst[included_indices] + value2_lst[included_indices])\n        worst_item = included_indices[np.argmax(costs)]\n        new_solution[worst_item] = 0\n\n    # 3. Add the best feasible item not currently in the solution\n    excluded_indices = np.where(new_solution == 0)[0]\n    if len(excluded_indices) > 0:\n        # Calculate potential improvement for each excluded item\n        improvements = (value1_lst[excluded_indices] + value2_lst[excluded_indices]) / weight_lst[excluded_indices]\n        best_candidate = excluded_indices[np.argmax(improvements)]\n\n        # Check if adding this item keeps the solution feasible\n        if np.sum(weight_lst * new_solution) + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 17,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine item swaps and random flips with feasibility checks\n    n_items = len(base_solution)\n    max_attempts = 10  # Limit attempts to avoid excessive computation\n\n    for _ in range(max_attempts):\n        # Randomly select an item to flip\n        item_to_flip = random.randint(0, n_items - 1)\n\n        if base_solution[item_to_flip] == 1:\n            # If item is included, try to exclude it\n            new_weight = current_weight - weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try to include it\n            new_weight = current_weight + weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 1\n                current_weight = new_weight\n\n        # Additional: Randomly swap two items if feasible\n        if random.random() < 0.3:  # 30% chance to perform a swap\n            item1, item2 = random.sample(range(n_items), 2)\n            if base_solution[item1] != base_solution[item2]:\n                # Calculate new weight after swap\n                delta_weight = (weight_lst[item2] - weight_lst[item1]) if base_solution[item1] == 1 else (weight_lst[item1] - weight_lst[item2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n",
        "score": [
            -0.44494411004352064,
            0.8638956844806671
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine item swaps and random flips with feasibility checks\n    n_items = len(base_solution)\n    max_attempts = 10  # Limit attempts to avoid excessive computation\n\n    for _ in range(max_attempts):\n        # Randomly select an item to flip\n        item_to_flip = random.randint(0, n_items - 1)\n\n        if base_solution[item_to_flip] == 1:\n            # If item is included, try to exclude it\n            new_weight = current_weight - weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try to include it\n            new_weight = current_weight + weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 1\n                current_weight = new_weight\n\n        # Additional: Randomly swap two items if feasible\n        if random.random() < 0.3:  # 30% chance to perform a swap\n            item1, item2 = random.sample(range(n_items), 2)\n            if base_solution[item1] != base_solution[item2]:\n                # Calculate new weight after swap\n                delta_weight = (weight_lst[item2] - weight_lst[item1]) if base_solution[item1] == 1 else (weight_lst[item1] - weight_lst[item2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 17,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine item swaps and random flips with feasibility checks\n    n_items = len(base_solution)\n    max_attempts = 10  # Limit attempts to avoid excessive computation\n\n    for _ in range(max_attempts):\n        # Randomly select an item to flip\n        item_to_flip = random.randint(0, n_items - 1)\n\n        if base_solution[item_to_flip] == 1:\n            # If item is included, try to exclude it\n            new_weight = current_weight - weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try to include it\n            new_weight = current_weight + weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 1\n                current_weight = new_weight\n\n        # Additional: Randomly swap two items if feasible\n        if random.random() < 0.3:  # 30% chance to perform a swap\n            item1, item2 = random.sample(range(n_items), 2)\n            if base_solution[item1] != base_solution[item2]:\n                # Calculate new weight after swap\n                delta_weight = (weight_lst[item2] - weight_lst[item1]) if base_solution[item1] == 1 else (weight_lst[item1] - weight_lst[item2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n",
        "score": [
            -0.44494411004352064,
            0.8638956844806671
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine item swaps and random flips with feasibility checks\n    n_items = len(base_solution)\n    max_attempts = 10  # Limit attempts to avoid excessive computation\n\n    for _ in range(max_attempts):\n        # Randomly select an item to flip\n        item_to_flip = random.randint(0, n_items - 1)\n\n        if base_solution[item_to_flip] == 1:\n            # If item is included, try to exclude it\n            new_weight = current_weight - weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try to include it\n            new_weight = current_weight + weight_lst[item_to_flip]\n            if new_weight <= capacity:\n                new_solution[item_to_flip] = 1\n                current_weight = new_weight\n\n        # Additional: Randomly swap two items if feasible\n        if random.random() < 0.3:  # 30% chance to perform a swap\n            item1, item2 = random.sample(range(n_items), 2)\n            if base_solution[item1] != base_solution[item2]:\n                # Calculate new weight after swap\n                delta_weight = (weight_lst[item2] - weight_lst[item1]) if base_solution[item1] == 1 else (weight_lst[item1] - weight_lst[item2])\n                if current_weight + delta_weight <= capacity:\n                    new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 18,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    current_weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    current_values1 = np.array([sol[1][0] for sol in archive])\n    current_values2 = np.array([sol[1][1] for sol in archive])\n\n    # Normalize objectives to identify solutions with room for improvement\n    norm_weights = (current_weights - np.min(current_weights)) / (np.max(current_weights) - np.min(current_weights) + 1e-10)\n    norm_values1 = (current_values1 - np.min(current_values1)) / (np.max(current_values1) - np.min(current_values1) + 1e-10)\n    norm_values2 = (current_values2 - np.min(current_values2)) / (np.max(current_values2) - np.min(current_values2) + 1e-10)\n\n    # Score solutions based on their normalized values and weight (lower weight is better)\n    scores = norm_values1 + norm_values2 - norm_weights\n    probabilities = np.exp(scores - np.max(scores)) / np.sum(np.exp(scores - np.max(scores)))\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: random mutation followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random mutation (flip a few bits)\n    flip_indices = random.sample(range(len(new_solution)), min(3, len(new_solution)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after mutation\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break\n            remove_idx = random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement (add items that improve both objectives)\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n    improved = True\n\n    while improved and len(remaining_items) > 0:\n        improved = False\n        # Calculate potential improvement for each remaining item\n        improvements = []\n        for idx in remaining_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                # Approximate improvement (sum of normalized values)\n                improvement = (value1_lst[idx] / (np.max(value1_lst) + 1e-10)) + (value2_lst[idx] / (np.max(value2_lst) + 1e-10))\n                improvements.append((improvement, idx))\n            else:\n                improvements.append((0, idx))\n\n        # Sort by improvement and select the best\n        improvements.sort(reverse=True, key=lambda x: x[0])\n        best_idx = improvements[0][1]\n\n        if improvements[0][0] > 0:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n            improved = True\n            remaining_items = np.delete(remaining_items, np.where(remaining_items == best_idx)[0])\n\n    return new_solution\n\n",
        "score": [
            -0.3945086805472446,
            6.346399366855621
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    current_weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    current_values1 = np.array([sol[1][0] for sol in archive])\n    current_values2 = np.array([sol[1][1] for sol in archive])\n\n    # Normalize objectives to identify solutions with room for improvement\n    norm_weights = (current_weights - np.min(current_weights)) / (np.max(current_weights) - np.min(current_weights) + 1e-10)\n    norm_values1 = (current_values1 - np.min(current_values1)) / (np.max(current_values1) - np.min(current_values1) + 1e-10)\n    norm_values2 = (current_values2 - np.min(current_values2)) / (np.max(current_values2) - np.min(current_values2) + 1e-10)\n\n    # Score solutions based on their normalized values and weight (lower weight is better)\n    scores = norm_values1 + norm_values2 - norm_weights\n    probabilities = np.exp(scores - np.max(scores)) / np.sum(np.exp(scores - np.max(scores)))\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: random mutation followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random mutation (flip a few bits)\n    flip_indices = random.sample(range(len(new_solution)), min(3, len(new_solution)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after mutation\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break\n            remove_idx = random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement (add items that improve both objectives)\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n    improved = True\n\n    while improved and len(remaining_items) > 0:\n        improved = False\n        # Calculate potential improvement for each remaining item\n        improvements = []\n        for idx in remaining_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                # Approximate improvement (sum of normalized values)\n                improvement = (value1_lst[idx] / (np.max(value1_lst) + 1e-10)) + (value2_lst[idx] / (np.max(value2_lst) + 1e-10))\n                improvements.append((improvement, idx))\n            else:\n                improvements.append((0, idx))\n\n        # Sort by improvement and select the best\n        improvements.sort(reverse=True, key=lambda x: x[0])\n        best_idx = improvements[0][1]\n\n        if improvements[0][0] > 0:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n            improved = True\n            remaining_items = np.delete(remaining_items, np.where(remaining_items == best_idx)[0])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 19,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objective values indicate more potential)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj[:, 0] + normalized_obj[:, 1]\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution, _ = archive[selected_idx]\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Determine operation type (add/remove) based on current solution density\n    density = current_weight / capacity\n    if density < 0.5:  # Underutilized capacity - try adding items\n        # Select items not in solution with high marginal value\n        not_in_sol = np.where(base_solution == 0)[0]\n        if len(not_in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            marginal_value2 = value2_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = not_in_sol[np.argsort(combined_marginal)[-max(1, len(not_in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Check if adding this item keeps solution feasible\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n    else:  # Overutilized capacity - try removing items\n        # Select items in solution with high marginal value\n        in_sol = np.where(base_solution == 1)[0]\n        if len(in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            marginal_value2 = value2_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = in_sol[np.argsort(combined_marginal)[-max(1, len(in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Remove the item\n            new_solution[candidate] = 0\n\n    # Verify feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9557740945060307,
            1.7336466908454895
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objective values indicate more potential)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj[:, 0] + normalized_obj[:, 1]\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution, _ = archive[selected_idx]\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Determine operation type (add/remove) based on current solution density\n    density = current_weight / capacity\n    if density < 0.5:  # Underutilized capacity - try adding items\n        # Select items not in solution with high marginal value\n        not_in_sol = np.where(base_solution == 0)[0]\n        if len(not_in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            marginal_value2 = value2_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = not_in_sol[np.argsort(combined_marginal)[-max(1, len(not_in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Check if adding this item keeps solution feasible\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n    else:  # Overutilized capacity - try removing items\n        # Select items in solution with high marginal value\n        in_sol = np.where(base_solution == 1)[0]\n        if len(in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            marginal_value2 = value2_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = in_sol[np.argsort(combined_marginal)[-max(1, len(in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Remove the item\n            new_solution[candidate] = 0\n\n    # Verify feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 19,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objective values indicate more potential)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj[:, 0] + normalized_obj[:, 1]\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution, _ = archive[selected_idx]\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Determine operation type (add/remove) based on current solution density\n    density = current_weight / capacity\n    if density < 0.5:  # Underutilized capacity - try adding items\n        # Select items not in solution with high marginal value\n        not_in_sol = np.where(base_solution == 0)[0]\n        if len(not_in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            marginal_value2 = value2_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = not_in_sol[np.argsort(combined_marginal)[-max(1, len(not_in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Check if adding this item keeps solution feasible\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n    else:  # Overutilized capacity - try removing items\n        # Select items in solution with high marginal value\n        in_sol = np.where(base_solution == 1)[0]\n        if len(in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            marginal_value2 = value2_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = in_sol[np.argsort(combined_marginal)[-max(1, len(in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Remove the item\n            new_solution[candidate] = 0\n\n    # Verify feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9557740945060307,
            1.7336466908454895
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution (higher objective values indicate more potential)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj[:, 0] + normalized_obj[:, 1]\n    selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n    base_solution, _ = archive[selected_idx]\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Determine operation type (add/remove) based on current solution density\n    density = current_weight / capacity\n    if density < 0.5:  # Underutilized capacity - try adding items\n        # Select items not in solution with high marginal value\n        not_in_sol = np.where(base_solution == 0)[0]\n        if len(not_in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            marginal_value2 = value2_lst[not_in_sol] / (weight_lst[not_in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = not_in_sol[np.argsort(combined_marginal)[-max(1, len(not_in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Check if adding this item keeps solution feasible\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n    else:  # Overutilized capacity - try removing items\n        # Select items in solution with high marginal value\n        in_sol = np.where(base_solution == 1)[0]\n        if len(in_sol) > 0:\n            # Calculate marginal value per weight for each candidate\n            marginal_value1 = value1_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            marginal_value2 = value2_lst[in_sol] / (weight_lst[in_sol] + 1e-8)\n            # Combine marginal values for both objectives\n            combined_marginal = marginal_value1 + marginal_value2\n            # Select top 20% candidates\n            top_candidates = in_sol[np.argsort(combined_marginal)[-max(1, len(in_sol)//5):]]\n            # Randomly select one\n            candidate = random.choice(top_candidates)\n            # Remove the item\n            new_solution[candidate] = 0\n\n    # Verify feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 20,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidate_indices = [i for i, (sol, obj) in enumerate(archive) if np.sum(weight_lst * sol) < 0.9 * capacity]\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # Step 1: Random flip with value-based bias\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_idx = random.choice(flip_candidates)\n        new_solution[flip_idx] = 0\n    else:\n        flip_candidates = np.where(new_solution == 0)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1\n\n    # Step 2: Value-based swap (prioritize items with high ratio of value1/value2)\n    swap_candidates = np.where(new_solution == 1)[0]\n    if len(swap_candidates) > 1:\n        # Calculate value ratios\n        ratios = (value1_lst / value2_lst)[swap_candidates]\n        # Select items with lowest ratio (potential for improvement)\n        low_ratio_items = swap_candidates[np.argsort(ratios)[:max(1, len(swap_candidates)//4)]]\n        if len(low_ratio_items) > 0:\n            swap_idx = random.choice(low_ratio_items)\n            # Find an item to swap with (not in solution)\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                # Select item with highest value ratio that fits capacity\n                potential_swaps = []\n                current_weight = np.sum(weight_lst * new_solution)\n                for item in out_items:\n                    if current_weight - weight_lst[swap_idx] + weight_lst[item] <= capacity:\n                        potential_swaps.append(item)\n                if potential_swaps:\n                    swap_with_idx = random.choice(potential_swaps)\n                    new_solution[swap_idx] = 0\n                    new_solution[swap_with_idx] = 1\n\n    # Step 3: Capacity-aware adjustment (if over capacity, remove lowest value items)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest combined value until feasible\n        while total_weight > capacity:\n            # Calculate combined value for each item\n            combined_value = value1_lst + value2_lst\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) == 0:\n                break  # No items left to remove\n            # Find item with lowest combined value\n            min_value_idx = in_items[np.argmin(combined_value[in_items])]\n            new_solution[min_value_idx] = 0\n            total_weight -= weight_lst[min_value_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5389148131135997,
            2.4540697932243347
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidate_indices = [i for i, (sol, obj) in enumerate(archive) if np.sum(weight_lst * sol) < 0.9 * capacity]\n    if not candidate_indices:\n        candidate_indices = list(range(len(archive)))\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # Step 1: Random flip with value-based bias\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_idx = random.choice(flip_candidates)\n        new_solution[flip_idx] = 0\n    else:\n        flip_candidates = np.where(new_solution == 0)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = random.choice(flip_candidates)\n            new_solution[flip_idx] = 1\n\n    # Step 2: Value-based swap (prioritize items with high ratio of value1/value2)\n    swap_candidates = np.where(new_solution == 1)[0]\n    if len(swap_candidates) > 1:\n        # Calculate value ratios\n        ratios = (value1_lst / value2_lst)[swap_candidates]\n        # Select items with lowest ratio (potential for improvement)\n        low_ratio_items = swap_candidates[np.argsort(ratios)[:max(1, len(swap_candidates)//4)]]\n        if len(low_ratio_items) > 0:\n            swap_idx = random.choice(low_ratio_items)\n            # Find an item to swap with (not in solution)\n            out_items = np.where(new_solution == 0)[0]\n            if len(out_items) > 0:\n                # Select item with highest value ratio that fits capacity\n                potential_swaps = []\n                current_weight = np.sum(weight_lst * new_solution)\n                for item in out_items:\n                    if current_weight - weight_lst[swap_idx] + weight_lst[item] <= capacity:\n                        potential_swaps.append(item)\n                if potential_swaps:\n                    swap_with_idx = random.choice(potential_swaps)\n                    new_solution[swap_idx] = 0\n                    new_solution[swap_with_idx] = 1\n\n    # Step 3: Capacity-aware adjustment (if over capacity, remove lowest value items)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest combined value until feasible\n        while total_weight > capacity:\n            # Calculate combined value for each item\n            combined_value = value1_lst + value2_lst\n            in_items = np.where(new_solution == 1)[0]\n            if len(in_items) == 0:\n                break  # No items left to remove\n            # Find item with lowest combined value\n            min_value_idx = in_items[np.argmin(combined_value[in_items])]\n            new_solution[min_value_idx] = 0\n            total_weight -= weight_lst[min_value_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 21,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine random flip with value-based flip\n    # First, try random flip to escape local optima\n    if random.random() < 0.5:\n        # Random flip: select a random item to flip\n        flip_idx = random.randint(0, len(base_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            # If item is excluded, try to add it\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n    else:\n        # Value-based flip: select the most valuable item to flip based on both objectives\n        # Calculate marginal value per weight for both objectives\n        marginal_val1 = value1_lst / weight_lst\n        marginal_val2 = value2_lst / weight_lst\n        combined_marginal = marginal_val1 + marginal_val2\n\n        # Find items that can be added or removed\n        addable = (base_solution == 0) & (weight_lst <= (capacity - current_weight))\n        removable = (base_solution == 1)\n\n        if np.any(addable) or np.any(removable):\n            # Select item with highest combined marginal value\n            if np.any(addable):\n                candidates = np.where(addable)[0]\n                best_candidate = candidates[np.argmax(combined_marginal[candidates])]\n                new_solution[best_candidate] = 1\n            else:\n                candidates = np.where(removable)[0]\n                best_candidate = candidates[np.argmax(combined_marginal[candidates])]\n                new_solution[best_candidate] = 0\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while new_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            new_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4888671090412277,
            6.201417475938797
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine random flip with value-based flip\n    # First, try random flip to escape local optima\n    if random.random() < 0.5:\n        # Random flip: select a random item to flip\n        flip_idx = random.randint(0, len(base_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            # If item is excluded, try to add it\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n    else:\n        # Value-based flip: select the most valuable item to flip based on both objectives\n        # Calculate marginal value per weight for both objectives\n        marginal_val1 = value1_lst / weight_lst\n        marginal_val2 = value2_lst / weight_lst\n        combined_marginal = marginal_val1 + marginal_val2\n\n        # Find items that can be added or removed\n        addable = (base_solution == 0) & (weight_lst <= (capacity - current_weight))\n        removable = (base_solution == 1)\n\n        if np.any(addable) or np.any(removable):\n            # Select item with highest combined marginal value\n            if np.any(addable):\n                candidates = np.where(addable)[0]\n                best_candidate = candidates[np.argmax(combined_marginal[candidates])]\n                new_solution[best_candidate] = 1\n            else:\n                candidates = np.where(removable)[0]\n                best_candidate = candidates[np.argmax(combined_marginal[candidates])]\n                new_solution[best_candidate] = 0\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If not feasible, remove items randomly until feasible\n        while new_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            new_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 22,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that have not been fully explored\n    # Here, we select the solution with the lowest sum of objective values to encourage diversity\n    base_solution, _ = min(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # Flip 20% of items randomly\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # 2. Ensure feasibility by removing excess items based on weight\n    excess_weight = np.sum(weight_lst[new_solution == 1]) - capacity\n    if excess_weight > 0:\n        # Remove items with the lowest marginal value for both objectives\n        while excess_weight > 0 and np.any(new_solution == 1):\n            # Calculate marginal value for each item (value/weight ratio)\n            marginal_value1 = value1_lst / weight_lst\n            marginal_value2 = value2_lst / weight_lst\n            marginal_value = marginal_value1 + marginal_value2  # Combined marginal value\n\n            # Find the item with the lowest marginal value among those included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            worst_item = included_items[np.argmin(marginal_value[included_items])]\n\n            # Remove the worst item\n            new_solution[worst_item] = 0\n            excess_weight -= weight_lst[worst_item]\n\n    # 3. Add items that can improve both objectives without exceeding capacity\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate potential value improvements\n        potential_value1 = value1_lst / weight_lst\n        potential_value2 = value2_lst / weight_lst\n        potential_value = potential_value1 + potential_value2  # Combined potential value\n\n        # Sort items by potential value in descending order\n        sorted_items = np.argsort(-potential_value)\n        for item in sorted_items:\n            if new_solution[item] == 0 and weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3776762753298405,
            4.5288010239601135
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that have not been fully explored\n    # Here, we select the solution with the lowest sum of objective values to encourage diversity\n    base_solution, _ = min(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # Flip 20% of items randomly\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # 2. Ensure feasibility by removing excess items based on weight\n    excess_weight = np.sum(weight_lst[new_solution == 1]) - capacity\n    if excess_weight > 0:\n        # Remove items with the lowest marginal value for both objectives\n        while excess_weight > 0 and np.any(new_solution == 1):\n            # Calculate marginal value for each item (value/weight ratio)\n            marginal_value1 = value1_lst / weight_lst\n            marginal_value2 = value2_lst / weight_lst\n            marginal_value = marginal_value1 + marginal_value2  # Combined marginal value\n\n            # Find the item with the lowest marginal value among those included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            worst_item = included_items[np.argmin(marginal_value[included_items])]\n\n            # Remove the worst item\n            new_solution[worst_item] = 0\n            excess_weight -= weight_lst[worst_item]\n\n    # 3. Add items that can improve both objectives without exceeding capacity\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate potential value improvements\n        potential_value1 = value1_lst / weight_lst\n        potential_value2 = value2_lst / weight_lst\n        potential_value = potential_value1 + potential_value2  # Combined potential value\n\n        # Sort items by potential value in descending order\n        sorted_items = np.argsort(-potential_value)\n        for item in sorted_items:\n            if new_solution[item] == 0 and weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 23,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prefer solutions that are not too close to the current non-dominated front\n    # and have some room for improvement in both objectives\n    candidate_indices = []\n    for idx, (sol, (v1, v2)) in enumerate(archive):\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        return archive[0][0].copy()\n\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their contribution)\n    # 2. Apply a greedy improvement step for one of the objectives\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Random flip with probability based on marginal contribution\n    for i in range(n_items):\n        if random.random() < 0.3:  # Base probability\n            # Adjust probability based on marginal contribution\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # Probability to remove based on how much it contributes\n                marginal_weight = weight_lst[i]\n                marginal_v1 = value1_lst[i]\n                marginal_v2 = value2_lst[i]\n                prob_remove = 0.5 * (marginal_weight / capacity) + 0.5 * (1 - (marginal_v1 + marginal_v2) / (np.sum(value1_lst) + np.sum(value2_lst)))\n                if random.random() < prob_remove:\n                    new_solution[i] = 0\n            else:\n                # Probability to add based on available capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    marginal_weight = weight_lst[i]\n                    marginal_v1 = value1_lst[i]\n                    marginal_v2 = value2_lst[i]\n                    prob_add = 0.5 * (marginal_weight / capacity) + 0.5 * ((marginal_v1 + marginal_v2) / (np.sum(value1_lst) + np.sum(value2_lst)))\n                    if random.random() < prob_add:\n                        new_solution[i] = 1\n\n    # Step 2: Greedy improvement for one objective (randomly chosen)\n    if random.random() < 0.5:  # Improve for objective 1\n        # Find items that can be added without violating capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n        if len(available_items) > 0:\n            # Select the item with highest value1\n            best_item = available_items[np.argmax(value1_lst[available_items])]\n            new_solution[best_item] = 1\n    else:  # Improve for objective 2\n        # Find items that can be added without violating capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n        if len(available_items) > 0:\n            # Select the item with highest value2\n            best_item = available_items[np.argmax(value2_lst[available_items])]\n            new_solution[best_item] = 1\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            item_to_remove = random.choice(excess_items)\n            new_solution[item_to_remove] = 0\n            excess -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.41163154811423985,
            8.89613127708435
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prefer solutions that are not too close to the current non-dominated front\n    # and have some room for improvement in both objectives\n    candidate_indices = []\n    for idx, (sol, (v1, v2)) in enumerate(archive):\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        return archive[0][0].copy()\n\n    selected_idx = random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their contribution)\n    # 2. Apply a greedy improvement step for one of the objectives\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Random flip with probability based on marginal contribution\n    for i in range(n_items):\n        if random.random() < 0.3:  # Base probability\n            # Adjust probability based on marginal contribution\n            current_weight = np.sum(weight_lst * new_solution)\n            if new_solution[i] == 1:\n                # Probability to remove based on how much it contributes\n                marginal_weight = weight_lst[i]\n                marginal_v1 = value1_lst[i]\n                marginal_v2 = value2_lst[i]\n                prob_remove = 0.5 * (marginal_weight / capacity) + 0.5 * (1 - (marginal_v1 + marginal_v2) / (np.sum(value1_lst) + np.sum(value2_lst)))\n                if random.random() < prob_remove:\n                    new_solution[i] = 0\n            else:\n                # Probability to add based on available capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    marginal_weight = weight_lst[i]\n                    marginal_v1 = value1_lst[i]\n                    marginal_v2 = value2_lst[i]\n                    prob_add = 0.5 * (marginal_weight / capacity) + 0.5 * ((marginal_v1 + marginal_v2) / (np.sum(value1_lst) + np.sum(value2_lst)))\n                    if random.random() < prob_add:\n                        new_solution[i] = 1\n\n    # Step 2: Greedy improvement for one objective (randomly chosen)\n    if random.random() < 0.5:  # Improve for objective 1\n        # Find items that can be added without violating capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n        if len(available_items) > 0:\n            # Select the item with highest value1\n            best_item = available_items[np.argmax(value1_lst[available_items])]\n            new_solution[best_item] = 1\n    else:  # Improve for objective 2\n        # Find items that can be added without violating capacity\n        current_weight = np.sum(weight_lst * new_solution)\n        available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n        if len(available_items) > 0:\n            # Select the item with highest value2\n            best_item = available_items[np.argmax(value2_lst[available_items])]\n            new_solution[best_item] = 1\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            item_to_remove = random.choice(excess_items)\n            new_solution[item_to_remove] = 0\n            excess -= weight_lst[item_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 24,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution from the archive (here, we randomly select one, but could be enhanced)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (perturbation)\n    num_items = len(new_solution)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Greedy improvement step: add items with the highest marginal contribution\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate marginal contribution for each item (weighted sum of normalized values)\n        included = new_solution == 1\n        excluded = ~included\n        marginal_contribution = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n\n        # Sort items by marginal contribution in descending order\n        sorted_indices = np.argsort(-marginal_contribution)\n        for idx in sorted_indices:\n            if weight_lst[excluded][idx] <= remaining_capacity:\n                new_solution[np.where(excluded)[0][idx]] = 1\n                remaining_capacity -= weight_lst[np.where(excluded)[0][idx]]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, remove items until it is\n        included = np.where(new_solution == 1)[0]\n        np.random.shuffle(included)\n        for idx in included:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.34269466791148656,
            1.650035709142685
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution from the archive (here, we randomly select one, but could be enhanced)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (perturbation)\n    num_items = len(new_solution)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Greedy improvement step: add items with the highest marginal contribution\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate marginal contribution for each item (weighted sum of normalized values)\n        included = new_solution == 1\n        excluded = ~included\n        marginal_contribution = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n\n        # Sort items by marginal contribution in descending order\n        sorted_indices = np.argsort(-marginal_contribution)\n        for idx in sorted_indices:\n            if weight_lst[excluded][idx] <= remaining_capacity:\n                new_solution[np.where(excluded)[0][idx]] = 1\n                remaining_capacity -= weight_lst[np.where(excluded)[0][idx]]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, remove items until it is\n        included = np.where(new_solution == 1)[0]\n        np.random.shuffle(included)\n        for idx in included:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 25,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, (current_value1, current_value2) = max(archive, key=lambda x: x[1][0] + x[1][1])\n    base_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: flip a subset of items based on marginal gains\n    new_solution = base_solution.copy()\n\n    # Identify items with high marginal gain for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal gains and sort by combined score\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(-combined_gain)  # Descending order\n\n    # Flip a subset of top items to explore new regions\n    flip_indices = sorted_indices[:max(1, len(sorted_indices) // 10)]  # Flip top 10% or at least 1 item\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random perturbation to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        perturb_idx = np.random.choice(len(new_solution))\n        if new_solution[perturb_idx] == 1:\n            if current_weight - weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 0\n        else:\n            if current_weight + weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8630361567771716,
            1.2525819540023804
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, (current_value1, current_value2) = max(archive, key=lambda x: x[1][0] + x[1][1])\n    base_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: flip a subset of items based on marginal gains\n    new_solution = base_solution.copy()\n\n    # Identify items with high marginal gain for both objectives\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal gains and sort by combined score\n    combined_gain = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(-combined_gain)  # Descending order\n\n    # Flip a subset of top items to explore new regions\n    flip_indices = sorted_indices[:max(1, len(sorted_indices) // 10)]  # Flip top 10% or at least 1 item\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random perturbation to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        perturb_idx = np.random.choice(len(new_solution))\n        if new_solution[perturb_idx] == 1:\n            if current_weight - weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 0\n        else:\n            if current_weight + weight_lst[perturb_idx] <= capacity:\n                new_solution[perturb_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 26,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    base_solution, (current_value1, current_value2) = random.choice(archive)\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip items to explore the neighborhood\n    for _ in range(3):  # Number of random flips\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            # If removing the item keeps the solution feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If adding the item keeps the solution feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Value-based flips: flip items with high value-to-weight ratios for both objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value_ratio1 + value_ratio2  # Prioritize items that improve both objectives\n\n    # Sort items by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    for idx in sorted_indices[:5]:  # Consider top 5 items\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # 3. Capacity-aware adjustments: ensure the solution is feasible\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Remove the item with the lowest combined value-to-weight ratio\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            break\n        worst_idx = candidate_indices[np.argmin(combined_ratio[candidate_indices])]\n        new_solution[worst_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5314879095008932,
            0.9680034518241882
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    base_solution, (current_value1, current_value2) = random.choice(archive)\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip items to explore the neighborhood\n    for _ in range(3):  # Number of random flips\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            # If removing the item keeps the solution feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If adding the item keeps the solution feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Value-based flips: flip items with high value-to-weight ratios for both objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value_ratio1 + value_ratio2  # Prioritize items that improve both objectives\n\n    # Sort items by combined ratio in descending order\n    sorted_indices = np.argsort(-combined_ratio)\n\n    for idx in sorted_indices[:5]:  # Consider top 5 items\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # 3. Capacity-aware adjustments: ensure the solution is feasible\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Remove the item with the lowest combined value-to-weight ratio\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            break\n        worst_idx = candidate_indices[np.argmin(combined_ratio[candidate_indices])]\n        new_solution[worst_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 27,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.argmin([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on a combination of weight and value ratios\n    for _ in range(min(5, len(weight_lst))):  # Limit the number of flips to avoid excessive changes\n        # Calculate flip scores: prioritize items with high value/weight ratio in either objective\n        flip_scores = []\n        for i in range(len(weight_lst)):\n            if base_solution[i] == 1:\n                # Score for removing an item: negative impact on both objectives\n                score = - (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n            else:\n                # Score for adding an item: positive impact on both objectives, penalize if over capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    score = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n                else:\n                    score = -np.inf  # Penalize infeasible additions\n            flip_scores.append(score)\n\n        # Select the best flip candidate\n        if flip_scores:\n            best_flip = np.argmax(flip_scores)\n            if flip_scores[best_flip] > 0:  # Only flip if it improves both objectives\n                new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    # Ensure feasibility by removing items if over capacity\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the smallest (value1 + value2)/weight ratio\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        to_remove = included_items[np.argmin(ratios)]\n        new_solution[to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9109269934537463,
            7.589722245931625
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.argmin([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on a combination of weight and value ratios\n    for _ in range(min(5, len(weight_lst))):  # Limit the number of flips to avoid excessive changes\n        # Calculate flip scores: prioritize items with high value/weight ratio in either objective\n        flip_scores = []\n        for i in range(len(weight_lst)):\n            if base_solution[i] == 1:\n                # Score for removing an item: negative impact on both objectives\n                score = - (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n            else:\n                # Score for adding an item: positive impact on both objectives, penalize if over capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    score = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n                else:\n                    score = -np.inf  # Penalize infeasible additions\n            flip_scores.append(score)\n\n        # Select the best flip candidate\n        if flip_scores:\n            best_flip = np.argmax(flip_scores)\n            if flip_scores[best_flip] > 0:  # Only flip if it improves both objectives\n                new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    # Ensure feasibility by removing items if over capacity\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the smallest (value1 + value2)/weight ratio\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        to_remove = included_items[np.argmin(ratios)]\n        new_solution[to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 28,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive (e.g., with high crowding distance or low dominance)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    max_attempts = 10\n    for _ in range(max_attempts):\n        # Randomly select items to flip (1 to 3 items)\n        flip_indices = random.sample(range(len(new_solution)), random.randint(1, 3))\n\n        # Calculate potential new solution\n        temp_solution = new_solution.copy()\n        for idx in flip_indices:\n            temp_solution[idx] = 1 - temp_solution[idx]  # Flip the item\n\n        # Check feasibility\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        # Calculate potential objective values\n        temp_val1 = np.sum(value1_lst * temp_solution)\n        temp_val2 = np.sum(value2_lst * temp_solution)\n\n        # Accept if it improves both objectives or one objective significantly\n        if (temp_val1 > base_val1 and temp_val2 > base_val2) or \\\n           (temp_val1 > base_val1 + 0.2 * np.mean(value1_lst) and temp_val2 > base_val2) or \\\n           (temp_val2 > base_val2 + 0.2 * np.mean(value2_lst) and temp_val1 > base_val1):\n            new_solution = temp_solution\n            base_val1, base_val2 = temp_val1, temp_val2\n\n    # Additional greedy improvement: try to add items if possible\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            temp_val1 = np.sum(value1_lst * temp_solution)\n            temp_val2 = np.sum(value2_lst * temp_solution)\n\n            if (temp_val1 > base_val1 and temp_val2 >= base_val2) or \\\n               (temp_val2 > base_val2 and temp_val1 >= base_val1):\n                new_solution = temp_solution\n                current_weight += weight_lst[idx]\n                base_val1, base_val2 = temp_val1, temp_val2\n\n    return new_solution\n\n",
        "score": [
            -0.26913622689890004,
            10.354299008846283
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive (e.g., with high crowding distance or low dominance)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    max_attempts = 10\n    for _ in range(max_attempts):\n        # Randomly select items to flip (1 to 3 items)\n        flip_indices = random.sample(range(len(new_solution)), random.randint(1, 3))\n\n        # Calculate potential new solution\n        temp_solution = new_solution.copy()\n        for idx in flip_indices:\n            temp_solution[idx] = 1 - temp_solution[idx]  # Flip the item\n\n        # Check feasibility\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        # Calculate potential objective values\n        temp_val1 = np.sum(value1_lst * temp_solution)\n        temp_val2 = np.sum(value2_lst * temp_solution)\n\n        # Accept if it improves both objectives or one objective significantly\n        if (temp_val1 > base_val1 and temp_val2 > base_val2) or \\\n           (temp_val1 > base_val1 + 0.2 * np.mean(value1_lst) and temp_val2 > base_val2) or \\\n           (temp_val2 > base_val2 + 0.2 * np.mean(value2_lst) and temp_val1 > base_val1):\n            new_solution = temp_solution\n            base_val1, base_val2 = temp_val1, temp_val2\n\n    # Additional greedy improvement: try to add items if possible\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1\n            temp_val1 = np.sum(value1_lst * temp_solution)\n            temp_val2 = np.sum(value2_lst * temp_solution)\n\n            if (temp_val1 > base_val1 and temp_val2 >= base_val2) or \\\n               (temp_val2 > base_val2 and temp_val1 >= base_val1):\n                new_solution = temp_solution\n                current_weight += weight_lst[idx]\n                base_val1, base_val2 = temp_val1, temp_val2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 29,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate the current total weight for each solution in the archive\n    weights = [np.sum(weight_lst * sol) for sol, _ in archive]\n\n    # Select the solution with the highest total weight (promising for further improvement)\n    base_solution = max(archive, key=lambda x: np.sum(weight_lst * x[0]))[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select a subset of items to consider for flipping\n    subset_size = min(5, n_items)\n    flip_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Randomly swap two items (if possible)\n    if n_items >= 2:\n        i, j = np.random.choice(n_items, size=2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility after swap\n            delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n            if current_weight + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8379476997939352,
            2.880673497915268
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate the current total weight for each solution in the archive\n    weights = [np.sum(weight_lst * sol) for sol, _ in archive]\n\n    # Select the solution with the highest total weight (promising for further improvement)\n    base_solution = max(archive, key=lambda x: np.sum(weight_lst * x[0]))[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select a subset of items to consider for flipping\n    subset_size = min(5, n_items)\n    flip_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Randomly swap two items (if possible)\n    if n_items >= 2:\n        i, j = np.random.choice(n_items, size=2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility after swap\n            delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] == 1 else (weight_lst[i] - weight_lst[j])\n            if current_weight + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 30,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the crowding distance for each solution in the archive\n    def crowding_distance(solutions):\n        obj1 = np.array([obj[0] for _, obj in solutions])\n        obj2 = np.array([obj[1] for _, obj in solutions])\n        distances = np.zeros(len(solutions))\n\n        for i in range(len(solutions)):\n            left = np.argmax(obj1[:i] >= obj1[i]) if i > 0 else -1\n            right = np.argmin(obj1[i+1:] <= obj1[i]) if i < len(solutions)-1 else -1\n            if left != -1:\n                distances[i] += (obj1[left] - obj1[i]) / (obj1.max() - obj1.min())\n            if right != -1:\n                distances[i] += (obj1[right] - obj1[i]) / (obj1.max() - obj1.min())\n\n            left = np.argmax(obj2[:i] >= obj2[i]) if i > 0 else -1\n            right = np.argmin(obj2[i+1:] <= obj2[i]) if i < len(solutions)-1 else -1\n            if left != -1:\n                distances[i] += (obj2[left] - obj2[i]) / (obj2.max() - obj2.min())\n            if right != -1:\n                distances[i] += (obj2[right] - obj2[i]) / (obj2.max() - obj2.min())\n\n        return distances\n\n    distances = crowding_distance(archive)\n    # Select solutions with top 30% crowding distance (promising for improvement)\n    top_indices = np.argsort(distances)[-max(1, int(0.3 * len(archive))):]\n    selected_solutions = [archive[i] for i in top_indices]\n\n    # Randomly select one of the top solutions\n    base_solution, _ = random.choice(selected_solutions)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combination of flip and swap\n    def is_feasible(solution):\n        return np.dot(solution, weight_lst) <= capacity\n\n    # Flip strategy: flip a random bit if feasible\n    if random.random() < 0.7:  # 70% chance to flip\n        flip_index = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_index] = 1 - new_solution[flip_index]\n        if not is_feasible(new_solution):\n            new_solution[flip_index] = 1 - new_solution[flip_index]  # revert if infeasible\n\n    # Swap strategy: swap two items if feasible\n    if random.random() < 0.5:  # 50% chance to swap\n        indices = random.sample(range(len(new_solution)), 2)\n        new_solution[indices[0]], new_solution[indices[1]] = new_solution[indices[1]], new_solution[indices[0]]\n        if not is_feasible(new_solution):\n            new_solution[indices[0]], new_solution[indices[1]] = new_solution[indices[1]], new_solution[indices[0]]  # revert if infeasible\n\n    # Random walk: add or remove a random item if feasible\n    if random.random() < 0.3:  # 30% chance for random walk\n        if random.random() < 0.5:  # 50% chance to add\n            zero_indices = np.where(new_solution == 0)[0]\n            if len(zero_indices) > 0:\n                add_index = random.choice(zero_indices)\n                if np.dot(new_solution, weight_lst) + weight_lst[add_index] <= capacity:\n                    new_solution[add_index] = 1\n        else:  # 50% chance to remove\n            one_indices = np.where(new_solution == 1)[0]\n            if len(one_indices) > 0:\n                remove_index = random.choice(one_indices)\n                if np.dot(new_solution, weight_lst) - weight_lst[remove_index] >= 0:\n                    new_solution[remove_index] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9547110436466555,
            9.176643341779709
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the crowding distance for each solution in the archive\n    def crowding_distance(solutions):\n        obj1 = np.array([obj[0] for _, obj in solutions])\n        obj2 = np.array([obj[1] for _, obj in solutions])\n        distances = np.zeros(len(solutions))\n\n        for i in range(len(solutions)):\n            left = np.argmax(obj1[:i] >= obj1[i]) if i > 0 else -1\n            right = np.argmin(obj1[i+1:] <= obj1[i]) if i < len(solutions)-1 else -1\n            if left != -1:\n                distances[i] += (obj1[left] - obj1[i]) / (obj1.max() - obj1.min())\n            if right != -1:\n                distances[i] += (obj1[right] - obj1[i]) / (obj1.max() - obj1.min())\n\n            left = np.argmax(obj2[:i] >= obj2[i]) if i > 0 else -1\n            right = np.argmin(obj2[i+1:] <= obj2[i]) if i < len(solutions)-1 else -1\n            if left != -1:\n                distances[i] += (obj2[left] - obj2[i]) / (obj2.max() - obj2.min())\n            if right != -1:\n                distances[i] += (obj2[right] - obj2[i]) / (obj2.max() - obj2.min())\n\n        return distances\n\n    distances = crowding_distance(archive)\n    # Select solutions with top 30% crowding distance (promising for improvement)\n    top_indices = np.argsort(distances)[-max(1, int(0.3 * len(archive))):]\n    selected_solutions = [archive[i] for i in top_indices]\n\n    # Randomly select one of the top solutions\n    base_solution, _ = random.choice(selected_solutions)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combination of flip and swap\n    def is_feasible(solution):\n        return np.dot(solution, weight_lst) <= capacity\n\n    # Flip strategy: flip a random bit if feasible\n    if random.random() < 0.7:  # 70% chance to flip\n        flip_index = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_index] = 1 - new_solution[flip_index]\n        if not is_feasible(new_solution):\n            new_solution[flip_index] = 1 - new_solution[flip_index]  # revert if infeasible\n\n    # Swap strategy: swap two items if feasible\n    if random.random() < 0.5:  # 50% chance to swap\n        indices = random.sample(range(len(new_solution)), 2)\n        new_solution[indices[0]], new_solution[indices[1]] = new_solution[indices[1]], new_solution[indices[0]]\n        if not is_feasible(new_solution):\n            new_solution[indices[0]], new_solution[indices[1]] = new_solution[indices[1]], new_solution[indices[0]]  # revert if infeasible\n\n    # Random walk: add or remove a random item if feasible\n    if random.random() < 0.3:  # 30% chance for random walk\n        if random.random() < 0.5:  # 50% chance to add\n            zero_indices = np.where(new_solution == 0)[0]\n            if len(zero_indices) > 0:\n                add_index = random.choice(zero_indices)\n                if np.dot(new_solution, weight_lst) + weight_lst[add_index] <= capacity:\n                    new_solution[add_index] = 1\n        else:  # 50% chance to remove\n            one_indices = np.where(new_solution == 1)[0]\n            if len(one_indices) > 0:\n                remove_index = random.choice(one_indices)\n                if np.dot(new_solution, weight_lst) - weight_lst[remove_index] >= 0:\n                    new_solution[remove_index] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 31,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., solutions with non-dominated neighbors)\n    # Here, we randomly select a solution for simplicity, but in practice, you might use more sophisticated criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine item swap and greedy addition\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly select a subset of items to consider for swap\n    n_items = len(base_solution)\n    swap_candidates = random.sample(range(n_items), min(5, n_items))\n\n    for i in swap_candidates:\n        if base_solution[i] == 1:\n            # Try removing the item and see if we can add better items\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n\n            # Find items not in the solution that can be added without exceeding capacity\n            available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - temp_weight)))[0]\n\n            if len(available_items) > 0:\n                # Evaluate potential items based on a weighted sum of both objectives\n                weights = np.array([0.5, 0.5])  # Equal weight for both objectives\n                scores = weights[0] * value1_lst[available_items] + weights[1] * value2_lst[available_items]\n                best_item = available_items[np.argmax(scores)]\n\n                # Add the best item\n                temp_solution[best_item] = 1\n\n                # Check feasibility\n                new_weight = temp_weight + weight_lst[best_item]\n                if new_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = new_weight\n        else:\n            # Try adding the item if it improves both objectives\n            if current_weight + weight_lst[i] <= capacity:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n\n                # Check if this addition improves both objectives\n                new_value1 = current_value1 + value1_lst[i]\n                new_value2 = current_value2 + value2_lst[i]\n\n                # Simple dominance check (can be enhanced)\n                if (new_value1 > current_value1 and new_value2 > current_value2):\n                    new_solution = temp_solution\n                    current_weight += weight_lst[i]\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n    # Step 2: Greedy addition of items not in the solution\n    available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n    if len(available_items) > 0:\n        # Evaluate potential items based on both objectives\n        weights = np.array([0.5, 0.5])  # Equal weight for both objectives\n        scores = weights[0] * value1_lst[available_items] + weights[1] * value2_lst[available_items]\n        best_items = available_items[np.argsort(scores)[::-1]]  # Sort in descending order\n\n        for item in best_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3613765389798976,
            2.695730149745941
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., solutions with non-dominated neighbors)\n    # Here, we randomly select a solution for simplicity, but in practice, you might use more sophisticated criteria\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine item swap and greedy addition\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly select a subset of items to consider for swap\n    n_items = len(base_solution)\n    swap_candidates = random.sample(range(n_items), min(5, n_items))\n\n    for i in swap_candidates:\n        if base_solution[i] == 1:\n            # Try removing the item and see if we can add better items\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n\n            # Find items not in the solution that can be added without exceeding capacity\n            available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - temp_weight)))[0]\n\n            if len(available_items) > 0:\n                # Evaluate potential items based on a weighted sum of both objectives\n                weights = np.array([0.5, 0.5])  # Equal weight for both objectives\n                scores = weights[0] * value1_lst[available_items] + weights[1] * value2_lst[available_items]\n                best_item = available_items[np.argmax(scores)]\n\n                # Add the best item\n                temp_solution[best_item] = 1\n\n                # Check feasibility\n                new_weight = temp_weight + weight_lst[best_item]\n                if new_weight <= capacity:\n                    new_solution = temp_solution\n                    current_weight = new_weight\n        else:\n            # Try adding the item if it improves both objectives\n            if current_weight + weight_lst[i] <= capacity:\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 1\n\n                # Check if this addition improves both objectives\n                new_value1 = current_value1 + value1_lst[i]\n                new_value2 = current_value2 + value2_lst[i]\n\n                # Simple dominance check (can be enhanced)\n                if (new_value1 > current_value1 and new_value2 > current_value2):\n                    new_solution = temp_solution\n                    current_weight += weight_lst[i]\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n    # Step 2: Greedy addition of items not in the solution\n    available_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n    if len(available_items) > 0:\n        # Evaluate potential items based on both objectives\n        weights = np.array([0.5, 0.5])  # Equal weight for both objectives\n        scores = weights[0] * value1_lst[available_items] + weights[1] * value2_lst[available_items]\n        best_items = available_items[np.argsort(scores)[::-1]]  # Sort in descending order\n\n        for item in best_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 32,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate the crowding distance for each solution in the archive\n        objectives = np.array([obj for _, obj in archive])\n        crowding_distances = np.zeros(len(archive))\n\n        for i in range(2):  # For each objective\n            sorted_indices = np.argsort(objectives[:, i])\n            objectives_sorted = objectives[sorted_indices, i]\n\n            # Calculate crowding distance\n            crowding_distances[sorted_indices[0]] = np.inf\n            crowding_distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(archive) - 1):\n                if objectives_sorted[-1] - objectives_sorted[0] == 0:\n                    crowding_distances[sorted_indices[j]] += 0\n                else:\n                    crowding_distances[sorted_indices[j]] += (objectives_sorted[j+1] - objectives_sorted[j-1]) / (objectives_sorted[-1] - objectives_sorted[0])\n\n        # Select a solution with high crowding distance (promising for improvement)\n        max_distance = np.max(crowding_distances)\n        candidates = [i for i, dist in enumerate(crowding_distances) if dist == max_distance]\n        selected_idx = random.choice(candidates)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: Randomly select a subset of items and perform a swap or flip operation\n    n_items = len(weight_lst)\n    subset_size = max(1, int(np.sqrt(n_items)))  # Dynamic subset size based on problem size\n    subset_indices = random.sample(range(n_items), subset_size)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Try to flip items in the subset to improve both objectives\n    for idx in subset_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_weight = current_weight + weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = temp_weight\n\n    # Additional improvement: Try to swap items between the subset and the rest\n    if len(subset_indices) > 1:\n        swap_idx1, swap_idx2 = random.sample(subset_indices, 2)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            # Calculate the weight difference\n            weight_diff = weight_lst[swap_idx2] - weight_lst[swap_idx1]\n            if (new_solution[swap_idx1] == 1 and weight_diff <= 0) or (new_solution[swap_idx1] == 0 and weight_diff >= 0):\n                temp_weight = current_weight + weight_diff\n                if temp_weight <= capacity:\n                    new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n\n    return new_solution\n\n",
        "score": [
            -0.4713600046563373,
            1.5830045640468597
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate the crowding distance for each solution in the archive\n        objectives = np.array([obj for _, obj in archive])\n        crowding_distances = np.zeros(len(archive))\n\n        for i in range(2):  # For each objective\n            sorted_indices = np.argsort(objectives[:, i])\n            objectives_sorted = objectives[sorted_indices, i]\n\n            # Calculate crowding distance\n            crowding_distances[sorted_indices[0]] = np.inf\n            crowding_distances[sorted_indices[-1]] = np.inf\n\n            for j in range(1, len(archive) - 1):\n                if objectives_sorted[-1] - objectives_sorted[0] == 0:\n                    crowding_distances[sorted_indices[j]] += 0\n                else:\n                    crowding_distances[sorted_indices[j]] += (objectives_sorted[j+1] - objectives_sorted[j-1]) / (objectives_sorted[-1] - objectives_sorted[0])\n\n        # Select a solution with high crowding distance (promising for improvement)\n        max_distance = np.max(crowding_distances)\n        candidates = [i for i, dist in enumerate(crowding_distances) if dist == max_distance]\n        selected_idx = random.choice(candidates)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: Randomly select a subset of items and perform a swap or flip operation\n    n_items = len(weight_lst)\n    subset_size = max(1, int(np.sqrt(n_items)))  # Dynamic subset size based on problem size\n    subset_indices = random.sample(range(n_items), subset_size)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Try to flip items in the subset to improve both objectives\n    for idx in subset_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_weight = current_weight + weight_lst[idx]\n            if temp_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = temp_weight\n\n    # Additional improvement: Try to swap items between the subset and the rest\n    if len(subset_indices) > 1:\n        swap_idx1, swap_idx2 = random.sample(subset_indices, 2)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            # Calculate the weight difference\n            weight_diff = weight_lst[swap_idx2] - weight_lst[swap_idx1]\n            if (new_solution[swap_idx1] == 1 and weight_diff <= 0) or (new_solution[swap_idx1] == 0 and weight_diff >= 0):\n                temp_weight = current_weight + weight_diff\n                if temp_weight <= capacity:\n                    new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 33,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1->0 or 0->1)\n    # 2. Ensure feasibility by checking the total weight\n    # 3. If flipping causes infeasibility, perform a greedy repair\n\n    # Step 1: Randomly select items to flip\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Step 3: Greedy repair - remove items with the smallest ratio of (value1 + value2) / weight\n        excess_weight = total_weight - capacity\n        current_items = np.where(new_solution == 1)[0]\n        if len(current_items) > 0:\n            value_density = (value1_lst[current_items] + value2_lst[current_items]) / weight_lst[current_items]\n            sorted_indices = np.argsort(value_density)\n            for i in sorted_indices:\n                if excess_weight <= 0:\n                    break\n                item_idx = current_items[i]\n                new_solution[item_idx] = 0\n                excess_weight -= weight_lst[item_idx]\n\n    # Step 4: If still infeasible, reset to base solution\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.367345956517229,
            1.5993983447551727
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1->0 or 0->1)\n    # 2. Ensure feasibility by checking the total weight\n    # 3. If flipping causes infeasibility, perform a greedy repair\n\n    # Step 1: Randomly select items to flip\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Step 3: Greedy repair - remove items with the smallest ratio of (value1 + value2) / weight\n        excess_weight = total_weight - capacity\n        current_items = np.where(new_solution == 1)[0]\n        if len(current_items) > 0:\n            value_density = (value1_lst[current_items] + value2_lst[current_items]) / weight_lst[current_items]\n            sorted_indices = np.argsort(value_density)\n            for i in sorted_indices:\n                if excess_weight <= 0:\n                    break\n                item_idx = current_items[i]\n                new_solution[item_idx] = 0\n                excess_weight -= weight_lst[item_idx]\n\n    # Step 4: If still infeasible, reset to base solution\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 34,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine bit-flip and swap operations\n    # Step 1: Randomly select a subset of items to flip (bit-flip)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Perform a swap operation between two items (if feasible)\n    if len(new_solution) >= 2:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        i, j = swap_indices[0], swap_indices[1]\n\n        # Calculate potential weight change\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] else (weight_lst[i] - weight_lst[j])\n\n        # Check feasibility and perform swap if beneficial\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.42552066050108733,
            1.422456443309784
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine bit-flip and swap operations\n    # Step 1: Randomly select a subset of items to flip (bit-flip)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item if feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Perform a swap operation between two items (if feasible)\n    if len(new_solution) >= 2:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        i, j = swap_indices[0], swap_indices[1]\n\n        # Calculate potential weight change\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] else (weight_lst[i] - weight_lst[j])\n\n        # Check feasibility and perform swap if beneficial\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 35,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with probability proportional to its dominance rank\n    # (higher objective values are more likely to be selected)\n    weights = np.array([sum(obj) for _, obj in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    base_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a candidate solution by flipping a random subset of bits\n    new_solution = base_solution.copy()\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    excess_weight = np.sum(weight_lst[new_solution == 1]) - capacity\n    if excess_weight > 0:\n        # Remove items with the smallest ratio of (value1 + value2) / weight until feasible\n        while excess_weight > 0 and np.any(new_solution == 1):\n            selected_items = np.where(new_solution == 1)[0]\n            ratios = (value1_lst[selected_items] + value2_lst[selected_items]) / weight_lst[selected_items]\n            remove_idx = selected_items[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Apply a greedy improvement step: add items with highest (value1 + value2) / weight if possible\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_weight > 0:\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            ratios = (value1_lst[available_items] + value2_lst[available_items]) / weight_lst[available_items]\n            best_candidate = available_items[np.argmax(ratios)]\n            if weight_lst[best_candidate] <= remaining_weight:\n                new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.36687117140588005,
            7.474997043609619
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with probability proportional to its dominance rank\n    # (higher objective values are more likely to be selected)\n    weights = np.array([sum(obj) for _, obj in archive])\n    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(archive)) / len(archive)\n    base_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a candidate solution by flipping a random subset of bits\n    new_solution = base_solution.copy()\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    excess_weight = np.sum(weight_lst[new_solution == 1]) - capacity\n    if excess_weight > 0:\n        # Remove items with the smallest ratio of (value1 + value2) / weight until feasible\n        while excess_weight > 0 and np.any(new_solution == 1):\n            selected_items = np.where(new_solution == 1)[0]\n            ratios = (value1_lst[selected_items] + value2_lst[selected_items]) / weight_lst[selected_items]\n            remove_idx = selected_items[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Apply a greedy improvement step: add items with highest (value1 + value2) / weight if possible\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_weight > 0:\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            ratios = (value1_lst[available_items] + value2_lst[available_items]) / weight_lst[available_items]\n            best_candidate = available_items[np.argmax(ratios)]\n            if weight_lst[best_candidate] <= remaining_weight:\n                new_solution[best_candidate] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 36,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of normalized objectives (higher sum = more potential)\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(value1_lst) + np.sum(value2_lst)), reverse=True)\n        # Select top 30% of solutions for random selection\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 3)]\n        base_solution, _ = top_solutions[np.random.randint(0, len(top_solutions))]\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of bits (perturbation)\n    n_items = len(new_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Check feasibility and fix if necessary\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            remove_idx = np.random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # 3. Value-based swap: replace a low-value item with a high-value item not in the solution\n    # Calculate marginal value ratios for items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate value ratios for not-in-solution items\n        value_ratios = (value1_lst[not_in_solution] + value2_lst[not_in_solution]) / weight_lst[not_in_solution]\n\n        # Select top 20% of items by value ratio\n        top_items = not_in_solution[np.argsort(value_ratios)[-max(1, len(not_in_solution) // 5):]]\n\n        # Try to add one of these top items if it fits\n        for item in top_items:\n            if total_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n                break\n\n    # 4. Optional: Randomly remove a low-value item if capacity allows\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate value ratios for items in solution\n        value_ratios_in = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        # Select bottom 20% of items by value ratio\n        bottom_items = in_solution[np.argsort(value_ratios_in)[:max(1, len(in_solution) // 5)]]\n\n        # Try to remove one of these bottom items\n        for item in bottom_items:\n            if total_weight - weight_lst[item] >= 0:  # Just to be safe\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.33184864562842764,
            2.2701478004455566
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of normalized objectives (higher sum = more potential)\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / (np.sum(value1_lst) + np.sum(value2_lst)), reverse=True)\n        # Select top 30% of solutions for random selection\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 3)]\n        base_solution, _ = top_solutions[np.random.randint(0, len(top_solutions))]\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of bits (perturbation)\n    n_items = len(new_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Check feasibility and fix if necessary\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            remove_idx = np.random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # 3. Value-based swap: replace a low-value item with a high-value item not in the solution\n    # Calculate marginal value ratios for items not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate value ratios for not-in-solution items\n        value_ratios = (value1_lst[not_in_solution] + value2_lst[not_in_solution]) / weight_lst[not_in_solution]\n\n        # Select top 20% of items by value ratio\n        top_items = not_in_solution[np.argsort(value_ratios)[-max(1, len(not_in_solution) // 5):]]\n\n        # Try to add one of these top items if it fits\n        for item in top_items:\n            if total_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n                break\n\n    # 4. Optional: Randomly remove a low-value item if capacity allows\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate value ratios for items in solution\n        value_ratios_in = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        # Select bottom 20% of items by value ratio\n        bottom_items = in_solution[np.argsort(value_ratios_in)[:max(1, len(in_solution) // 5)]]\n\n        # Try to remove one of these bottom items\n        for item in bottom_items:\n            if total_weight - weight_lst[item] >= 0:  # Just to be safe\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 37,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Prefer solutions with room for improvement\n            candidates.append(sol)\n    if not candidates:\n        candidates = [sol for sol, _ in archive]  # Fallback to all if no candidates\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random swap between two items (exploration)\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high marginal value-to-weight ratio (exploitation)\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n    if remaining_capacity > 0:\n        # Calculate marginal value-to-weight ratios\n        ratios1 = value1_lst / (weight_lst + 1e-6)\n        ratios2 = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = ratios1 + ratios2  # Balance both objectives\n\n        # Identify items to potentially add (not in solution)\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            # Select top 20% by combined ratio\n            top_candidates = np.argsort(combined_ratio[candidates])[-max(1, len(candidates)//5):]\n            for idx in candidates[top_candidates]:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    # 3. Remove low-value items to free up capacity\n    if remaining_capacity < 0:\n        # Calculate marginal value\n        value1 = value1_lst * new_solution\n        value2 = value2_lst * new_solution\n        combined_value = value1 + value2\n\n        # Identify items to potentially remove (in solution)\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Select bottom 20% by combined value\n            bottom_candidates = np.argsort(combined_value[candidates])[:max(1, len(candidates)//5)]\n            for idx in candidates[bottom_candidates]:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n                if remaining_capacity >= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.3210320127005597,
            7.594650328159332
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Prefer solutions with room for improvement\n            candidates.append(sol)\n    if not candidates:\n        candidates = [sol for sol, _ in archive]  # Fallback to all if no candidates\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random swap between two items (exploration)\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high marginal value-to-weight ratio (exploitation)\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n    if remaining_capacity > 0:\n        # Calculate marginal value-to-weight ratios\n        ratios1 = value1_lst / (weight_lst + 1e-6)\n        ratios2 = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = ratios1 + ratios2  # Balance both objectives\n\n        # Identify items to potentially add (not in solution)\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            # Select top 20% by combined ratio\n            top_candidates = np.argsort(combined_ratio[candidates])[-max(1, len(candidates)//5):]\n            for idx in candidates[top_candidates]:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    # 3. Remove low-value items to free up capacity\n    if remaining_capacity < 0:\n        # Calculate marginal value\n        value1 = value1_lst * new_solution\n        value2 = value2_lst * new_solution\n        combined_value = value1 + value2\n\n        # Identify items to potentially remove (in solution)\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Select bottom 20% by combined value\n            bottom_candidates = np.argsort(combined_value[candidates])[:max(1, len(candidates)//5)]\n            for idx in candidates[bottom_candidates]:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n                if remaining_capacity >= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 38,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # (assuming archive is sorted by some metric of diversity)\n    if len(archive) > 1:\n        # Randomly select among the top 30% of solutions (promising candidates)\n        selected_idx = random.randint(0, min(2, len(archive) - 1))\n        base_solution, (base_value1, base_value2) = archive[selected_idx]\n    else:\n        base_solution, (base_value1, base_value2) = archive[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: Combine random flips with greedy improvement\n    # Step 1: Randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedily add items that improve both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate the ratio of improvement for each item (weighted sum of normalized values)\n        value1_normalized = value1_lst / (np.max(value1_lst) + 1e-6)\n        value2_normalized = value2_lst / (np.max(value2_lst) + 1e-6)\n        combined_value = value1_normalized + value2_normalized\n        # Sort items by the combined value in descending order\n        sorted_indices = np.argsort(-combined_value)\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Randomly remove items to create diversity\n    if np.random.rand() < 0.3:  # 30% chance to remove some items\n        remove_indices = np.where(new_solution == 1)[0]\n        if len(remove_indices) > 0:\n            num_to_remove = min(2, len(remove_indices))\n            remove_idx = np.random.choice(remove_indices, size=num_to_remove, replace=False)\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.34065908609983997,
            3.3258531391620636
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # (assuming archive is sorted by some metric of diversity)\n    if len(archive) > 1:\n        # Randomly select among the top 30% of solutions (promising candidates)\n        selected_idx = random.randint(0, min(2, len(archive) - 1))\n        base_solution, (base_value1, base_value2) = archive[selected_idx]\n    else:\n        base_solution, (base_value1, base_value2) = archive[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: Combine random flips with greedy improvement\n    # Step 1: Randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedily add items that improve both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate the ratio of improvement for each item (weighted sum of normalized values)\n        value1_normalized = value1_lst / (np.max(value1_lst) + 1e-6)\n        value2_normalized = value2_lst / (np.max(value2_lst) + 1e-6)\n        combined_value = value1_normalized + value2_normalized\n        # Sort items by the combined value in descending order\n        sorted_indices = np.argsort(-combined_value)\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Randomly remove items to create diversity\n    if np.random.rand() < 0.3:  # 30% chance to remove some items\n        remove_indices = np.where(new_solution == 1)[0]\n        if len(remove_indices) > 0:\n            num_to_remove = min(2, len(remove_indices))\n            remove_idx = np.random.choice(remove_indices, size=num_to_remove, replace=False)\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 39,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the boundary\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    available_capacity = capacity - current_weight\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly swap a few items to introduce diversity\n    num_swaps = min(3, len(new_solution))\n    swap_indices = np.random.choice(len(new_solution), size=num_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedily add the most promising items (highest value-to-weight ratio) that fit\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        value1_ratio = value1_lst / weight_lst\n        value2_ratio = value2_lst / weight_lst\n\n        # Combine ratios with a weighted sum (50-50 for simplicity)\n        combined_ratio = 0.5 * value1_ratio + 0.5 * value2_ratio\n\n        # Sort items by combined ratio in descending order\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # 3. Probabilistically remove items to explore the space\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1 and random.random() < 0.1:  # 10% chance to remove\n            new_solution[idx] = 0\n\n    # Ensure feasibility (though greedy addition should already handle this)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove items until feasible\n        while total_weight > capacity:\n            # Find items to remove (randomly select from included items)\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # no items to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3413540190655223,
            1.6547712087631226
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the boundary\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    available_capacity = capacity - current_weight\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly swap a few items to introduce diversity\n    num_swaps = min(3, len(new_solution))\n    swap_indices = np.random.choice(len(new_solution), size=num_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Greedily add the most promising items (highest value-to-weight ratio) that fit\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        value1_ratio = value1_lst / weight_lst\n        value2_ratio = value2_lst / weight_lst\n\n        # Combine ratios with a weighted sum (50-50 for simplicity)\n        combined_ratio = 0.5 * value1_ratio + 0.5 * value2_ratio\n\n        # Sort items by combined ratio in descending order\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                if remaining_capacity <= 0:\n                    break\n\n    # 3. Probabilistically remove items to explore the space\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1 and random.random() < 0.1:  # 10% chance to remove\n            new_solution[idx] = 0\n\n    # Ensure feasibility (though greedy addition should already handle this)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, remove items until feasible\n        while total_weight > capacity:\n            # Find items to remove (randomly select from included items)\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # no items to remove\n            remove_idx = random.choice(included_items)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 40,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Rank solutions by their potential to improve both objectives\n    potential_scores = []\n    for i, sol in enumerate(archive_solutions):\n        # Calculate the ratio of unused capacity\n        unused_capacity = capacity - archive_weights[i]\n        # Calculate the potential to improve both objectives\n        potential1 = (np.sum(value1_lst) - archive_values1[i]) / (unused_capacity + 1e-6)\n        potential2 = (np.sum(value2_lst) - archive_values2[i]) / (unused_capacity + 1e-6)\n        potential_scores.append(potential1 + potential2)\n\n    # Select top 20% of solutions with highest potential\n    num_candidates = max(1, len(archive) // 5)\n    top_indices = np.argsort(potential_scores)[-num_candidates:]\n    selected_solution = archive_solutions[random.choice(top_indices)].copy()\n\n    # Hybrid local search: flip random bits with a probability that decreases with solution quality\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate the \"quality\" of the solution (normalized)\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    quality = (current_value1 / max_value1 + current_value2 / max_value2) / 2\n\n    # Higher quality solutions have lower probability of flipping\n    flip_prob = 0.3 * (1 - quality)\n\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            # Try flipping the bit\n            if new_solution[i] == 1:\n                # If item is included, try removing it\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If item is excluded, try adding it\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Additional greedy improvement: add items that improve both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate the \"value density\" for both objectives\n        value_density1 = value1_lst / weight_lst\n        value_density2 = value2_lst / weight_lst\n\n        # Sort items by the sum of their normalized value densities\n        combined_density = (value_density1 + value_density2) / 2\n        sorted_indices = np.argsort(combined_density)[::-1]\n\n        for i in sorted_indices:\n            if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.34830930489444833,
            3.809640049934387
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Rank solutions by their potential to improve both objectives\n    potential_scores = []\n    for i, sol in enumerate(archive_solutions):\n        # Calculate the ratio of unused capacity\n        unused_capacity = capacity - archive_weights[i]\n        # Calculate the potential to improve both objectives\n        potential1 = (np.sum(value1_lst) - archive_values1[i]) / (unused_capacity + 1e-6)\n        potential2 = (np.sum(value2_lst) - archive_values2[i]) / (unused_capacity + 1e-6)\n        potential_scores.append(potential1 + potential2)\n\n    # Select top 20% of solutions with highest potential\n    num_candidates = max(1, len(archive) // 5)\n    top_indices = np.argsort(potential_scores)[-num_candidates:]\n    selected_solution = archive_solutions[random.choice(top_indices)].copy()\n\n    # Hybrid local search: flip random bits with a probability that decreases with solution quality\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate the \"quality\" of the solution (normalized)\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    quality = (current_value1 / max_value1 + current_value2 / max_value2) / 2\n\n    # Higher quality solutions have lower probability of flipping\n    flip_prob = 0.3 * (1 - quality)\n\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            # Try flipping the bit\n            if new_solution[i] == 1:\n                # If item is included, try removing it\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If item is excluded, try adding it\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Additional greedy improvement: add items that improve both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate the \"value density\" for both objectives\n        value_density1 = value1_lst / weight_lst\n        value_density2 = value2_lst / weight_lst\n\n        # Sort items by the sum of their normalized value densities\n        combined_density = (value_density1 + value_density2) / 2\n        sorted_indices = np.argsort(combined_density)[::-1]\n\n        for i in sorted_indices:\n            if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 41,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    if np.sum(total_values) == 0:\n        probs = np.ones(len(archive)) / len(archive)  # Uniform if all values are zero\n    else:\n        probs = total_values / np.sum(total_values)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal contribution\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    candidates = np.where(new_solution == 1)[0] if np.random.rand() < 0.7 else np.where(new_solution == 0)[0]\n\n    if len(candidates) > 0:\n        # Compute marginal contributions for both objectives\n        marginal1 = value1_lst[candidates] / weight_lst[candidates]\n        marginal2 = value2_lst[candidates] / weight_lst[candidates]\n        combined_marginal = marginal1 + marginal2\n\n        # Select top 20% candidates by marginal contribution\n        top_k = max(1, len(candidates) // 5)\n        top_indices = np.argsort(combined_marginal)[-top_k:]\n        selected_candidate = candidates[top_indices[np.random.randint(top_k)]]\n\n        # Flip the selected item\n        if new_solution[selected_candidate] == 1:\n            if current_weight - weight_lst[selected_candidate] <= capacity:\n                new_solution[selected_candidate] = 0\n        else:\n            if current_weight + weight_lst[selected_candidate] <= capacity:\n                new_solution[selected_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5149945929992319,
            6.269910752773285
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    if np.sum(total_values) == 0:\n        probs = np.ones(len(archive)) / len(archive)  # Uniform if all values are zero\n    else:\n        probs = total_values / np.sum(total_values)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal contribution\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    candidates = np.where(new_solution == 1)[0] if np.random.rand() < 0.7 else np.where(new_solution == 0)[0]\n\n    if len(candidates) > 0:\n        # Compute marginal contributions for both objectives\n        marginal1 = value1_lst[candidates] / weight_lst[candidates]\n        marginal2 = value2_lst[candidates] / weight_lst[candidates]\n        combined_marginal = marginal1 + marginal2\n\n        # Select top 20% candidates by marginal contribution\n        top_k = max(1, len(candidates) // 5)\n        top_indices = np.argsort(combined_marginal)[-top_k:]\n        selected_candidate = candidates[top_indices[np.random.randint(top_k)]]\n\n        # Flip the selected item\n        if new_solution[selected_candidate] == 1:\n            if current_weight - weight_lst[selected_candidate] <= capacity:\n                new_solution[selected_candidate] = 0\n        else:\n            if current_weight + weight_lst[selected_candidate] <= capacity:\n                new_solution[selected_candidate] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 42,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of normalized value-to-weight ratios for both objectives\n        normalized_value1 = value1_lst / np.maximum(weight_lst, 1e-6)\n        normalized_value2 = value2_lst / np.maximum(weight_lst, 1e-6)\n        scores = []\n        for sol, _ in archive:\n            selected_items = np.where(sol == 1)[0]\n            score = np.sum(normalized_value1[selected_items]) + np.sum(normalized_value2[selected_items])\n            scores.append(score)\n        # Select solutions with top 30% scores\n        top_indices = np.argsort(scores)[-max(1, len(scores) // 3):]\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: flip items based on a combination of randomness and value-to-weight ratio\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    candidate_indices = np.where(new_solution == 1)[0]  # Initially consider included items\n\n    # Expand candidates to include some excluded items with high value-to-weight ratio\n    excluded_indices = np.where(new_solution == 0)[0]\n    if len(excluded_indices) > 0:\n        excluded_value_ratio = (value1_lst[excluded_indices] + value2_lst[excluded_indices]) / np.maximum(weight_lst[excluded_indices], 1e-6)\n        top_excluded = excluded_indices[np.argsort(excluded_value_ratio)[-min(3, len(excluded_indices)):]]\n        candidate_indices = np.concatenate([candidate_indices, top_excluded])\n\n    # Perform flips with a probability that depends on value-to-weight ratio\n    for idx in candidate_indices:\n        if random.random() < 0.3:  # Base probability\n            # Increase probability for items with high value-to-weight ratio\n            value_ratio = (value1_lst[idx] + value2_lst[idx]) / np.maximum(weight_lst[idx], 1e-6)\n            flip_prob = min(0.9, 0.3 + 0.6 * (value_ratio / np.max(value_ratio + 1e-6)))\n            if random.random() < flip_prob:\n                if new_solution[idx] == 1:\n                    # Check if removing would keep solution feasible\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n                else:\n                    # Check if adding would keep solution feasible\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n\n    # Ensure solution is feasible (in case of any errors)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break\n            remove_idx = random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9033473428331151,
            5.258937627077103
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of normalized value-to-weight ratios for both objectives\n        normalized_value1 = value1_lst / np.maximum(weight_lst, 1e-6)\n        normalized_value2 = value2_lst / np.maximum(weight_lst, 1e-6)\n        scores = []\n        for sol, _ in archive:\n            selected_items = np.where(sol == 1)[0]\n            score = np.sum(normalized_value1[selected_items]) + np.sum(normalized_value2[selected_items])\n            scores.append(score)\n        # Select solutions with top 30% scores\n        top_indices = np.argsort(scores)[-max(1, len(scores) // 3):]\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: flip items based on a combination of randomness and value-to-weight ratio\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    candidate_indices = np.where(new_solution == 1)[0]  # Initially consider included items\n\n    # Expand candidates to include some excluded items with high value-to-weight ratio\n    excluded_indices = np.where(new_solution == 0)[0]\n    if len(excluded_indices) > 0:\n        excluded_value_ratio = (value1_lst[excluded_indices] + value2_lst[excluded_indices]) / np.maximum(weight_lst[excluded_indices], 1e-6)\n        top_excluded = excluded_indices[np.argsort(excluded_value_ratio)[-min(3, len(excluded_indices)):]]\n        candidate_indices = np.concatenate([candidate_indices, top_excluded])\n\n    # Perform flips with a probability that depends on value-to-weight ratio\n    for idx in candidate_indices:\n        if random.random() < 0.3:  # Base probability\n            # Increase probability for items with high value-to-weight ratio\n            value_ratio = (value1_lst[idx] + value2_lst[idx]) / np.maximum(weight_lst[idx], 1e-6)\n            flip_prob = min(0.9, 0.3 + 0.6 * (value_ratio / np.max(value_ratio + 1e-6)))\n            if random.random() < flip_prob:\n                if new_solution[idx] == 1:\n                    # Check if removing would keep solution feasible\n                    if current_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n                        current_weight -= weight_lst[idx]\n                else:\n                    # Check if adding would keep solution feasible\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n\n    # Ensure solution is feasible (in case of any errors)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break\n            remove_idx = random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 43,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too similar to others\n    base_solution, _ = random.choice(archive)\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Randomly flip a subset of items to introduce diversity\n    num_flips = min(5, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure the solution remains feasible by removing items that exceed capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Sort items in the solution by their marginal contribution to the objectives\n        selected_items = np.where(new_solution == 1)[0]\n        # Calculate marginal contribution (value per unit weight)\n        marginal_contribution = (value1_lst[selected_items] + value2_lst[selected_items]) / weight_lst[selected_items]\n        # Sort by marginal contribution and remove items with the least contribution\n        sorted_indices = selected_items[np.argsort(marginal_contribution)]\n        while total_weight > capacity and len(sorted_indices) > 0:\n            # Remove the item with the least marginal contribution\n            item_to_remove = sorted_indices[0]\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n            sorted_indices = sorted_indices[1:]\n\n    # Apply a greedy improvement step to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize to avoid bias\n\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_total_weight = total_weight + weight_lst[item]\n            new_value1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[item]\n            new_value2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[item]\n\n            # Compare with the current objectives to decide if the item should be added\n            # This is a simplified heuristic; more sophisticated criteria can be used\n            if (new_value1 > np.sum(value1_lst[new_solution == 1]) and\n                new_value2 > np.sum(value2_lst[new_solution == 1])):\n                new_solution[item] = 1\n                total_weight = new_total_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3589290984489813,
            2.3018683791160583
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too similar to others\n    base_solution, _ = random.choice(archive)\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Randomly flip a subset of items to introduce diversity\n    num_flips = min(5, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure the solution remains feasible by removing items that exceed capacity\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Sort items in the solution by their marginal contribution to the objectives\n        selected_items = np.where(new_solution == 1)[0]\n        # Calculate marginal contribution (value per unit weight)\n        marginal_contribution = (value1_lst[selected_items] + value2_lst[selected_items]) / weight_lst[selected_items]\n        # Sort by marginal contribution and remove items with the least contribution\n        sorted_indices = selected_items[np.argsort(marginal_contribution)]\n        while total_weight > capacity and len(sorted_indices) > 0:\n            # Remove the item with the least marginal contribution\n            item_to_remove = sorted_indices[0]\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n            sorted_indices = sorted_indices[1:]\n\n    # Apply a greedy improvement step to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize to avoid bias\n\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_total_weight = total_weight + weight_lst[item]\n            new_value1 = np.sum(value1_lst[new_solution == 1]) + value1_lst[item]\n            new_value2 = np.sum(value2_lst[new_solution == 1]) + value2_lst[item]\n\n            # Compare with the current objectives to decide if the item should be added\n            # This is a simplified heuristic; more sophisticated criteria can be used\n            if (new_value1 > np.sum(value1_lst[new_solution == 1]) and\n                new_value2 > np.sum(value2_lst[new_solution == 1])):\n                new_solution[item] = 1\n                total_weight = new_total_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 44,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly biased towards higher objectives)\n    weights = np.array([obj[0] + obj[1] for _, obj in archive])\n    weights = np.maximum(weights, 0)  # Ensure non-negative weights\n    if np.sum(weights) == 0:\n        weights = np.ones(len(archive))  # Uniform selection if all weights are zero\n    selected_idx = np.random.choice(len(archive), p=weights/np.sum(weights))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate candidate neighbors using hybrid strategy\n    candidates = []\n    n_items = len(base_solution)\n\n    # Strategy 1: Randomly flip a small number of bits (1-3)\n    for _ in range(5):\n        neighbor = base_solution.copy()\n        flip_indices = np.random.choice(n_items, size=random.randint(1, 3), replace=False)\n        neighbor[flip_indices] = 1 - neighbor[flip_indices]\n\n        # Ensure feasibility\n        new_weight = np.sum(weight_lst * neighbor)\n        if new_weight <= capacity:\n            candidates.append(neighbor)\n\n    # Strategy 2: Greedy addition of items with high marginal benefit\n    if len(candidates) < 5:\n        # Calculate marginal benefits for items not in the solution\n        marginal_benefits = (value1_lst + value2_lst) * (1 - base_solution)\n        sorted_indices = np.argsort(-marginal_benefits)\n\n        for idx in sorted_indices[:5]:\n            if base_solution[idx] == 0:\n                neighbor = base_solution.copy()\n                neighbor[idx] = 1\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    candidates.append(neighbor)\n                    if len(candidates) >= 5:\n                        break\n\n    # Strategy 3: Greedy removal of items with low marginal benefit\n    if len(candidates) < 5:\n        # Calculate marginal benefits for items in the solution\n        marginal_benefits = (value1_lst + value2_lst) * base_solution\n        sorted_indices = np.argsort(marginal_benefits)\n\n        for idx in sorted_indices[:5]:\n            if base_solution[idx] == 1:\n                neighbor = base_solution.copy()\n                neighbor[idx] = 0\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    candidates.append(neighbor)\n                    if len(candidates) >= 5:\n                        break\n\n    # If no candidates found, return the base solution\n    if not candidates:\n        return base_solution\n\n    # Select the best candidate based on both objectives\n    best_neighbor = None\n    best_score = -np.inf\n\n    for candidate in candidates:\n        total_value1 = np.sum(value1_lst * candidate)\n        total_value2 = np.sum(value2_lst * candidate)\n        # Use a weighted sum of both objectives as the score\n        score = 0.5 * total_value1 + 0.5 * total_value2\n\n        if score > best_score:\n            best_score = score\n            best_neighbor = candidate\n\n    return best_neighbor if best_neighbor is not None else base_solution\n\n",
        "score": [
            -0.3419580883070929,
            3.875054270029068
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly biased towards higher objectives)\n    weights = np.array([obj[0] + obj[1] for _, obj in archive])\n    weights = np.maximum(weights, 0)  # Ensure non-negative weights\n    if np.sum(weights) == 0:\n        weights = np.ones(len(archive))  # Uniform selection if all weights are zero\n    selected_idx = np.random.choice(len(archive), p=weights/np.sum(weights))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate candidate neighbors using hybrid strategy\n    candidates = []\n    n_items = len(base_solution)\n\n    # Strategy 1: Randomly flip a small number of bits (1-3)\n    for _ in range(5):\n        neighbor = base_solution.copy()\n        flip_indices = np.random.choice(n_items, size=random.randint(1, 3), replace=False)\n        neighbor[flip_indices] = 1 - neighbor[flip_indices]\n\n        # Ensure feasibility\n        new_weight = np.sum(weight_lst * neighbor)\n        if new_weight <= capacity:\n            candidates.append(neighbor)\n\n    # Strategy 2: Greedy addition of items with high marginal benefit\n    if len(candidates) < 5:\n        # Calculate marginal benefits for items not in the solution\n        marginal_benefits = (value1_lst + value2_lst) * (1 - base_solution)\n        sorted_indices = np.argsort(-marginal_benefits)\n\n        for idx in sorted_indices[:5]:\n            if base_solution[idx] == 0:\n                neighbor = base_solution.copy()\n                neighbor[idx] = 1\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    candidates.append(neighbor)\n                    if len(candidates) >= 5:\n                        break\n\n    # Strategy 3: Greedy removal of items with low marginal benefit\n    if len(candidates) < 5:\n        # Calculate marginal benefits for items in the solution\n        marginal_benefits = (value1_lst + value2_lst) * base_solution\n        sorted_indices = np.argsort(marginal_benefits)\n\n        for idx in sorted_indices[:5]:\n            if base_solution[idx] == 1:\n                neighbor = base_solution.copy()\n                neighbor[idx] = 0\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    candidates.append(neighbor)\n                    if len(candidates) >= 5:\n                        break\n\n    # If no candidates found, return the base solution\n    if not candidates:\n        return base_solution\n\n    # Select the best candidate based on both objectives\n    best_neighbor = None\n    best_score = -np.inf\n\n    for candidate in candidates:\n        total_value1 = np.sum(value1_lst * candidate)\n        total_value2 = np.sum(value2_lst * candidate)\n        # Use a weighted sum of both objectives as the score\n        score = 0.5 * total_value1 + 0.5 * total_value2\n\n        if score > best_score:\n            best_score = score\n            best_neighbor = candidate\n\n    return best_neighbor if best_neighbor is not None else base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 45,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Prioritize solutions with high values but not fully packed\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = [val for _, val in archive]\n\n    # Calculate the \"potential\" for each solution (e.g., how much more it can gain)\n    potentials = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        # Potential is based on the maximum possible improvement in both objectives\n        potential_val1 = np.sum(value1_lst * (1 - sol) * (weight_lst <= remaining_capacity))\n        potential_val2 = np.sum(value2_lst * (1 - sol) * (weight_lst <= remaining_capacity))\n        potentials.append(potential_val1 + potential_val2)\n\n    # Select the solution with the highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search: combine random perturbation with greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a few bits)\n    n_items = len(weight_lst)\n    n_flips = min(3, n_items)  # Flip up to 3 items\n    flip_indices = random.sample(range(n_items), n_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove excess items greedily (based on combined value-to-weight ratio)\n        excess_weight = current_weight - capacity\n        while excess_weight > 0:\n            # Find items to remove (prefer low value-to-weight ratio)\n            combined_value = value1_lst + value2_lst\n            value_to_weight = combined_value / (weight_lst + 1e-10)  # Avoid division by zero\n            # Remove items with the lowest value-to-weight ratio\n            remove_idx = np.argmin(value_to_weight * new_solution)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n            else:\n                break  # No more items to remove\n\n    # Step 2: Greedy improvement (add items that improve both objectives)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate potential improvement for each item\n    potential_improvement = (value1_lst + value2_lst) * (weight_lst <= remaining_capacity) * (1 - new_solution)\n\n    # Add items with the highest potential improvement\n    while np.any(potential_improvement > 0):\n        best_idx = np.argmax(potential_improvement)\n        if potential_improvement[best_idx] <= 0:\n            break\n        new_weight = current_weight + weight_lst[best_idx]\n        if new_weight <= capacity:\n            new_solution[best_idx] = 1\n            current_weight = new_weight\n            remaining_capacity = capacity - current_weight\n            potential_improvement = (value1_lst + value2_lst) * (weight_lst <= remaining_capacity) * (1 - new_solution)\n        else:\n            potential_improvement[best_idx] = 0  # Mark as unavailable\n\n    return new_solution\n\n",
        "score": [
            -0.2517102804149506,
            5.534265398979187
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Prioritize solutions with high values but not fully packed\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = [val for _, val in archive]\n\n    # Calculate the \"potential\" for each solution (e.g., how much more it can gain)\n    potentials = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        # Potential is based on the maximum possible improvement in both objectives\n        potential_val1 = np.sum(value1_lst * (1 - sol) * (weight_lst <= remaining_capacity))\n        potential_val2 = np.sum(value2_lst * (1 - sol) * (weight_lst <= remaining_capacity))\n        potentials.append(potential_val1 + potential_val2)\n\n    # Select the solution with the highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search: combine random perturbation with greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a few bits)\n    n_items = len(weight_lst)\n    n_flips = min(3, n_items)  # Flip up to 3 items\n    flip_indices = random.sample(range(n_items), n_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove excess items greedily (based on combined value-to-weight ratio)\n        excess_weight = current_weight - capacity\n        while excess_weight > 0:\n            # Find items to remove (prefer low value-to-weight ratio)\n            combined_value = value1_lst + value2_lst\n            value_to_weight = combined_value / (weight_lst + 1e-10)  # Avoid division by zero\n            # Remove items with the lowest value-to-weight ratio\n            remove_idx = np.argmin(value_to_weight * new_solution)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n            else:\n                break  # No more items to remove\n\n    # Step 2: Greedy improvement (add items that improve both objectives)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate potential improvement for each item\n    potential_improvement = (value1_lst + value2_lst) * (weight_lst <= remaining_capacity) * (1 - new_solution)\n\n    # Add items with the highest potential improvement\n    while np.any(potential_improvement > 0):\n        best_idx = np.argmax(potential_improvement)\n        if potential_improvement[best_idx] <= 0:\n            break\n        new_weight = current_weight + weight_lst[best_idx]\n        if new_weight <= capacity:\n            new_solution[best_idx] = 1\n            current_weight = new_weight\n            remaining_capacity = capacity - current_weight\n            potential_improvement = (value1_lst + value2_lst) * (weight_lst <= remaining_capacity) * (1 - new_solution)\n        else:\n            potential_improvement[best_idx] = 0  # Mark as unavailable\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 46,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards higher total value (sum of both objectives)\n    objectives = np.array([sum(obj) for _, obj in archive])\n    probabilities = objectives / np.sum(objectives)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Random flip (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        while current_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve at least one objective without violating capacity\n    for _ in range(5):  # Limit iterations to prevent excessive computation\n        zero_indices = np.where(new_solution == 0)[0]\n        if len(zero_indices) == 0:\n            break\n\n        for idx in zero_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                # Calculate potential improvement in both objectives\n                value1_improvement = value1_lst[idx]\n                value2_improvement = value2_lst[idx]\n\n                # Add item if it improves at least one objective\n                if value1_improvement > 0 or value2_improvement > 0:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    break  # Break after first improvement to keep changes small\n\n    return new_solution\n\n",
        "score": [
            -0.3831787448572985,
            3.8130583465099335
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards higher total value (sum of both objectives)\n    objectives = np.array([sum(obj) for _, obj in archive])\n    probabilities = objectives / np.sum(objectives)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Random flip (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        while current_weight > capacity:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve at least one objective without violating capacity\n    for _ in range(5):  # Limit iterations to prevent excessive computation\n        zero_indices = np.where(new_solution == 0)[0]\n        if len(zero_indices) == 0:\n            break\n\n        for idx in zero_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                # Calculate potential improvement in both objectives\n                value1_improvement = value1_lst[idx]\n                value2_improvement = value2_lst[idx]\n\n                # Add item if it improves at least one objective\n                if value1_improvement > 0 or value2_improvement > 0:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    break  # Break after first improvement to keep changes small\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 47,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with a bias towards higher value solutions\n    values = np.array([obj[0] + obj[1] for _, obj in archive])\n    if len(values) > 1:\n        probs = values / np.sum(values)\n        selected_idx = np.random.choice(len(archive), p=probs)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (0 <-> 1)\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) > 0:\n        num_flips = min(2, len(flip_indices))  # Limit to 2 flips to avoid large changes\n        flip_items = np.random.choice(flip_indices, size=num_flips, replace=False)\n        new_solution[flip_items] = 0\n\n    # 2. Add items with high value-to-weight ratio if there's remaining capacity\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for all items\n        value_ratios = (value1_lst + value2_lst) / weight_lst\n        # Sort items by value-to-weight ratio in descending order\n        sorted_indices = np.argsort(-value_ratios)\n        # Try to add the top items that fit within remaining capacity\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, remove the heaviest item(s) until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            included_indices = np.where(new_solution == 1)[0]\n            if len(included_indices) == 0:\n                break\n            # Remove the item with the lowest value-to-weight ratio\n            item_to_remove = np.argmin((value1_lst + value2_lst) / weight_lst[included_indices])\n            new_solution[included_indices[item_to_remove]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.6126294250276572,
            2.3120997548103333
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with a bias towards higher value solutions\n    values = np.array([obj[0] + obj[1] for _, obj in archive])\n    if len(values) > 1:\n        probs = values / np.sum(values)\n        selected_idx = np.random.choice(len(archive), p=probs)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (0 <-> 1)\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) > 0:\n        num_flips = min(2, len(flip_indices))  # Limit to 2 flips to avoid large changes\n        flip_items = np.random.choice(flip_indices, size=num_flips, replace=False)\n        new_solution[flip_items] = 0\n\n    # 2. Add items with high value-to-weight ratio if there's remaining capacity\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for all items\n        value_ratios = (value1_lst + value2_lst) / weight_lst\n        # Sort items by value-to-weight ratio in descending order\n        sorted_indices = np.argsort(-value_ratios)\n        # Try to add the top items that fit within remaining capacity\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, remove the heaviest item(s) until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            included_indices = np.where(new_solution == 1)[0]\n            if len(included_indices) == 0:\n                break\n            # Remove the item with the lowest value-to-weight ratio\n            item_to_remove = np.argmin((value1_lst + value2_lst) / weight_lst[included_indices])\n            new_solution[included_indices[item_to_remove]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 48,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a promising solution with high potential for improvement\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        possible_gain = np.sum((value1_lst + value2_lst) * (1 - sol))\n        candidates.append((sol, v1, v2, possible_gain))\n\n    # Sort candidates by potential gain and select top 30% or at least 1\n    candidates.sort(key=lambda x: -x[3])\n    selected = random.choice(candidates[:max(1, len(candidates) // 3)])\n    base_solution = selected[0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly flip items to explore neighborhood\n    for _ in range(3):\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Objective-specific flips: try to improve both objectives\n    for _ in range(2):\n        # For objective 1: flip items with high value1/weight ratio\n        value1_ratios = value1_lst / (weight_lst + 1e-6)\n        best_idx = np.argmax(value1_ratios * (1 - new_solution))\n        if new_solution[best_idx] == 0 and current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n\n        # For objective 2: flip items with high value2/weight ratio\n        value2_ratios = value2_lst / (weight_lst + 1e-6)\n        best_idx = np.argmax(value2_ratios * (1 - new_solution))\n        if new_solution[best_idx] == 0 and current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.761210393681291,
            8.069639056921005
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst)\n\n    # Select a promising solution with high potential for improvement\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        possible_gain = np.sum((value1_lst + value2_lst) * (1 - sol))\n        candidates.append((sol, v1, v2, possible_gain))\n\n    # Sort candidates by potential gain and select top 30% or at least 1\n    candidates.sort(key=lambda x: -x[3])\n    selected = random.choice(candidates[:max(1, len(candidates) // 3)])\n    base_solution = selected[0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly flip items to explore neighborhood\n    for _ in range(3):\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Objective-specific flips: try to improve both objectives\n    for _ in range(2):\n        # For objective 1: flip items with high value1/weight ratio\n        value1_ratios = value1_lst / (weight_lst + 1e-6)\n        best_idx = np.argmax(value1_ratios * (1 - new_solution))\n        if new_solution[best_idx] == 0 and current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n\n        # For objective 2: flip items with high value2/weight ratio\n        value2_ratios = value2_lst / (weight_lst + 1e-6)\n        best_idx = np.argmax(value2_ratios * (1 - new_solution))\n        if new_solution[best_idx] == 0 and current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n            current_weight += weight_lst[best_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 49,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a base solution with high potential for improvement\n    # Here, we select the solution with the highest sum of normalized values\n    normalized_values = np.array([(v1 + v2) / (np.sum(weight_lst) + 1e-6) for _, (v1, v2) in archive])\n    selected_idx = np.argmax(normalized_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: combination of swap and flip operations\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for flipping\n    num_items = len(weight_lst)\n    subset_size = min(5, num_items)  # Consider up to 5 items for flipping\n    candidate_indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n    for idx in candidate_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Additional swap operation to explore neighborhood\n    if num_items >= 2:\n        swap_indices = np.random.choice(num_items, size=2, replace=False)\n        i, j = swap_indices\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility after swap\n            if (new_solution[i] == 1 and total_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n               (new_solution[j] == 1 and total_weight - weight_lst[j] + weight_lst[i] <= capacity):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.30159968141026317,
            2.378047823905945
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a base solution with high potential for improvement\n    # Here, we select the solution with the highest sum of normalized values\n    normalized_values = np.array([(v1 + v2) / (np.sum(weight_lst) + 1e-6) for _, (v1, v2) in archive])\n    selected_idx = np.argmax(normalized_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: combination of swap and flip operations\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for flipping\n    num_items = len(weight_lst)\n    subset_size = min(5, num_items)  # Consider up to 5 items for flipping\n    candidate_indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n    for idx in candidate_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Additional swap operation to explore neighborhood\n    if num_items >= 2:\n        swap_indices = np.random.choice(num_items, size=2, replace=False)\n        i, j = swap_indices\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility after swap\n            if (new_solution[i] == 1 and total_weight - weight_lst[i] + weight_lst[j] <= capacity) or \\\n               (new_solution[j] == 1 and total_weight - weight_lst[j] + weight_lst[i] <= capacity):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 50,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine flip and swap operations\n    # Flip operation: randomly flip a bit (add or remove an item)\n    if random.random() < 0.7:  # Higher probability for flip operation\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            # Check if removing the item keeps the solution feasible\n            if (np.sum(weight_lst * new_solution) - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if (np.sum(weight_lst * new_solution) + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Swap operation: randomly swap two items (if feasible)\n    if random.random() < 0.3:  # Lower probability for swap operation\n        swap_idx1, swap_idx2 = random.sample(range(len(new_solution)), 2)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            # Check feasibility for swap\n            current_weight = np.sum(weight_lst * new_solution)\n            weight_diff = weight_lst[swap_idx2] - weight_lst[swap_idx1]\n            if (current_weight + weight_diff) <= capacity:\n                new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n\n    return new_solution\n\n",
        "score": [
            -0.2864735341870044,
            3.0774667859077454
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine flip and swap operations\n    # Flip operation: randomly flip a bit (add or remove an item)\n    if random.random() < 0.7:  # Higher probability for flip operation\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            # Check if removing the item keeps the solution feasible\n            if (np.sum(weight_lst * new_solution) - weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if (np.sum(weight_lst * new_solution) + weight_lst[flip_idx]) <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Swap operation: randomly swap two items (if feasible)\n    if random.random() < 0.3:  # Lower probability for swap operation\n        swap_idx1, swap_idx2 = random.sample(range(len(new_solution)), 2)\n        if new_solution[swap_idx1] != new_solution[swap_idx2]:\n            # Check feasibility for swap\n            current_weight = np.sum(weight_lst * new_solution)\n            weight_diff = weight_lst[swap_idx2] - weight_lst[swap_idx1]\n            if (current_weight + weight_diff) <= capacity:\n                new_solution[swap_idx1], new_solution[swap_idx2] = new_solution[swap_idx2], new_solution[swap_idx1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 51,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate value ratios for each solution\n    value_ratios = []\n    for sol, obj in archive:\n        v1, v2 = obj\n        ratio = v1 / (v2 + 1e-10)  # Avoid division by zero\n        value_ratios.append(ratio)\n\n    # Normalize ratios and use as selection probabilities\n    max_ratio = max(value_ratios) if value_ratios else 1.0\n    selection_probs = [ratio / max_ratio for ratio in value_ratios]\n\n    # Select a base solution with probability proportional to its value ratio\n    selected_idx = random.choices(range(len(archive)), weights=selection_probs, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Adaptive item swapping: swap items based on their marginal contribution\n    # 2. Value-based neighborhood exploration: explore items with high value/weight ratios\n\n    # Calculate marginal contribution for each item\n    marginal_v1 = value1_lst / (weight_lst + 1e-10)\n    marginal_v2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal contributions (simple average for this example)\n    marginal = (marginal_v1 + marginal_v2) / 2\n\n    # Get indices of items in and out of the solution\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Strategy 1: Swap items with high marginal contribution\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Select top 20% of in_items with lowest marginal contribution\n        in_marginal = marginal[in_items]\n        low_marginal_in = in_items[np.argsort(in_marginal)[:max(1, len(in_items) // 5)]]\n\n        # Select top 20% of out_items with highest marginal contribution\n        out_marginal = marginal[out_items]\n        high_marginal_out = out_items[np.argsort(out_marginal)[-max(1, len(out_items) // 5):]]\n\n        # Try to swap items\n        for in_idx in low_marginal_in:\n            for out_idx in high_marginal_out:\n                if current_weight - weight_lst[in_idx] + weight_lst[out_idx] <= capacity:\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    current_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n                    break\n\n    # Strategy 2: Add items with highest marginal contribution if capacity allows\n    if current_weight < capacity:\n        # Get items not in solution sorted by marginal contribution\n        out_marginal = marginal[out_items]\n        sorted_out = out_items[np.argsort(out_marginal)[::-1]]\n\n        for item in sorted_out:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            else:\n                break\n\n    # Strategy 3: Remove items with lowest marginal contribution if needed\n    if current_weight > capacity:\n        # Get items in solution sorted by marginal contribution\n        in_marginal = marginal[in_items]\n        sorted_in = in_items[np.argsort(in_marginal)]\n\n        for item in sorted_in:\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n            else:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.40255772097382525,
            1.6244504153728485
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate value ratios for each solution\n    value_ratios = []\n    for sol, obj in archive:\n        v1, v2 = obj\n        ratio = v1 / (v2 + 1e-10)  # Avoid division by zero\n        value_ratios.append(ratio)\n\n    # Normalize ratios and use as selection probabilities\n    max_ratio = max(value_ratios) if value_ratios else 1.0\n    selection_probs = [ratio / max_ratio for ratio in value_ratios]\n\n    # Select a base solution with probability proportional to its value ratio\n    selected_idx = random.choices(range(len(archive)), weights=selection_probs, k=1)[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Adaptive item swapping: swap items based on their marginal contribution\n    # 2. Value-based neighborhood exploration: explore items with high value/weight ratios\n\n    # Calculate marginal contribution for each item\n    marginal_v1 = value1_lst / (weight_lst + 1e-10)\n    marginal_v2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal contributions (simple average for this example)\n    marginal = (marginal_v1 + marginal_v2) / 2\n\n    # Get indices of items in and out of the solution\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Strategy 1: Swap items with high marginal contribution\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Select top 20% of in_items with lowest marginal contribution\n        in_marginal = marginal[in_items]\n        low_marginal_in = in_items[np.argsort(in_marginal)[:max(1, len(in_items) // 5)]]\n\n        # Select top 20% of out_items with highest marginal contribution\n        out_marginal = marginal[out_items]\n        high_marginal_out = out_items[np.argsort(out_marginal)[-max(1, len(out_items) // 5):]]\n\n        # Try to swap items\n        for in_idx in low_marginal_in:\n            for out_idx in high_marginal_out:\n                if current_weight - weight_lst[in_idx] + weight_lst[out_idx] <= capacity:\n                    new_solution[in_idx] = 0\n                    new_solution[out_idx] = 1\n                    current_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n                    break\n\n    # Strategy 2: Add items with highest marginal contribution if capacity allows\n    if current_weight < capacity:\n        # Get items not in solution sorted by marginal contribution\n        out_marginal = marginal[out_items]\n        sorted_out = out_items[np.argsort(out_marginal)[::-1]]\n\n        for item in sorted_out:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            else:\n                break\n\n    # Strategy 3: Remove items with lowest marginal contribution if needed\n    if current_weight > capacity:\n        # Get items in solution sorted by marginal contribution\n        in_marginal = marginal[in_items]\n        sorted_in = in_items[np.argsort(in_marginal)]\n\n        for item in sorted_in:\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n            else:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 52,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a random solution from the archive with preference for those near the Pareto front\n    selected_idx = random.choices(range(len(archive)), k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine bit-flip with item swapping\n    new_solution = base_solution.copy()\n\n    # First, perform a bit-flip operation (flip a random item if feasible)\n    flip_candidate = random.randint(0, len(weight_lst) - 1)\n    if new_solution[flip_candidate] == 1:\n        # Try to remove the item if it's in the solution\n        if current_weight - weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 0\n    else:\n        # Try to add the item if it's not in the solution\n        if current_weight + weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 1\n\n    # Second, perform a random swap between two items (if feasible)\n    if len(weight_lst) >= 2:\n        i, j = random.sample(range(len(weight_lst)), 2)\n        delta_weight = weight_lst[j] - weight_lst[i]\n        if (new_solution[i] == 1 and new_solution[j] == 0 and\n            current_weight + delta_weight <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        elif (new_solution[i] == 0 and new_solution[j] == 1 and\n              current_weight + delta_weight <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Third, perform a random flip of multiple items (if feasible)\n    num_flips = random.randint(1, min(3, len(weight_lst)))\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5036491294174343,
            1.0941497385501862
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a random solution from the archive with preference for those near the Pareto front\n    selected_idx = random.choices(range(len(archive)), k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine bit-flip with item swapping\n    new_solution = base_solution.copy()\n\n    # First, perform a bit-flip operation (flip a random item if feasible)\n    flip_candidate = random.randint(0, len(weight_lst) - 1)\n    if new_solution[flip_candidate] == 1:\n        # Try to remove the item if it's in the solution\n        if current_weight - weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 0\n    else:\n        # Try to add the item if it's not in the solution\n        if current_weight + weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 1\n\n    # Second, perform a random swap between two items (if feasible)\n    if len(weight_lst) >= 2:\n        i, j = random.sample(range(len(weight_lst)), 2)\n        delta_weight = weight_lst[j] - weight_lst[i]\n        if (new_solution[i] == 1 and new_solution[j] == 0 and\n            current_weight + delta_weight <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        elif (new_solution[i] == 0 and new_solution[j] == 1 and\n              current_weight + delta_weight <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Third, perform a random flip of multiple items (if feasible)\n    num_flips = random.randint(1, min(3, len(weight_lst)))\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 53,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import numpy as np\n    from random import choices, randint, random\n\n    # Select a base solution with a bias toward solutions with higher total value\n    if len(archive) == 0:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the total value (sum of both objectives) for each solution\n    total_values = [sum(obj) for _, obj in archive]\n    max_total = max(total_values) if total_values else 1.0\n    weights = [tv / max_total for tv in total_values]  # Normalize weights\n\n    # Select a base solution with probability proportional to its total value\n    base_idx = choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (1-3) to explore neighborhood\n    # 2. If the flip is feasible, keep it; otherwise, try another flip\n    # 3. If no feasible flip is found, perform a more aggressive local search:\n    #    - Randomly select a subset of items and try to swap their inclusion status\n    #    - Ensure feasibility at each step\n\n    # Step 1: Random flip\n    num_flips = randint(1, 3)\n    feasible = False\n    for _ in range(num_flips):\n        item = randint(0, len(weight_lst) - 1)\n        if new_solution[item] == 1:\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[item]) <= capacity:\n                new_solution[item] = 0\n                feasible = True\n        else:\n            if (np.sum(weight_lst[new_solution == 1]) + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n                feasible = True\n\n    if feasible:\n        return new_solution\n\n    # Step 2: Aggressive local search (subset swap)\n    subset_size = min(5, len(weight_lst) // 2)\n    subset = np.random.choice(len(weight_lst), subset_size, replace=False)\n\n    # Try to flip all items in the subset if feasible\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    subset_weight = np.sum(weight_lst[subset])\n    subset_included = np.sum(new_solution[subset])\n\n    if subset_included == subset_size:  # All in subset are included\n        if current_weight - subset_weight >= 0:\n            new_solution[subset] = 0\n    elif subset_included == 0:  # None in subset are included\n        if current_weight + subset_weight <= capacity:\n            new_solution[subset] = 1\n    else:  # Mixed case - try to include as many as possible\n        # Calculate how many we can include\n        max_add = min(int((capacity - (current_weight - subset_weight)) // np.mean(weight_lst[subset])), subset_size)\n        if max_add > 0:\n            # Randomly select items to include\n            items_to_add = np.random.choice(subset, max_add, replace=False)\n            new_solution[items_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3471758749740841,
            0.9198507070541382
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    import numpy as np\n    from random import choices, randint, random\n\n    # Select a base solution with a bias toward solutions with higher total value\n    if len(archive) == 0:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the total value (sum of both objectives) for each solution\n    total_values = [sum(obj) for _, obj in archive]\n    max_total = max(total_values) if total_values else 1.0\n    weights = [tv / max_total for tv in total_values]  # Normalize weights\n\n    # Select a base solution with probability proportional to its total value\n    base_idx = choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of items (1-3) to explore neighborhood\n    # 2. If the flip is feasible, keep it; otherwise, try another flip\n    # 3. If no feasible flip is found, perform a more aggressive local search:\n    #    - Randomly select a subset of items and try to swap their inclusion status\n    #    - Ensure feasibility at each step\n\n    # Step 1: Random flip\n    num_flips = randint(1, 3)\n    feasible = False\n    for _ in range(num_flips):\n        item = randint(0, len(weight_lst) - 1)\n        if new_solution[item] == 1:\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[item]) <= capacity:\n                new_solution[item] = 0\n                feasible = True\n        else:\n            if (np.sum(weight_lst[new_solution == 1]) + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n                feasible = True\n\n    if feasible:\n        return new_solution\n\n    # Step 2: Aggressive local search (subset swap)\n    subset_size = min(5, len(weight_lst) // 2)\n    subset = np.random.choice(len(weight_lst), subset_size, replace=False)\n\n    # Try to flip all items in the subset if feasible\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    subset_weight = np.sum(weight_lst[subset])\n    subset_included = np.sum(new_solution[subset])\n\n    if subset_included == subset_size:  # All in subset are included\n        if current_weight - subset_weight >= 0:\n            new_solution[subset] = 0\n    elif subset_included == 0:  # None in subset are included\n        if current_weight + subset_weight <= capacity:\n            new_solution[subset] = 1\n    else:  # Mixed case - try to include as many as possible\n        # Calculate how many we can include\n        max_add = min(int((capacity - (current_weight - subset_weight)) // np.mean(weight_lst[subset])), subset_size)\n        if max_add > 0:\n            # Randomly select items to include\n            items_to_add = np.random.choice(subset, max_add, replace=False)\n            new_solution[items_to_add] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 54,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., non-dominated but not too crowded)\n    # Here, we prioritize solutions with high values but not too close to the Pareto front\n    candidates = []\n    for sol, obj in archive:\n        # Calculate a score based on value and diversity (simplified)\n        score = obj[0] + obj[1] - 0.1 * np.sum(sol * weight_lst)  # Penalize high weight\n        candidates.append((score, sol))\n\n    # Select top 3 candidates and pick one randomly\n    candidates.sort(key=lambda x: -x[0])\n    selected = random.choice(candidates[:min(3, len(candidates))])[1]\n    base_solution = selected.copy()\n\n    # Hybrid local search: random perturbation + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a few bits)\n    n_perturb = min(3, len(new_solution))\n    perturb_indices = random.sample(range(len(new_solution)), n_perturb)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove heaviest items until feasible\n        sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n        for idx in sorted_indices:\n            if total_weight > capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Try adding items that improve at least one objective\n    candidate_items = np.where(new_solution == 0)[0]\n    random.shuffle(candidate_items)\n    for idx in candidate_items:\n        if weight_lst[idx] + np.sum(new_solution * weight_lst) <= capacity:\n            new_value1 = obj[0] + value1_lst[idx] if idx in np.where(base_solution == 0)[0] else obj[0]\n            new_value2 = obj[1] + value2_lst[idx] if idx in np.where(base_solution == 0)[0] else obj[1]\n            # Accept if at least one objective improves\n            if new_value1 > obj[0] or new_value2 > obj[1]:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3322505932170595,
            9.348564058542252
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., non-dominated but not too crowded)\n    # Here, we prioritize solutions with high values but not too close to the Pareto front\n    candidates = []\n    for sol, obj in archive:\n        # Calculate a score based on value and diversity (simplified)\n        score = obj[0] + obj[1] - 0.1 * np.sum(sol * weight_lst)  # Penalize high weight\n        candidates.append((score, sol))\n\n    # Select top 3 candidates and pick one randomly\n    candidates.sort(key=lambda x: -x[0])\n    selected = random.choice(candidates[:min(3, len(candidates))])[1]\n    base_solution = selected.copy()\n\n    # Hybrid local search: random perturbation + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a few bits)\n    n_perturb = min(3, len(new_solution))\n    perturb_indices = random.sample(range(len(new_solution)), n_perturb)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove heaviest items until feasible\n        sorted_indices = np.argsort(weight_lst * new_solution)[::-1]\n        for idx in sorted_indices:\n            if total_weight > capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Try adding items that improve at least one objective\n    candidate_items = np.where(new_solution == 0)[0]\n    random.shuffle(candidate_items)\n    for idx in candidate_items:\n        if weight_lst[idx] + np.sum(new_solution * weight_lst) <= capacity:\n            new_value1 = obj[0] + value1_lst[idx] if idx in np.where(base_solution == 0)[0] else obj[0]\n            new_value2 = obj[1] + value2_lst[idx] if idx in np.where(base_solution == 0)[0] else obj[1]\n            # Accept if at least one objective improves\n            if new_value1 > obj[0] or new_value2 > obj[1]:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 55,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly perturb the solution by flipping a few items\n    # 2. Perform a value-weighted swap to maximize both objectives\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip 1-3 items)\n    num_perturb = np.random.randint(1, 4)\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturb, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it doesn't violate capacity\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Value-weighted swap to improve both objectives\n    # Calculate marginal gains for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal gains (simple average for simplicity)\n    combined_marginal = (marginal_value1 + marginal_value2) / 2\n\n    # Sort items by combined marginal value\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Try to replace low-value items with high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Find an item to remove (prioritize low-value items)\n            remove_candidates = np.where((new_solution == 1) & (weight_lst <= weight_lst[idx]))[0]\n            if len(remove_candidates) > 0:\n                remove_idx = remove_candidates[np.argmin(combined_marginal[remove_candidates])]\n                if current_weight - weight_lst[remove_idx] + weight_lst[idx] <= capacity:\n                    new_solution[remove_idx] = 0\n                    new_solution[idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5981191944281259,
            3.396324723958969
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly perturb the solution by flipping a few items\n    # 2. Perform a value-weighted swap to maximize both objectives\n\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip 1-3 items)\n    num_perturb = np.random.randint(1, 4)\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturb, replace=False)\n    for idx in perturb_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it doesn't violate capacity\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Add item if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Value-weighted swap to improve both objectives\n    # Calculate marginal gains for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal gains (simple average for simplicity)\n    combined_marginal = (marginal_value1 + marginal_value2) / 2\n\n    # Sort items by combined marginal value\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Try to replace low-value items with high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Find an item to remove (prioritize low-value items)\n            remove_candidates = np.where((new_solution == 1) & (weight_lst <= weight_lst[idx]))[0]\n            if len(remove_candidates) > 0:\n                remove_idx = remove_candidates[np.argmin(combined_marginal[remove_candidates])]\n                if current_weight - weight_lst[remove_idx] + weight_lst[idx] <= capacity:\n                    new_solution[remove_idx] = 0\n                    new_solution[idx] = 1\n                    current_weight = current_weight - weight_lst[remove_idx] + weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 56,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Prioritize solutions with high total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (perturbation)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            proposed_weight = np.sum(weight_lst[new_solution == 1]) - weight_lst[idx]\n            if proposed_weight <= capacity:\n                new_solution[idx] = 0\n        else:\n            proposed_weight = np.sum(weight_lst[new_solution == 1]) + weight_lst[idx]\n            if proposed_weight <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Value-based swap to improve both objectives\n    # Identify items with high marginal value in either objective\n    selected_items = np.where(new_solution == 1)[0]\n    unselected_items = np.where(new_solution == 0)[0]\n\n    if len(selected_items) > 0 and len(unselected_items) > 0:\n        # Calculate marginal value for selected items\n        marginal_value1 = value1_lst[selected_items] / weight_lst[selected_items]\n        marginal_value2 = value2_lst[selected_items] / weight_lst[selected_items]\n\n        # Calculate marginal value for unselected items\n        marginal_value1_unselected = value1_lst[unselected_items] / weight_lst[unselected_items]\n        marginal_value2_unselected = value2_lst[unselected_items] / weight_lst[unselected_items]\n\n        # Find the most valuable selected item to remove\n        worst_selected_idx = np.argmin(marginal_value1 + marginal_value2)\n        worst_selected_item = selected_items[worst_selected_idx]\n\n        # Find the most valuable unselected item to add\n        best_unselected_idx = np.argmax(marginal_value1_unselected + marginal_value2_unselected)\n        best_unselected_item = unselected_items[best_unselected_idx]\n\n        # Perform the swap if feasible\n        proposed_weight = np.sum(weight_lst[new_solution == 1]) - weight_lst[worst_selected_item] + weight_lst[best_unselected_item]\n        if proposed_weight <= capacity:\n            new_solution[worst_selected_item] = 0\n            new_solution[best_unselected_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3397395156349393,
            2.188614398241043
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Prioritize solutions with high total value in either objective\n    archive_sorted = sorted(archive, key=lambda x: max(x[1][0], x[1][1]), reverse=True)\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = selected_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (perturbation)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            proposed_weight = np.sum(weight_lst[new_solution == 1]) - weight_lst[idx]\n            if proposed_weight <= capacity:\n                new_solution[idx] = 0\n        else:\n            proposed_weight = np.sum(weight_lst[new_solution == 1]) + weight_lst[idx]\n            if proposed_weight <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Value-based swap to improve both objectives\n    # Identify items with high marginal value in either objective\n    selected_items = np.where(new_solution == 1)[0]\n    unselected_items = np.where(new_solution == 0)[0]\n\n    if len(selected_items) > 0 and len(unselected_items) > 0:\n        # Calculate marginal value for selected items\n        marginal_value1 = value1_lst[selected_items] / weight_lst[selected_items]\n        marginal_value2 = value2_lst[selected_items] / weight_lst[selected_items]\n\n        # Calculate marginal value for unselected items\n        marginal_value1_unselected = value1_lst[unselected_items] / weight_lst[unselected_items]\n        marginal_value2_unselected = value2_lst[unselected_items] / weight_lst[unselected_items]\n\n        # Find the most valuable selected item to remove\n        worst_selected_idx = np.argmin(marginal_value1 + marginal_value2)\n        worst_selected_item = selected_items[worst_selected_idx]\n\n        # Find the most valuable unselected item to add\n        best_unselected_idx = np.argmax(marginal_value1_unselected + marginal_value2_unselected)\n        best_unselected_item = unselected_items[best_unselected_idx]\n\n        # Perform the swap if feasible\n        proposed_weight = np.sum(weight_lst[new_solution == 1]) - weight_lst[worst_selected_item] + weight_lst[best_unselected_item]\n        if proposed_weight <= capacity:\n            new_solution[worst_selected_item] = 0\n            new_solution[best_unselected_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 57,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on objective diversity and potential for improvement\n    selected_solution = None\n    max_potential = -1\n\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate potential for improvement: items that could be added without exceeding capacity\n        potential_items = (weight_lst <= remaining_capacity) & (sol == 0)\n        potential_value1 = np.sum(value1_lst * potential_items)\n        potential_value2 = np.sum(value2_lst * potential_items)\n\n        # Calculate potential for objective improvement\n        potential = potential_value1 + potential_value2\n\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = random.choice(archive)[0]\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy: combination of addition and removal\n    # Step 1: Randomly select a subset of items to remove (with probability based on their value)\n    removal_candidates = np.where(new_solution == 1)[0]\n    if len(removal_candidates) > 0:\n        removal_probs = np.array([value1_lst[i] + value2_lst[i] for i in removal_candidates])\n        removal_probs = removal_probs / np.sum(removal_probs)\n        items_to_remove = random.choices(removal_candidates, weights=removal_probs, k=min(2, len(removal_candidates)))\n        new_solution[items_to_remove] = 0\n\n    # Step 2: Randomly select a subset of items to add (with probability based on their value)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    addition_candidates = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    if len(addition_candidates) > 0:\n        addition_probs = np.array([value1_lst[i] + value2_lst[i] for i in addition_candidates])\n        addition_probs = addition_probs / np.sum(addition_probs)\n        items_to_add = random.choices(addition_candidates, weights=addition_probs, k=min(2, len(addition_candidates)))\n        new_solution[items_to_add] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If still over capacity, remove items with lowest combined value\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            item_to_remove = min(included_items, key=lambda i: value1_lst[i] + value2_lst[i])\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.8753356025293424,
            5.667171388864517
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on objective diversity and potential for improvement\n    selected_solution = None\n    max_potential = -1\n\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate potential for improvement: items that could be added without exceeding capacity\n        potential_items = (weight_lst <= remaining_capacity) & (sol == 0)\n        potential_value1 = np.sum(value1_lst * potential_items)\n        potential_value2 = np.sum(value2_lst * potential_items)\n\n        # Calculate potential for objective improvement\n        potential = potential_value1 + potential_value2\n\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    if selected_solution is None:\n        selected_solution = random.choice(archive)[0]\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy: combination of addition and removal\n    # Step 1: Randomly select a subset of items to remove (with probability based on their value)\n    removal_candidates = np.where(new_solution == 1)[0]\n    if len(removal_candidates) > 0:\n        removal_probs = np.array([value1_lst[i] + value2_lst[i] for i in removal_candidates])\n        removal_probs = removal_probs / np.sum(removal_probs)\n        items_to_remove = random.choices(removal_candidates, weights=removal_probs, k=min(2, len(removal_candidates)))\n        new_solution[items_to_remove] = 0\n\n    # Step 2: Randomly select a subset of items to add (with probability based on their value)\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    addition_candidates = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    if len(addition_candidates) > 0:\n        addition_probs = np.array([value1_lst[i] + value2_lst[i] for i in addition_candidates])\n        addition_probs = addition_probs / np.sum(addition_probs)\n        items_to_add = random.choices(addition_candidates, weights=addition_probs, k=min(2, len(addition_candidates)))\n        new_solution[items_to_add] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If still over capacity, remove items with lowest combined value\n        while current_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            item_to_remove = min(included_items, key=lambda i: value1_lst[i] + value2_lst[i])\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 58,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the boundary\n    base_solution, (current_value1, current_value2) = archive[np.random.choice(len(archive))]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    for _ in range(5):  # Number of random swaps\n        # Select two random items to swap\n        item1, item2 = np.random.choice(len(new_solution), 2, replace=False)\n\n        # Calculate weight change if we swap these items\n        delta_weight = (weight_lst[item2] - weight_lst[item1]) * (new_solution[item1] - new_solution[item2])\n\n        # Only perform swap if it doesn't violate capacity\n        if current_weight + delta_weight <= capacity:\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n            current_weight += delta_weight\n\n    # Greedy improvement step: try to add items that improve both objectives\n    for item in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate potential improvement for both objectives\n            delta_value1 = value1_lst[item]\n            delta_value2 = value2_lst[item]\n\n            # Accept the addition if it improves both objectives\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Final check to ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            items_in = np.where(new_solution == 1)[0]\n            if len(items_in) == 0:\n                break\n            item_to_remove = np.random.choice(items_in)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3710725058966804,
            5.4425033032894135
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the boundary\n    base_solution, (current_value1, current_value2) = archive[np.random.choice(len(archive))]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    for _ in range(5):  # Number of random swaps\n        # Select two random items to swap\n        item1, item2 = np.random.choice(len(new_solution), 2, replace=False)\n\n        # Calculate weight change if we swap these items\n        delta_weight = (weight_lst[item2] - weight_lst[item1]) * (new_solution[item1] - new_solution[item2])\n\n        # Only perform swap if it doesn't violate capacity\n        if current_weight + delta_weight <= capacity:\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n            current_weight += delta_weight\n\n    # Greedy improvement step: try to add items that improve both objectives\n    for item in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate potential improvement for both objectives\n            delta_value1 = value1_lst[item]\n            delta_value2 = value2_lst[item]\n\n            # Accept the addition if it improves both objectives\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Final check to ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            items_in = np.where(new_solution == 1)[0]\n            if len(items_in) == 0:\n                break\n            item_to_remove = np.random.choice(items_in)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 59,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a candidate set of items to flip (combine randomness with value-to-weight ratio)\n    candidate_items = np.where(base_solution == 1)[0]\n    if len(candidate_items) > 0:\n        # Randomly select some items to remove\n        num_to_remove = min(3, len(candidate_items))\n        items_to_remove = np.random.choice(candidate_items, num_to_remove, replace=False)\n        new_solution[items_to_remove] = 0\n\n    # Calculate remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n\n    # Add items with high value-to-weight ratios for both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0 and remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Combine ratios and select top candidates\n        combined_ratio = (v1_ratio + v2_ratio) / 2  # Simple average for multi-objective\n        sorted_items = np.argsort(combined_ratio)[::-1]\n\n        for item in sorted_items:\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n                if remaining_capacity <= 0:\n                    break\n\n    # Ensure feasibility (shouldn't be necessary due to capacity checks, but added as safeguard)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if total_weight <= capacity:\n                break\n            new_solution[item] = 0\n            total_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.37807257257180626,
            5.871571719646454
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a candidate set of items to flip (combine randomness with value-to-weight ratio)\n    candidate_items = np.where(base_solution == 1)[0]\n    if len(candidate_items) > 0:\n        # Randomly select some items to remove\n        num_to_remove = min(3, len(candidate_items))\n        items_to_remove = np.random.choice(candidate_items, num_to_remove, replace=False)\n        new_solution[items_to_remove] = 0\n\n    # Calculate remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n\n    # Add items with high value-to-weight ratios for both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0 and remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Combine ratios and select top candidates\n        combined_ratio = (v1_ratio + v2_ratio) / 2  # Simple average for multi-objective\n        sorted_items = np.argsort(combined_ratio)[::-1]\n\n        for item in sorted_items:\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n                if remaining_capacity <= 0:\n                    break\n\n    # Ensure feasibility (shouldn't be necessary due to capacity checks, but added as safeguard)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If infeasible, remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if total_weight <= capacity:\n                break\n            new_solution[item] = 0\n            total_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 60,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with higher potential for improvement\n    # We prioritize solutions that are not too close to the Pareto front or have high diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate potential for improvement: items that can be added without exceeding capacity\n            potential_items = (weight_lst <= remaining_capacity) & (sol == 0)\n            if np.any(potential_items):\n                candidates.append(sol)\n\n    if not candidates:\n        # If no candidates, select a random solution from the archive\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the highest potential for improvement\n        base_solution = max(candidates, key=lambda x: np.sum((weight_lst <= (capacity - np.sum(weight_lst * x))) & (x == 0)))\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random perturbation and greedy improvement\n    # Step 1: Random perturbation - flip a small number of bits\n    num_flips = min(3, len(new_solution) // 10)  # Flip up to 3 or 10% of items\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        while excess_weight > 0 and np.any(new_solution):\n            remove_candidates = np.where(new_solution == 1)[0]\n            if not remove_candidates.size:\n                break\n            remove_idx = random.choice(remove_candidates)\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate potential items to add\n        potential_items = (weight_lst <= remaining_capacity) & (new_solution == 0)\n        if np.any(potential_items):\n            # Evaluate potential items based on a combined objective score\n            item_scores = (value1_lst + value2_lst) / weight_lst\n            best_items = np.argsort(-item_scores)[potential_items]\n\n            # Add items one by one until capacity is reached\n            for item in best_items:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n                else:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.43532142694239273,
            2.7966724038124084
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with higher potential for improvement\n    # We prioritize solutions that are not too close to the Pareto front or have high diversity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Calculate potential for improvement: items that can be added without exceeding capacity\n            potential_items = (weight_lst <= remaining_capacity) & (sol == 0)\n            if np.any(potential_items):\n                candidates.append(sol)\n\n    if not candidates:\n        # If no candidates, select a random solution from the archive\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the highest potential for improvement\n        base_solution = max(candidates, key=lambda x: np.sum((weight_lst <= (capacity - np.sum(weight_lst * x))) & (x == 0)))\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random perturbation and greedy improvement\n    # Step 1: Random perturbation - flip a small number of bits\n    num_flips = min(3, len(new_solution) // 10)  # Flip up to 3 or 10% of items\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        while excess_weight > 0 and np.any(new_solution):\n            remove_candidates = np.where(new_solution == 1)[0]\n            if not remove_candidates.size:\n                break\n            remove_idx = random.choice(remove_candidates)\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate potential items to add\n        potential_items = (weight_lst <= remaining_capacity) & (new_solution == 0)\n        if np.any(potential_items):\n            # Evaluate potential items based on a combined objective score\n            item_scores = (value1_lst + value2_lst) / weight_lst\n            best_items = np.argsort(-item_scores)[potential_items]\n\n            # Add items one by one until capacity is reached\n            for item in best_items:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n                else:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 61,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., solutions near the Pareto front)\n    # Here, we select a solution with the highest combined value\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = np.array([obj for _, obj in archive])\n\n    # Normalize the objectives to avoid bias towards one objective\n    normalized_values = archive_values / np.max(archive_values, axis=0)\n    combined_scores = np.sum(normalized_values, axis=1)\n\n    # Select the solution with the highest combined score (promising for improvement)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by performing a hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after random flip\n    while np.sum(weight_lst * new_solution) > capacity:\n        # If infeasible, randomly remove an item to make it feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) > 0:\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n\n    # Step 2: Greedily improve the solution by adding the best item not in the solution\n    # Calculate marginal gains for each item not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Evaluate adding each item (consider both objectives)\n        candidate_values1 = value1_lst[not_in_solution]\n        candidate_values2 = value2_lst[not_in_solution]\n        candidate_weights = weight_lst[not_in_solution]\n\n        # Normalize the marginal gains to avoid bias\n        normalized_gains1 = candidate_values1 / np.max(candidate_values1) if np.max(candidate_values1) > 0 else 0\n        normalized_gains2 = candidate_values2 / np.max(candidate_values2) if np.max(candidate_values2) > 0 else 0\n        combined_gains = normalized_gains1 + normalized_gains2\n\n        # Select the item with the highest combined gain that fits in the knapsack\n        best_candidate_idx = np.argmax(combined_gains)\n        best_item = not_in_solution[best_candidate_idx]\n\n        # Check if adding the best item is feasible\n        if candidate_weights[best_candidate_idx] + np.sum(weight_lst * new_solution) <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3273462665620939,
            1.98467156291008
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., solutions near the Pareto front)\n    # Here, we select a solution with the highest combined value\n    archive_solutions = [sol for sol, _ in archive]\n    archive_values = np.array([obj for _, obj in archive])\n\n    # Normalize the objectives to avoid bias towards one objective\n    normalized_values = archive_values / np.max(archive_values, axis=0)\n    combined_scores = np.sum(normalized_values, axis=1)\n\n    # Select the solution with the highest combined score (promising for improvement)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by performing a hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after random flip\n    while np.sum(weight_lst * new_solution) > capacity:\n        # If infeasible, randomly remove an item to make it feasible\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) > 0:\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n\n    # Step 2: Greedily improve the solution by adding the best item not in the solution\n    # Calculate marginal gains for each item not in the solution\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Evaluate adding each item (consider both objectives)\n        candidate_values1 = value1_lst[not_in_solution]\n        candidate_values2 = value2_lst[not_in_solution]\n        candidate_weights = weight_lst[not_in_solution]\n\n        # Normalize the marginal gains to avoid bias\n        normalized_gains1 = candidate_values1 / np.max(candidate_values1) if np.max(candidate_values1) > 0 else 0\n        normalized_gains2 = candidate_values2 / np.max(candidate_values2) if np.max(candidate_values2) > 0 else 0\n        combined_gains = normalized_gains1 + normalized_gains2\n\n        # Select the item with the highest combined gain that fits in the knapsack\n        best_candidate_idx = np.argmax(combined_gains)\n        best_item = not_in_solution[best_candidate_idx]\n\n        # Check if adding the best item is feasible\n        if candidate_weights[best_candidate_idx] + np.sum(weight_lst * new_solution) <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 62,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with high potential for improvement\n            potential = (np.sum(value1_lst * sol) + np.sum(value1_lst * (weight_lst <= remaining_capacity))) / (np.sum(value1_lst) + 1e-6)\n            candidates.append((sol, potential))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select the solution with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search: flip items with high marginal gain and low weight\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Calculate marginal gains for excluded items\n    excluded_items = np.where(new_solution == 0)[0]\n    marginal_gains = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    marginal_gains[new_solution == 1] = -np.inf  # Exclude already included items\n\n    # Sort by marginal gain and select top candidates\n    top_candidates = np.argsort(marginal_gains)[-min(5, len(excluded_items)):]\n\n    # Try adding one item at a time\n    for item in top_candidates:\n        if weight_lst[item] <= remaining_capacity:\n            new_solution[item] = 1\n            remaining_capacity -= weight_lst[item]\n\n    # If no items added, try removing low-value items\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        marginal_losses = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        marginal_losses[new_solution == 0] = np.inf  # Exclude excluded items\n\n        # Sort by marginal loss and remove worst candidates\n        worst_candidates = np.argsort(marginal_losses)[:min(3, len(included_items))]\n        for item in worst_candidates:\n            if total_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.7866282285701711,
            5.312748163938522
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with high potential for improvement\n            potential = (np.sum(value1_lst * sol) + np.sum(value1_lst * (weight_lst <= remaining_capacity))) / (np.sum(value1_lst) + 1e-6)\n            candidates.append((sol, potential))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select the solution with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search: flip items with high marginal gain and low weight\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Calculate marginal gains for excluded items\n    excluded_items = np.where(new_solution == 0)[0]\n    marginal_gains = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    marginal_gains[new_solution == 1] = -np.inf  # Exclude already included items\n\n    # Sort by marginal gain and select top candidates\n    top_candidates = np.argsort(marginal_gains)[-min(5, len(excluded_items)):]\n\n    # Try adding one item at a time\n    for item in top_candidates:\n        if weight_lst[item] <= remaining_capacity:\n            new_solution[item] = 1\n            remaining_capacity -= weight_lst[item]\n\n    # If no items added, try removing low-value items\n    if np.array_equal(new_solution, base_solution):\n        included_items = np.where(new_solution == 1)[0]\n        marginal_losses = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        marginal_losses[new_solution == 0] = np.inf  # Exclude excluded items\n\n        # Sort by marginal loss and remove worst candidates\n        worst_candidates = np.argsort(marginal_losses)[:min(3, len(included_items))]\n        for item in worst_candidates:\n            if total_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                total_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 63,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Randomly select a candidate with higher probability if it has more room for improvement\n    selected_sol = random.choices(\n        candidates,\n        weights=[1.0 / (1 + np.sum(sol)) for sol in candidates]  # Prefer solutions with fewer items\n    )[0].copy()\n\n    # Hybrid local search: flip a random subset of items and then greedily add items\n    new_solution = selected_sol.copy()\n\n    # Random flip: flip a random subset of items (up to 20% of the items)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove excess items by removing the ones with the lowest ratio of (value1 + value2) / weight\n        excess = total_weight - capacity\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    # Greedy addition: add items that improve both objectives\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    for idx in np.argsort(-(value1_lst + value2_lst)):  # Sort by descending value sum\n        if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3814349738776416,
            2.7241977751255035
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Randomly select a candidate with higher probability if it has more room for improvement\n    selected_sol = random.choices(\n        candidates,\n        weights=[1.0 / (1 + np.sum(sol)) for sol in candidates]  # Prefer solutions with fewer items\n    )[0].copy()\n\n    # Hybrid local search: flip a random subset of items and then greedily add items\n    new_solution = selected_sol.copy()\n\n    # Random flip: flip a random subset of items (up to 20% of the items)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flip\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove excess items by removing the ones with the lowest ratio of (value1 + value2) / weight\n        excess = total_weight - capacity\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if excess <= 0:\n                break\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n\n    # Greedy addition: add items that improve both objectives\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    for idx in np.argsort(-(value1_lst + value2_lst)):  # Sort by descending value sum\n        if weight_lst[idx] <= remaining_capacity and new_solution[idx] == 0:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 64,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with higher probability for those closer to the Pareto front\n    # Here, we use a simple heuristic: higher probability for solutions with higher combined value\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    selection_probs = combined_values / np.sum(combined_values)\n    base_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with bias towards higher-value items)\n    # 2. For each selected item, decide to flip based on its potential to improve both objectives\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Select items to consider for flipping (biased towards higher-value items)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) == 0:\n        flip_candidates = np.arange(len(weight_lst))\n\n    # For each candidate, decide whether to flip based on potential improvement\n    for item in flip_candidates:\n        if new_solution[item] == 1:\n            # If item is in the solution, consider removing it if it's not critical\n            if current_weight - weight_lst[item] <= capacity:\n                # Calculate potential improvement\n                potential_value1 = current_value1 - value1_lst[item]\n                potential_value2 = current_value2 - value2_lst[item]\n\n                # Accept removal if it doesn't significantly worsen both objectives\n                if (potential_value1 >= current_value1 * 0.95 and\n                    potential_value2 >= current_value2 * 0.95):\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    current_value1 = potential_value1\n                    current_value2 = potential_value2\n        else:\n            # If item is not in the solution, consider adding it if it fits\n            if current_weight + weight_lst[item] <= capacity:\n                # Calculate potential improvement\n                potential_value1 = current_value1 + value1_lst[item]\n                potential_value2 = current_value2 + value2_lst[item]\n\n                # Accept addition if it improves both objectives\n                if (potential_value1 > current_value1 and\n                    potential_value2 > current_value2):\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n                    current_value1 = potential_value1\n                    current_value2 = potential_value2\n\n    # Additional random flips to escape local optima\n    if random.random() < 0.3:  # 30% chance to perform additional random flips\n        num_flips = min(3, len(weight_lst))  # Limit number of random flips\n        for _ in range(num_flips):\n            item = random.choice(np.arange(len(weight_lst)))\n            if new_solution[item] == 1:\n                if current_weight - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n            else:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.783933634059973,
            2.1406440138816833
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with higher probability for those closer to the Pareto front\n    # Here, we use a simple heuristic: higher probability for solutions with higher combined value\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    selection_probs = combined_values / np.sum(combined_values)\n    base_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with bias towards higher-value items)\n    # 2. For each selected item, decide to flip based on its potential to improve both objectives\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Select items to consider for flipping (biased towards higher-value items)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) == 0:\n        flip_candidates = np.arange(len(weight_lst))\n\n    # For each candidate, decide whether to flip based on potential improvement\n    for item in flip_candidates:\n        if new_solution[item] == 1:\n            # If item is in the solution, consider removing it if it's not critical\n            if current_weight - weight_lst[item] <= capacity:\n                # Calculate potential improvement\n                potential_value1 = current_value1 - value1_lst[item]\n                potential_value2 = current_value2 - value2_lst[item]\n\n                # Accept removal if it doesn't significantly worsen both objectives\n                if (potential_value1 >= current_value1 * 0.95 and\n                    potential_value2 >= current_value2 * 0.95):\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    current_value1 = potential_value1\n                    current_value2 = potential_value2\n        else:\n            # If item is not in the solution, consider adding it if it fits\n            if current_weight + weight_lst[item] <= capacity:\n                # Calculate potential improvement\n                potential_value1 = current_value1 + value1_lst[item]\n                potential_value2 = current_value2 + value2_lst[item]\n\n                # Accept addition if it improves both objectives\n                if (potential_value1 > current_value1 and\n                    potential_value2 > current_value2):\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n                    current_value1 = potential_value1\n                    current_value2 = potential_value2\n\n    # Additional random flips to escape local optima\n    if random.random() < 0.3:  # 30% chance to perform additional random flips\n        num_flips = min(3, len(weight_lst))  # Limit number of random flips\n        for _ in range(num_flips):\n            item = random.choice(np.arange(len(weight_lst)))\n            if new_solution[item] == 1:\n                if current_weight - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n            else:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 65,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a preference for those closer to the Pareto front\n    weights = np.array([1.0 / (i + 1) for i in range(len(archive))])  # Higher weight for earlier (better?) solutions\n    weights = weights / weights.sum()  # Normalize\n    selected = random.choices(archive, weights=weights, k=1)[0]\n    base_solution = selected[0].copy()\n    current_obj = selected[1]\n\n    # Generate a candidate solution using a hybrid approach\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly select a subset of items to flip (1 to 3 items)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility by removing excess items if necessary\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with the lowest marginal contribution (weight / (value1 + value2))\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal contribution for included items\n            included = np.where(new_solution == 1)[0]\n            marginal_contributions = (weight_lst[included] /\n                                    (value1_lst[included] + value2_lst[included] + 1e-6))\n            # Remove the item with the lowest marginal contribution\n            remove_idx = included[np.argmin(marginal_contributions)]\n            new_solution[remove_idx] = 0\n            excess = np.sum(weight_lst[new_solution == 1]) - capacity\n\n    # Step 3: Add items with high marginal contribution if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate marginal contribution for excluded items\n        excluded = np.where(new_solution == 0)[0]\n        marginal_contributions = (value1_lst[excluded] + value2_lst[excluded]) / (weight_lst[excluded] + 1e-6)\n        # Sort by marginal contribution in descending order\n        sorted_indices = excluded[np.argsort(-marginal_contributions)]\n        # Add items until capacity is reached\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n            else:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.3411425671513279,
            4.27432844042778
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a preference for those closer to the Pareto front\n    weights = np.array([1.0 / (i + 1) for i in range(len(archive))])  # Higher weight for earlier (better?) solutions\n    weights = weights / weights.sum()  # Normalize\n    selected = random.choices(archive, weights=weights, k=1)[0]\n    base_solution = selected[0].copy()\n    current_obj = selected[1]\n\n    # Generate a candidate solution using a hybrid approach\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly select a subset of items to flip (1 to 3 items)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Ensure feasibility by removing excess items if necessary\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # Remove items with the lowest marginal contribution (weight / (value1 + value2))\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal contribution for included items\n            included = np.where(new_solution == 1)[0]\n            marginal_contributions = (weight_lst[included] /\n                                    (value1_lst[included] + value2_lst[included] + 1e-6))\n            # Remove the item with the lowest marginal contribution\n            remove_idx = included[np.argmin(marginal_contributions)]\n            new_solution[remove_idx] = 0\n            excess = np.sum(weight_lst[new_solution == 1]) - capacity\n\n    # Step 3: Add items with high marginal contribution if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_capacity > 0:\n        # Calculate marginal contribution for excluded items\n        excluded = np.where(new_solution == 0)[0]\n        marginal_contributions = (value1_lst[excluded] + value2_lst[excluded]) / (weight_lst[excluded] + 1e-6)\n        # Sort by marginal contribution in descending order\n        sorted_indices = excluded[np.argsort(-marginal_contributions)]\n        # Add items until capacity is reached\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n            else:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 66,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate potential improvement score (difference from ideal)\n    ideal_obj1 = max(obj[0] for obj in archive_objectives)\n    ideal_obj2 = max(obj[1] for obj in archive_objectives)\n    improvement_scores = [(ideal_obj1 - obj[0] + ideal_obj2 - obj[1]) for obj in archive_objectives]\n\n    # Select top 30% solutions with highest improvement potential\n    top_indices = np.argsort(improvement_scores)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a small subset of items (1-3)\n    flip_count = np.random.randint(1, 4)\n    flip_indices = np.random.choice(n_items, flip_count, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        sorted_indices = np.argsort(weight_lst * new_solution)\n        for idx in sorted_indices[::-1]:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n                if excess <= 0:\n                    break\n\n    # Step 2: Add items with high marginal value-to-weight ratio\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal ratios for items not in solution\n        marginal_ratios = (value1_lst + value2_lst) / weight_lst\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Sort by descending marginal ratio\n            sorted_candidates = candidate_indices[np.argsort(marginal_ratios[candidate_indices])[::-1]]\n            for idx in sorted_candidates:\n                if weight_lst[idx] <= remaining_weight:\n                    new_solution[idx] = 1\n                    remaining_weight -= weight_lst[idx]\n                    if remaining_weight <= 0:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.4060759491109963,
            5.730576395988464
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate potential improvement score (difference from ideal)\n    ideal_obj1 = max(obj[0] for obj in archive_objectives)\n    ideal_obj2 = max(obj[1] for obj in archive_objectives)\n    improvement_scores = [(ideal_obj1 - obj[0] + ideal_obj2 - obj[1]) for obj in archive_objectives]\n\n    # Select top 30% solutions with highest improvement potential\n    top_indices = np.argsort(improvement_scores)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a small subset of items (1-3)\n    flip_count = np.random.randint(1, 4)\n    flip_indices = np.random.choice(n_items, flip_count, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        sorted_indices = np.argsort(weight_lst * new_solution)\n        for idx in sorted_indices[::-1]:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n                if excess <= 0:\n                    break\n\n    # Step 2: Add items with high marginal value-to-weight ratio\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal ratios for items not in solution\n        marginal_ratios = (value1_lst + value2_lst) / weight_lst\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Sort by descending marginal ratio\n            sorted_candidates = candidate_indices[np.argsort(marginal_ratios[candidate_indices])[::-1]]\n            for idx in sorted_candidates:\n                if weight_lst[idx] <= remaining_weight:\n                    new_solution[idx] = 1\n                    remaining_weight -= weight_lst[idx]\n                    if remaining_weight <= 0:\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 67,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (perturbation)\n    # 2. Perform a value-based swap to improve the solution\n\n    # Step 1: Random perturbation (flip 10-20% of items)\n    flip_count = np.random.randint(max(1, n_items // 10), max(2, n_items // 5))\n    flip_indices = np.random.choice(n_items, flip_count, replace=False)\n    for idx in flip_indices:\n        # Flip the item and check feasibility\n        if new_solution[idx] == 1:\n            if (np.sum(new_solution * weight_lst) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            if (np.sum(new_solution * weight_lst) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Value-based swap (swap items with high value ratio)\n    # Calculate value ratios for both objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-8)\n    value_ratio2 = value2_lst / (weight_lst + 1e-8)\n\n    # Combine ratios and select top candidates\n    combined_ratio = value_ratio1 + value_ratio2\n    top_candidates = np.argsort(-combined_ratio)[:min(10, n_items)]\n\n    # Try to swap items with top candidates\n    for idx in top_candidates:\n        if new_solution[idx] == 1:\n            # Try to exclude this item if it's included\n            if (np.sum(new_solution * weight_lst) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to include this item if it's excluded\n            if (np.sum(new_solution * weight_lst) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3980421233091487,
            4.001521021127701
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a few items (perturbation)\n    # 2. Perform a value-based swap to improve the solution\n\n    # Step 1: Random perturbation (flip 10-20% of items)\n    flip_count = np.random.randint(max(1, n_items // 10), max(2, n_items // 5))\n    flip_indices = np.random.choice(n_items, flip_count, replace=False)\n    for idx in flip_indices:\n        # Flip the item and check feasibility\n        if new_solution[idx] == 1:\n            if (np.sum(new_solution * weight_lst) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            if (np.sum(new_solution * weight_lst) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Value-based swap (swap items with high value ratio)\n    # Calculate value ratios for both objectives\n    value_ratio1 = value1_lst / (weight_lst + 1e-8)\n    value_ratio2 = value2_lst / (weight_lst + 1e-8)\n\n    # Combine ratios and select top candidates\n    combined_ratio = value_ratio1 + value_ratio2\n    top_candidates = np.argsort(-combined_ratio)[:min(10, n_items)]\n\n    # Try to swap items with top candidates\n    for idx in top_candidates:\n        if new_solution[idx] == 1:\n            # Try to exclude this item if it's included\n            if (np.sum(new_solution * weight_lst) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to include this item if it's excluded\n            if (np.sum(new_solution * weight_lst) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 68,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with probability proportional to its objective values\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    if np.sum(total_values) == 0:\n        probabilities = np.ones(len(archive)) / len(archive)\n    else:\n        probabilities = total_values / np.sum(total_values)\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Determine the number of flips (between 1 and min(10, N))\n    num_flips = min(10, len(weight_lst))\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n\n    # Hybrid flip strategy: combine random, value-based, and weight-based flips\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, decide to remove it based on its marginal contribution\n            marginal_value1 = value1_lst[idx]\n            marginal_value2 = value2_lst[idx]\n            marginal_weight = weight_lst[idx]\n\n            # Probability of removal is higher if the item has low value or high weight\n            remove_prob = 0.5 * (1 - (marginal_value1 + marginal_value2) / (np.sum(value1_lst) + np.sum(value2_lst))) + \\\n                          0.5 * (marginal_weight / capacity)\n            if random.random() < remove_prob and current_weight - marginal_weight >= 0:\n                new_solution[idx] = 0\n                current_weight -= marginal_weight\n        else:\n            # If item is excluded, decide to include it based on its marginal contribution\n            marginal_value1 = value1_lst[idx]\n            marginal_value2 = value2_lst[idx]\n            marginal_weight = weight_lst[idx]\n\n            # Probability of inclusion is higher if the item has high value or low weight\n            include_prob = 0.5 * ((marginal_value1 + marginal_value2) / (np.sum(value1_lst) + np.sum(value2_lst))) + \\\n                           0.5 * (1 - marginal_weight / capacity)\n            if random.random() < include_prob and current_weight + marginal_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight += marginal_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3881824200528678,
            2.2330272793769836
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with probability proportional to its objective values\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    if np.sum(total_values) == 0:\n        probabilities = np.ones(len(archive)) / len(archive)\n    else:\n        probabilities = total_values / np.sum(total_values)\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Determine the number of flips (between 1 and min(10, N))\n    num_flips = min(10, len(weight_lst))\n    flip_indices = random.sample(range(len(weight_lst)), num_flips)\n\n    # Hybrid flip strategy: combine random, value-based, and weight-based flips\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If item is included, decide to remove it based on its marginal contribution\n            marginal_value1 = value1_lst[idx]\n            marginal_value2 = value2_lst[idx]\n            marginal_weight = weight_lst[idx]\n\n            # Probability of removal is higher if the item has low value or high weight\n            remove_prob = 0.5 * (1 - (marginal_value1 + marginal_value2) / (np.sum(value1_lst) + np.sum(value2_lst))) + \\\n                          0.5 * (marginal_weight / capacity)\n            if random.random() < remove_prob and current_weight - marginal_weight >= 0:\n                new_solution[idx] = 0\n                current_weight -= marginal_weight\n        else:\n            # If item is excluded, decide to include it based on its marginal contribution\n            marginal_value1 = value1_lst[idx]\n            marginal_value2 = value2_lst[idx]\n            marginal_weight = weight_lst[idx]\n\n            # Probability of inclusion is higher if the item has high value or low weight\n            include_prob = 0.5 * ((marginal_value1 + marginal_value2) / (np.sum(value1_lst) + np.sum(value2_lst))) + \\\n                           0.5 * (1 - marginal_weight / capacity)\n            if random.random() < include_prob and current_weight + marginal_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight += marginal_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 69,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified: higher value1 + value2)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution from the middle to avoid extremes\n        base_solution = archive_sorted[len(archive) // 2][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine bit-flip and swap\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly select a number of bits to flip (1 to min(5, n_items//2))\n    n_flips = np.random.randint(1, min(5, n_items // 2) + 1)\n\n    for _ in range(n_flips):\n        # Randomly select an item to flip\n        idx = np.random.randint(0, n_items)\n        if base_solution[idx] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Optionally perform a swap if weight allows\n    if np.random.rand() < 0.5 and n_items >= 2:\n        idx1, idx2 = np.random.choice(np.where(new_solution == 1)[0], size=2, replace=False)\n        # Swap only if weight difference is within capacity\n        if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "score": [
            -0.871748931960371,
            0.9177767038345337
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified: higher value1 + value2)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution from the middle to avoid extremes\n        base_solution = archive_sorted[len(archive) // 2][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine bit-flip and swap\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly select a number of bits to flip (1 to min(5, n_items//2))\n    n_flips = np.random.randint(1, min(5, n_items // 2) + 1)\n\n    for _ in range(n_flips):\n        # Randomly select an item to flip\n        idx = np.random.randint(0, n_items)\n        if base_solution[idx] == 1:\n            # If item is included, try to remove it\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to add it\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Optionally perform a swap if weight allows\n    if np.random.rand() < 0.5 and n_items >= 2:\n        idx1, idx2 = np.random.choice(np.where(new_solution == 1)[0], size=2, replace=False)\n        # Swap only if weight difference is within capacity\n        if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 70,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Prefer solutions that are not too close to the boundary (not too tight or too loose)\n    weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    tightness = np.abs(weights - capacity * 0.7)  # Prefer solutions around 70% capacity\n    selected_idx = np.argmin(tightness)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combine random flips with objective-aware flips\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Objective-aware flip: flip items that improve both objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item if it fits\n            if weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                remaining_capacity -= weight_lst[i]\n\n    # Random flip: flip a random item to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance of random flip\n        candidate_indices = np.where(new_solution != base_solution)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = np.random.choice(candidate_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If infeasible, remove items until feasible (greedy removal)\n        over_weight = new_weight - capacity\n        items_sorted = np.argsort(weight_lst * new_solution)\n        for i in reversed(items_sorted):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                over_weight -= weight_lst[i]\n                if over_weight <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8175605922555089,
            2.845208615064621
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Prefer solutions that are not too close to the boundary (not too tight or too loose)\n    weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    tightness = np.abs(weights - capacity * 0.7)  # Prefer solutions around 70% capacity\n    selected_idx = np.argmin(tightness)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combine random flips with objective-aware flips\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Objective-aware flip: flip items that improve both objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item if it fits\n            if weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                remaining_capacity -= weight_lst[i]\n\n    # Random flip: flip a random item to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance of random flip\n        candidate_indices = np.where(new_solution != base_solution)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = np.random.choice(candidate_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If infeasible, remove items until feasible (greedy removal)\n        over_weight = new_weight - capacity\n        items_sorted = np.argsort(weight_lst * new_solution)\n        for i in reversed(items_sorted):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                over_weight -= weight_lst[i]\n                if over_weight <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 71,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we select the solution with the highest sum of normalized marginal utilities\n    marginal_utilities = []\n    for sol, _ in archive:\n        included = np.where(sol == 1)[0]\n        excluded = np.where(sol == 0)[0]\n\n        # Calculate marginal utility for excluded items\n        if len(excluded) > 0:\n            excluded_utilities = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n            max_excluded_util = np.max(excluded_utilities)\n        else:\n            max_excluded_util = 0\n\n        # Calculate marginal utility for included items\n        if len(included) > 0:\n            included_utilities = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n            min_included_util = np.min(included_utilities)\n        else:\n            min_included_util = 0\n\n        marginal_utilities.append(max_excluded_util - min_included_util)\n\n    # Select the solution with highest potential improvement\n    selected_idx = np.argmax(marginal_utilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal utility first, then random flips\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[included])\n\n    # First, try to add high-margin items that fit\n    if len(excluded) > 0:\n        # Calculate marginal utility for excluded items\n        excluded_utilities = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n        sorted_indices = np.argsort(excluded_utilities)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            item_idx = excluded[idx]\n            if current_weight + weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Then, try to remove low-margin items\n    if len(included) > 0:\n        # Calculate marginal utility for included items\n        included_utilities = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        sorted_indices = np.argsort(included_utilities)  # Ascending order\n\n        for idx in sorted_indices:\n            item_idx = included[idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n            # Check if solution is still feasible\n            if np.sum(weight_lst[new_solution == 1]) <= capacity:\n                break  # Keep one low-margin item removed\n            else:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Finally, perform a random flip to escape local optima\n    if len(included) > 0 and len(excluded) > 0:\n        # Randomly choose an included item to remove\n        item_to_remove = random.choice(included)\n        new_solution[item_to_remove] = 0\n        current_weight -= weight_lst[item_to_remove]\n\n        # Randomly choose an excluded item to add that fits\n        available_excluded = [i for i in excluded if weight_lst[i] <= (capacity - current_weight)]\n        if available_excluded:\n            item_to_add = random.choice(available_excluded)\n            new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9273700308381412,
            6.090930610895157
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we select the solution with the highest sum of normalized marginal utilities\n    marginal_utilities = []\n    for sol, _ in archive:\n        included = np.where(sol == 1)[0]\n        excluded = np.where(sol == 0)[0]\n\n        # Calculate marginal utility for excluded items\n        if len(excluded) > 0:\n            excluded_utilities = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n            max_excluded_util = np.max(excluded_utilities)\n        else:\n            max_excluded_util = 0\n\n        # Calculate marginal utility for included items\n        if len(included) > 0:\n            included_utilities = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n            min_included_util = np.min(included_utilities)\n        else:\n            min_included_util = 0\n\n        marginal_utilities.append(max_excluded_util - min_included_util)\n\n    # Select the solution with highest potential improvement\n    selected_idx = np.argmax(marginal_utilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items with high marginal utility first, then random flips\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[included])\n\n    # First, try to add high-margin items that fit\n    if len(excluded) > 0:\n        # Calculate marginal utility for excluded items\n        excluded_utilities = (value1_lst[excluded] + value2_lst[excluded]) / weight_lst[excluded]\n        sorted_indices = np.argsort(excluded_utilities)[::-1]  # Descending order\n\n        for idx in sorted_indices:\n            item_idx = excluded[idx]\n            if current_weight + weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Then, try to remove low-margin items\n    if len(included) > 0:\n        # Calculate marginal utility for included items\n        included_utilities = (value1_lst[included] + value2_lst[included]) / weight_lst[included]\n        sorted_indices = np.argsort(included_utilities)  # Ascending order\n\n        for idx in sorted_indices:\n            item_idx = included[idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n            # Check if solution is still feasible\n            if np.sum(weight_lst[new_solution == 1]) <= capacity:\n                break  # Keep one low-margin item removed\n            else:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Finally, perform a random flip to escape local optima\n    if len(included) > 0 and len(excluded) > 0:\n        # Randomly choose an included item to remove\n        item_to_remove = random.choice(included)\n        new_solution[item_to_remove] = 0\n        current_weight -= weight_lst[item_to_remove]\n\n        # Randomly choose an excluded item to add that fits\n        available_excluded = [i for i in excluded if weight_lst[i] <= (capacity - current_weight)]\n        if available_excluded:\n            item_to_add = random.choice(available_excluded)\n            new_solution[item_to_add] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 72,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Randomly select a solution with probability inversely proportional to its dominance count\n        # (simplified heuristic: higher objective values are more likely to be selected)\n        weights = [obj[0] + obj[1] for _, obj in archive]\n        selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Randomly flip a subset of items (1-3 items)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        candidate_items = np.where(new_solution == 1)[0]\n        while excess_weight > 0 and len(candidate_items) > 0:\n            remove_idx = random.choice(candidate_items)\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n            candidate_items = np.where(new_solution == 1)[0]\n\n    # Step 3: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n            old_value1 = np.sum(value1_lst * new_solution)\n            old_value2 = np.sum(value2_lst * new_solution)\n\n            if (new_value1 > old_value1) and (new_value2 > old_value2):\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4271090726389245,
            7.8505373895168304
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Randomly select a solution with probability inversely proportional to its dominance count\n        # (simplified heuristic: higher objective values are more likely to be selected)\n        weights = [obj[0] + obj[1] for _, obj in archive]\n        selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip followed by greedy improvement\n    # Step 1: Randomly flip a subset of items (1-3 items)\n    n_items = len(weight_lst)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and repair if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        candidate_items = np.where(new_solution == 1)[0]\n        while excess_weight > 0 and len(candidate_items) > 0:\n            remove_idx = random.choice(candidate_items)\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n            candidate_items = np.where(new_solution == 1)[0]\n\n    # Step 3: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n            old_value1 = np.sum(value1_lst * new_solution)\n            old_value2 = np.sum(value2_lst * new_solution)\n\n            if (new_value1 > old_value1) and (new_value2 > old_value2):\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 73,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 0.9, len(archive)) / np.linspace(0.1, 0.9, len(archive)).sum())\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: Combine bit-flip with value-based selection\n    for _ in range(3):  # Number of local search steps\n        # Identify items that could be flipped (either included or excluded)\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        # Calculate potential improvements for each objective\n        if len(included) > 0:\n            # Evaluate removing items to free up capacity\n            remove_candidates = included[np.argsort(value1_lst[included] + value2_lst[included])][:max(1, len(included)//4)]\n            for item in remove_candidates:\n                if np.random.rand() < 0.7:  # Higher probability for items with lower combined value\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 0\n                    if np.dot(temp_solution, weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n        if len(excluded) > 0:\n            # Evaluate adding items to maximize both objectives\n            add_candidates = excluded[np.argsort(value1_lst[excluded] + value2_lst[excluded])[-max(1, len(excluded)//4):]]\n            for item in add_candidates:\n                if np.random.rand() < 0.7:  # Higher probability for items with higher combined value\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 1\n                    if np.dot(temp_solution, weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.34041707795922754,
            5.806856542825699
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 0.9, len(archive)) / np.linspace(0.1, 0.9, len(archive)).sum())\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: Combine bit-flip with value-based selection\n    for _ in range(3):  # Number of local search steps\n        # Identify items that could be flipped (either included or excluded)\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        # Calculate potential improvements for each objective\n        if len(included) > 0:\n            # Evaluate removing items to free up capacity\n            remove_candidates = included[np.argsort(value1_lst[included] + value2_lst[included])][:max(1, len(included)//4)]\n            for item in remove_candidates:\n                if np.random.rand() < 0.7:  # Higher probability for items with lower combined value\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 0\n                    if np.dot(temp_solution, weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n        if len(excluded) > 0:\n            # Evaluate adding items to maximize both objectives\n            add_candidates = excluded[np.argsort(value1_lst[excluded] + value2_lst[excluded])[-max(1, len(excluded)//4):]]\n            for item in add_candidates:\n                if np.random.rand() < 0.7:  # Higher probability for items with higher combined value\n                    temp_solution = new_solution.copy()\n                    temp_solution[item] = 1\n                    if np.dot(temp_solution, weight_lst) <= capacity:\n                        new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 74,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    # 1. Randomly select a subset of items to swap or flip\n    n_items = len(weight_lst)\n    subset_size = max(1, n_items // 10)  # Adjust subset size as needed\n    swap_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    # 2. Apply swap or flip operations to the subset\n    for idx in swap_indices:\n        # Flip operation: toggle the item's inclusion\n        if np.random.rand() < 0.7:  # Higher probability for flip\n            new_solution[idx] = 1 - new_solution[idx]\n        else:  # Swap with another random item\n            swap_idx = np.random.choice(n_items)\n            new_solution[idx], new_solution[swap_idx] = new_solution[swap_idx], new_solution[idx]\n\n    # Ensure feasibility: if the new solution exceeds capacity, remove the heaviest items\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Sort items by weight and remove the heaviest until feasible\n        sorted_indices = np.argsort(weight_lst[new_solution == 1])\n        for idx in sorted_indices[::-1]:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3782005194373734,
            1.9220519363880157
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with a high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine swap and flip operations\n    # 1. Randomly select a subset of items to swap or flip\n    n_items = len(weight_lst)\n    subset_size = max(1, n_items // 10)  # Adjust subset size as needed\n    swap_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    # 2. Apply swap or flip operations to the subset\n    for idx in swap_indices:\n        # Flip operation: toggle the item's inclusion\n        if np.random.rand() < 0.7:  # Higher probability for flip\n            new_solution[idx] = 1 - new_solution[idx]\n        else:  # Swap with another random item\n            swap_idx = np.random.choice(n_items)\n            new_solution[idx], new_solution[swap_idx] = new_solution[swap_idx], new_solution[idx]\n\n    # Ensure feasibility: if the new solution exceeds capacity, remove the heaviest items\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Sort items by weight and remove the heaviest until feasible\n        sorted_indices = np.argsort(weight_lst[new_solution == 1])\n        for idx in sorted_indices[::-1]:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 75,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: sum(x[0]) * (sum(value1_lst) + sum(value2_lst)))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip a subset of items based on their marginal contribution\n    n_items = len(new_solution)\n    flip_prob = 0.2  # Probability of flipping each item\n\n    for i in range(n_items):\n        if np.random.random() < flip_prob:\n            if new_solution[i] == 1:\n                # Try to remove item if it doesn't violate capacity\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to add item if it fits\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Additional refinement: flip items with highest marginal contribution\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    for i in sorted_indices:\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.41928917683843653,
            7.598717957735062
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: sum(x[0]) * (sum(value1_lst) + sum(value2_lst)))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: flip a subset of items based on their marginal contribution\n    n_items = len(new_solution)\n    flip_prob = 0.2  # Probability of flipping each item\n\n    for i in range(n_items):\n        if np.random.random() < flip_prob:\n            if new_solution[i] == 1:\n                # Try to remove item if it doesn't violate capacity\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to add item if it fits\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Additional refinement: flip items with highest marginal contribution\n    marginal_contribution = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-marginal_contribution)\n\n    for i in sorted_indices:\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n        elif new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 76,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate total values for each solution\n    total_values1 = np.array([obj[0] for _, obj in archive])\n    total_values2 = np.array([obj[1] for _, obj in archive])\n\n    # Normalize and combine the two objectives to create a composite score\n    max_value1 = np.max(total_values1) if np.max(total_values1) != 0 else 1\n    max_value2 = np.max(total_values2) if np.max(total_values2) != 0 else 1\n    normalized_values1 = total_values1 / max_value1\n    normalized_values2 = total_values2 / max_value2\n    composite_scores = normalized_values1 + normalized_values2\n\n    # Select a solution with probability proportional to its composite score\n    probs = composite_scores / np.sum(composite_scores)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a bit (with probability 0.5)\n    # 2. If the flip is feasible, keep it; otherwise, try another bit\n    # 3. If no feasible flip is found, perform a value-weighted flip\n\n    # Try random bit flips (up to 10 attempts)\n    for _ in range(10):\n        flip_idx = np.random.randint(0, len(new_solution))\n        current_weight = np.sum(weight_lst * new_solution)\n        new_weight = current_weight - weight_lst[flip_idx] * new_solution[flip_idx] + weight_lst[flip_idx] * (1 - new_solution[flip_idx])\n\n        if new_weight <= capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n\n    # If no random flip worked, perform a value-weighted flip\n    # Calculate the marginal value-to-weight ratio for each item\n    marginal_ratio1 = (value1_lst - value1_lst * new_solution) / weight_lst\n    marginal_ratio2 = (value2_lst - value2_lst * new_solution) / weight_lst\n\n    # Combine the two ratios\n    combined_ratio = marginal_ratio1 + marginal_ratio2\n\n    # Find the best feasible flip\n    for flip_idx in np.argsort(-combined_ratio):\n        current_weight = np.sum(weight_lst * new_solution)\n        new_weight = current_weight - weight_lst[flip_idx] * new_solution[flip_idx] + weight_lst[flip_idx] * (1 - new_solution[flip_idx])\n\n        if new_weight <= capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n\n    return new_solution\n\n",
        "score": [
            -0.866607896587104,
            2.1807519793510437
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate total values for each solution\n    total_values1 = np.array([obj[0] for _, obj in archive])\n    total_values2 = np.array([obj[1] for _, obj in archive])\n\n    # Normalize and combine the two objectives to create a composite score\n    max_value1 = np.max(total_values1) if np.max(total_values1) != 0 else 1\n    max_value2 = np.max(total_values2) if np.max(total_values2) != 0 else 1\n    normalized_values1 = total_values1 / max_value1\n    normalized_values2 = total_values2 / max_value2\n    composite_scores = normalized_values1 + normalized_values2\n\n    # Select a solution with probability proportional to its composite score\n    probs = composite_scores / np.sum(composite_scores)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a bit (with probability 0.5)\n    # 2. If the flip is feasible, keep it; otherwise, try another bit\n    # 3. If no feasible flip is found, perform a value-weighted flip\n\n    # Try random bit flips (up to 10 attempts)\n    for _ in range(10):\n        flip_idx = np.random.randint(0, len(new_solution))\n        current_weight = np.sum(weight_lst * new_solution)\n        new_weight = current_weight - weight_lst[flip_idx] * new_solution[flip_idx] + weight_lst[flip_idx] * (1 - new_solution[flip_idx])\n\n        if new_weight <= capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n\n    # If no random flip worked, perform a value-weighted flip\n    # Calculate the marginal value-to-weight ratio for each item\n    marginal_ratio1 = (value1_lst - value1_lst * new_solution) / weight_lst\n    marginal_ratio2 = (value2_lst - value2_lst * new_solution) / weight_lst\n\n    # Combine the two ratios\n    combined_ratio = marginal_ratio1 + marginal_ratio2\n\n    # Find the best feasible flip\n    for flip_idx in np.argsort(-combined_ratio):\n        current_weight = np.sum(weight_lst * new_solution)\n        new_weight = current_weight - weight_lst[flip_idx] * new_solution[flip_idx] + weight_lst[flip_idx] * (1 - new_solution[flip_idx])\n\n        if new_weight <= capacity:\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 77,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Only consider solutions that are not too close to capacity\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if none meet the criteria\n\n    # Select a solution with high potential for improvement\n    selected_sol, _ = random.choice(candidates)\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search strategy: combine item swaps and flips\n    n_items = len(weight_lst)\n    for _ in range(3):  # Perform a few local search steps\n        # Randomly select two items to swap\n        i, j = random.sample(range(n_items), 2)\n\n        # Check if swapping these items keeps the solution feasible\n        if new_solution[i] != new_solution[j]:\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                continue\n\n        # If swap didn't work, try flipping a random item\n        k = random.randint(0, n_items - 1)\n        if new_solution[k] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[k] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[k] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.45308352987273404,
            2.8040084540843964
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Only consider solutions that are not too close to capacity\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if none meet the criteria\n\n    # Select a solution with high potential for improvement\n    selected_sol, _ = random.choice(candidates)\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search strategy: combine item swaps and flips\n    n_items = len(weight_lst)\n    for _ in range(3):  # Perform a few local search steps\n        # Randomly select two items to swap\n        i, j = random.sample(range(n_items), 2)\n\n        # Check if swapping these items keeps the solution feasible\n        if new_solution[i] != new_solution[j]:\n            temp_solution = new_solution.copy()\n            temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                continue\n\n        # If swap didn't work, try flipping a random item\n        k = random.randint(0, n_items - 1)\n        if new_solution[k] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[k] = 0\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[k] = 1\n            temp_weight = np.sum(weight_lst * temp_solution)\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 78,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential = np.sum((value1_lst + value2_lst) * (1 - sol))  # Potential improvement if items not in solution are added\n        candidates.append((potential, sol))\n\n    # Sort by potential and select top 20% candidates\n    candidates.sort(reverse=True, key=lambda x: x[0])\n    top_candidates = [sol for _, sol in candidates[:max(1, len(candidates) // 5)]]\n\n    if not top_candidates:\n        base_solution = archive[np.random.randint(len(archive))][0].copy()\n    else:\n        base_solution = top_candidates[np.random.randint(len(top_candidates))].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly select a subset of items to consider for swapping\n    num_items = len(weight_lst)\n    subset_size = min(5, num_items)\n    swap_indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n    # 2. Evaluate each swap and select the best one that improves both objectives\n    best_improvement = -np.inf\n    best_swap = None\n\n    for i in swap_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n\n        # Check feasibility\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight > capacity:\n            continue\n\n        # Calculate objective improvements\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n        new_value1 = np.sum(value1_lst * temp_solution)\n        new_value2 = np.sum(value2_lst * temp_solution)\n\n        # Use a combined objective function to balance improvements\n        improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_swap = i\n\n    # Apply the best swap if found\n    if best_swap is not None:\n        new_solution[best_swap] = 1 - new_solution[best_swap]\n\n    # 3. If no improvement found, perform a random walk to escape local optima\n    if best_improvement <= 0:\n        # Randomly select 2 items to swap\n        swap_indices = np.random.choice(num_items, size=2, replace=False)\n        i, j = swap_indices\n\n        # Try swapping the items\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        # Check feasibility\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.7890663955150696,
            4.769759982824326
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential = np.sum((value1_lst + value2_lst) * (1 - sol))  # Potential improvement if items not in solution are added\n        candidates.append((potential, sol))\n\n    # Sort by potential and select top 20% candidates\n    candidates.sort(reverse=True, key=lambda x: x[0])\n    top_candidates = [sol for _, sol in candidates[:max(1, len(candidates) // 5)]]\n\n    if not top_candidates:\n        base_solution = archive[np.random.randint(len(archive))][0].copy()\n    else:\n        base_solution = top_candidates[np.random.randint(len(top_candidates))].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Randomly select a subset of items to consider for swapping\n    num_items = len(weight_lst)\n    subset_size = min(5, num_items)\n    swap_indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n    # 2. Evaluate each swap and select the best one that improves both objectives\n    best_improvement = -np.inf\n    best_swap = None\n\n    for i in swap_indices:\n        # Try flipping the item\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n\n        # Check feasibility\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight > capacity:\n            continue\n\n        # Calculate objective improvements\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n        new_value1 = np.sum(value1_lst * temp_solution)\n        new_value2 = np.sum(value2_lst * temp_solution)\n\n        # Use a combined objective function to balance improvements\n        improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_swap = i\n\n    # Apply the best swap if found\n    if best_swap is not None:\n        new_solution[best_swap] = 1 - new_solution[best_swap]\n\n    # 3. If no improvement found, perform a random walk to escape local optima\n    if best_improvement <= 0:\n        # Randomly select 2 items to swap\n        swap_indices = np.random.choice(num_items, size=2, replace=False)\n        i, j = swap_indices\n\n        # Try swapping the items\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        # Check feasibility\n        temp_weight = np.sum(weight_lst * temp_solution)\n        if temp_weight <= capacity:\n            new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 79,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random swaps with value-based swaps\n    n_items = len(base_solution)\n\n    # Random swap: flip a random bit\n    if np.random.random() < 0.5:\n        flip_idx = np.random.randint(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        # Ensure feasibility\n        if np.sum(weight_lst * new_solution) > capacity:\n            new_solution[flip_idx] = base_solution[flip_idx]\n    else:\n        # Value-based swap: swap items with high marginal value improvement\n        included = np.where(base_solution == 1)[0]\n        excluded = np.where(base_solution == 0)[0]\n\n        # Calculate marginal values for excluded items\n        if len(excluded) > 0:\n            marginal_value1 = value1_lst[excluded]\n            marginal_value2 = value2_lst[excluded]\n            marginal_weights = weight_lst[excluded]\n\n            # Select top 20% of excluded items by combined value\n            top_indices = np.argsort(marginal_value1 + marginal_value2)[-max(1, len(excluded)//5):]\n            candidate_indices = excluded[top_indices]\n\n            # Try to include one of the top candidates\n            for idx in candidate_indices:\n                if marginal_weights[np.where(excluded == idx)[0][0]] + np.sum(weight_lst * base_solution) <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n        # Calculate marginal values for included items\n        if len(included) > 0:\n            marginal_value1 = value1_lst[included]\n            marginal_value2 = value2_lst[included]\n            marginal_weights = weight_lst[included]\n\n            # Select bottom 20% of included items by combined value\n            bottom_indices = np.argsort(marginal_value1 + marginal_value2)[:max(1, len(included)//5)]\n            candidate_indices = included[bottom_indices]\n\n            # Try to exclude one of the bottom candidates\n            for idx in candidate_indices:\n                new_solution[idx] = 0\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    break\n                else:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.531646654610813,
            6.943724304437637
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random swaps with value-based swaps\n    n_items = len(base_solution)\n\n    # Random swap: flip a random bit\n    if np.random.random() < 0.5:\n        flip_idx = np.random.randint(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        # Ensure feasibility\n        if np.sum(weight_lst * new_solution) > capacity:\n            new_solution[flip_idx] = base_solution[flip_idx]\n    else:\n        # Value-based swap: swap items with high marginal value improvement\n        included = np.where(base_solution == 1)[0]\n        excluded = np.where(base_solution == 0)[0]\n\n        # Calculate marginal values for excluded items\n        if len(excluded) > 0:\n            marginal_value1 = value1_lst[excluded]\n            marginal_value2 = value2_lst[excluded]\n            marginal_weights = weight_lst[excluded]\n\n            # Select top 20% of excluded items by combined value\n            top_indices = np.argsort(marginal_value1 + marginal_value2)[-max(1, len(excluded)//5):]\n            candidate_indices = excluded[top_indices]\n\n            # Try to include one of the top candidates\n            for idx in candidate_indices:\n                if marginal_weights[np.where(excluded == idx)[0][0]] + np.sum(weight_lst * base_solution) <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n        # Calculate marginal values for included items\n        if len(included) > 0:\n            marginal_value1 = value1_lst[included]\n            marginal_value2 = value2_lst[included]\n            marginal_weights = weight_lst[included]\n\n            # Select bottom 20% of included items by combined value\n            bottom_indices = np.argsort(marginal_value1 + marginal_value2)[:max(1, len(included)//5)]\n            candidate_indices = included[bottom_indices]\n\n            # Try to exclude one of the bottom candidates\n            for idx in candidate_indices:\n                new_solution[idx] = 0\n                if np.sum(weight_lst * new_solution) <= capacity:\n                    break\n                else:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 80,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement: those with low objective values relative to their weight\n    objectives = np.array([obj for sol, obj in archive])\n    weights = np.array([np.sum(weight_lst[sol[0]]) for sol, obj in archive])\n    value_ratios = (objectives[:, 0] + objectives[:, 1]) / (weights + 1e-6)\n\n    # Select solutions with the lowest value-to-weight ratio (potential for improvement)\n    sorted_indices = np.argsort(value_ratios)\n    selected_idx = np.random.choice(sorted_indices[:max(1, len(sorted_indices) // 3)])\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine item swapping and probabilistic flipping\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # 1. Item swapping (swap two items if it improves both objectives)\n    for _ in range(min(3, n_items // 2)):\n        i, j = np.random.choice(n_items, 2, replace=False)\n        if new_solution[i] == new_solution[j]:\n            continue\n\n        # Calculate potential new weight\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] else (weight_lst[i] - weight_lst[j])\n        if current_weight + delta_weight > capacity:\n            continue\n\n        # If swap improves both objectives, perform it\n        if (value1_lst[i] + value1_lst[j] > value1_lst[i] + value1_lst[j]) and (value2_lst[i] + value2_lst[j] > value2_lst[i] + value2_lst[j]):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n\n    # 2. Probabilistic flipping (flip bits with probability based on value improvement)\n    for i in range(n_items):\n        if np.random.random() < 0.2:  # 20% probability of flipping\n            if new_solution[i]:\n                # If removing item keeps solution feasible\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If adding item keeps solution feasible\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4293853898225587,
            3.0929082334041595
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement: those with low objective values relative to their weight\n    objectives = np.array([obj for sol, obj in archive])\n    weights = np.array([np.sum(weight_lst[sol[0]]) for sol, obj in archive])\n    value_ratios = (objectives[:, 0] + objectives[:, 1]) / (weights + 1e-6)\n\n    # Select solutions with the lowest value-to-weight ratio (potential for improvement)\n    sorted_indices = np.argsort(value_ratios)\n    selected_idx = np.random.choice(sorted_indices[:max(1, len(sorted_indices) // 3)])\n    base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine item swapping and probabilistic flipping\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # 1. Item swapping (swap two items if it improves both objectives)\n    for _ in range(min(3, n_items // 2)):\n        i, j = np.random.choice(n_items, 2, replace=False)\n        if new_solution[i] == new_solution[j]:\n            continue\n\n        # Calculate potential new weight\n        delta_weight = (weight_lst[j] - weight_lst[i]) if new_solution[i] else (weight_lst[i] - weight_lst[j])\n        if current_weight + delta_weight > capacity:\n            continue\n\n        # If swap improves both objectives, perform it\n        if (value1_lst[i] + value1_lst[j] > value1_lst[i] + value1_lst[j]) and (value2_lst[i] + value2_lst[j] > value2_lst[i] + value2_lst[j]):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n\n    # 2. Probabilistic flipping (flip bits with probability based on value improvement)\n    for i in range(n_items):\n        if np.random.random() < 0.2:  # 20% probability of flipping\n            if new_solution[i]:\n                # If removing item keeps solution feasible\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If adding item keeps solution feasible\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 81,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution = random.choice(archive)[0].copy()\n    current_weight = np.sum(weight_lst[selected_solution == 1])\n    current_value1 = np.sum(value1_lst[selected_solution == 1])\n    current_value2 = np.sum(value2_lst[selected_solution == 1])\n\n    # Hybrid local search: random swaps with greedy evaluation\n    for _ in range(10):  # Number of attempts to find a better neighbor\n        # Randomly select two items to swap (add/remove)\n        idx1, idx2 = random.sample(range(len(selected_solution)), 2)\n\n        # Create a candidate solution by swapping the two items\n        candidate = selected_solution.copy()\n        candidate[idx1], candidate[idx2] = candidate[idx2], candidate[idx1]\n\n        # Check feasibility\n        candidate_weight = np.sum(weight_lst[candidate == 1])\n        if candidate_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        # Evaluate the candidate\n        candidate_value1 = np.sum(value1_lst[candidate == 1])\n        candidate_value2 = np.sum(value2_lst[candidate == 1])\n\n        # Accept the candidate if it improves both objectives\n        if (candidate_value1 > current_value1 and candidate_value2 > current_value2) or \\\n           (candidate_value1 >= current_value1 and candidate_value2 >= current_value2 and candidate_weight <= capacity):\n            selected_solution = candidate\n            current_weight = candidate_weight\n            current_value1 = candidate_value1\n            current_value2 = candidate_value2\n\n    # If no improvement found, perform a random feasible flip\n    if np.array_equal(selected_solution, archive[0][0]):\n        # Find a feasible flip\n        for _ in range(20):\n            idx = random.randint(0, len(selected_solution) - 1)\n            if selected_solution[idx] == 1:\n                # Try to remove the item\n                if current_weight - weight_lst[idx] <= capacity:\n                    selected_solution[idx] = 0\n                    break\n            else:\n                # Try to add the item\n                if current_weight + weight_lst[idx] <= capacity:\n                    selected_solution[idx] = 1\n                    break\n\n    return selected_solution\n\n",
        "score": [
            -0.2726098887400764,
            2.8678970336914062
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution = random.choice(archive)[0].copy()\n    current_weight = np.sum(weight_lst[selected_solution == 1])\n    current_value1 = np.sum(value1_lst[selected_solution == 1])\n    current_value2 = np.sum(value2_lst[selected_solution == 1])\n\n    # Hybrid local search: random swaps with greedy evaluation\n    for _ in range(10):  # Number of attempts to find a better neighbor\n        # Randomly select two items to swap (add/remove)\n        idx1, idx2 = random.sample(range(len(selected_solution)), 2)\n\n        # Create a candidate solution by swapping the two items\n        candidate = selected_solution.copy()\n        candidate[idx1], candidate[idx2] = candidate[idx2], candidate[idx1]\n\n        # Check feasibility\n        candidate_weight = np.sum(weight_lst[candidate == 1])\n        if candidate_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        # Evaluate the candidate\n        candidate_value1 = np.sum(value1_lst[candidate == 1])\n        candidate_value2 = np.sum(value2_lst[candidate == 1])\n\n        # Accept the candidate if it improves both objectives\n        if (candidate_value1 > current_value1 and candidate_value2 > current_value2) or \\\n           (candidate_value1 >= current_value1 and candidate_value2 >= current_value2 and candidate_weight <= capacity):\n            selected_solution = candidate\n            current_weight = candidate_weight\n            current_value1 = candidate_value1\n            current_value2 = candidate_value2\n\n    # If no improvement found, perform a random feasible flip\n    if np.array_equal(selected_solution, archive[0][0]):\n        # Find a feasible flip\n        for _ in range(20):\n            idx = random.randint(0, len(selected_solution) - 1)\n            if selected_solution[idx] == 1:\n                # Try to remove the item\n                if current_weight - weight_lst[idx] <= capacity:\n                    selected_solution[idx] = 0\n                    break\n            else:\n                # Try to add the item\n                if current_weight + weight_lst[idx] <= capacity:\n                    selected_solution[idx] = 1\n                    break\n\n    return selected_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 82,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on potential for improvement\n    # Solutions with higher potential are those that are not fully packed and have room for better items\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential = (capacity - current_weight) / capacity\n        candidates.append((sol, potential))\n\n    # Sort candidates by potential (descending) and select top 10% or at least 1\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = [c[0] for c in candidates[:max(1, len(candidates)//10)]]\n    base_solution = random.choice(top_candidates).copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to swap (exploration)\n    # 2. Apply a greedy improvement step to maximize both objectives (exploitation)\n\n    # Step 1: Random swaps (exploration)\n    items_to_swap = random.sample(range(len(weight_lst)), min(5, len(weight_lst)))\n    for i in items_to_swap:\n        if random.random() < 0.5:  # 50% chance to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility after random swaps\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove heaviest items until feasible\n        while current_weight > capacity:\n            heaviest_included = np.where((new_solution == 1) & (weight_lst > 0))[0]\n            if len(heaviest_included) == 0:\n                break\n            idx = heaviest_included[np.argmax(weight_lst[heaviest_included])]\n            new_solution[idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for exploration\n\n    for i in remaining_items:\n        if current_weight + weight_lst[i] <= capacity:\n            # Check if adding this item improves both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Simple greedy condition: accept if both objectives improve\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3464761817349639,
            4.763850033283234
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on potential for improvement\n    # Solutions with higher potential are those that are not fully packed and have room for better items\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential = (capacity - current_weight) / capacity\n        candidates.append((sol, potential))\n\n    # Sort candidates by potential (descending) and select top 10% or at least 1\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = [c[0] for c in candidates[:max(1, len(candidates)//10)]]\n    base_solution = random.choice(top_candidates).copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to swap (exploration)\n    # 2. Apply a greedy improvement step to maximize both objectives (exploitation)\n\n    # Step 1: Random swaps (exploration)\n    items_to_swap = random.sample(range(len(weight_lst)), min(5, len(weight_lst)))\n    for i in items_to_swap:\n        if random.random() < 0.5:  # 50% chance to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility after random swaps\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove heaviest items until feasible\n        while current_weight > capacity:\n            heaviest_included = np.where((new_solution == 1) & (weight_lst > 0))[0]\n            if len(heaviest_included) == 0:\n                break\n            idx = heaviest_included[np.argmax(weight_lst[heaviest_included])]\n            new_solution[idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for exploration\n\n    for i in remaining_items:\n        if current_weight + weight_lst[i] <= capacity:\n            # Check if adding this item improves both objectives\n            current_value1 = np.sum(value1_lst * new_solution)\n            current_value2 = np.sum(value2_lst * new_solution)\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Simple greedy condition: accept if both objectives improve\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 83,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions with high potential for improvement\n    archive_solutions = [s[0] for s in archive]\n    archive_weights = np.array([np.sum(weight_lst[s]) for s in archive_solutions])\n    archive_values1 = np.array([np.sum(value1_lst[s]) for s in archive_solutions])\n    archive_values2 = np.array([np.sum(value2_lst[s]) for s in archive_solutions])\n\n    # Calculate potential improvement scores (normalized)\n    potential_scores = []\n    for i, sol in enumerate(archive_solutions):\n        current_weight = archive_weights[i]\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity <= 0:\n            potential_scores.append(0)\n            continue\n\n        # Calculate potential marginal utility for each objective\n        excluded_items = np.where(sol == 0)[0]\n        if len(excluded_items) == 0:\n            potential_scores.append(0)\n            continue\n\n        # Evaluate potential marginal utility for each objective\n        marginal_value1 = np.sum(value1_lst[excluded_items] / weight_lst[excluded_items])\n        marginal_value2 = np.sum(value2_lst[excluded_items] / weight_lst[excluded_items])\n\n        # Combine both objectives in a weighted sum (can be adjusted)\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n        potential_scores.append(combined_marginal)\n\n    # Select the solution with highest potential improvement\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Step 2: Generate neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution])\n\n    # Step 2.1: Random flip (with probability based on current solution quality)\n    flip_prob = 0.3 if np.sum(new_solution) / len(new_solution) < 0.5 else 0.1\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2.2: Greedy improvement for both objectives\n    # Calculate marginal utility for each item\n    marginal_utils = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                # Calculate combined marginal utility\n                marginal_util = 0.5 * (value1_lst[i] / weight_lst[i]) + 0.5 * (value2_lst[i] / weight_lst[i])\n                marginal_utils.append((i, marginal_util))\n            else:\n                marginal_utils.append((i, -np.inf))\n        else:\n            marginal_utils.append((i, -np.inf))\n\n    # Sort by marginal utility (descending)\n    marginal_utils.sort(key=lambda x: -x[1])\n\n    # Apply the best improvements that fit within capacity\n    for i, util in marginal_utils:\n        if util > 0 and new_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7843732655061819,
            4.914028763771057
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # We prioritize solutions with high potential for improvement\n    archive_solutions = [s[0] for s in archive]\n    archive_weights = np.array([np.sum(weight_lst[s]) for s in archive_solutions])\n    archive_values1 = np.array([np.sum(value1_lst[s]) for s in archive_solutions])\n    archive_values2 = np.array([np.sum(value2_lst[s]) for s in archive_solutions])\n\n    # Calculate potential improvement scores (normalized)\n    potential_scores = []\n    for i, sol in enumerate(archive_solutions):\n        current_weight = archive_weights[i]\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity <= 0:\n            potential_scores.append(0)\n            continue\n\n        # Calculate potential marginal utility for each objective\n        excluded_items = np.where(sol == 0)[0]\n        if len(excluded_items) == 0:\n            potential_scores.append(0)\n            continue\n\n        # Evaluate potential marginal utility for each objective\n        marginal_value1 = np.sum(value1_lst[excluded_items] / weight_lst[excluded_items])\n        marginal_value2 = np.sum(value2_lst[excluded_items] / weight_lst[excluded_items])\n\n        # Combine both objectives in a weighted sum (can be adjusted)\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n        potential_scores.append(combined_marginal)\n\n    # Select the solution with highest potential improvement\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Step 2: Generate neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution])\n\n    # Step 2.1: Random flip (with probability based on current solution quality)\n    flip_prob = 0.3 if np.sum(new_solution) / len(new_solution) < 0.5 else 0.1\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2.2: Greedy improvement for both objectives\n    # Calculate marginal utility for each item\n    marginal_utils = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                # Calculate combined marginal utility\n                marginal_util = 0.5 * (value1_lst[i] / weight_lst[i]) + 0.5 * (value2_lst[i] / weight_lst[i])\n                marginal_utils.append((i, marginal_util))\n            else:\n                marginal_utils.append((i, -np.inf))\n        else:\n            marginal_utils.append((i, -np.inf))\n\n    # Sort by marginal utility (descending)\n    marginal_utils.sort(key=lambda x: -x[1])\n\n    # Apply the best improvements that fit within capacity\n    for i, util in marginal_utils:\n        if util > 0 and new_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 84,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance scores (number of solutions that dominate each solution)\n    dominance_scores = np.zeros(len(archive))\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i == j:\n                continue\n            # Check if sol_j dominates sol_i\n            if (obj_j[0] >= obj_i[0] and obj_j[1] > obj_i[1]) or (obj_j[0] > obj_i[0] and obj_j[1] >= obj_i[1]):\n                dominance_scores[i] += 1\n\n    # Select solutions with the lowest dominance score (most promising)\n    min_dominance = np.min(dominance_scores)\n    candidates = [i for i, score in enumerate(dominance_scores) if score == min_dominance]\n\n    # Randomly select from candidates\n    selected_idx = random.choice(candidates)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search\n    # Randomly flip a subset of items (exploration)\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = total_weight - capacity\n        items_in_solution = np.where(new_solution == 1)[0]\n\n        while excess_weight > 0 and len(items_in_solution) > 0:\n            # Remove the item with the smallest ratio of weight to sum of values\n            ratios = (weight_lst[items_in_solution] /\n                     (value1_lst[items_in_solution] + value2_lst[items_in_solution] + 1e-6))\n            remove_idx = items_in_solution[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n            items_in_solution = np.where(new_solution == 1)[0]\n\n    # Step 3: Greedy improvement step (exploitation)\n    # For each item not in the solution, consider adding it if it improves both objectives\n    items_not_in_solution = np.where(new_solution == 0)[0]\n    current_total_weight = np.sum(weight_lst * new_solution)\n\n    for idx in items_not_in_solution:\n        if current_total_weight + weight_lst[idx] <= capacity:\n            # Calculate potential improvement in both objectives\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n\n            # If both values are positive, add the item\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[idx] = 1\n                current_total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3702275708409022,
            2.9728351831436157
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance scores (number of solutions that dominate each solution)\n    dominance_scores = np.zeros(len(archive))\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i == j:\n                continue\n            # Check if sol_j dominates sol_i\n            if (obj_j[0] >= obj_i[0] and obj_j[1] > obj_i[1]) or (obj_j[0] > obj_i[0] and obj_j[1] >= obj_i[1]):\n                dominance_scores[i] += 1\n\n    # Select solutions with the lowest dominance score (most promising)\n    min_dominance = np.min(dominance_scores)\n    candidates = [i for i, score in enumerate(dominance_scores) if score == min_dominance]\n\n    # Randomly select from candidates\n    selected_idx = random.choice(candidates)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search\n    # Randomly flip a subset of items (exploration)\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = total_weight - capacity\n        items_in_solution = np.where(new_solution == 1)[0]\n\n        while excess_weight > 0 and len(items_in_solution) > 0:\n            # Remove the item with the smallest ratio of weight to sum of values\n            ratios = (weight_lst[items_in_solution] /\n                     (value1_lst[items_in_solution] + value2_lst[items_in_solution] + 1e-6))\n            remove_idx = items_in_solution[np.argmin(ratios)]\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n            items_in_solution = np.where(new_solution == 1)[0]\n\n    # Step 3: Greedy improvement step (exploitation)\n    # For each item not in the solution, consider adding it if it improves both objectives\n    items_not_in_solution = np.where(new_solution == 0)[0]\n    current_total_weight = np.sum(weight_lst * new_solution)\n\n    for idx in items_not_in_solution:\n        if current_total_weight + weight_lst[idx] <= capacity:\n            # Calculate potential improvement in both objectives\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n\n            # If both values are positive, add the item\n            if delta_value1 > 0 and delta_value2 > 0:\n                new_solution[idx] = 1\n                current_total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 85,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with high potential for improvement\n    base_sol, (current_val1, current_val2) = random.choices(archive, weights=[1.0 / (i + 1) for i in range(len(archive))])[0]\n    new_solution = base_sol.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Number of attempts to improve\n        # Random swap between included and excluded items\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Select items to swap\n            swap_in = random.choice(excluded)\n            swap_out = random.choice(included)\n\n            # Check if swap is feasible\n            new_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n            if new_weight <= capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n                current_weight = new_weight\n\n        # Value-based flip: flip items with high marginal value\n        marginal_val1 = value1_lst - np.sum(value1_lst[new_solution == 1]) / len(new_solution)\n        marginal_val2 = value2_lst - np.sum(value2_lst[new_solution == 1]) / len(new_solution)\n\n        # Consider both objectives with random weighting\n        alpha = random.random()\n        marginal_val = alpha * marginal_val1 + (1 - alpha) * marginal_val2\n\n        # Flip items with positive marginal value\n        for item in np.argsort(marginal_val)[-3:]:  # Consider top 3 items\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            elif new_solution[item] == 1:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.33100289726579285,
            4.9909957349300385
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with high potential for improvement\n    base_sol, (current_val1, current_val2) = random.choices(archive, weights=[1.0 / (i + 1) for i in range(len(archive))])[0]\n    new_solution = base_sol.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy\n    for _ in range(10):  # Number of attempts to improve\n        # Random swap between included and excluded items\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) > 0 and len(excluded) > 0:\n            # Select items to swap\n            swap_in = random.choice(excluded)\n            swap_out = random.choice(included)\n\n            # Check if swap is feasible\n            new_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n            if new_weight <= capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n                current_weight = new_weight\n\n        # Value-based flip: flip items with high marginal value\n        marginal_val1 = value1_lst - np.sum(value1_lst[new_solution == 1]) / len(new_solution)\n        marginal_val2 = value2_lst - np.sum(value2_lst[new_solution == 1]) / len(new_solution)\n\n        # Consider both objectives with random weighting\n        alpha = random.random()\n        marginal_val = alpha * marginal_val1 + (1 - alpha) * marginal_val2\n\n        # Flip items with positive marginal value\n        for item in np.argsort(marginal_val)[-3:]:  # Consider top 3 items\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n            elif new_solution[item] == 1:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 86,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the current archive extremes\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(solutions))\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort([obj[i] for obj in objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(solutions)-1):\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1]][i] - objectives[sorted_indices[j-1]][i])\n\n    # Select a solution with good crowding distance (not too crowded)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = solutions[selected_idx].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Random item swap (with weight feasibility check)\n    if random.random() < 0.3:\n        # Select two items to swap\n        idx1, idx2 = random.sample(range(n_items), 2)\n        if base_solution[idx1] != base_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            # Check feasibility\n            if np.dot(new_solution, weight_lst) > capacity:\n                # Undo if infeasible\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Strategy 2: Weighted item addition (objective-aware)\n    elif random.random() < 0.6:\n        # Calculate per-item marginal contributions\n        marginal1 = value1_lst / weight_lst\n        marginal2 = value2_lst / weight_lst\n\n        # Combine marginal contributions with random weights\n        alpha = random.random()\n        combined_marginal = alpha * marginal1 + (1 - alpha) * marginal2\n\n        # Sort items by combined marginal value\n        sorted_items = np.argsort(combined_marginal)[::-1]\n\n        # Try to add the most valuable items not currently in the knapsack\n        for idx in sorted_items:\n            if not base_solution[idx]:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n                    break\n\n    # Strategy 3: Objective-aware perturbation\n    else:\n        # Calculate current objective values\n        current_value1 = np.dot(new_solution, value1_lst)\n        current_value2 = np.dot(new_solution, value2_lst)\n\n        # Identify items that could improve the worse objective\n        worse_obj = 0 if current_value1 < current_value2 else 1\n        if worse_obj == 0:\n            # Try to improve value1\n            marginal = value1_lst / weight_lst\n        else:\n            # Try to improve value2\n            marginal = value2_lst / weight_lst\n\n        # Sort items by marginal value and try to add the most valuable ones\n        sorted_items = np.argsort(marginal)[::-1]\n        for idx in sorted_items:\n            if not base_solution[idx]:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.6980388733150642,
            6.3967702984809875
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the current archive extremes\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(solutions))\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort([obj[i] for obj in objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(solutions)-1):\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1]][i] - objectives[sorted_indices[j-1]][i])\n\n    # Select a solution with good crowding distance (not too crowded)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = solutions[selected_idx].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Random item swap (with weight feasibility check)\n    if random.random() < 0.3:\n        # Select two items to swap\n        idx1, idx2 = random.sample(range(n_items), 2)\n        if base_solution[idx1] != base_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            # Check feasibility\n            if np.dot(new_solution, weight_lst) > capacity:\n                # Undo if infeasible\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Strategy 2: Weighted item addition (objective-aware)\n    elif random.random() < 0.6:\n        # Calculate per-item marginal contributions\n        marginal1 = value1_lst / weight_lst\n        marginal2 = value2_lst / weight_lst\n\n        # Combine marginal contributions with random weights\n        alpha = random.random()\n        combined_marginal = alpha * marginal1 + (1 - alpha) * marginal2\n\n        # Sort items by combined marginal value\n        sorted_items = np.argsort(combined_marginal)[::-1]\n\n        # Try to add the most valuable items not currently in the knapsack\n        for idx in sorted_items:\n            if not base_solution[idx]:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n                    break\n\n    # Strategy 3: Objective-aware perturbation\n    else:\n        # Calculate current objective values\n        current_value1 = np.dot(new_solution, value1_lst)\n        current_value2 = np.dot(new_solution, value2_lst)\n\n        # Identify items that could improve the worse objective\n        worse_obj = 0 if current_value1 < current_value2 else 1\n        if worse_obj == 0:\n            # Try to improve value1\n            marginal = value1_lst / weight_lst\n        else:\n            # Try to improve value2\n            marginal = value2_lst / weight_lst\n\n        # Sort items by marginal value and try to add the most valuable ones\n        sorted_items = np.argsort(marginal)[::-1]\n        for idx in sorted_items:\n            if not base_solution[idx]:\n                temp_solution = new_solution.copy()\n                temp_solution[idx] = 1\n                if np.dot(temp_solution, weight_lst) <= capacity:\n                    new_solution = temp_solution\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 87,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prefer solutions that are not fully packed or have room for improvement in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity * 0.9:  # Prefer solutions that are not fully packed\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if no candidates found\n\n    # Randomly select a solution from the top 30% of candidates to encourage diversity\n    selected_idx = np.random.choice(min(3, len(candidates)), size=1)[0] if len(candidates) > 1 else 0\n    base_solution, base_obj = candidates[selected_idx]\n\n    # Hybrid local search operator: combine random flips with objective-aware swaps\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (1-3) to introduce diversity\n    flip_indices = np.random.choice(n_items, size=np.random.randint(1, 4), replace=False)\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility after flips\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items with lowest (value1 + value2) until feasible\n        while total_weight > capacity:\n            item_values = (value1_lst + value2_lst) * new_solution\n            remove_idx = np.argmax(item_values)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(new_solution * weight_lst)\n\n    # Step 2: Objective-aware swap - swap an item with a removed item if it improves both objectives\n    removed_items = np.where(base_solution != new_solution)[0]\n    if len(removed_items) > 0:\n        for i in removed_items:\n            if new_solution[i] == 1:  # Was removed, try to reinsert\n                if np.sum(new_solution * weight_lst) + weight_lst[i] <= capacity:\n                    value1_improvement = value1_lst[i] - np.sum(new_solution * value1_lst) + base_obj[0]\n                    value2_improvement = value2_lst[i] - np.sum(new_solution * value2_lst) + base_obj[1]\n                    if value1_improvement > 0 and value2_improvement > 0:\n                        new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8552239620446679,
            2.2053362131118774
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prefer solutions that are not fully packed or have room for improvement in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity * 0.9:  # Prefer solutions that are not fully packed\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if no candidates found\n\n    # Randomly select a solution from the top 30% of candidates to encourage diversity\n    selected_idx = np.random.choice(min(3, len(candidates)), size=1)[0] if len(candidates) > 1 else 0\n    base_solution, base_obj = candidates[selected_idx]\n\n    # Hybrid local search operator: combine random flips with objective-aware swaps\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Randomly flip a subset of items (1-3) to introduce diversity\n    flip_indices = np.random.choice(n_items, size=np.random.randint(1, 4), replace=False)\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility after flips\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items with lowest (value1 + value2) until feasible\n        while total_weight > capacity:\n            item_values = (value1_lst + value2_lst) * new_solution\n            remove_idx = np.argmax(item_values)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(new_solution * weight_lst)\n\n    # Step 2: Objective-aware swap - swap an item with a removed item if it improves both objectives\n    removed_items = np.where(base_solution != new_solution)[0]\n    if len(removed_items) > 0:\n        for i in removed_items:\n            if new_solution[i] == 1:  # Was removed, try to reinsert\n                if np.sum(new_solution * weight_lst) + weight_lst[i] <= capacity:\n                    value1_improvement = value1_lst[i] - np.sum(new_solution * value1_lst) + base_obj[0]\n                    value2_improvement = value2_lst[i] - np.sum(new_solution * value2_lst) + base_obj[1]\n                    if value1_improvement > 0 and value2_improvement > 0:\n                        new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 88,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundaries in either objective\n    # and have a balanced trade-off between the two objectives.\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    min_obj1, min_obj2 = np.min(objectives, axis=0)\n\n    # Calculate a score for each solution based on its position in the objective space\n    scores = []\n    for sol, obj in archive:\n        obj1, obj2 = obj\n        # Normalize the objectives to [0, 1]\n        norm_obj1 = (obj1 - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n        norm_obj2 = (obj2 - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n        # Score is the distance from the anti-diagonal (indicating balanced trade-off)\n        score = abs(norm_obj1 - norm_obj2)\n        scores.append(score)\n\n    # Select the solution with the highest score (most balanced trade-off)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to explore the neighborhood\n    # 2. Perform objective-specific swaps to improve both objectives\n\n    # Step 1: Random flips\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, min(5, len(new_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Check if removing this item keeps the solution feasible\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Check if adding this item keeps the solution feasible\n            if (np.sum(weight_lst[new_solution == 1]) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Objective-specific swaps\n    # Swap items between high-value1 and high-value2 to balance the objectives\n    high_value1_items = np.argsort(value1_lst)[-5:]  # Top 5 items by value1\n    high_value2_items = np.argsort(value2_lst)[-5:]  # Top 5 items by value2\n\n    for item1 in high_value1_items:\n        for item2 in high_value2_items:\n            if new_solution[item1] == 1 and new_solution[item2] == 0:\n                # Check if swapping item1 (out) and item2 (in) keeps the solution feasible\n                if (np.sum(weight_lst[new_solution == 1]) - weight_lst[item1] + weight_lst[item2]) <= capacity:\n                    new_solution[item1] = 0\n                    new_solution[item2] = 1\n                    break  # Only perform one swap per item to limit computation\n\n    return new_solution\n\n",
        "score": [
            -0.8227402791180639,
            2.218418836593628
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundaries in either objective\n    # and have a balanced trade-off between the two objectives.\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n    min_obj1, min_obj2 = np.min(objectives, axis=0)\n\n    # Calculate a score for each solution based on its position in the objective space\n    scores = []\n    for sol, obj in archive:\n        obj1, obj2 = obj\n        # Normalize the objectives to [0, 1]\n        norm_obj1 = (obj1 - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n        norm_obj2 = (obj2 - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n        # Score is the distance from the anti-diagonal (indicating balanced trade-off)\n        score = abs(norm_obj1 - norm_obj2)\n        scores.append(score)\n\n    # Select the solution with the highest score (most balanced trade-off)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to explore the neighborhood\n    # 2. Perform objective-specific swaps to improve both objectives\n\n    # Step 1: Random flips\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, min(5, len(new_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Check if removing this item keeps the solution feasible\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Check if adding this item keeps the solution feasible\n            if (np.sum(weight_lst[new_solution == 1]) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Objective-specific swaps\n    # Swap items between high-value1 and high-value2 to balance the objectives\n    high_value1_items = np.argsort(value1_lst)[-5:]  # Top 5 items by value1\n    high_value2_items = np.argsort(value2_lst)[-5:]  # Top 5 items by value2\n\n    for item1 in high_value1_items:\n        for item2 in high_value2_items:\n            if new_solution[item1] == 1 and new_solution[item2] == 0:\n                # Check if swapping item1 (out) and item2 (in) keeps the solution feasible\n                if (np.sum(weight_lst[new_solution == 1]) - weight_lst[item1] + weight_lst[item2]) <= capacity:\n                    new_solution[item1] = 0\n                    new_solution[item2] = 1\n                    break  # Only perform one swap per item to limit computation\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 89,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Determine items that can be flipped (either included or excluded while staying within capacity)\n    flippable_indices = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Can exclude if the solution remains feasible without this item\n            if current_weight - weight_lst[i] <= capacity:\n                flippable_indices.append((i, -1))  # -1 indicates exclusion\n        else:\n            # Can include if the solution remains feasible with this item\n            if current_weight + weight_lst[i] <= capacity:\n                flippable_indices.append((i, 1))  # 1 indicates inclusion\n\n    if not flippable_indices:\n        # No flips possible, return a random solution from archive\n        return archive[np.random.choice(len(archive))][0].copy()\n\n    # Hybrid local search: randomly select a flip and then apply a greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip\n    flip_idx, flip_action = random.choice(flippable_indices)\n    new_solution[flip_idx] = flip_action\n\n    # Greedy improvement: flip another item that improves both objectives\n    best_improvement = 0\n    best_flip = None\n\n    for i, action in flippable_indices:\n        if i == flip_idx:\n            continue  # Skip the already flipped item\n\n        temp_solution = new_solution.copy()\n        temp_solution[i] = action\n\n        # Calculate marginal improvement in both objectives\n        delta_value1 = (value1_lst[i] * action) - (value1_lst[i] * base_solution[i])\n        delta_value2 = (value2_lst[i] * action) - (value2_lst[i] * base_solution[i])\n\n        # Simple heuristic for combined improvement (can be replaced with a more sophisticated one)\n        combined_improvement = delta_value1 + delta_value2\n\n        if combined_improvement > best_improvement:\n            best_improvement = combined_improvement\n            best_flip = (i, action)\n\n    if best_flip is not None:\n        new_solution[best_flip[0]] = best_flip[1]\n\n    return new_solution\n\n",
        "score": [
            -0.8251028421969958,
            2.7908036708831787
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Determine items that can be flipped (either included or excluded while staying within capacity)\n    flippable_indices = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Can exclude if the solution remains feasible without this item\n            if current_weight - weight_lst[i] <= capacity:\n                flippable_indices.append((i, -1))  # -1 indicates exclusion\n        else:\n            # Can include if the solution remains feasible with this item\n            if current_weight + weight_lst[i] <= capacity:\n                flippable_indices.append((i, 1))  # 1 indicates inclusion\n\n    if not flippable_indices:\n        # No flips possible, return a random solution from archive\n        return archive[np.random.choice(len(archive))][0].copy()\n\n    # Hybrid local search: randomly select a flip and then apply a greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random flip\n    flip_idx, flip_action = random.choice(flippable_indices)\n    new_solution[flip_idx] = flip_action\n\n    # Greedy improvement: flip another item that improves both objectives\n    best_improvement = 0\n    best_flip = None\n\n    for i, action in flippable_indices:\n        if i == flip_idx:\n            continue  # Skip the already flipped item\n\n        temp_solution = new_solution.copy()\n        temp_solution[i] = action\n\n        # Calculate marginal improvement in both objectives\n        delta_value1 = (value1_lst[i] * action) - (value1_lst[i] * base_solution[i])\n        delta_value2 = (value2_lst[i] * action) - (value2_lst[i] * base_solution[i])\n\n        # Simple heuristic for combined improvement (can be replaced with a more sophisticated one)\n        combined_improvement = delta_value1 + delta_value2\n\n        if combined_improvement > best_improvement:\n            best_improvement = combined_improvement\n            best_flip = (i, action)\n\n    if best_flip is not None:\n        new_solution[best_flip[0]] = best_flip[1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 90,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with potential for improvement (e.g., not too crowded)\n    # Here, we randomly select a solution with a probability inversely proportional to its crowding distance\n    # For simplicity, we use a uniform random selection here, but in practice, you might use crowding distance\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip + greedy improvement\n    # Step 1: Randomly flip a subset of items\n    num_items = len(weight_lst)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)  # Flip up to 3 items\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            removable_indices = np.where(new_solution == 1)[0]\n            if len(removable_indices) == 0:\n                break  # No items left to remove, return base solution\n            remove_idx = np.random.choice(removable_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement step (add or remove one item to maximize a weighted sum of objectives)\n    # We use a random weight to balance the two objectives\n    alpha = random.random()\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n\n    for _ in range(5):  # Limit iterations to avoid long computation\n        # Evaluate adding an item\n        add_candidates = np.where(new_solution == 0)[0]\n        if len(add_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvements = np.zeros(len(add_candidates))\n            for i, idx in enumerate(add_candidates):\n                if total_weight + weight_lst[idx] <= capacity:\n                    improvements[i] = weighted_values[idx]\n\n            if np.any(improvements > 0):\n                best_add_idx = add_candidates[np.argmax(improvements)]\n                new_solution[best_add_idx] = 1\n                total_weight += weight_lst[best_add_idx]\n\n        # Evaluate removing an item\n        remove_candidates = np.where(new_solution == 1)[0]\n        if len(remove_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvements = np.zeros(len(remove_candidates))\n            for i, idx in enumerate(remove_candidates):\n                improvements[i] = -weighted_values[idx]  # Negative because we're removing\n\n            if np.any(improvements > 0):\n                best_remove_idx = remove_candidates[np.argmax(improvements)]\n                new_solution[best_remove_idx] = 0\n                total_weight -= weight_lst[best_remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.38356398333247865,
            5.659302234649658
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with potential for improvement (e.g., not too crowded)\n    # Here, we randomly select a solution with a probability inversely proportional to its crowding distance\n    # For simplicity, we use a uniform random selection here, but in practice, you might use crowding distance\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip + greedy improvement\n    # Step 1: Randomly flip a subset of items\n    num_items = len(weight_lst)\n    flip_indices = np.random.choice(num_items, size=min(3, num_items), replace=False)  # Flip up to 3 items\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            removable_indices = np.where(new_solution == 1)[0]\n            if len(removable_indices) == 0:\n                break  # No items left to remove, return base solution\n            remove_idx = np.random.choice(removable_indices)\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement step (add or remove one item to maximize a weighted sum of objectives)\n    # We use a random weight to balance the two objectives\n    alpha = random.random()\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n\n    for _ in range(5):  # Limit iterations to avoid long computation\n        # Evaluate adding an item\n        add_candidates = np.where(new_solution == 0)[0]\n        if len(add_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvements = np.zeros(len(add_candidates))\n            for i, idx in enumerate(add_candidates):\n                if total_weight + weight_lst[idx] <= capacity:\n                    improvements[i] = weighted_values[idx]\n\n            if np.any(improvements > 0):\n                best_add_idx = add_candidates[np.argmax(improvements)]\n                new_solution[best_add_idx] = 1\n                total_weight += weight_lst[best_add_idx]\n\n        # Evaluate removing an item\n        remove_candidates = np.where(new_solution == 1)[0]\n        if len(remove_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvements = np.zeros(len(remove_candidates))\n            for i, idx in enumerate(remove_candidates):\n                improvements[i] = -weighted_values[idx]  # Negative because we're removing\n\n            if np.any(improvements > 0):\n                best_remove_idx = remove_candidates[np.argmax(improvements)]\n                new_solution[best_remove_idx] = 0\n                total_weight -= weight_lst[best_remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 91,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Normalize objectives to select a promising solution\n    max_val1 = max(obj[0] for _, obj in archive)\n    max_val2 = max(obj[1] for _, obj in archive)\n    if max_val1 == 0 or max_val2 == 0:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        # Select solution with highest sum of normalized objectives\n        best_score = -1\n        selected_solution = None\n        for sol, obj in archive:\n            score = (obj[0]/max_val1 + obj[1]/max_val2) / 2\n            if score > best_score:\n                best_score = score\n                selected_solution = sol.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: probabilistic swap with objective-aware selection\n    for _ in range(10):  # Number of local search iterations\n        # Identify candidate items to swap (both included and excluded)\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) == 0 or len(excluded) == 0:\n            break\n\n        # Select a random item to remove and a random item to add\n        item_to_remove = random.choice(included)\n        item_to_add = random.choice(excluded)\n\n        # Calculate potential new weight\n        new_weight = current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]\n\n        if new_weight <= capacity:\n            # Calculate potential improvement in both objectives\n            delta_val1 = value1_lst[item_to_add] - value1_lst[item_to_remove]\n            delta_val2 = value2_lst[item_to_add] - value2_lst[item_to_remove]\n\n            # Accept swap if it improves at least one objective\n            if delta_val1 > 0 or delta_val2 > 0:\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n                current_weight = new_weight\n\n    # Diversification step: with 20% probability, perform a random flip\n    if random.random() < 0.2:\n        flip_pos = random.randint(0, len(new_solution)-1)\n        if new_solution[flip_pos] == 1:\n            if current_weight - weight_lst[flip_pos] <= capacity:\n                new_solution[flip_pos] = 0\n        else:\n            if current_weight + weight_lst[flip_pos] <= capacity:\n                new_solution[flip_pos] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3460198224802041,
            4.124793529510498
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Normalize objectives to select a promising solution\n    max_val1 = max(obj[0] for _, obj in archive)\n    max_val2 = max(obj[1] for _, obj in archive)\n    if max_val1 == 0 or max_val2 == 0:\n        selected_solution = random.choice(archive)[0].copy()\n    else:\n        # Select solution with highest sum of normalized objectives\n        best_score = -1\n        selected_solution = None\n        for sol, obj in archive:\n            score = (obj[0]/max_val1 + obj[1]/max_val2) / 2\n            if score > best_score:\n                best_score = score\n                selected_solution = sol.copy()\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: probabilistic swap with objective-aware selection\n    for _ in range(10):  # Number of local search iterations\n        # Identify candidate items to swap (both included and excluded)\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        if len(included) == 0 or len(excluded) == 0:\n            break\n\n        # Select a random item to remove and a random item to add\n        item_to_remove = random.choice(included)\n        item_to_add = random.choice(excluded)\n\n        # Calculate potential new weight\n        new_weight = current_weight - weight_lst[item_to_remove] + weight_lst[item_to_add]\n\n        if new_weight <= capacity:\n            # Calculate potential improvement in both objectives\n            delta_val1 = value1_lst[item_to_add] - value1_lst[item_to_remove]\n            delta_val2 = value2_lst[item_to_add] - value2_lst[item_to_remove]\n\n            # Accept swap if it improves at least one objective\n            if delta_val1 > 0 or delta_val2 > 0:\n                new_solution[item_to_remove] = 0\n                new_solution[item_to_add] = 1\n                current_weight = new_weight\n\n    # Diversification step: with 20% probability, perform a random flip\n    if random.random() < 0.2:\n        flip_pos = random.randint(0, len(new_solution)-1)\n        if new_solution[flip_pos] == 1:\n            if current_weight - weight_lst[flip_pos] <= capacity:\n                new_solution[flip_pos] = 0\n        else:\n            if current_weight + weight_lst[flip_pos] <= capacity:\n                new_solution[flip_pos] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 92,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total value-to-weight ratios\n    weighted_ratios = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        total_value1 = np.sum(value1_lst * sol)\n        total_value2 = np.sum(value2_lst * sol)\n        if total_weight > 0:\n            ratio1 = total_value1 / total_weight\n            ratio2 = total_value2 / total_weight\n            weighted_ratios.append((ratio1 + ratio2) / 2)\n        else:\n            weighted_ratios.append(0)\n\n    # Normalize ratios to form probabilities\n    total_ratio = sum(weighted_ratios)\n    if total_ratio == 0:\n        probabilities = [1.0 / len(archive) for _ in archive]\n    else:\n        probabilities = [ratio / total_ratio for ratio in weighted_ratios]\n\n    # Select a base solution with probability proportional to its weighted ratio\n    base_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on a value-to-weight ratio heuristic\n    # First, calculate the value-to-weight ratios for all items\n    ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Sort items by decreasing ratio\n    sorted_items = np.argsort(ratios)[::-1]\n\n    # Randomly select a subset of top items to flip (k is a small integer)\n    k = min(3, len(sorted_items))\n    flip_indices = random.sample(list(sorted_items[:k]), k=min(k, len(sorted_items)))\n\n    # Flip the selected items and ensure feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item exceeds capacity\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # If no flips were made, randomly flip one item to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[random_idx] == 1:\n            new_solution[random_idx] = 0\n        else:\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8182871030595968,
            4.14748215675354
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total value-to-weight ratios\n    weighted_ratios = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        total_value1 = np.sum(value1_lst * sol)\n        total_value2 = np.sum(value2_lst * sol)\n        if total_weight > 0:\n            ratio1 = total_value1 / total_weight\n            ratio2 = total_value2 / total_weight\n            weighted_ratios.append((ratio1 + ratio2) / 2)\n        else:\n            weighted_ratios.append(0)\n\n    # Normalize ratios to form probabilities\n    total_ratio = sum(weighted_ratios)\n    if total_ratio == 0:\n        probabilities = [1.0 / len(archive) for _ in archive]\n    else:\n        probabilities = [ratio / total_ratio for ratio in weighted_ratios]\n\n    # Select a base solution with probability proportional to its weighted ratio\n    base_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip items based on a value-to-weight ratio heuristic\n    # First, calculate the value-to-weight ratios for all items\n    ratios = (value1_lst + value2_lst) / weight_lst\n\n    # Sort items by decreasing ratio\n    sorted_items = np.argsort(ratios)[::-1]\n\n    # Randomly select a subset of top items to flip (k is a small integer)\n    k = min(3, len(sorted_items))\n    flip_indices = random.sample(list(sorted_items[:k]), k=min(k, len(sorted_items)))\n\n    # Flip the selected items and ensure feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item exceeds capacity\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # If no flips were made, randomly flip one item to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[random_idx] == 1:\n            new_solution[random_idx] = 0\n        else:\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 93,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with high potential improvement\n    # We prioritize solutions that are not too close to the capacity to allow more flexibility\n    def potential_score(solution, objective):\n        current_weight = np.sum(weight_lst * solution)\n        remaining_capacity = capacity - current_weight\n        # Prefer solutions that are not at full capacity and have high objective values\n        return (objective[0] + objective[1]) * (1 - current_weight / capacity)\n\n    scored_solutions = [(solution, objective, potential_score(solution, objective))\n                        for solution, objective in archive]\n    scored_solutions.sort(key=lambda x: -x[2])  # Sort by potential score in descending order\n\n    # Select top 20% of solutions to choose from\n    top_k = max(1, len(scored_solutions) // 5)\n    selected = random.choice(scored_solutions[:top_k])\n    base_solution = selected[0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n\n    # Strategy 1: Randomly swap items with a bias towards high-value items\n    for _ in range(min(3, num_items // 2)):  # Limit the number of swaps to avoid excessive changes\n        # Select two items to swap\n        item1 = random.randint(0, num_items - 1)\n        item2 = random.randint(0, num_items - 1)\n\n        # Calculate the change in weight and value\n        delta_weight = weight_lst[item2] - weight_lst[item1]\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            # Swap items if feasible\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n            current_weight = new_weight\n\n    # Strategy 2: Add or remove a high-value item that fits the remaining capacity\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Find items that can be added without exceeding capacity\n        feasible_items = np.where((weight_lst <= remaining_capacity) & (base_solution == 0))[0]\n        if len(feasible_items) > 0:\n            # Add the item with the highest combined value\n            best_item = max(feasible_items, key=lambda i: value1_lst[i] + value2_lst[i])\n            new_solution[best_item] = 1\n\n    # Strategy 3: Remove an item if it's not contributing significantly to the objective\n    if current_weight > 0:\n        # Find items that can be removed to potentially improve the objective\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) > 0:\n            # Remove the item with the lowest combined value\n            worst_item = min(removable_items, key=lambda i: value1_lst[i] + value2_lst[i])\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.346236865662608,
            8.844668358564377
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with high potential improvement\n    # We prioritize solutions that are not too close to the capacity to allow more flexibility\n    def potential_score(solution, objective):\n        current_weight = np.sum(weight_lst * solution)\n        remaining_capacity = capacity - current_weight\n        # Prefer solutions that are not at full capacity and have high objective values\n        return (objective[0] + objective[1]) * (1 - current_weight / capacity)\n\n    scored_solutions = [(solution, objective, potential_score(solution, objective))\n                        for solution, objective in archive]\n    scored_solutions.sort(key=lambda x: -x[2])  # Sort by potential score in descending order\n\n    # Select top 20% of solutions to choose from\n    top_k = max(1, len(scored_solutions) // 5)\n    selected = random.choice(scored_solutions[:top_k])\n    base_solution = selected[0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n\n    # Strategy 1: Randomly swap items with a bias towards high-value items\n    for _ in range(min(3, num_items // 2)):  # Limit the number of swaps to avoid excessive changes\n        # Select two items to swap\n        item1 = random.randint(0, num_items - 1)\n        item2 = random.randint(0, num_items - 1)\n\n        # Calculate the change in weight and value\n        delta_weight = weight_lst[item2] - weight_lst[item1]\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            # Swap items if feasible\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n            current_weight = new_weight\n\n    # Strategy 2: Add or remove a high-value item that fits the remaining capacity\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Find items that can be added without exceeding capacity\n        feasible_items = np.where((weight_lst <= remaining_capacity) & (base_solution == 0))[0]\n        if len(feasible_items) > 0:\n            # Add the item with the highest combined value\n            best_item = max(feasible_items, key=lambda i: value1_lst[i] + value2_lst[i])\n            new_solution[best_item] = 1\n\n    # Strategy 3: Remove an item if it's not contributing significantly to the objective\n    if current_weight > 0:\n        # Find items that can be removed to potentially improve the objective\n        removable_items = np.where(new_solution == 1)[0]\n        if len(removable_items) > 0:\n            # Remove the item with the lowest combined value\n            worst_item = min(removable_items, key=lambda i: value1_lst[i] + value2_lst[i])\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 94,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with a probability proportional to its potential for improvement\n    total_potential = sum(abs(obj[0] - obj[1]) for _, obj in archive)\n    if total_potential == 0:\n        # If all solutions are equally balanced, choose randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Weighted random selection based on potential for improvement\n        weights = [abs(obj[0] - obj[1]) / total_potential for _, obj in archive]\n        selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # Phase 1: Randomly flip a subset of items (intensification)\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Phase 2: Check feasibility and repair if necessary\n    current_weight = np.dot(new_solution, weight_lst)\n    if current_weight > capacity:\n        # If infeasible, remove items with lowest value-to-weight ratio\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n        combined_ratio = value_ratio1 + value_ratio2  # Simple combination of both objectives\n\n        while current_weight > capacity:\n            # Find the item with the lowest combined value-to-weight ratio that is currently included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n\n            min_ratio_idx = included_items[np.argmin(combined_ratio[included_items])]\n            new_solution[min_ratio_idx] = 0\n            current_weight -= weight_lst[min_ratio_idx]\n\n    # Phase 3: Add items with highest marginal gain (diversification)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        current_weight = np.dot(new_solution, weight_lst)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate marginal gain for each excluded item\n        marginal_gains = []\n        for idx in excluded_items:\n            if weight_lst[idx] <= remaining_capacity:\n                marginal_gain = value1_lst[idx] + value2_lst[idx]\n                marginal_gains.append((marginal_gain, idx))\n            else:\n                marginal_gains.append((0, idx))\n\n        # Add items with highest marginal gain\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n        for gain, idx in marginal_gains[:2]:  # Add up to 2 items\n            if gain > 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3243696602689704,
            8.549076825380325
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with a probability proportional to its potential for improvement\n    total_potential = sum(abs(obj[0] - obj[1]) for _, obj in archive)\n    if total_potential == 0:\n        # If all solutions are equally balanced, choose randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Weighted random selection based on potential for improvement\n        weights = [abs(obj[0] - obj[1]) / total_potential for _, obj in archive]\n        selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search strategy\n    # Phase 1: Randomly flip a subset of items (intensification)\n    n_items = len(new_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Phase 2: Check feasibility and repair if necessary\n    current_weight = np.dot(new_solution, weight_lst)\n    if current_weight > capacity:\n        # If infeasible, remove items with lowest value-to-weight ratio\n        value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n        value_ratio2 = value2_lst / (weight_lst + 1e-10)\n        combined_ratio = value_ratio1 + value_ratio2  # Simple combination of both objectives\n\n        while current_weight > capacity:\n            # Find the item with the lowest combined value-to-weight ratio that is currently included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break  # No items left to remove\n\n            min_ratio_idx = included_items[np.argmin(combined_ratio[included_items])]\n            new_solution[min_ratio_idx] = 0\n            current_weight -= weight_lst[min_ratio_idx]\n\n    # Phase 3: Add items with highest marginal gain (diversification)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        current_weight = np.dot(new_solution, weight_lst)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate marginal gain for each excluded item\n        marginal_gains = []\n        for idx in excluded_items:\n            if weight_lst[idx] <= remaining_capacity:\n                marginal_gain = value1_lst[idx] + value2_lst[idx]\n                marginal_gains.append((marginal_gain, idx))\n            else:\n                marginal_gains.append((0, idx))\n\n        # Add items with highest marginal gain\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n        for gain, idx in marginal_gains[:2]:  # Add up to 2 items\n            if gain > 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 95,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    objectives = [obj for _, obj in archive]\n\n    # Prioritize solutions with lower total weight (more room for improvement)\n    candidates = sorted(zip(archive_solutions, weights, objectives), key=lambda x: x[1])\n    selected_sol, selected_weight, selected_obj = candidates[0]\n\n    # Hybrid local search: random flip + greedy improvement\n    new_solution = selected_sol.copy()\n\n    # Random flip: flip a random subset of items (up to 3)\n    flip_indices = random.sample(range(len(new_solution)), min(3, len(new_solution)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove the most expensive item in the random flip\n        flip_weights = weight_lst[flip_indices]\n        remove_idx = flip_indices[np.argmax(flip_weights)]\n        new_solution[remove_idx] = 1 - new_solution[remove_idx]\n\n    # Greedy improvement: try to add the best item not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Evaluate the improvement in both objectives\n            new_value1 = selected_obj[0] + value1_lst[item]\n            new_value2 = selected_obj[1] + value2_lst[item]\n\n            # Accept if it improves at least one objective (non-dominated)\n            if (new_value1 > selected_obj[0] or new_value2 > selected_obj[1]):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.2546852429161918,
            2.3830366134643555
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    objectives = [obj for _, obj in archive]\n\n    # Prioritize solutions with lower total weight (more room for improvement)\n    candidates = sorted(zip(archive_solutions, weights, objectives), key=lambda x: x[1])\n    selected_sol, selected_weight, selected_obj = candidates[0]\n\n    # Hybrid local search: random flip + greedy improvement\n    new_solution = selected_sol.copy()\n\n    # Random flip: flip a random subset of items (up to 3)\n    flip_indices = random.sample(range(len(new_solution)), min(3, len(new_solution)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flip\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove the most expensive item in the random flip\n        flip_weights = weight_lst[flip_indices]\n        remove_idx = flip_indices[np.argmax(flip_weights)]\n        new_solution[remove_idx] = 1 - new_solution[remove_idx]\n\n    # Greedy improvement: try to add the best item not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Evaluate the improvement in both objectives\n            new_value1 = selected_obj[0] + value1_lst[item]\n            new_value2 = selected_obj[1] + value2_lst[item]\n\n            # Accept if it improves at least one objective (non-dominated)\n            if (new_value1 > selected_obj[0] or new_value2 > selected_obj[1]):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 96,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the frontier (have some room for improvement)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(archive_sorted) * 0.3), len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. First, perform a random flip of a subset of items (similar to random local search)\n    # 2. Then, perform a value-based flip to maximize one objective while maintaining feasibility\n    new_solution = base_solution.copy()\n\n    # Step 1: Random flip of a subset of items\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to maintain diversity\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n\n        for item in excess_items:\n            if excess_weight <= 0:\n                break\n            if weight_lst[item] <= excess_weight:\n                new_solution[item] = 0\n                excess_weight -= weight_lst[item]\n\n    # Step 2: Value-based flip to maximize one objective\n    # Choose the objective to maximize (randomly)\n    obj_to_maximize = random.choice([0, 1])  # 0 for value1, 1 for value2\n    value_lst = value1_lst if obj_to_maximize == 0 else value2_lst\n\n    # Find items not in the solution that can be added without exceeding capacity\n    not_in_solution = np.where(new_solution == 0)[0]\n    feasible_additions = [i for i in not_in_solution if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity]\n\n    if feasible_additions:\n        # Add the item with the highest value for the chosen objective\n        best_addition = max(feasible_additions, key=lambda i: value_lst[i])\n        new_solution[best_addition] = 1\n\n    # If no additions possible, try removing the least valuable item for the chosen objective\n    else:\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            worst_removal = min(in_solution, key=lambda i: value_lst[i])\n            new_solution[worst_removal] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3784374905051071,
            9.017316430807114
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the frontier (have some room for improvement)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(archive_sorted) * 0.3), len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Hybrid local search strategy:\n    # 1. First, perform a random flip of a subset of items (similar to random local search)\n    # 2. Then, perform a value-based flip to maximize one objective while maintaining feasibility\n    new_solution = base_solution.copy()\n\n    # Step 1: Random flip of a subset of items\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to maintain diversity\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n\n        for item in excess_items:\n            if excess_weight <= 0:\n                break\n            if weight_lst[item] <= excess_weight:\n                new_solution[item] = 0\n                excess_weight -= weight_lst[item]\n\n    # Step 2: Value-based flip to maximize one objective\n    # Choose the objective to maximize (randomly)\n    obj_to_maximize = random.choice([0, 1])  # 0 for value1, 1 for value2\n    value_lst = value1_lst if obj_to_maximize == 0 else value2_lst\n\n    # Find items not in the solution that can be added without exceeding capacity\n    not_in_solution = np.where(new_solution == 0)[0]\n    feasible_additions = [i for i in not_in_solution if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity]\n\n    if feasible_additions:\n        # Add the item with the highest value for the chosen objective\n        best_addition = max(feasible_additions, key=lambda i: value_lst[i])\n        new_solution[best_addition] = 1\n\n    # If no additions possible, try removing the least valuable item for the chosen objective\n    else:\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            worst_removal = min(in_solution, key=lambda i: value_lst[i])\n            new_solution[worst_removal] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 97,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.argmax([np.sum(sol[0]) / len(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Random swaps (exploration)\n    for _ in range(min(5, n_items // 2)):\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility of swap\n            delta_weight = (weight_lst[j] if new_solution[i] else -weight_lst[j]) - (weight_lst[i] if new_solution[j] else -weight_lst[i])\n            if current_weight + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight += delta_weight\n\n    # Greedy improvement (exploitation)\n    for i in range(n_items):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            # Add item if it improves both objectives\n            if (value1_lst[i] > 0 and value2_lst[i] > 0):\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n        elif new_solution[i] == 1:\n            # Remove item if it doesn't contribute to both objectives\n            if (value1_lst[i] <= 0 and value2_lst[i] <= 0):\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.37612350715041576,
            5.966978669166565
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.argmax([np.sum(sol[0]) / len(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Random swaps (exploration)\n    for _ in range(min(5, n_items // 2)):\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility of swap\n            delta_weight = (weight_lst[j] if new_solution[i] else -weight_lst[j]) - (weight_lst[i] if new_solution[j] else -weight_lst[i])\n            if current_weight + delta_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                current_weight += delta_weight\n\n    # Greedy improvement (exploitation)\n    for i in range(n_items):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            # Add item if it improves both objectives\n            if (value1_lst[i] > 0 and value2_lst[i] > 0):\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n        elif new_solution[i] == 1:\n            # Remove item if it doesn't contribute to both objectives\n            if (value1_lst[i] <= 0 and value2_lst[i] <= 0):\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 98,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Randomly flip a subset of items (perturbation)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 2: Greedy improvement to restore feasibility and quality\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                excess_weight -= weight_lst[item]\n\n    # Step 3: Add items greedily to improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n\n    # Sort remaining items by a combined score (lexicographic order)\n    scores = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n    sorted_items = remaining_items[np.argsort(-scores[remaining_items])]\n\n    for item in sorted_items:\n        if weight_lst[item] <= remaining_weight:\n            new_solution[item] = 1\n            remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.40214691273201586,
            1.9877961575984955
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Randomly flip a subset of items (perturbation)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 2: Greedy improvement to restore feasibility and quality\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for item in excess_items:\n            if excess_weight <= 0:\n                break\n            if new_solution[item] == 1:\n                new_solution[item] = 0\n                excess_weight -= weight_lst[item]\n\n    # Step 3: Add items greedily to improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n\n    # Sort remaining items by a combined score (lexicographic order)\n    scores = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n    sorted_items = remaining_items[np.argsort(-scores[remaining_items])]\n\n    for item in sorted_items:\n        if weight_lst[item] <= remaining_weight:\n            new_solution[item] = 1\n            remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 99,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidate_indices = []\n    for i, (sol, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * sol)\n        # Consider solutions that are not at full capacity or have room for improvement\n        if current_weight < 0.9 * capacity:\n            candidate_indices.append(i)\n\n    if not candidate_indices:\n        # Fallback: select a random solution if no candidates found\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        # Select a candidate with high potential (e.g., one with the highest total value in one objective)\n        selected_idx = random.choice(candidate_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (both 0 to 1 and 1 to 0)\n    # 2. Use a greedy approach to add items that improve at least one objective\n    # 3. Ensure feasibility by removing items if capacity is exceeded\n\n    # Step 1: Randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Step 2: Greedy improvement for objective 1\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    for i in np.where(new_solution == 0)[0]:\n        if weight_lst[i] <= remaining_weight:\n            new_solution[i] = 1\n            remaining_weight -= weight_lst[i]\n\n    # Step 3: Greedy improvement for objective 2 (if no improvement in objective 1)\n    if remaining_weight > 0:\n        for i in np.where(new_solution == 0)[0]:\n            if weight_lst[i] <= remaining_weight:\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the smallest ratio of value1/weight + value2/weight\n        while current_weight > capacity:\n            ratios = []\n            for i in np.where(new_solution == 1)[0]:\n                ratio = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n                ratios.append((i, ratio))\n            ratios.sort(key=lambda x: x[1])\n            if not ratios:\n                break  # No items left to remove\n            remove_idx = ratios[0][0]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3501974107134189,
            5.8080529272556305
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidate_indices = []\n    for i, (sol, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * sol)\n        # Consider solutions that are not at full capacity or have room for improvement\n        if current_weight < 0.9 * capacity:\n            candidate_indices.append(i)\n\n    if not candidate_indices:\n        # Fallback: select a random solution if no candidates found\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        # Select a candidate with high potential (e.g., one with the highest total value in one objective)\n        selected_idx = random.choice(candidate_indices)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (both 0 to 1 and 1 to 0)\n    # 2. Use a greedy approach to add items that improve at least one objective\n    # 3. Ensure feasibility by removing items if capacity is exceeded\n\n    # Step 1: Randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Step 2: Greedy improvement for objective 1\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    for i in np.where(new_solution == 0)[0]:\n        if weight_lst[i] <= remaining_weight:\n            new_solution[i] = 1\n            remaining_weight -= weight_lst[i]\n\n    # Step 3: Greedy improvement for objective 2 (if no improvement in objective 1)\n    if remaining_weight > 0:\n        for i in np.where(new_solution == 0)[0]:\n            if weight_lst[i] <= remaining_weight:\n                new_solution[i] = 1\n                remaining_weight -= weight_lst[i]\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the smallest ratio of value1/weight + value2/weight\n        while current_weight > capacity:\n            ratios = []\n            for i in np.where(new_solution == 1)[0]:\n                ratio = (value1_lst[i] + value2_lst[i]) / weight_lst[i]\n                ratios.append((i, ratio))\n            ratios.sort(key=lambda x: x[1])\n            if not ratios:\n                break  # No items left to remove\n            remove_idx = ratios[0][0]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 100,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    # Here we use a simple heuristic: select a solution with a unique objective value\n    unique_objectives = set(obj for _, obj in archive)\n    candidates = [sol for sol, obj in archive if obj in unique_objectives]\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random flip + value-density improvement\n    # Step 1: Randomly flip a few bits (with probability based on the current solution's quality)\n    for i in range(len(new_solution)):\n        if random.random() < 0.2:  # 20% chance to flip each bit\n            if new_solution[i] == 1:\n                # Remove item if possible\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Add item if possible\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Value-density improvement step (add items with high value/weight ratio)\n    # Calculate value densities for both objectives\n    density1 = value1_lst / weight_lst\n    density2 = value2_lst / weight_lst\n\n    # Combine densities with some randomness to avoid getting stuck\n    combined_density = 0.6 * density1 + 0.4 * density2 + 0.1 * np.random.rand(len(weight_lst))\n\n    # Sort items by combined density in descending order\n    sorted_items = np.argsort(-combined_density)\n\n    for i in sorted_items:\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 3: Remove low-value items if space allows\n    # Sort items by their contribution to both objectives\n    total_value1 = np.sum(value1_lst[new_solution == 1])\n    total_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Calculate marginal contribution for each item in the solution\n    marginal_contribution = np.zeros(len(new_solution))\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Calculate what would happen if we removed this item\n            new_value1 = total_value1 - value1_lst[i]\n            new_value2 = total_value2 - value2_lst[i]\n            new_weight = current_weight - weight_lst[i]\n\n            # Simple heuristic: remove if it doesn't significantly improve either objective\n            if new_weight <= capacity and (new_value1 >= 0.95 * total_value1 or new_value2 >= 0.95 * total_value2):\n                new_solution[i] = 0\n                current_weight = new_weight\n                total_value1 = new_value1\n                total_value2 = new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.8340399040166384,
            3.0758100748062134
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    # Here we use a simple heuristic: select a solution with a unique objective value\n    unique_objectives = set(obj for _, obj in archive)\n    candidates = [sol for sol, obj in archive if obj in unique_objectives]\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random flip + value-density improvement\n    # Step 1: Randomly flip a few bits (with probability based on the current solution's quality)\n    for i in range(len(new_solution)):\n        if random.random() < 0.2:  # 20% chance to flip each bit\n            if new_solution[i] == 1:\n                # Remove item if possible\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Add item if possible\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Value-density improvement step (add items with high value/weight ratio)\n    # Calculate value densities for both objectives\n    density1 = value1_lst / weight_lst\n    density2 = value2_lst / weight_lst\n\n    # Combine densities with some randomness to avoid getting stuck\n    combined_density = 0.6 * density1 + 0.4 * density2 + 0.1 * np.random.rand(len(weight_lst))\n\n    # Sort items by combined density in descending order\n    sorted_items = np.argsort(-combined_density)\n\n    for i in sorted_items:\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            current_weight += weight_lst[i]\n\n    # Step 3: Remove low-value items if space allows\n    # Sort items by their contribution to both objectives\n    total_value1 = np.sum(value1_lst[new_solution == 1])\n    total_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Calculate marginal contribution for each item in the solution\n    marginal_contribution = np.zeros(len(new_solution))\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Calculate what would happen if we removed this item\n            new_value1 = total_value1 - value1_lst[i]\n            new_value2 = total_value2 - value2_lst[i]\n            new_weight = current_weight - weight_lst[i]\n\n            # Simple heuristic: remove if it doesn't significantly improve either objective\n            if new_weight <= capacity and (new_value1 >= 0.95 * total_value1 or new_value2 >= 0.95 * total_value2):\n                new_solution[i] = 0\n                current_weight = new_weight\n                total_value1 = new_value1\n                total_value2 = new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 101,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already Pareto-optimal in both objectives)\n    # Here, we select a solution that is not dominated by others in the archive\n    non_dominated_indices = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated_indices.append(i)\n\n    if not non_dominated_indices:\n        non_dominated_indices = list(range(len(archive)))\n\n    selected_idx = np.random.choice(non_dominated_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search operator: combine swap and flip with weight adjustment\n    new_solution = base_solution.copy()\n    num_items = len(base_solution)\n    max_attempts = 10  # Limit the number of attempts to avoid infinite loops\n\n    for _ in range(max_attempts):\n        # Randomly select a subset of items to flip or swap\n        subset_size = max(1, min(3, num_items // 4))  # Subset size between 1 and 1/4 of total items\n        indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n        # Apply flip or swap based on a coin flip\n        if np.random.rand() < 0.5:\n            # Flip operation (change 0 to 1 or 1 to 0)\n            for idx in indices:\n                new_solution[idx] = 1 - new_solution[idx]\n        else:\n            # Swap operation (swap two items)\n            if len(indices) >= 2:\n                new_solution[indices[0]], new_solution[indices[1]] = new_solution[indices[1]], new_solution[indices[0]]\n\n        # Check feasibility\n        new_weight = np.sum(weight_lst * new_solution)\n        if new_weight <= capacity:\n            # If feasible, accept the change\n            base_solution = new_solution.copy()\n            current_weight = new_weight\n        else:\n            # Revert to previous solution if infeasible\n            new_solution = base_solution.copy()\n\n    return base_solution\n\n",
        "score": [
            -0.3922776751961619,
            6.160970449447632
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already Pareto-optimal in both objectives)\n    # Here, we select a solution that is not dominated by others in the archive\n    non_dominated_indices = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for other_sol, other_obj in archive:\n            if (other_obj[0] >= obj[0] and other_obj[1] > obj[1]) or (other_obj[0] > obj[0] and other_obj[1] >= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated_indices.append(i)\n\n    if not non_dominated_indices:\n        non_dominated_indices = list(range(len(archive)))\n\n    selected_idx = np.random.choice(non_dominated_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search operator: combine swap and flip with weight adjustment\n    new_solution = base_solution.copy()\n    num_items = len(base_solution)\n    max_attempts = 10  # Limit the number of attempts to avoid infinite loops\n\n    for _ in range(max_attempts):\n        # Randomly select a subset of items to flip or swap\n        subset_size = max(1, min(3, num_items // 4))  # Subset size between 1 and 1/4 of total items\n        indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n        # Apply flip or swap based on a coin flip\n        if np.random.rand() < 0.5:\n            # Flip operation (change 0 to 1 or 1 to 0)\n            for idx in indices:\n                new_solution[idx] = 1 - new_solution[idx]\n        else:\n            # Swap operation (swap two items)\n            if len(indices) >= 2:\n                new_solution[indices[0]], new_solution[indices[1]] = new_solution[indices[1]], new_solution[indices[0]]\n\n        # Check feasibility\n        new_weight = np.sum(weight_lst * new_solution)\n        if new_weight <= capacity:\n            # If feasible, accept the change\n            base_solution = new_solution.copy()\n            current_weight = new_weight\n        else:\n            # Revert to previous solution if infeasible\n            new_solution = base_solution.copy()\n\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 102,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not already fully packed\n    total_weights = [np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    remaining_capacities = [capacity - tw for tw in total_weights]\n    normalized_remaining = np.array(remaining_capacities) / capacity\n    probabilities = normalized_remaining / np.sum(normalized_remaining)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate the current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items that can be added without exceeding capacity\n    excluded_items = np.where(new_solution == 0)[0]\n    potential_items = [item for item in excluded_items if weight_lst[item] <= remaining_capacity]\n\n    if not potential_items:\n        # If no items can be added, try removing items\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            item_to_remove = random.choice(included_items)\n            new_solution[item_to_remove] = 0\n        return new_solution\n\n    # Calculate the weighted potential of each potential item\n    potential_weights = np.array([weight_lst[item] for item in potential_items])\n    potential_value1 = np.array([value1_lst[item] for item in potential_items])\n    potential_value2 = np.array([value2_lst[item] for item in potential_items])\n\n    # Normalize the values to avoid bias towards one objective\n    if np.max(potential_value1) != 0:\n        normalized_value1 = potential_value1 / np.max(potential_value1)\n    else:\n        normalized_value1 = np.zeros_like(potential_value1)\n\n    if np.max(potential_value2) != 0:\n        normalized_value2 = potential_value2 / np.max(potential_value2)\n    else:\n        normalized_value2 = np.zeros_like(potential_value2)\n\n    # Combine the normalized values and weights to create a score\n    scores = normalized_value1 + normalized_value2 - (potential_weights / remaining_capacity)\n\n    # Select the item with the highest score\n    selected_item_idx = np.argmax(scores)\n    item_to_add = potential_items[selected_item_idx]\n\n    # Add the selected item\n    new_solution[item_to_add] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8795797382368837,
            2.911361426115036
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not already fully packed\n    total_weights = [np.sum(weight_lst[sol[0] == 1]) for sol in archive]\n    remaining_capacities = [capacity - tw for tw in total_weights]\n    normalized_remaining = np.array(remaining_capacities) / capacity\n    probabilities = normalized_remaining / np.sum(normalized_remaining)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate the current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Identify items that can be added without exceeding capacity\n    excluded_items = np.where(new_solution == 0)[0]\n    potential_items = [item for item in excluded_items if weight_lst[item] <= remaining_capacity]\n\n    if not potential_items:\n        # If no items can be added, try removing items\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            item_to_remove = random.choice(included_items)\n            new_solution[item_to_remove] = 0\n        return new_solution\n\n    # Calculate the weighted potential of each potential item\n    potential_weights = np.array([weight_lst[item] for item in potential_items])\n    potential_value1 = np.array([value1_lst[item] for item in potential_items])\n    potential_value2 = np.array([value2_lst[item] for item in potential_items])\n\n    # Normalize the values to avoid bias towards one objective\n    if np.max(potential_value1) != 0:\n        normalized_value1 = potential_value1 / np.max(potential_value1)\n    else:\n        normalized_value1 = np.zeros_like(potential_value1)\n\n    if np.max(potential_value2) != 0:\n        normalized_value2 = potential_value2 / np.max(potential_value2)\n    else:\n        normalized_value2 = np.zeros_like(potential_value2)\n\n    # Combine the normalized values and weights to create a score\n    scores = normalized_value1 + normalized_value2 - (potential_weights / remaining_capacity)\n\n    # Select the item with the highest score\n    selected_item_idx = np.argmax(scores)\n    item_to_add = potential_items[selected_item_idx]\n\n    # Add the selected item\n    new_solution[item_to_add] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 103,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards non-dominated solutions with higher potential\n    base_solution, (val1, val2) = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy\n    # 1. Randomly swap items (exploration)\n    if len(new_solution) > 1:\n        i, j = random.sample(range(len(new_solution)), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Objective-based flip: flip items that contribute less to the dominant objective\n    dominant_obj = 1 if val1 > val2 else 2\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if dominant_obj == 1:\n                if value1_lst[i] < np.mean(value1_lst) and (current_weight - weight_lst[i]) <= capacity:\n                    new_solution[i] = 0\n            else:\n                if value2_lst[i] < np.mean(value2_lst) and (current_weight - weight_lst[i]) <= capacity:\n                    new_solution[i] = 0\n\n    # 3. Add items that can improve the non-dominant objective without violating capacity\n    non_dominant_obj = 2 if dominant_obj == 1 else 1\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            if non_dominant_obj == 1:\n                if value1_lst[i] > np.mean(value1_lst):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n            else:\n                if value2_lst[i] > np.mean(value2_lst):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    # Ensure feasibility by removing excess items if necessary\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) > 0:\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8103706697201132,
            4.369010835886002
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards non-dominated solutions with higher potential\n    base_solution, (val1, val2) = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy\n    # 1. Randomly swap items (exploration)\n    if len(new_solution) > 1:\n        i, j = random.sample(range(len(new_solution)), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Objective-based flip: flip items that contribute less to the dominant objective\n    dominant_obj = 1 if val1 > val2 else 2\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if dominant_obj == 1:\n                if value1_lst[i] < np.mean(value1_lst) and (current_weight - weight_lst[i]) <= capacity:\n                    new_solution[i] = 0\n            else:\n                if value2_lst[i] < np.mean(value2_lst) and (current_weight - weight_lst[i]) <= capacity:\n                    new_solution[i] = 0\n\n    # 3. Add items that can improve the non-dominant objective without violating capacity\n    non_dominant_obj = 2 if dominant_obj == 1 else 1\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            if non_dominant_obj == 1:\n                if value1_lst[i] > np.mean(value1_lst):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n            else:\n                if value2_lst[i] > np.mean(value2_lst):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n\n    # Ensure feasibility by removing excess items if necessary\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        if len(excess_items) > 0:\n            remove_idx = random.choice(excess_items)\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 104,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., top 20% by objective values)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = random.randint(0, max(0, len(sorted_archive) // 5 - 1))\n    base_solution = sorted_archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items to explore the neighborhood\n    flip_mask = np.random.rand(len(new_solution)) < 0.1  # 10% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility by removing excess weight\n    excess_weight = np.sum(weight_lst * new_solution) - capacity\n    if excess_weight > 0:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while excess_weight > 0:\n            # Calculate value-to-weight ratio for included items\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Remove the item with the lowest ratio (prioritize value1 and value2)\n            ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            item_to_remove = included_items[np.argmin(ratios)]\n            new_solution[item_to_remove] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    # Strategy 2: Add high-value items if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Identify items not in the solution and sort by combined value-to-weight ratio\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_items = excluded_items[np.argsort(ratios)[::-1]]  # Descending order\n            for item in sorted_items:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.34863148834084773,
            2.5045802295207977
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., top 20% by objective values)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = random.randint(0, max(0, len(sorted_archive) // 5 - 1))\n    base_solution = sorted_archive[selected_idx][0].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Strategy 1: Randomly flip a subset of items to explore the neighborhood\n    flip_mask = np.random.rand(len(new_solution)) < 0.1  # 10% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility by removing excess weight\n    excess_weight = np.sum(weight_lst * new_solution) - capacity\n    if excess_weight > 0:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while excess_weight > 0:\n            # Calculate value-to-weight ratio for included items\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            # Remove the item with the lowest ratio (prioritize value1 and value2)\n            ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            item_to_remove = included_items[np.argmin(ratios)]\n            new_solution[item_to_remove] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    # Strategy 2: Add high-value items if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Identify items not in the solution and sort by combined value-to-weight ratio\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_items = excluded_items[np.argsort(ratios)[::-1]]  # Descending order\n            for item in sorted_items:\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 105,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    potential_solutions = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        # Solutions with some slack (not fully packed) are more promising for improvement\n        if current_weight < capacity * 0.9:\n            potential_solutions.append(sol)\n\n    if not potential_solutions:\n        potential_solutions = [sol for sol, _ in archive]\n\n    base_solution = random.choice(potential_solutions).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swap and value-based perturbation\n    # Step 1: Identify items that could be swapped for better multi-objective performance\n    candidate_indices = np.where(base_solution == 1)[0]\n    if len(candidate_indices) > 0:\n        # Select a random item to consider flipping\n        i = random.choice(candidate_indices)\n        new_solution[i] = 1 - new_solution[i]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight > capacity:\n            # If infeasible, try to replace with a lighter item\n            excluded_indices = np.where(base_solution == 0)[0]\n            if len(excluded_indices) > 0:\n                # Select the lightest item that can be added without violating capacity\n                feasible_indices = [j for j in excluded_indices if weight_lst[j] <= (capacity - current_weight + weight_lst[i])]\n                if feasible_indices:\n                    j = min(feasible_indices, key=lambda x: weight_lst[x])\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n\n    # Step 2: Add a value-based perturbation (consider items with high marginal value)\n    if random.random() < 0.3:  # 30% chance to apply perturbation\n        excluded_indices = np.where(new_solution == 0)[0]\n        if len(excluded_indices) > 0:\n            # Select items with highest marginal value (considering both objectives)\n            marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n            top_candidates = excluded_indices[np.argsort(marginal_values[excluded_indices])[-min(5, len(excluded_indices)):]]\n            if len(top_candidates) > 0:\n                j = random.choice(top_candidates)\n                if np.sum(weight_lst * new_solution) + weight_lst[j] <= capacity:\n                    new_solution[j] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3899337474096574,
            2.2844156622886658
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    potential_solutions = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        # Solutions with some slack (not fully packed) are more promising for improvement\n        if current_weight < capacity * 0.9:\n            potential_solutions.append(sol)\n\n    if not potential_solutions:\n        potential_solutions = [sol for sol, _ in archive]\n\n    base_solution = random.choice(potential_solutions).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swap and value-based perturbation\n    # Step 1: Identify items that could be swapped for better multi-objective performance\n    candidate_indices = np.where(base_solution == 1)[0]\n    if len(candidate_indices) > 0:\n        # Select a random item to consider flipping\n        i = random.choice(candidate_indices)\n        new_solution[i] = 1 - new_solution[i]\n\n        # Ensure feasibility\n        current_weight = np.sum(weight_lst * new_solution)\n        if current_weight > capacity:\n            # If infeasible, try to replace with a lighter item\n            excluded_indices = np.where(base_solution == 0)[0]\n            if len(excluded_indices) > 0:\n                # Select the lightest item that can be added without violating capacity\n                feasible_indices = [j for j in excluded_indices if weight_lst[j] <= (capacity - current_weight + weight_lst[i])]\n                if feasible_indices:\n                    j = min(feasible_indices, key=lambda x: weight_lst[x])\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n\n    # Step 2: Add a value-based perturbation (consider items with high marginal value)\n    if random.random() < 0.3:  # 30% chance to apply perturbation\n        excluded_indices = np.where(new_solution == 0)[0]\n        if len(excluded_indices) > 0:\n            # Select items with highest marginal value (considering both objectives)\n            marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n            top_candidates = excluded_indices[np.argsort(marginal_values[excluded_indices])[-min(5, len(excluded_indices)):]]\n            if len(top_candidates) > 0:\n                j = random.choice(top_candidates)\n                if np.sum(weight_lst * new_solution) + weight_lst[j] <= capacity:\n                    new_solution[j] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 106,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution based on a combination of objective values and solution diversity\n    weights = np.array([solution[0] for solution in archive])\n    objectives = np.array([solution[1] for solution in archive])\n\n    # Normalize objectives to make them comparable\n    if len(objectives) > 1:\n        objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        objective_scores = objectives[:, 0] + objectives[:, 1]  # Simple sum of normalized objectives\n    else:\n        objective_scores = np.array([1.0])\n\n    # Compute diversity scores (distance to other solutions in the archive)\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        diversity = np.sum(np.abs(weights - weights[i]), axis=1)\n        diversity_scores[i] = np.mean(diversity)\n\n    # Normalize diversity scores\n    if len(diversity_scores) > 1:\n        diversity_scores = (diversity_scores - diversity_scores.min()) / (diversity_scores.max() - diversity_scores.min() + 1e-10)\n\n    # Combine objective and diversity scores to select a promising solution\n    combined_scores = objective_scores + diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 2: Apply hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a small number of bits (items) to explore the neighborhood\n    num_flips = max(1, int(0.1 * len(base_solution)))  # Flip 10% of the items or at least 1\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item if it's in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Try adding the item if it's not in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Greedy improvement step: iterate through all items to see if flipping improves the solution\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Try removing the item if it's in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution_temp = new_solution.copy()\n                new_solution_temp[idx] = 0\n                new_weight = current_weight - weight_lst[idx]\n                new_value1 = current_value1 - value1_lst[idx]\n                new_value2 = current_value2 - value2_lst[idx]\n\n                # Check if the new solution dominates the previous one\n                if (new_value1 >= current_value1 and new_value2 >= current_value2) and \\\n                   (new_value1 > current_value1 or new_value2 > current_value2):\n                    new_solution = new_solution_temp\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n        else:\n            # Try adding the item if it's not in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution_temp = new_solution.copy()\n                new_solution_temp[idx] = 1\n                new_weight = current_weight + weight_lst[idx]\n                new_value1 = current_value1 + value1_lst[idx]\n                new_value2 = current_value2 + value2_lst[idx]\n\n                # Check if the new solution dominates the previous one\n                if (new_value1 >= current_value1 and new_value2 >= current_value2) and \\\n                   (new_value1 > current_value1 or new_value2 > current_value2):\n                    new_solution = new_solution_temp\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.4013360060831719,
            5.550976037979126
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution based on a combination of objective values and solution diversity\n    weights = np.array([solution[0] for solution in archive])\n    objectives = np.array([solution[1] for solution in archive])\n\n    # Normalize objectives to make them comparable\n    if len(objectives) > 1:\n        objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        objective_scores = objectives[:, 0] + objectives[:, 1]  # Simple sum of normalized objectives\n    else:\n        objective_scores = np.array([1.0])\n\n    # Compute diversity scores (distance to other solutions in the archive)\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        diversity = np.sum(np.abs(weights - weights[i]), axis=1)\n        diversity_scores[i] = np.mean(diversity)\n\n    # Normalize diversity scores\n    if len(diversity_scores) > 1:\n        diversity_scores = (diversity_scores - diversity_scores.min()) / (diversity_scores.max() - diversity_scores.min() + 1e-10)\n\n    # Combine objective and diversity scores to select a promising solution\n    combined_scores = objective_scores + diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 2: Apply hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a small number of bits (items) to explore the neighborhood\n    num_flips = max(1, int(0.1 * len(base_solution)))  # Flip 10% of the items or at least 1\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item if it's in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Try adding the item if it's not in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Greedy improvement step: iterate through all items to see if flipping improves the solution\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Try removing the item if it's in the solution\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution_temp = new_solution.copy()\n                new_solution_temp[idx] = 0\n                new_weight = current_weight - weight_lst[idx]\n                new_value1 = current_value1 - value1_lst[idx]\n                new_value2 = current_value2 - value2_lst[idx]\n\n                # Check if the new solution dominates the previous one\n                if (new_value1 >= current_value1 and new_value2 >= current_value2) and \\\n                   (new_value1 > current_value1 or new_value2 > current_value2):\n                    new_solution = new_solution_temp\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n        else:\n            # Try adding the item if it's not in the solution\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution_temp = new_solution.copy()\n                new_solution_temp[idx] = 1\n                new_weight = current_weight + weight_lst[idx]\n                new_value1 = current_value1 + value1_lst[idx]\n                new_value2 = current_value2 + value2_lst[idx]\n\n                # Check if the new solution dominates the previous one\n                if (new_value1 >= current_value1 and new_value2 >= current_value2) and \\\n                   (new_value1 > current_value1 or new_value2 > current_value2):\n                    new_solution = new_solution_temp\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 107,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions with non-zero items that can be flipped without violating capacity\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.dot(sol, weight_lst)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            # Find items that can be added without exceeding capacity\n            possible_additions = (weight_lst <= remaining_capacity) & (~sol.astype(bool))\n            if np.any(possible_additions):\n                candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply value-to-weight ratio heuristic (exploitation)\n    n_items = len(new_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_solution[idx] = 0\n            if np.dot(new_solution, weight_lst) <= capacity:\n                # If feasible, keep the change\n                continue\n            else:\n                # Revert if infeasible\n                new_solution[idx] = 1\n        else:\n            # Try adding the item if it fits\n            if weight_lst[idx] <= (capacity - np.dot(new_solution, weight_lst)):\n                # Apply value-to-weight ratio heuristic for selection\n                if np.random.rand() < 0.7:  # Higher probability for better items\n                    ratio1 = value1_lst[idx] / weight_lst[idx]\n                    ratio2 = value2_lst[idx] / weight_lst[idx]\n                    if (ratio1 > 1.0 or ratio2 > 1.0):  # Only add high-value items\n                        new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3106298716240442,
            4.907813787460327
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # Criteria: solutions with non-zero items that can be flipped without violating capacity\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.dot(sol, weight_lst)\n        remaining_capacity = capacity - total_weight\n        if remaining_capacity > 0:\n            # Find items that can be added without exceeding capacity\n            possible_additions = (weight_lst <= remaining_capacity) & (~sol.astype(bool))\n            if np.any(possible_additions):\n                candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply value-to-weight ratio heuristic (exploitation)\n    n_items = len(new_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_solution[idx] = 0\n            if np.dot(new_solution, weight_lst) <= capacity:\n                # If feasible, keep the change\n                continue\n            else:\n                # Revert if infeasible\n                new_solution[idx] = 1\n        else:\n            # Try adding the item if it fits\n            if weight_lst[idx] <= (capacity - np.dot(new_solution, weight_lst)):\n                # Apply value-to-weight ratio heuristic for selection\n                if np.random.rand() < 0.7:  # Higher probability for better items\n                    ratio1 = value1_lst[idx] / weight_lst[idx]\n                    ratio2 = value2_lst[idx] / weight_lst[idx]\n                    if (ratio1 > 1.0 or ratio2 > 1.0):  # Only add high-value items\n                        new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 108,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random flip + Greedy improvement\n    n_items = len(base_solution)\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Randomly flip a subset of items (to escape local optima)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it fits\n            new_solution[idx] = 0\n        else:\n            # Add item if it fits\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Evaluate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n\n    # Combine marginal gains (weighted sum for bi-objective)\n    combined_gain = 0.5 * marginal_gain1 + 0.5 * marginal_gain2\n\n    # Sort items by combined marginal gain (descending)\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            # Try to add item if it fits\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n        else:\n            # Try to remove item\n            new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        # Remove items with lowest combined gain\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8803064377798864,
            1.9241360425949097
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random flip + Greedy improvement\n    n_items = len(base_solution)\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Randomly flip a subset of items (to escape local optima)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Remove item if it fits\n            new_solution[idx] = 0\n        else:\n            # Add item if it fits\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Step 2: Greedy improvement for both objectives\n    # Evaluate marginal gains for both objectives\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n\n    # Combine marginal gains (weighted sum for bi-objective)\n    combined_gain = 0.5 * marginal_gain1 + 0.5 * marginal_gain2\n\n    # Sort items by combined marginal gain (descending)\n    sorted_indices = np.argsort(-combined_gain)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            # Try to add item if it fits\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n        else:\n            # Try to remove item\n            new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        # Remove items with lowest combined gain\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 109,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the boundary\n    # This helps avoid getting stuck in local optima\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]) * 0.3 + np.random.random() * 0.7)\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility: if the solution is infeasible, flip back the last flipped item\n    if np.dot(new_solution, weight_lst) > capacity:\n        for idx in reversed(flip_indices):\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                if np.dot(new_solution, weight_lst) <= capacity:\n                    break\n\n    # Greedy improvement: flip items that improve both objectives\n    # Calculate the marginal gain for each item\n    marginal_gain1 = value1_lst * (1 - 2 * new_solution)  # Gain if flipped\n    marginal_gain2 = value2_lst * (1 - 2 * new_solution)\n\n    # Calculate the total weight if flipped\n    new_weight = np.dot(new_solution, weight_lst)\n\n    # Iterate over items to find the best flip that improves both objectives\n    best_improvement = -1\n    best_idx = -1\n    for idx in range(n_items):\n        if new_solution[idx] == 0 and new_weight + weight_lst[idx] <= capacity:\n            # Calculate the improvement in both objectives\n            improvement = marginal_gain1[idx] + marginal_gain2[idx]\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_idx = idx\n        elif new_solution[idx] == 1:\n            # Check if removing the item improves the objectives\n            improvement = marginal_gain1[idx] + marginal_gain2[idx]\n            if improvement > best_improvement and new_weight - weight_lst[idx] <= capacity:\n                best_improvement = improvement\n                best_idx = idx\n\n    # Apply the best improvement if it exists\n    if best_idx != -1:\n        new_solution[best_idx] = 1 - new_solution[best_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3446570704767426,
            9.904735773801804
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not too close to the boundary\n    # This helps avoid getting stuck in local optima\n    base_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]) * 0.3 + np.random.random() * 0.7)\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility: if the solution is infeasible, flip back the last flipped item\n    if np.dot(new_solution, weight_lst) > capacity:\n        for idx in reversed(flip_indices):\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                if np.dot(new_solution, weight_lst) <= capacity:\n                    break\n\n    # Greedy improvement: flip items that improve both objectives\n    # Calculate the marginal gain for each item\n    marginal_gain1 = value1_lst * (1 - 2 * new_solution)  # Gain if flipped\n    marginal_gain2 = value2_lst * (1 - 2 * new_solution)\n\n    # Calculate the total weight if flipped\n    new_weight = np.dot(new_solution, weight_lst)\n\n    # Iterate over items to find the best flip that improves both objectives\n    best_improvement = -1\n    best_idx = -1\n    for idx in range(n_items):\n        if new_solution[idx] == 0 and new_weight + weight_lst[idx] <= capacity:\n            # Calculate the improvement in both objectives\n            improvement = marginal_gain1[idx] + marginal_gain2[idx]\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_idx = idx\n        elif new_solution[idx] == 1:\n            # Check if removing the item improves the objectives\n            improvement = marginal_gain1[idx] + marginal_gain2[idx]\n            if improvement > best_improvement and new_weight - weight_lst[idx] <= capacity:\n                best_improvement = improvement\n                best_idx = idx\n\n    # Apply the best improvement if it exists\n    if best_idx != -1:\n        new_solution[best_idx] = 1 - new_solution[best_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 110,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.linspace(0.1, 1.0, len(archive)).sum())\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Find items that are in the solution (included) and not in the solution (excluded)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Hybrid local search operator\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Randomly select an item to remove and an item to add\n        item_to_remove = np.random.choice(included_items)\n        item_to_add = np.random.choice(excluded_items)\n\n        # Check if swapping these items maintains feasibility\n        delta_weight = weight_lst[item_to_add] - weight_lst[item_to_remove]\n        if current_weight + delta_weight <= capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # If no swap was made, try adding a random item if possible\n    elif len(excluded_items) > 0:\n        item_to_add = np.random.choice(excluded_items)\n        if current_weight + weight_lst[item_to_add] <= capacity:\n            new_solution[item_to_add] = 1\n\n    # If no addition possible, try removing a random item\n    elif len(included_items) > 0:\n        item_to_remove = np.random.choice(included_items)\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.708605846792016,
            2.7235207557678223
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.linspace(0.1, 1.0, len(archive)).sum())\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Find items that are in the solution (included) and not in the solution (excluded)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Hybrid local search operator\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Randomly select an item to remove and an item to add\n        item_to_remove = np.random.choice(included_items)\n        item_to_add = np.random.choice(excluded_items)\n\n        # Check if swapping these items maintains feasibility\n        delta_weight = weight_lst[item_to_add] - weight_lst[item_to_remove]\n        if current_weight + delta_weight <= capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # If no swap was made, try adding a random item if possible\n    elif len(excluded_items) > 0:\n        item_to_add = np.random.choice(excluded_items)\n        if current_weight + weight_lst[item_to_add] <= capacity:\n            new_solution[item_to_add] = 1\n\n    # If no addition possible, try removing a random item\n    elif len(included_items) > 0:\n        item_to_remove = np.random.choice(included_items)\n        new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 111,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution (with high marginal gains or low crowding distance)\n    # Here, we use a simple heuristic: select a solution with high total value1 or value2\n    # In practice, you might use more sophisticated criteria like crowding distance\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_solution, _ = sorted_archive[0]\n    base_solution = selected_solution.copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Greedy improvement step (exploitation)\n    # Try to add items that improve at least one objective without violating capacity\n    for i in range(n_items):\n        if new_solution[i] == 0:\n            new_weight = np.sum(weight_lst * new_solution) + weight_lst[i]\n            if new_weight <= capacity:\n                # Calculate marginal gains\n                marginal_value1 = value1_lst[i]\n                marginal_value2 = value2_lst[i]\n                # If adding the item improves at least one objective, add it\n                if marginal_value1 > 0 or marginal_value2 > 0:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.34017630478348115,
            8.365561693906784
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution (with high marginal gains or low crowding distance)\n    # Here, we use a simple heuristic: select a solution with high total value1 or value2\n    # In practice, you might use more sophisticated criteria like crowding distance\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_solution, _ = sorted_archive[0]\n    base_solution = selected_solution.copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly flip a subset of items (exploration)\n    flip_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Greedy improvement step (exploitation)\n    # Try to add items that improve at least one objective without violating capacity\n    for i in range(n_items):\n        if new_solution[i] == 0:\n            new_weight = np.sum(weight_lst * new_solution) + weight_lst[i]\n            if new_weight <= capacity:\n                # Calculate marginal gains\n                marginal_value1 = value1_lst[i]\n                marginal_value2 = value2_lst[i]\n                # If adding the item improves at least one objective, add it\n                if marginal_value1 > 0 or marginal_value2 > 0:\n                    new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 112,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the current Pareto front\n    # and have a good balance between both objectives\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_v1, current_v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Novel local search strategy: \"Objective-Driven Flip and Balance\"\n    # Step 1: Identify items that could improve both objectives when flipped\n    potential_flips = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing the item could improve both objectives\n            new_v1 = current_v1 - value1_lst[i]\n            new_v2 = current_v2 - value2_lst[i]\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                potential_flips.append((i, new_v1, new_v2, new_weight))\n        else:\n            # Check if adding the item could improve both objectives\n            new_v1 = current_v1 + value1_lst[i]\n            new_v2 = current_v2 + value2_lst[i]\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                potential_flips.append((i, new_v1, new_v2, new_weight))\n\n    # Step 2: Select the flip that provides the best balance between both objectives\n    if potential_flips:\n        # Calculate improvement scores for both objectives\n        improvements = []\n        for i, new_v1, new_v2, new_weight in potential_flips:\n            v1_improvement = new_v1 - current_v1 if base_solution[i] == 1 else new_v1 - current_v1\n            v2_improvement = new_v2 - current_v2 if base_solution[i] == 1 else new_v2 - current_v2\n            # Balance score: prioritize flips that improve both objectives\n            balance_score = v1_improvement * v2_improvement\n            improvements.append((i, balance_score))\n\n        # Select the flip with the highest balance score\n        if improvements:\n            best_flip_idx = max(improvements, key=lambda x: x[1])[0]\n            new_solution[best_flip_idx] = 1 - new_solution[best_flip_idx]\n\n    # Step 3: If no balanced flip found, perform a random but feasible flip\n    if np.array_equal(new_solution, base_solution):\n        feasible_indices = []\n        for i in range(len(base_solution)):\n            if base_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    feasible_indices.append(i)\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    feasible_indices.append(i)\n\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8865222704939997,
            2.847458153963089
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the current Pareto front\n    # and have a good balance between both objectives\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_v1, current_v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Novel local search strategy: \"Objective-Driven Flip and Balance\"\n    # Step 1: Identify items that could improve both objectives when flipped\n    potential_flips = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing the item could improve both objectives\n            new_v1 = current_v1 - value1_lst[i]\n            new_v2 = current_v2 - value2_lst[i]\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                potential_flips.append((i, new_v1, new_v2, new_weight))\n        else:\n            # Check if adding the item could improve both objectives\n            new_v1 = current_v1 + value1_lst[i]\n            new_v2 = current_v2 + value2_lst[i]\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                potential_flips.append((i, new_v1, new_v2, new_weight))\n\n    # Step 2: Select the flip that provides the best balance between both objectives\n    if potential_flips:\n        # Calculate improvement scores for both objectives\n        improvements = []\n        for i, new_v1, new_v2, new_weight in potential_flips:\n            v1_improvement = new_v1 - current_v1 if base_solution[i] == 1 else new_v1 - current_v1\n            v2_improvement = new_v2 - current_v2 if base_solution[i] == 1 else new_v2 - current_v2\n            # Balance score: prioritize flips that improve both objectives\n            balance_score = v1_improvement * v2_improvement\n            improvements.append((i, balance_score))\n\n        # Select the flip with the highest balance score\n        if improvements:\n            best_flip_idx = max(improvements, key=lambda x: x[1])[0]\n            new_solution[best_flip_idx] = 1 - new_solution[best_flip_idx]\n\n    # Step 3: If no balanced flip found, perform a random but feasible flip\n    if np.array_equal(new_solution, base_solution):\n        feasible_indices = []\n        for i in range(len(base_solution)):\n            if base_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    feasible_indices.append(i)\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    feasible_indices.append(i)\n\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 113,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity:\n            # Check if the solution can be improved in either objective\n            possible_improvement = False\n            for i in range(len(sol)):\n                if sol[i] == 0 and total_weight + weight_lst[i] <= capacity:\n                    # Check if adding this item improves at least one objective\n                    if (value1_lst[i] > 0) or (value2_lst[i] > 0):\n                        possible_improvement = True\n                        break\n            if possible_improvement:\n                candidates.append((sol, obj))\n\n    if not candidates:\n        # If no candidates, select a random solution\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select a candidate with high potential (e.g., high total value in one objective but low in the other)\n        base_solution = candidates[np.random.randint(0, len(candidates))][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flips with targeted improvements\n    total_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - total_weight\n\n    # Step 1: Randomly flip a subset of items to escape local optima\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) > 0:\n        num_flips = min(3, len(flip_indices))  # Limit the number of flips\n        flip_indices = np.random.choice(flip_indices, num_flips, replace=False)\n        new_solution[flip_indices] = 0\n        total_weight = np.sum(new_solution * weight_lst)\n\n    # Step 2: Add items that improve at least one objective, prioritizing those with high marginal utility\n    candidate_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(candidate_items)  # Randomize order for diversity\n\n    for i in candidate_items:\n        if weight_lst[i] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[i] > 0) or (value2_lst[i] > 0):\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n                remaining_capacity = capacity - total_weight\n                if total_weight >= capacity:\n                    break\n\n    # Step 3: Remove items that don't contribute to any objective (if capacity allows)\n    if total_weight < capacity:\n        remove_indices = np.where((new_solution == 1) & (value1_lst == 0) & (value2_lst == 0))[0]\n        for i in remove_indices:\n            if total_weight - weight_lst[i] >= 0:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4767366693297306,
            8.527386486530304
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity:\n            # Check if the solution can be improved in either objective\n            possible_improvement = False\n            for i in range(len(sol)):\n                if sol[i] == 0 and total_weight + weight_lst[i] <= capacity:\n                    # Check if adding this item improves at least one objective\n                    if (value1_lst[i] > 0) or (value2_lst[i] > 0):\n                        possible_improvement = True\n                        break\n            if possible_improvement:\n                candidates.append((sol, obj))\n\n    if not candidates:\n        # If no candidates, select a random solution\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select a candidate with high potential (e.g., high total value in one objective but low in the other)\n        base_solution = candidates[np.random.randint(0, len(candidates))][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flips with targeted improvements\n    total_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - total_weight\n\n    # Step 1: Randomly flip a subset of items to escape local optima\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) > 0:\n        num_flips = min(3, len(flip_indices))  # Limit the number of flips\n        flip_indices = np.random.choice(flip_indices, num_flips, replace=False)\n        new_solution[flip_indices] = 0\n        total_weight = np.sum(new_solution * weight_lst)\n\n    # Step 2: Add items that improve at least one objective, prioritizing those with high marginal utility\n    candidate_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(candidate_items)  # Randomize order for diversity\n\n    for i in candidate_items:\n        if weight_lst[i] <= remaining_capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[i] > 0) or (value2_lst[i] > 0):\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n                remaining_capacity = capacity - total_weight\n                if total_weight >= capacity:\n                    break\n\n    # Step 3: Remove items that don't contribute to any objective (if capacity allows)\n    if total_weight < capacity:\n        remove_indices = np.where((new_solution == 1) & (value1_lst == 0) & (value2_lst == 0))[0]\n        for i in remove_indices:\n            if total_weight - weight_lst[i] >= 0:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 114,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution: prioritize those with high marginal potential\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[(obj[0] + obj[1]) for (_, obj) in archive],\n        k=1\n    )[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Random swaps (exploration)\n    for _ in range(min(5, n_items // 2)):\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Greedy improvement (exploitation)\n    for i in range(n_items):\n        if new_solution[i]:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.4539216525046867,
            1.6801519989967346
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution: prioritize those with high marginal potential\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[(obj[0] + obj[1]) for (_, obj) in archive],\n        k=1\n    )[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps followed by greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Random swaps (exploration)\n    for _ in range(min(5, n_items // 2)):\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Greedy improvement (exploitation)\n    for i in range(n_items):\n        if new_solution[i]:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 115,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement by considering both objectives\n    # and the solution's proximity to the Pareto front\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Calculate the total weight of the base solution\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a list of candidate items to flip (0 to 1 or 1 to 0)\n    candidate_items = np.where(base_solution == 1)[0].tolist() + np.where(base_solution == 0)[0].tolist()\n\n    # Sort candidate items by their potential impact on both objectives\n    # Items with high value ratios are prioritized\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value_ratio1 + value_ratio2  # Simple combination of both objectives\n\n    # Sort items by combined ratio (descending) to prioritize high-value items\n    sorted_items = sorted(candidate_items, key=lambda x: -combined_ratio[x])\n\n    # Try to flip items in order of priority until a feasible neighbor is found\n    new_solution = base_solution.copy()\n    for item in sorted_items:\n        # Calculate the new weight if we flip this item\n        new_weight = total_weight - weight_lst[item] * (2 * base_solution[item] - 1)\n\n        if new_weight <= capacity:\n            # Flip the item and update the solution\n            new_solution[item] = 1 - new_solution[item]\n            total_weight = new_weight\n            break  # Only make one flip to maintain local search\n\n    # If no improvement found, perform a random flip among feasible items\n    if np.array_equal(new_solution, base_solution):\n        feasible_items = [i for i in range(len(weight_lst))\n                         if (base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity) or\n                         (base_solution[i] == 1 and total_weight - weight_lst[i] >= 0)]\n\n        if feasible_items:\n            random_item = np.random.choice(feasible_items)\n            new_solution[random_item] = 1 - new_solution[random_item]\n\n    return new_solution\n\n",
        "score": [
            -0.880916904484998,
            1.623263269662857
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement by considering both objectives\n    # and the solution's proximity to the Pareto front\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Calculate the total weight of the base solution\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a list of candidate items to flip (0 to 1 or 1 to 0)\n    candidate_items = np.where(base_solution == 1)[0].tolist() + np.where(base_solution == 0)[0].tolist()\n\n    # Sort candidate items by their potential impact on both objectives\n    # Items with high value ratios are prioritized\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value_ratio1 + value_ratio2  # Simple combination of both objectives\n\n    # Sort items by combined ratio (descending) to prioritize high-value items\n    sorted_items = sorted(candidate_items, key=lambda x: -combined_ratio[x])\n\n    # Try to flip items in order of priority until a feasible neighbor is found\n    new_solution = base_solution.copy()\n    for item in sorted_items:\n        # Calculate the new weight if we flip this item\n        new_weight = total_weight - weight_lst[item] * (2 * base_solution[item] - 1)\n\n        if new_weight <= capacity:\n            # Flip the item and update the solution\n            new_solution[item] = 1 - new_solution[item]\n            total_weight = new_weight\n            break  # Only make one flip to maintain local search\n\n    # If no improvement found, perform a random flip among feasible items\n    if np.array_equal(new_solution, base_solution):\n        feasible_items = [i for i in range(len(weight_lst))\n                         if (base_solution[i] == 0 and total_weight + weight_lst[i] <= capacity) or\n                         (base_solution[i] == 1 and total_weight - weight_lst[i] >= 0)]\n\n        if feasible_items:\n            random_item = np.random.choice(feasible_items)\n            new_solution[random_item] = 1 - new_solution[random_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 116,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Choose the solution with the highest combined value ratio (value1 + value2) / weight\n    current_values = np.array([(obj[0] + obj[1]) / max(np.dot(sol, weight_lst), 1e-6) for sol, obj in archive])\n    selected_idx = np.argmax(current_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (perturbation)\n    # 2. Apply value-based selection to improve both objectives\n    n_items = len(base_solution)\n    perturbation_size = max(1, int(0.2 * n_items))  # Flip 20% of items\n    flip_indices = np.random.choice(n_items, size=perturbation_size, replace=False)\n\n    # Flip selected items and check feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.dot(new_solution, weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Value-based selection: prioritize items that improve both objectives\n    # Calculate marginal gains for each item\n    marginal_gains = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    candidate_items = np.where(new_solution == 0)[0]\n\n    # Sort candidates by marginal gain and try to add the most promising ones\n    sorted_indices = np.argsort(marginal_gains[candidate_items])[::-1]\n    for idx in sorted_indices:\n        real_idx = candidate_items[idx]\n        current_weight = np.dot(new_solution, weight_lst)\n        if current_weight + weight_lst[real_idx] <= capacity:\n            new_solution[real_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.33490723658719196,
            4.5712069272994995
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Choose the solution with the highest combined value ratio (value1 + value2) / weight\n    current_values = np.array([(obj[0] + obj[1]) / max(np.dot(sol, weight_lst), 1e-6) for sol, obj in archive])\n    selected_idx = np.argmax(current_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (perturbation)\n    # 2. Apply value-based selection to improve both objectives\n    n_items = len(base_solution)\n    perturbation_size = max(1, int(0.2 * n_items))  # Flip 20% of items\n    flip_indices = np.random.choice(n_items, size=perturbation_size, replace=False)\n\n    # Flip selected items and check feasibility\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only flip to 1 if it doesn't exceed capacity\n            current_weight = np.dot(new_solution, weight_lst)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Value-based selection: prioritize items that improve both objectives\n    # Calculate marginal gains for each item\n    marginal_gains = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    candidate_items = np.where(new_solution == 0)[0]\n\n    # Sort candidates by marginal gain and try to add the most promising ones\n    sorted_indices = np.argsort(marginal_gains[candidate_items])[::-1]\n    for idx in sorted_indices:\n        real_idx = candidate_items[idx]\n        current_weight = np.dot(new_solution, weight_lst)\n        if current_weight + weight_lst[real_idx] <= capacity:\n            new_solution[real_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 117,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias toward those with higher total value sums\n    total_values = np.array([sum(obj) for _, obj in archive])\n    if len(total_values) > 1:\n        probs = total_values / np.sum(total_values)\n        selected_idx = np.random.choice(len(archive), p=probs)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search: flip bits with a bias toward items that could improve both objectives\n    for i in range(len(base_solution)):\n        # Calculate potential weight and value changes\n        if base_solution[i] == 1:\n            potential_weight = current_weight - weight_lst[i]\n            potential_value1 = current_value1 - value1_lst[i]\n            potential_value2 = current_value2 - value2_lst[i]\n        else:\n            potential_weight = current_weight + weight_lst[i]\n            potential_value1 = current_value1 + value1_lst[i]\n            potential_value2 = current_value2 + value2_lst[i]\n\n        # Check feasibility\n        if potential_weight <= capacity:\n            # Calculate improvement in both objectives\n            improvement1 = potential_value1 - current_value1 if base_solution[i] == 0 else current_value1 - potential_value1\n            improvement2 = potential_value2 - current_value2 if base_solution[i] == 0 else current_value2 - potential_value2\n\n            # Flip with probability based on improvement in both objectives\n            flip_prob = min(1.0, 0.5 * (improvement1 / (value1_lst[i] + 1e-6) + improvement2 / (value2_lst[i] + 1e-6)))\n            if random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8346022624039049,
            3.4447542130947113
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias toward those with higher total value sums\n    total_values = np.array([sum(obj) for _, obj in archive])\n    if len(total_values) > 1:\n        probs = total_values / np.sum(total_values)\n        selected_idx = np.random.choice(len(archive), p=probs)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Hybrid local search: flip bits with a bias toward items that could improve both objectives\n    for i in range(len(base_solution)):\n        # Calculate potential weight and value changes\n        if base_solution[i] == 1:\n            potential_weight = current_weight - weight_lst[i]\n            potential_value1 = current_value1 - value1_lst[i]\n            potential_value2 = current_value2 - value2_lst[i]\n        else:\n            potential_weight = current_weight + weight_lst[i]\n            potential_value1 = current_value1 + value1_lst[i]\n            potential_value2 = current_value2 + value2_lst[i]\n\n        # Check feasibility\n        if potential_weight <= capacity:\n            # Calculate improvement in both objectives\n            improvement1 = potential_value1 - current_value1 if base_solution[i] == 0 else current_value1 - potential_value1\n            improvement2 = potential_value2 - current_value2 if base_solution[i] == 0 else current_value2 - potential_value2\n\n            # Flip with probability based on improvement in both objectives\n            flip_prob = min(1.0, 0.5 * (improvement1 / (value1_lst[i] + 1e-6) + improvement2 / (value2_lst[i] + 1e-6)))\n            if random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 118,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Hybrid local search: random flip followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random flip (with probability inversely proportional to item weight)\n    flip_prob = 0.5 / (1 + weight_lst / np.max(weight_lst))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flip\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items with smallest marginal value until feasible\n        while excess_weight > 0:\n            # Calculate marginal value for each item (weighted sum of both objectives)\n            marginal_value = (value1_lst + value2_lst) * new_solution\n            # Remove the item with smallest marginal value\n            remove_idx = np.argmax(marginal_value)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n            else:\n                break\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate potential improvement for each item\n        improvement = (value1_lst + value2_lst) * (1 - new_solution)\n        # Sort items by improvement in descending order\n        sorted_indices = np.argsort(-improvement)\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_weight and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.517971000350614,
            3.5276768803596497
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Hybrid local search: random flip followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random flip (with probability inversely proportional to item weight)\n    flip_prob = 0.5 / (1 + weight_lst / np.max(weight_lst))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after random flip\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items with smallest marginal value until feasible\n        while excess_weight > 0:\n            # Calculate marginal value for each item (weighted sum of both objectives)\n            marginal_value = (value1_lst + value2_lst) * new_solution\n            # Remove the item with smallest marginal value\n            remove_idx = np.argmax(marginal_value)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n            else:\n                break\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate potential improvement for each item\n        improvement = (value1_lst + value2_lst) * (1 - new_solution)\n        # Sort items by improvement in descending order\n        sorted_indices = np.argsort(-improvement)\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_weight and new_solution[idx] == 0:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 119,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower objective values (potential for improvement)\n    weights = [obj[0] * obj[1] for _, obj in archive]\n    total_weight = sum(weights)\n    if total_weight == 0:\n        # Uniform selection if all weights are zero\n        base_solution, _ = random.choice(archive)\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        base_solution, _ = random.choices(archive, weights=normalized_weights, k=1)[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily flip items with high marginal gains (exploitation)\n\n    # Step 1: Random flip (exploration)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items randomly\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedy flip based on marginal gains (exploitation)\n    # Calculate marginal gains for all items\n    marginal_gains = []\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Marginal gain if removed\n            gain1 = -value1_lst[idx]\n            gain2 = -value2_lst[idx]\n            marginal_gains.append((gain1, gain2, idx, False))\n        else:\n            # Marginal gain if added (if feasible)\n            if current_weight + weight_lst[idx] <= capacity:\n                gain1 = value1_lst[idx]\n                gain2 = value2_lst[idx]\n                marginal_gains.append((gain1, gain2, idx, True))\n\n    # Sort by combined marginal gain (lexicographic order)\n    marginal_gains.sort(key=lambda x: (x[0] + x[1], x[0]), reverse=True)\n\n    # Flip top 2 items with highest marginal gains\n    for i in range(min(2, len(marginal_gains))):\n        gain1, gain2, idx, add = marginal_gains[i]\n        if add:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        else:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.373702060076116,
            2.5599890053272247
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower objective values (potential for improvement)\n    weights = [obj[0] * obj[1] for _, obj in archive]\n    total_weight = sum(weights)\n    if total_weight == 0:\n        # Uniform selection if all weights are zero\n        base_solution, _ = random.choice(archive)\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        base_solution, _ = random.choices(archive, weights=normalized_weights, k=1)[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Greedily flip items with high marginal gains (exploitation)\n\n    # Step 1: Random flip (exploration)\n    num_items = len(weight_lst)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items randomly\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Greedy flip based on marginal gains (exploitation)\n    # Calculate marginal gains for all items\n    marginal_gains = []\n    for idx in range(num_items):\n        if new_solution[idx] == 1:\n            # Marginal gain if removed\n            gain1 = -value1_lst[idx]\n            gain2 = -value2_lst[idx]\n            marginal_gains.append((gain1, gain2, idx, False))\n        else:\n            # Marginal gain if added (if feasible)\n            if current_weight + weight_lst[idx] <= capacity:\n                gain1 = value1_lst[idx]\n                gain2 = value2_lst[idx]\n                marginal_gains.append((gain1, gain2, idx, True))\n\n    # Sort by combined marginal gain (lexicographic order)\n    marginal_gains.sort(key=lambda x: (x[0] + x[1], x[0]), reverse=True)\n\n    # Flip top 2 items with highest marginal gains\n    for i in range(min(2, len(marginal_gains))):\n        gain1, gain2, idx, add = marginal_gains[i]\n        if add:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        else:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 120,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (neither full nor empty)\n    # and have high marginal gains for both objectives\n    def score_solution(sol_obj_pair):\n        sol, (val1, val2) = sol_obj_pair\n        current_weight = np.sum(weight_lst * sol)\n        # Score based on distance from boundary and marginal gains\n        boundary_score = 1 - abs(2 * current_weight / capacity - 1)  # Prefer solutions not too close to full/empty\n        marginal_gain1 = np.sum(value1_lst * (1 - sol))  # Potential gain if we add more items\n        marginal_gain2 = np.sum(value2_lst * (1 - sol))\n        return boundary_score + marginal_gain1 + marginal_gain2\n\n    scored_solutions = [(score_solution(pair), pair) for pair in archive]\n    scored_solutions.sort(key=lambda x: -x[0])  # Sort by score descending\n    selected_pair = scored_solutions[0][1]  # Select the highest-scoring solution\n    base_solution = selected_pair[0].copy()\n\n    # Hybrid local search operator: combination of random flip and value-based flip\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # First, try to add items with high marginal gain for both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst * (1 - new_solution)\n        marginal_gain2 = value2_lst * (1 - new_solution)\n        # Normalize and combine gains\n        total_gain = marginal_gain1 + marginal_gain2\n        # Select top-k candidates based on combined gain\n        k = min(5, np.sum(1 - new_solution))  # Limit to top 5 or fewer available items\n        if k > 0:\n            top_indices = np.argpartition(total_gain, -k)[-k:]\n            # Try to add the top items if they fit\n            for idx in top_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    # Second, perform random flips to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance of random flip\n        # Select a random subset of items to flip\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If over capacity, remove items with lowest marginal gain\n        while current_weight > capacity:\n            # Calculate marginal gains for currently included items\n            marginal_gain = value1_lst * new_solution + value2_lst * new_solution\n            worst_idx = np.argmin(marginal_gain * new_solution)\n            if new_solution[worst_idx] == 1:\n                new_solution[worst_idx] = 0\n                current_weight -= weight_lst[worst_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8882812426366247,
            5.3356974720954895
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (neither full nor empty)\n    # and have high marginal gains for both objectives\n    def score_solution(sol_obj_pair):\n        sol, (val1, val2) = sol_obj_pair\n        current_weight = np.sum(weight_lst * sol)\n        # Score based on distance from boundary and marginal gains\n        boundary_score = 1 - abs(2 * current_weight / capacity - 1)  # Prefer solutions not too close to full/empty\n        marginal_gain1 = np.sum(value1_lst * (1 - sol))  # Potential gain if we add more items\n        marginal_gain2 = np.sum(value2_lst * (1 - sol))\n        return boundary_score + marginal_gain1 + marginal_gain2\n\n    scored_solutions = [(score_solution(pair), pair) for pair in archive]\n    scored_solutions.sort(key=lambda x: -x[0])  # Sort by score descending\n    selected_pair = scored_solutions[0][1]  # Select the highest-scoring solution\n    base_solution = selected_pair[0].copy()\n\n    # Hybrid local search operator: combination of random flip and value-based flip\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # First, try to add items with high marginal gain for both objectives\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal gains for both objectives\n        marginal_gain1 = value1_lst * (1 - new_solution)\n        marginal_gain2 = value2_lst * (1 - new_solution)\n        # Normalize and combine gains\n        total_gain = marginal_gain1 + marginal_gain2\n        # Select top-k candidates based on combined gain\n        k = min(5, np.sum(1 - new_solution))  # Limit to top 5 or fewer available items\n        if k > 0:\n            top_indices = np.argpartition(total_gain, -k)[-k:]\n            # Try to add the top items if they fit\n            for idx in top_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    # Second, perform random flips to escape local optima\n    if np.random.rand() < 0.3:  # 30% chance of random flip\n        # Select a random subset of items to flip\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If over capacity, remove items with lowest marginal gain\n        while current_weight > capacity:\n            # Calculate marginal gains for currently included items\n            marginal_gain = value1_lst * new_solution + value2_lst * new_solution\n            worst_idx = np.argmin(marginal_gain * new_solution)\n            if new_solution[worst_idx] == 1:\n                new_solution[worst_idx] = 0\n                current_weight -= weight_lst[worst_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 121,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with a higher chance for solutions that are not too crowded in the objective space\n    if len(archive) > 1:\n        # Calculate crowding distance for each solution in the archive\n        crowding_distances = np.zeros(len(archive))\n        objectives = np.array([obj for _, obj in archive])\n        for i in range(2):  # For each objective\n            sorted_indices = np.argsort(objectives[:, i])\n            crowding_distances[sorted_indices[0]] = np.inf\n            crowding_distances[sorted_indices[-1]] = np.inf\n            for j in range(1, len(archive) - 1):\n                crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i])\n\n        # Select a solution with lower crowding distance (more promising for improvement)\n        selected_idx = np.argmin(crowding_distances)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combination of random flip and value-based flip\n    # First, try to flip a random item\n    random_item = np.random.randint(0, len(weight_lst))\n    if new_solution[random_item] == 1:\n        new_solution[random_item] = 0\n    else:\n        if np.sum(weight_lst * new_solution) + weight_lst[random_item] <= capacity:\n            new_solution[random_item] = 1\n\n    # Then, try to flip an item that would improve both objectives\n    # Calculate the marginal contribution of each item\n    marginal_value1 = value1_lst * (1 - 2 * new_solution)\n    marginal_value2 = value2_lst * (1 - 2 * new_solution)\n    marginal_weight = weight_lst * (1 - 2 * new_solution)\n\n    # Calculate the \"benefit\" of flipping each item (considering both objectives)\n    benefit = (marginal_value1 + marginal_value2) / (marginal_weight + 1e-6)  # Avoid division by zero\n\n    # Find the best item to flip (considering both objectives)\n    best_item = np.argmax(benefit)\n\n    # Flip the best item if it improves the solution\n    if new_solution[best_item] == 1:\n        new_solution[best_item] = 0\n    else:\n        if np.sum(weight_lst * new_solution) + weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9286694836943352,
            1.6411748230457306
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with a higher chance for solutions that are not too crowded in the objective space\n    if len(archive) > 1:\n        # Calculate crowding distance for each solution in the archive\n        crowding_distances = np.zeros(len(archive))\n        objectives = np.array([obj for _, obj in archive])\n        for i in range(2):  # For each objective\n            sorted_indices = np.argsort(objectives[:, i])\n            crowding_distances[sorted_indices[0]] = np.inf\n            crowding_distances[sorted_indices[-1]] = np.inf\n            for j in range(1, len(archive) - 1):\n                crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i])\n\n        # Select a solution with lower crowding distance (more promising for improvement)\n        selected_idx = np.argmin(crowding_distances)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combination of random flip and value-based flip\n    # First, try to flip a random item\n    random_item = np.random.randint(0, len(weight_lst))\n    if new_solution[random_item] == 1:\n        new_solution[random_item] = 0\n    else:\n        if np.sum(weight_lst * new_solution) + weight_lst[random_item] <= capacity:\n            new_solution[random_item] = 1\n\n    # Then, try to flip an item that would improve both objectives\n    # Calculate the marginal contribution of each item\n    marginal_value1 = value1_lst * (1 - 2 * new_solution)\n    marginal_value2 = value2_lst * (1 - 2 * new_solution)\n    marginal_weight = weight_lst * (1 - 2 * new_solution)\n\n    # Calculate the \"benefit\" of flipping each item (considering both objectives)\n    benefit = (marginal_value1 + marginal_value2) / (marginal_weight + 1e-6)  # Avoid division by zero\n\n    # Find the best item to flip (considering both objectives)\n    best_item = np.argmax(benefit)\n\n    # Flip the best item if it improves the solution\n    if new_solution[best_item] == 1:\n        new_solution[best_item] = 0\n    else:\n        if np.sum(weight_lst * new_solution) + weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 122,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the current best in either objective\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the range of objectives to identify promising candidates\n    max_value1 = max(obj[0] for obj in archive_objectives)\n    min_value1 = min(obj[0] for obj in archive_objectives)\n    max_value2 = max(obj[1] for obj in archive_objectives)\n    min_value2 = min(obj[1] for obj in archive_objectives)\n\n    # Select solutions that are not at the extremes in both objectives\n    promising_indices = [\n        i for i, obj in enumerate(archive_objectives)\n        if (obj[0] < 0.9 * max_value1) and (obj[1] < 0.9 * max_value2)\n    ]\n\n    if not promising_indices:\n        promising_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = archive_objectives[selected_idx][0]\n    current_value2 = archive_objectives[selected_idx][1]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a few items to escape local optima\n    # 2. Greedily add items that improve both objectives\n    # 3. Remove items that do not contribute to either objective\n\n    # Step 1: Random swaps (1-3 items)\n    num_swaps = random.randint(1, min(3, len(new_solution)))\n    swap_indices = random.sample(range(len(new_solution)), num_swaps)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after swaps\n    new_weight = np.sum(weight_lst[new_solution == 1])\n    if new_weight > capacity:\n        # Remove items randomly until feasible\n        while new_weight > capacity:\n            remove_idx = random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            new_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Greedy addition of items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for idx in remaining_items:\n        if (current_weight + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n\n            # If both objectives improve, add the item\n            if (new_value1 > current_value1) and (new_value2 > current_value2):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Step 3: Remove items that do not contribute to either objective\n    for idx in np.where(new_solution == 1)[0]:\n        if value1_lst[idx] <= 0 and value2_lst[idx] <= 0:\n            new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8875302756625673,
            2.067548781633377
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the current best in either objective\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the range of objectives to identify promising candidates\n    max_value1 = max(obj[0] for obj in archive_objectives)\n    min_value1 = min(obj[0] for obj in archive_objectives)\n    max_value2 = max(obj[1] for obj in archive_objectives)\n    min_value2 = min(obj[1] for obj in archive_objectives)\n\n    # Select solutions that are not at the extremes in both objectives\n    promising_indices = [\n        i for i, obj in enumerate(archive_objectives)\n        if (obj[0] < 0.9 * max_value1) and (obj[1] < 0.9 * max_value2)\n    ]\n\n    if not promising_indices:\n        promising_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = archive_objectives[selected_idx][0]\n    current_value2 = archive_objectives[selected_idx][1]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a few items to escape local optima\n    # 2. Greedily add items that improve both objectives\n    # 3. Remove items that do not contribute to either objective\n\n    # Step 1: Random swaps (1-3 items)\n    num_swaps = random.randint(1, min(3, len(new_solution)))\n    swap_indices = random.sample(range(len(new_solution)), num_swaps)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after swaps\n    new_weight = np.sum(weight_lst[new_solution == 1])\n    if new_weight > capacity:\n        # Remove items randomly until feasible\n        while new_weight > capacity:\n            remove_idx = random.choice(np.where(new_solution == 1)[0])\n            new_solution[remove_idx] = 0\n            new_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Greedy addition of items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for idx in remaining_items:\n        if (current_weight + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n\n            # If both objectives improve, add the item\n            if (new_value1 > current_value1) and (new_value2 > current_value2):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Step 3: Remove items that do not contribute to either objective\n    for idx in np.where(new_solution == 1)[0]:\n        if value1_lst[idx] <= 0 and value2_lst[idx] <= 0:\n            new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 123,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate a neighbor by flipping a random subset of items\n    new_solution = base_solution.copy()\n    flip_indices = random.sample(range(len(base_solution)), min(3, len(base_solution)))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Perform a greedy improvement step: add items that improve at least one objective\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        new_weight = current_weight + weight_lst[idx]\n        if new_weight <= capacity:\n            # Check if adding the item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Perform another greedy improvement step: remove items that do not contribute to any objective\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            if (value1_lst[idx] == 0) and (value2_lst[idx] == 0):\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.38999437885594135,
            2.86831396818161
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Generate a neighbor by flipping a random subset of items\n    new_solution = base_solution.copy()\n    flip_indices = random.sample(range(len(base_solution)), min(3, len(base_solution)))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Perform a greedy improvement step: add items that improve at least one objective\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        new_weight = current_weight + weight_lst[idx]\n        if new_weight <= capacity:\n            # Check if adding the item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight = new_weight\n\n    # Perform another greedy improvement step: remove items that do not contribute to any objective\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            if (value1_lst[idx] == 0) and (value2_lst[idx] == 0):\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 124,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selected_idx = min(5, len(sorted_archive) - 1)\n    base_solution, _ = sorted_archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly flip a subset of items (1-3 items) to create diversity\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess weight\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedily remove items with the lowest ratio of (value1 + value2) / weight\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and total_weight > capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Greedy improvement: add items not in the solution that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if (total_weight + weight_lst[idx]) <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n            old_value1, old_value2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n\n            if (new_value1 > old_value1) and (new_value2 > old_value2):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.33028352718754395,
            3.9597346782684326
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selected_idx = min(5, len(sorted_archive) - 1)\n    base_solution, _ = sorted_archive[selected_idx]\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Randomly flip a subset of items (1-3 items) to create diversity\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess weight\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedily remove items with the lowest ratio of (value1 + value2) / weight\n        item_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_ratios)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and total_weight > capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Greedy improvement: add items not in the solution that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if (total_weight + weight_lst[idx]) <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n            old_value1, old_value2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n\n            if (new_value1 > old_value1) and (new_value2 > old_value2):\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 125,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Identify items to potentially flip\n    flip_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item could improve at least one objective\n            new_weight = current_weight - weight_lst[i]\n            new_value1 = current_value1 - value1_lst[i]\n            new_value2 = current_value2 - value2_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if adding this item could improve at least one objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append(i)\n\n    if not flip_candidates:\n        # No feasible flips, return a random neighbor\n        new_solution = base_solution.copy()\n        flip_idx = random.randint(0, len(base_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Hybrid local search strategy: flip multiple items with high potential\n    new_solution = base_solution.copy()\n    num_flips = min(3, len(flip_candidates))  # Limit to 3 flips for efficiency\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, try to fix by removing items with lowest ratio of (value1 + value2)/weight\n        while total_weight > capacity and np.sum(new_solution) > 0:\n            ratios = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n            ratios[new_solution == 0] = np.inf  # Only consider included items\n            remove_idx = np.argmin(ratios)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.9140990094874053,
            1.8202087879180908
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Identify items to potentially flip\n    flip_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item could improve at least one objective\n            new_weight = current_weight - weight_lst[i]\n            new_value1 = current_value1 - value1_lst[i]\n            new_value2 = current_value2 - value2_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append(i)\n        else:\n            # Check if adding this item could improve at least one objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                flip_candidates.append(i)\n\n    if not flip_candidates:\n        # No feasible flips, return a random neighbor\n        new_solution = base_solution.copy()\n        flip_idx = random.randint(0, len(base_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Hybrid local search strategy: flip multiple items with high potential\n    new_solution = base_solution.copy()\n    num_flips = min(3, len(flip_candidates))  # Limit to 3 flips for efficiency\n    flip_indices = random.sample(flip_candidates, num_flips)\n\n    for i in flip_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, try to fix by removing items with lowest ratio of (value1 + value2)/weight\n        while total_weight > capacity and np.sum(new_solution) > 0:\n            ratios = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n            ratios[new_solution == 0] = np.inf  # Only consider included items\n            remove_idx = np.argmin(ratios)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 126,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of randomness and potential for improvement\n    # Here, we prioritize solutions that are not too close to the Pareto front or have high potential\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[(1 / (1 + obj[0] + obj[1])) for _, obj in archive],\n        k=1\n    )[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a pair of items (if feasible)\n    # 2. Flip items based on marginal improvement in both objectives\n    # 3. Perform a limited number of random flips to escape local optima\n\n    # Step 1: Random swap\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) >= 2:\n        i, j = random.sample(list(candidates), 2)\n        if (current_weight - weight_lst[i] + weight_lst[j] <= capacity) and \\\n           (current_weight - weight_lst[j] + weight_lst[i] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Flip items based on marginal improvement\n    for _ in range(min(5, len(weight_lst))):  # Limit flips to avoid excessive computation\n        # Calculate marginal gains for each item\n        marginal_gains = []\n        for idx in range(len(weight_lst)):\n            if new_solution[idx] == 1:\n                # Potential gain if removed\n                gain1 = -value1_lst[idx]\n                gain2 = -value2_lst[idx]\n                new_weight = current_weight - weight_lst[idx]\n            else:\n                # Potential gain if added (must be feasible)\n                if current_weight + weight_lst[idx] > capacity:\n                    continue\n                gain1 = value1_lst[idx]\n                gain2 = value2_lst[idx]\n                new_weight = current_weight + weight_lst[idx]\n\n            marginal_gains.append((gain1, gain2, idx, new_weight))\n\n        # Sort by combined marginal gain (lexicographic order)\n        marginal_gains.sort(key=lambda x: (-x[0], -x[1]))\n\n        # Apply the best flip if it improves at least one objective\n        for gain1, gain2, idx, new_weight in marginal_gains:\n            if (gain1 > 0 or gain2 > 0) and new_weight <= capacity:\n                new_solution[idx] = 1 - new_solution[idx]\n                current_weight = new_weight\n                break\n\n    # Step 3: Random flips to escape local optima\n    for _ in range(min(3, len(weight_lst))):\n        idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.34004042360064196,
            8.064337730407715
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of randomness and potential for improvement\n    # Here, we prioritize solutions that are not too close to the Pareto front or have high potential\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[(1 / (1 + obj[0] + obj[1])) for _, obj in archive],\n        k=1\n    )[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a pair of items (if feasible)\n    # 2. Flip items based on marginal improvement in both objectives\n    # 3. Perform a limited number of random flips to escape local optima\n\n    # Step 1: Random swap\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) >= 2:\n        i, j = random.sample(list(candidates), 2)\n        if (current_weight - weight_lst[i] + weight_lst[j] <= capacity) and \\\n           (current_weight - weight_lst[j] + weight_lst[i] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Flip items based on marginal improvement\n    for _ in range(min(5, len(weight_lst))):  # Limit flips to avoid excessive computation\n        # Calculate marginal gains for each item\n        marginal_gains = []\n        for idx in range(len(weight_lst)):\n            if new_solution[idx] == 1:\n                # Potential gain if removed\n                gain1 = -value1_lst[idx]\n                gain2 = -value2_lst[idx]\n                new_weight = current_weight - weight_lst[idx]\n            else:\n                # Potential gain if added (must be feasible)\n                if current_weight + weight_lst[idx] > capacity:\n                    continue\n                gain1 = value1_lst[idx]\n                gain2 = value2_lst[idx]\n                new_weight = current_weight + weight_lst[idx]\n\n            marginal_gains.append((gain1, gain2, idx, new_weight))\n\n        # Sort by combined marginal gain (lexicographic order)\n        marginal_gains.sort(key=lambda x: (-x[0], -x[1]))\n\n        # Apply the best flip if it improves at least one objective\n        for gain1, gain2, idx, new_weight in marginal_gains:\n            if (gain1 > 0 or gain2 > 0) and new_weight <= capacity:\n                new_solution[idx] = 1 - new_solution[idx]\n                current_weight = new_weight\n                break\n\n    # Step 3: Random flips to escape local optima\n    for _ in range(min(3, len(weight_lst))):\n        idx = random.randint(0, len(weight_lst) - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 127,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (higher sum indicates potential for improvement)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% of solutions for random selection\n        top_solutions = archive_sorted[:max(1, len(archive) // 3)]\n        base_solution, _ = random.choice(top_solutions)\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (30% of items)\n    n_items = len(weight_lst)\n    flip_indices = np.random.choice(n_items, size=max(1, n_items // 3), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Greedy improvement step: flip items that improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = new_weight\n\n    # Ensure feasibility (should already be ensured by the above steps)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If still infeasible, remove items randomly until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.37882427256391,
            5.702637732028961
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (higher sum indicates potential for improvement)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% of solutions for random selection\n        top_solutions = archive_sorted[:max(1, len(archive) // 3)]\n        base_solution, _ = random.choice(top_solutions)\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (30% of items)\n    n_items = len(weight_lst)\n    flip_indices = np.random.choice(n_items, size=max(1, n_items // 3), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Greedy improvement step: flip items that improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Try removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 0\n                current_weight = new_weight\n        else:\n            # Try adding item i\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i] = 1\n                current_weight = new_weight\n\n    # Ensure feasibility (should already be ensured by the above steps)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # If still infeasible, remove items randomly until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            excess_items = np.where(new_solution == 1)[0]\n            if len(excess_items) == 0:\n                break\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 128,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, base_objective = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combine swap and shift operations\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # First, perform a random swap of two items\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            # Check feasibility after swap\n            new_weight = np.sum(weight_lst[new_solution == 1])\n            if new_weight > capacity:\n                # If infeasible, revert and try another operation\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            else:\n                current_weight = new_weight\n\n    # Second, perform a shift operation (move an item in or out)\n    if random.random() < 0.5:  # 50% chance to perform shift\n        candidates = [i for i in range(n_items) if new_solution[i] == 1]\n        if candidates:\n            i = random.choice(candidates)\n            new_solution[i] = 0\n            # Check if feasible after removal\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                current_weight = new_weight\n            else:\n                new_solution[i] = 1  # Revert if infeasible\n\n        # Try adding an item if feasible\n        candidates = [i for i in range(n_items) if new_solution[i] == 0]\n        if candidates:\n            i = random.choice(candidates)\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.5248628549752661,
            1.325457602739334
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, base_objective = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combine swap and shift operations\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # First, perform a random swap of two items\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            # Check feasibility after swap\n            new_weight = np.sum(weight_lst[new_solution == 1])\n            if new_weight > capacity:\n                # If infeasible, revert and try another operation\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            else:\n                current_weight = new_weight\n\n    # Second, perform a shift operation (move an item in or out)\n    if random.random() < 0.5:  # 50% chance to perform shift\n        candidates = [i for i in range(n_items) if new_solution[i] == 1]\n        if candidates:\n            i = random.choice(candidates)\n            new_solution[i] = 0\n            # Check if feasible after removal\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                current_weight = new_weight\n            else:\n                new_solution[i] = 1  # Revert if infeasible\n\n        # Try adding an item if feasible\n        candidates = [i for i in range(n_items) if new_solution[i] == 0]\n        if candidates:\n            i = random.choice(candidates)\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 129,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    # Here, we select the solution with the highest sum of normalized objective values\n    normalized_objectives = np.array([(v1 / np.max(value1_lst), v2 / np.max(value2_lst)) for _, (v1, v2) in archive])\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by performing a hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap a subset of items (exploration)\n    num_swaps = np.random.randint(1, min(5, len(new_solution)))  # Swap 1 to 5 items\n    swap_indices = np.random.choice(len(new_solution), size=num_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break  # No items to remove, solution is infeasible\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 3: Greedy improvement phase (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n    for idx in remaining_items:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            current_v1, current_v2 = archive[selected_idx][1]\n            new_v1 = current_v1 + value1_lst[idx]\n            new_v2 = current_v2 + value2_lst[idx]\n            if new_v1 > current_v1 and new_v2 > current_v2:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.31494688455171177,
            7.415964663028717
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    # Here, we select the solution with the highest sum of normalized objective values\n    normalized_objectives = np.array([(v1 / np.max(value1_lst), v2 / np.max(value2_lst)) for _, (v1, v2) in archive])\n    scores = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by performing a hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap a subset of items (exploration)\n    num_swaps = np.random.randint(1, min(5, len(new_solution)))  # Swap 1 to 5 items\n    swap_indices = np.random.choice(len(new_solution), size=num_swaps, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Check feasibility and repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            excess_indices = np.where(new_solution == 1)[0]\n            if len(excess_indices) == 0:\n                break  # No items to remove, solution is infeasible\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    # Step 3: Greedy improvement phase (exploitation)\n    # Try to add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n    for idx in remaining_items:\n        if total_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            current_v1, current_v2 = archive[selected_idx][1]\n            new_v1 = current_v1 + value1_lst[idx]\n            new_v2 = current_v2 + value2_lst[idx]\n            if new_v1 > current_v1 and new_v2 > current_v2:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 130,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combination of objective values to find potentially under-explored regions\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2)\n        # Select a solution that is not too close to the best solutions\n        candidate_idx = min(int(len(archive_sorted) * 0.3), len(archive_sorted) - 1)\n        base_solution = archive_sorted[candidate_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    # Step 1: Randomly select a subset of items to consider flipping\n    n_items = len(base_solution)\n    flip_candidates = random.sample(range(n_items), max(1, n_items // 5))\n\n    for idx in flip_candidates:\n        # Step 2: For each candidate, decide whether to flip based on value density\n        current_weight = np.sum(weight_lst * base_solution)\n        if base_solution[idx] == 1:\n            # If item is included, consider removing it if its value contribution is low\n            value_contribution = (value1_lst[idx] + value2_lst[idx]) / weight_lst[idx]\n            if value_contribution < (np.sum(value1_lst + value2_lst) / np.sum(weight_lst)) * 0.7:\n                new_solution[idx] = 0\n        else:\n            # If item is excluded, consider adding it if it fits within capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                # Add item with probability proportional to its value density\n                value_density = (value1_lst[idx] + value2_lst[idx]) / weight_lst[idx]\n                if random.random() < min(1.0, value_density * 0.1):\n                    new_solution[idx] = 1\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value density until capacity is met\n        while total_weight > capacity:\n            # Identify items that are included in new_solution but not in base_solution\n            diff_items = np.where((new_solution == 1) & (base_solution == 0))[0]\n            if len(diff_items) > 0:\n                # Remove the item with lowest value density\n                remove_idx = min(diff_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n                new_solution[remove_idx] = 0\n            else:\n                # If no new items added, remove any item (shouldn't happen if base solution is feasible)\n                remove_idx = np.argmax(weight_lst * new_solution)\n                new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.8375918946639725,
            4.027032971382141
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combination of objective values to find potentially under-explored regions\n        archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]) / 2)\n        # Select a solution that is not too close to the best solutions\n        candidate_idx = min(int(len(archive_sorted) * 0.3), len(archive_sorted) - 1)\n        base_solution = archive_sorted[candidate_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    # Step 1: Randomly select a subset of items to consider flipping\n    n_items = len(base_solution)\n    flip_candidates = random.sample(range(n_items), max(1, n_items // 5))\n\n    for idx in flip_candidates:\n        # Step 2: For each candidate, decide whether to flip based on value density\n        current_weight = np.sum(weight_lst * base_solution)\n        if base_solution[idx] == 1:\n            # If item is included, consider removing it if its value contribution is low\n            value_contribution = (value1_lst[idx] + value2_lst[idx]) / weight_lst[idx]\n            if value_contribution < (np.sum(value1_lst + value2_lst) / np.sum(weight_lst)) * 0.7:\n                new_solution[idx] = 0\n        else:\n            # If item is excluded, consider adding it if it fits within capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                # Add item with probability proportional to its value density\n                value_density = (value1_lst[idx] + value2_lst[idx]) / weight_lst[idx]\n                if random.random() < min(1.0, value_density * 0.1):\n                    new_solution[idx] = 1\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value density until capacity is met\n        while total_weight > capacity:\n            # Identify items that are included in new_solution but not in base_solution\n            diff_items = np.where((new_solution == 1) & (base_solution == 0))[0]\n            if len(diff_items) > 0:\n                # Remove the item with lowest value density\n                remove_idx = min(diff_items, key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x])\n                new_solution[remove_idx] = 0\n            else:\n                # If no new items added, remove any item (shouldn't happen if base solution is feasible)\n                remove_idx = np.argmax(weight_lst * new_solution)\n                new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 131,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the highest sum of normalized objectives to focus on promising regions\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine random flip with objective-aware flip\n    new_solution = base_solution.copy()\n\n    # Random flip (exploration)\n    if np.random.rand() < 0.5:\n        flip_idx = np.random.choice(len(new_solution))\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Objective-aware flip (exploitation)\n    else:\n        # Calculate marginal gains if we flip each item\n        current_weight = np.sum(weight_lst * new_solution)\n        marginal_weights = weight_lst * (1 - 2 * new_solution)  # Weight change if flipped\n\n        # Calculate potential new weight\n        potential_weights = current_weight + marginal_weights\n\n        # Only consider flips that keep us within capacity\n        feasible_flips = (potential_weights <= capacity)\n\n        if np.any(feasible_flips):\n            # Calculate marginal gains for both objectives\n            marginal_value1 = value1_lst * (1 - 2 * new_solution)\n            marginal_value2 = value2_lst * (1 - 2 * new_solution)\n\n            # Combine gains using a weighted sum (could be improved with more sophisticated approach)\n            combined_gains = marginal_value1 + marginal_value2\n\n            # Select the flip with highest combined gain\n            best_flip = np.argmax(combined_gains * feasible_flips)\n            new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    return new_solution\n\n",
        "score": [
            -0.8277616600369742,
            0.995412290096283
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the highest sum of normalized objectives to focus on promising regions\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    scores = normalized_obj.sum(axis=1)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine random flip with objective-aware flip\n    new_solution = base_solution.copy()\n\n    # Random flip (exploration)\n    if np.random.rand() < 0.5:\n        flip_idx = np.random.choice(len(new_solution))\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Objective-aware flip (exploitation)\n    else:\n        # Calculate marginal gains if we flip each item\n        current_weight = np.sum(weight_lst * new_solution)\n        marginal_weights = weight_lst * (1 - 2 * new_solution)  # Weight change if flipped\n\n        # Calculate potential new weight\n        potential_weights = current_weight + marginal_weights\n\n        # Only consider flips that keep us within capacity\n        feasible_flips = (potential_weights <= capacity)\n\n        if np.any(feasible_flips):\n            # Calculate marginal gains for both objectives\n            marginal_value1 = value1_lst * (1 - 2 * new_solution)\n            marginal_value2 = value2_lst * (1 - 2 * new_solution)\n\n            # Combine gains using a weighted sum (could be improved with more sophisticated approach)\n            combined_gains = marginal_value1 + marginal_value2\n\n            # Select the flip with highest combined gain\n            best_flip = np.argmax(combined_gains * feasible_flips)\n            new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 132,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total value\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n\n    # Calculate current total weight and value-to-weight ratios\n    current_weight = np.sum(weight_lst * base_solution)\n    value1_weight_ratios = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value2_weight_ratios = value2_lst / (weight_lst + 1e-10)\n\n    # Hybrid local search: flip items based on value-to-weight ratios and randomness\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n\n    # Determine the number of flips (adaptive based on solution size)\n    num_flips = max(1, int(np.sqrt(num_items)) // 2)\n\n    for _ in range(num_flips):\n        # Select items to flip based on a combination of randomness and value-to-weight ratios\n        flip_candidates = np.where(new_solution == 1)[0] if random.random() < 0.7 else np.where(new_solution == 0)[0]\n\n        if len(flip_candidates) == 0:\n            continue\n\n        # Prioritize items with high value-to-weight ratios for the objectives\n        if random.random() < 0.5:\n            # Prioritize value1\n            selected_item = flip_candidates[np.argmax(value1_weight_ratios[flip_candidates])]\n        else:\n            # Prioritize value2\n            selected_item = flip_candidates[np.argmax(value2_weight_ratios[flip_candidates])]\n\n        # Perform the flip and check feasibility\n        if new_solution[selected_item] == 1:\n            # If removing, ensure the solution remains feasible\n            if current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n        else:\n            # If adding, ensure the solution remains feasible\n            if current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    return new_solution\n\n",
        "score": [
            -0.2823768042137148,
            1.8773143887519836
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher total value\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n\n    # Calculate current total weight and value-to-weight ratios\n    current_weight = np.sum(weight_lst * base_solution)\n    value1_weight_ratios = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value2_weight_ratios = value2_lst / (weight_lst + 1e-10)\n\n    # Hybrid local search: flip items based on value-to-weight ratios and randomness\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n\n    # Determine the number of flips (adaptive based on solution size)\n    num_flips = max(1, int(np.sqrt(num_items)) // 2)\n\n    for _ in range(num_flips):\n        # Select items to flip based on a combination of randomness and value-to-weight ratios\n        flip_candidates = np.where(new_solution == 1)[0] if random.random() < 0.7 else np.where(new_solution == 0)[0]\n\n        if len(flip_candidates) == 0:\n            continue\n\n        # Prioritize items with high value-to-weight ratios for the objectives\n        if random.random() < 0.5:\n            # Prioritize value1\n            selected_item = flip_candidates[np.argmax(value1_weight_ratios[flip_candidates])]\n        else:\n            # Prioritize value2\n            selected_item = flip_candidates[np.argmax(value2_weight_ratios[flip_candidates])]\n\n        # Perform the flip and check feasibility\n        if new_solution[selected_item] == 1:\n            # If removing, ensure the solution remains feasible\n            if current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n        else:\n            # If adding, ensure the solution remains feasible\n            if current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 133,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive (with potential for improvement)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a list of candidate items to flip (not already in solution)\n    candidate_items = np.where(base_solution == 0)[0]\n\n    # If no candidates, flip a random item from the solution\n    if len(candidate_items) == 0:\n        candidate_items = np.where(base_solution == 1)[0]\n\n    # Calculate marginal gains for each candidate item\n    marginal_gains = []\n    for item in candidate_items:\n        new_weight = current_weight + weight_lst[item]\n        if new_weight > capacity:\n            continue  # Skip if adding would exceed capacity\n        gain1 = value1_lst[item]\n        gain2 = value2_lst[item]\n        marginal_gains.append((item, gain1 + gain2))\n\n    if not marginal_gains:\n        # If no feasible additions, try removing items with low marginal loss\n        candidate_items = np.where(base_solution == 1)[0]\n        marginal_gains = []\n        for item in candidate_items:\n            loss1 = value1_lst[item]\n            loss2 = value2_lst[item]\n            marginal_gains.append((item, -(loss1 + loss2)))\n\n    if not marginal_gains:\n        # If no marginal gains, perform random flip\n        item_to_flip = np.random.choice(len(base_solution))\n    else:\n        # Select the item with the highest marginal gain (or random if ties)\n        marginal_gains.sort(key=lambda x: x[1], reverse=True)\n        max_gain = marginal_gains[0][1]\n        best_items = [x[0] for x in marginal_gains if x[1] == max_gain]\n        item_to_flip = np.random.choice(best_items)\n\n    # Flip the selected item\n    new_solution = base_solution.copy()\n    new_solution[item_to_flip] = 1 - new_solution[item_to_flip]\n\n    # Ensure feasibility (if flipping caused infeasibility, undo)\n    if np.sum(weight_lst * new_solution) > capacity:\n        new_solution[item_to_flip] = base_solution[item_to_flip]\n\n    return new_solution\n\n",
        "score": [
            -0.9502079319147736,
            1.9325589537620544
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive (with potential for improvement)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a list of candidate items to flip (not already in solution)\n    candidate_items = np.where(base_solution == 0)[0]\n\n    # If no candidates, flip a random item from the solution\n    if len(candidate_items) == 0:\n        candidate_items = np.where(base_solution == 1)[0]\n\n    # Calculate marginal gains for each candidate item\n    marginal_gains = []\n    for item in candidate_items:\n        new_weight = current_weight + weight_lst[item]\n        if new_weight > capacity:\n            continue  # Skip if adding would exceed capacity\n        gain1 = value1_lst[item]\n        gain2 = value2_lst[item]\n        marginal_gains.append((item, gain1 + gain2))\n\n    if not marginal_gains:\n        # If no feasible additions, try removing items with low marginal loss\n        candidate_items = np.where(base_solution == 1)[0]\n        marginal_gains = []\n        for item in candidate_items:\n            loss1 = value1_lst[item]\n            loss2 = value2_lst[item]\n            marginal_gains.append((item, -(loss1 + loss2)))\n\n    if not marginal_gains:\n        # If no marginal gains, perform random flip\n        item_to_flip = np.random.choice(len(base_solution))\n    else:\n        # Select the item with the highest marginal gain (or random if ties)\n        marginal_gains.sort(key=lambda x: x[1], reverse=True)\n        max_gain = marginal_gains[0][1]\n        best_items = [x[0] for x in marginal_gains if x[1] == max_gain]\n        item_to_flip = np.random.choice(best_items)\n\n    # Flip the selected item\n    new_solution = base_solution.copy()\n    new_solution[item_to_flip] = 1 - new_solution[item_to_flip]\n\n    # Ensure feasibility (if flipping caused infeasibility, undo)\n    if np.sum(weight_lst * new_solution) > capacity:\n        new_solution[item_to_flip] = base_solution[item_to_flip]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 134,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance count (simplified approximation)\n        archive_sorted = sorted(archive, key=lambda x: np.sum(x[0]))\n        # Select from the middle of the sorted list to avoid extremes\n        base_solution = random.choice(archive_sorted[len(archive_sorted)//4 : 3*len(archive_sorted)//4])[0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    n_items = len(weight_lst)\n\n    # Determine the operation based on the current solution's characteristics\n    if np.sum(new_solution) == 0:\n        # If solution is empty, try adding items that have high ratio of value1+value2 to weight\n        combined_value = value1_lst + value2_lst\n        value_ratio = combined_value / weight_lst\n        candidates = np.argsort(value_ratio)[-min(5, n_items):]  # Top 5 items by ratio\n        for item in candidates:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break\n    else:\n        # Hybrid local search: combine swap, insertion, and removal with biased probabilities\n        operation = random.choices(['swap', 'insert', 'remove'], weights=[0.4, 0.3, 0.3])[0]\n\n        if operation == 'swap':\n            # Swap two items: one in the solution and one not in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            out_solution = np.where(new_solution == 0)[0]\n\n            if len(in_solution) > 0 and len(out_solution) > 0:\n                item_out = random.choice(in_solution)\n                item_in = random.choice(out_solution)\n\n                if (current_weight - weight_lst[item_out] + weight_lst[item_in]) <= capacity:\n                    new_solution[item_out] = 0\n                    new_solution[item_in] = 1\n\n        elif operation == 'insert':\n            # Insert a new item into the solution\n            out_solution = np.where(new_solution == 0)[0]\n            if len(out_solution) > 0:\n                # Prefer items with high value1+value2 to weight ratio\n                combined_value = value1_lst + value2_lst\n                value_ratio = combined_value / weight_lst\n                candidates = np.argsort(value_ratio)[-min(3, len(out_solution)):]  # Top 3 candidates\n                for item in candidates:\n                    if weight_lst[item] <= (capacity - current_weight):\n                        new_solution[item] = 1\n                        break\n\n        elif operation == 'remove':\n            # Remove an item from the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) > 0:\n                # Prefer items with low value1+value2 to weight ratio (least beneficial)\n                combined_value = value1_lst + value2_lst\n                value_ratio = combined_value / weight_lst\n                candidates = np.argsort(value_ratio)[:min(2, len(in_solution))]  # Bottom 2 candidates\n                for item in candidates:\n                    if item in in_solution:\n                        new_solution[item] = 0\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.5561382726236835,
            3.0246675610542297
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance count (simplified approximation)\n        archive_sorted = sorted(archive, key=lambda x: np.sum(x[0]))\n        # Select from the middle of the sorted list to avoid extremes\n        base_solution = random.choice(archive_sorted[len(archive_sorted)//4 : 3*len(archive_sorted)//4])[0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    n_items = len(weight_lst)\n\n    # Determine the operation based on the current solution's characteristics\n    if np.sum(new_solution) == 0:\n        # If solution is empty, try adding items that have high ratio of value1+value2 to weight\n        combined_value = value1_lst + value2_lst\n        value_ratio = combined_value / weight_lst\n        candidates = np.argsort(value_ratio)[-min(5, n_items):]  # Top 5 items by ratio\n        for item in candidates:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                break\n    else:\n        # Hybrid local search: combine swap, insertion, and removal with biased probabilities\n        operation = random.choices(['swap', 'insert', 'remove'], weights=[0.4, 0.3, 0.3])[0]\n\n        if operation == 'swap':\n            # Swap two items: one in the solution and one not in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            out_solution = np.where(new_solution == 0)[0]\n\n            if len(in_solution) > 0 and len(out_solution) > 0:\n                item_out = random.choice(in_solution)\n                item_in = random.choice(out_solution)\n\n                if (current_weight - weight_lst[item_out] + weight_lst[item_in]) <= capacity:\n                    new_solution[item_out] = 0\n                    new_solution[item_in] = 1\n\n        elif operation == 'insert':\n            # Insert a new item into the solution\n            out_solution = np.where(new_solution == 0)[0]\n            if len(out_solution) > 0:\n                # Prefer items with high value1+value2 to weight ratio\n                combined_value = value1_lst + value2_lst\n                value_ratio = combined_value / weight_lst\n                candidates = np.argsort(value_ratio)[-min(3, len(out_solution)):]  # Top 3 candidates\n                for item in candidates:\n                    if weight_lst[item] <= (capacity - current_weight):\n                        new_solution[item] = 1\n                        break\n\n        elif operation == 'remove':\n            # Remove an item from the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) > 0:\n                # Prefer items with low value1+value2 to weight ratio (least beneficial)\n                combined_value = value1_lst + value2_lst\n                value_ratio = combined_value / weight_lst\n                candidates = np.argsort(value_ratio)[:min(2, len(in_solution))]  # Bottom 2 candidates\n                for item in candidates:\n                    if item in in_solution:\n                        new_solution[item] = 0\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 135,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the total value for each solution in the archive\n    total_values = np.array([sum(sol[1]) for sol in archive])\n    if len(total_values) > 0:\n        max_value = np.max(total_values)\n        # Select solutions with total value close to the maximum\n        candidates = [sol for sol, obj in archive if sum(obj) >= max_value * 0.9]\n    else:\n        candidates = [sol for sol, _ in archive]\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: random walk with value-based swaps\n    for _ in range(5):  # Number of iterations\n        # Randomly select a subset of items to consider\n        indices = np.where(base_solution == 1)[0]\n        if len(indices) == 0:\n            break\n\n        # Select a random item to flip\n        flip_idx = random.choice(indices)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Check feasibility\n        total_weight = np.sum(weight_lst[new_solution == 1])\n        if total_weight > capacity:\n            new_solution[flip_idx] = base_solution[flip_idx]  # Revert if infeasible\n\n        # Perform value-based swaps to improve both objectives\n        if random.random() < 0.5:  # 50% chance to perform swap\n            # Select items with high value1 and low weight\n            high_value1_items = np.argsort(-value1_lst)[:len(value1_lst)//2]\n            # Select items with high value2 and low weight\n            high_value2_items = np.argsort(-value2_lst)[:len(value2_lst)//2]\n\n            # Try to swap items to improve both objectives\n            for item in high_value1_items:\n                if new_solution[item] == 0 and np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n            for item in high_value2_items:\n                if new_solution[item] == 0 and np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.4129511882491036,
            9.985515654087067
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the total value for each solution in the archive\n    total_values = np.array([sum(sol[1]) for sol in archive])\n    if len(total_values) > 0:\n        max_value = np.max(total_values)\n        # Select solutions with total value close to the maximum\n        candidates = [sol for sol, obj in archive if sum(obj) >= max_value * 0.9]\n    else:\n        candidates = [sol for sol, _ in archive]\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: random walk with value-based swaps\n    for _ in range(5):  # Number of iterations\n        # Randomly select a subset of items to consider\n        indices = np.where(base_solution == 1)[0]\n        if len(indices) == 0:\n            break\n\n        # Select a random item to flip\n        flip_idx = random.choice(indices)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Check feasibility\n        total_weight = np.sum(weight_lst[new_solution == 1])\n        if total_weight > capacity:\n            new_solution[flip_idx] = base_solution[flip_idx]  # Revert if infeasible\n\n        # Perform value-based swaps to improve both objectives\n        if random.random() < 0.5:  # 50% chance to perform swap\n            # Select items with high value1 and low weight\n            high_value1_items = np.argsort(-value1_lst)[:len(value1_lst)//2]\n            # Select items with high value2 and low weight\n            high_value2_items = np.argsort(-value2_lst)[:len(value2_lst)//2]\n\n            # Try to swap items to improve both objectives\n            for item in high_value1_items:\n                if new_solution[item] == 0 and np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n            for item in high_value2_items:\n                if new_solution[item] == 0 and np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 136,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (np.sum(weight_lst[x[0] == 1]) / capacity) * (np.sum(value1_lst[x[0] == 1]) + np.sum(value2_lst[x[0] == 1])))\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy: combination of item swaps and flips\n    for _ in range(5):  # Perform multiple local search steps\n        # Randomly select two distinct items\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Attempt to swap items\n        if new_solution[i] != new_solution[j]:\n            temp = new_solution[i]\n            new_solution[i] = new_solution[j]\n            new_solution[j] = temp\n\n            # Check feasibility\n            if np.sum(weight_lst[new_solution == 1]) > capacity:\n                # If swap makes it infeasible, revert\n                new_solution[j] = new_solution[i]\n                new_solution[i] = temp\n            else:\n                continue  # Keep the swap if feasible\n\n        # If swap didn't happen or was reverted, try flipping a random item\n        k = np.random.randint(n_items)\n        if new_solution[k] == 1:\n            new_solution[k] = 0\n            if np.sum(weight_lst[new_solution == 1]) > capacity:\n                new_solution[k] = 1\n        else:\n            new_solution[k] = 1\n            if np.sum(weight_lst[new_solution == 1]) > capacity:\n                new_solution[k] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.35749981766240285,
            6.028353184461594
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    base_solution, _ = max(archive, key=lambda x: (np.sum(weight_lst[x[0] == 1]) / capacity) * (np.sum(value1_lst[x[0] == 1]) + np.sum(value2_lst[x[0] == 1])))\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy: combination of item swaps and flips\n    for _ in range(5):  # Perform multiple local search steps\n        # Randomly select two distinct items\n        i, j = np.random.choice(n_items, size=2, replace=False)\n\n        # Attempt to swap items\n        if new_solution[i] != new_solution[j]:\n            temp = new_solution[i]\n            new_solution[i] = new_solution[j]\n            new_solution[j] = temp\n\n            # Check feasibility\n            if np.sum(weight_lst[new_solution == 1]) > capacity:\n                # If swap makes it infeasible, revert\n                new_solution[j] = new_solution[i]\n                new_solution[i] = temp\n            else:\n                continue  # Keep the swap if feasible\n\n        # If swap didn't happen or was reverted, try flipping a random item\n        k = np.random.randint(n_items)\n        if new_solution[k] == 1:\n            new_solution[k] = 0\n            if np.sum(weight_lst[new_solution == 1]) > capacity:\n                new_solution[k] = 1\n        else:\n            new_solution[k] = 1\n            if np.sum(weight_lst[new_solution == 1]) > capacity:\n                new_solution[k] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 137,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher combined value\n    total_values = np.array([sum(obj) for _, obj in archive])\n    probabilities = total_values / total_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Get current weight and objective values\n    current_weight = np.dot(base_solution, weight_lst)\n    current_value1 = np.dot(base_solution, value1_lst)\n    current_value2 = np.dot(base_solution, value2_lst)\n\n    # Hybrid local search: random swaps with greedy improvement\n    for _ in range(5):  # Number of attempts to improve\n        # Randomly select two indices to swap\n        idx1, idx2 = random.sample(range(len(new_solution)), 2)\n\n        # Temporarily swap the items\n        temp_solution = new_solution.copy()\n        temp_solution[idx1], temp_solution[idx2] = temp_solution[idx2], temp_solution[idx1]\n\n        # Check feasibility\n        new_weight = np.dot(temp_solution, weight_lst)\n        if new_weight > capacity:\n            continue  # Skip if infeasible\n\n        # Calculate new objective values\n        new_value1 = np.dot(temp_solution, value1_lst)\n        new_value2 = np.dot(temp_solution, value2_lst)\n\n        # Accept if at least one objective improves\n        if new_value1 > current_value1 or new_value2 > current_value2:\n            new_solution = temp_solution\n            current_weight = new_weight\n            current_value1 = new_value1\n            current_value2 = new_value2\n\n    # Greedy improvement step: add or remove items to improve objectives\n    for _ in range(3):\n        # Try adding an item not in the solution\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            idx = random.choice(candidates)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Try removing an item in the solution\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            idx = random.choice(candidates)\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6523188292141289,
            1.9283274114131927
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher combined value\n    total_values = np.array([sum(obj) for _, obj in archive])\n    probabilities = total_values / total_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Get current weight and objective values\n    current_weight = np.dot(base_solution, weight_lst)\n    current_value1 = np.dot(base_solution, value1_lst)\n    current_value2 = np.dot(base_solution, value2_lst)\n\n    # Hybrid local search: random swaps with greedy improvement\n    for _ in range(5):  # Number of attempts to improve\n        # Randomly select two indices to swap\n        idx1, idx2 = random.sample(range(len(new_solution)), 2)\n\n        # Temporarily swap the items\n        temp_solution = new_solution.copy()\n        temp_solution[idx1], temp_solution[idx2] = temp_solution[idx2], temp_solution[idx1]\n\n        # Check feasibility\n        new_weight = np.dot(temp_solution, weight_lst)\n        if new_weight > capacity:\n            continue  # Skip if infeasible\n\n        # Calculate new objective values\n        new_value1 = np.dot(temp_solution, value1_lst)\n        new_value2 = np.dot(temp_solution, value2_lst)\n\n        # Accept if at least one objective improves\n        if new_value1 > current_value1 or new_value2 > current_value2:\n            new_solution = temp_solution\n            current_weight = new_weight\n            current_value1 = new_value1\n            current_value2 = new_value2\n\n    # Greedy improvement step: add or remove items to improve objectives\n    for _ in range(3):\n        # Try adding an item not in the solution\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            idx = random.choice(candidates)\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Try removing an item in the solution\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            idx = random.choice(candidates)\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 138,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the total value of each solution in the archive\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flip and value-based flip\n    if random.random() < 0.5:\n        # Random flip: flip a random subset of items\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        new_solution[flip_indices] = 1 - new_solution[flip_indices]\n    else:\n        # Value-based flip: flip items with the highest marginal value improvement\n        current_weight = np.sum(weight_lst * new_solution)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate marginal value per weight for items not in the solution\n        marginal_value1 = value1_lst * (1 - new_solution) / (weight_lst + 1e-6)\n        marginal_value2 = value2_lst * (1 - new_solution) / (weight_lst + 1e-6)\n        marginal_value = marginal_value1 + marginal_value2\n\n        # Select top items that can be added without exceeding capacity\n        candidate_indices = np.where((1 - new_solution) & (weight_lst <= remaining_capacity))[0]\n        if len(candidate_indices) > 0:\n            top_indices = candidate_indices[np.argsort(marginal_value[candidate_indices])[-min(3, len(candidate_indices)):]]\n            new_solution[top_indices] = 1\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest marginal value until feasible\n        while current_weight > capacity:\n            marginal_value = (value1_lst + value2_lst) * new_solution / (weight_lst + 1e-6)\n            remove_idx = np.argmax(marginal_value * new_solution)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3215800820442999,
            4.206854552030563
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate the total value of each solution in the archive\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of random flip and value-based flip\n    if random.random() < 0.5:\n        # Random flip: flip a random subset of items\n        flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n        new_solution[flip_indices] = 1 - new_solution[flip_indices]\n    else:\n        # Value-based flip: flip items with the highest marginal value improvement\n        current_weight = np.sum(weight_lst * new_solution)\n        remaining_capacity = capacity - current_weight\n\n        # Calculate marginal value per weight for items not in the solution\n        marginal_value1 = value1_lst * (1 - new_solution) / (weight_lst + 1e-6)\n        marginal_value2 = value2_lst * (1 - new_solution) / (weight_lst + 1e-6)\n        marginal_value = marginal_value1 + marginal_value2\n\n        # Select top items that can be added without exceeding capacity\n        candidate_indices = np.where((1 - new_solution) & (weight_lst <= remaining_capacity))[0]\n        if len(candidate_indices) > 0:\n            top_indices = candidate_indices[np.argsort(marginal_value[candidate_indices])[-min(3, len(candidate_indices)):]]\n            new_solution[top_indices] = 1\n\n    # Ensure feasibility by removing items if capacity is exceeded\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest marginal value until feasible\n        while current_weight > capacity:\n            marginal_value = (value1_lst + value2_lst) * new_solution / (weight_lst + 1e-6)\n            remove_idx = np.argmax(marginal_value * new_solution)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 139,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (higher sum indicates better potential)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% of solutions with the highest potential\n        top_candidates = archive_sorted[:max(1, len(archive) // 3)]\n        # Randomly select one from the top candidates\n        base_solution, _ = random.choice(top_candidates)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with bias towards items that could improve objectives)\n    # 2. If feasible, apply a targeted swap of items\n\n    # Step 1: Random flip with bias\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) > 0:\n        # Randomly select a subset of included items to flip\n        flip_subset = np.random.choice(flip_indices, size=min(3, len(flip_indices)), replace=False)\n        new_solution[flip_subset] = 0\n\n    # Step 2: Targeted swap if feasible\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Find items not in the solution that could be added without exceeding capacity\n    remaining_weight = capacity - current_weight\n    available_items = np.where(new_solution == 0)[0]\n    feasible_additions = [i for i in available_items if weight_lst[i] <= remaining_weight]\n\n    if feasible_additions:\n        # Select items that would most improve both objectives\n        improvements = []\n        for i in feasible_additions:\n            improvement1 = value1_lst[i]\n            improvement2 = value2_lst[i]\n            improvements.append((improvement1 + improvement2, i))\n\n        if improvements:\n            # Sort by total improvement and select top 3 candidates\n            improvements.sort(reverse=True, key=lambda x: x[0])\n            top_candidates = [x[1] for x in improvements[:min(3, len(improvements))]]\n\n            # Randomly select one of the top candidates\n            selected_item = random.choice(top_candidates)\n            new_solution[selected_item] = 1\n\n    # Verify feasibility (should always be feasible due to checks above)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If somehow infeasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.5407510476277226,
            2.4637683629989624
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (higher sum indicates better potential)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 30% of solutions with the highest potential\n        top_candidates = archive_sorted[:max(1, len(archive) // 3)]\n        # Randomly select one from the top candidates\n        base_solution, _ = random.choice(top_candidates)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with bias towards items that could improve objectives)\n    # 2. If feasible, apply a targeted swap of items\n\n    # Step 1: Random flip with bias\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) > 0:\n        # Randomly select a subset of included items to flip\n        flip_subset = np.random.choice(flip_indices, size=min(3, len(flip_indices)), replace=False)\n        new_solution[flip_subset] = 0\n\n    # Step 2: Targeted swap if feasible\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Find items not in the solution that could be added without exceeding capacity\n    remaining_weight = capacity - current_weight\n    available_items = np.where(new_solution == 0)[0]\n    feasible_additions = [i for i in available_items if weight_lst[i] <= remaining_weight]\n\n    if feasible_additions:\n        # Select items that would most improve both objectives\n        improvements = []\n        for i in feasible_additions:\n            improvement1 = value1_lst[i]\n            improvement2 = value2_lst[i]\n            improvements.append((improvement1 + improvement2, i))\n\n        if improvements:\n            # Sort by total improvement and select top 3 candidates\n            improvements.sort(reverse=True, key=lambda x: x[0])\n            top_candidates = [x[1] for x in improvements[:min(3, len(improvements))]]\n\n            # Randomly select one of the top candidates\n            selected_item = random.choice(top_candidates)\n            new_solution[selected_item] = 1\n\n    # Verify feasibility (should always be feasible due to checks above)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If somehow infeasible, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 140,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high crowding distance or random if archive is small\n    if len(archive) > 5:\n        # Calculate crowding distance for each solution\n        objectives = np.array([obj for _, obj in archive])\n        crowding_distances = np.zeros(len(archive))\n\n        for m in range(2):  # For each objective\n            sorted_idx = np.argsort(objectives[:, m])\n            crowding_distances[sorted_idx[0]] = np.inf\n            crowding_distances[sorted_idx[-1]] = np.inf\n            for i in range(1, len(archive)-1):\n                crowding_distances[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m])\n\n        # Select solution with highest crowding distance\n        selected_idx = np.argmax(crowding_distances)\n    else:\n        selected_idx = random.randint(0, len(archive)-1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random swaps with value-based selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # First, try to add items with high marginal value\n    for _ in range(min(5, num_items)):\n        candidates = np.where(base_solution == 0)[0]\n        if len(candidates) == 0:\n            break\n\n        # Calculate marginal values for each candidate\n        marginal_values = []\n        for item in candidates:\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                # Use a weighted sum of both objectives for selection\n                marginal_value = (value1_lst[item] + value2_lst[item]) / (weight_lst[item] + 1e-6)\n                marginal_values.append((marginal_value, item))\n            else:\n                marginal_values.append((-np.inf, item))\n\n        if not marginal_values:\n            break\n\n        _, best_item = max(marginal_values)\n        if marginal_values[np.argmax([v[0] for v in marginal_values])][0] > 0:\n            new_solution[best_item] = 1\n            current_weight += weight_lst[best_item]\n\n    # Then, try to remove items with low marginal value\n    for _ in range(min(3, num_items)):\n        candidates = np.where(base_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n\n        # Calculate marginal values for each candidate\n        marginal_values = []\n        for item in candidates:\n            # Use a weighted sum of both objectives for selection\n            marginal_value = (value1_lst[item] + value2_lst[item]) / (weight_lst[item] + 1e-6)\n            marginal_values.append((marginal_value, item))\n\n        if not marginal_values:\n            break\n\n        _, worst_item = min(marginal_values)\n        if marginal_values[np.argmin([v[0] for v in marginal_values])][0] > 0:\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Final check for feasibility\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If not feasible, try to remove items randomly until feasible\n        while np.sum(weight_lst[new_solution == 1]) > capacity:\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) == 0:\n                break\n            item_to_remove = random.choice(candidates)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.8314953632070659,
            7.405985772609711
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high crowding distance or random if archive is small\n    if len(archive) > 5:\n        # Calculate crowding distance for each solution\n        objectives = np.array([obj for _, obj in archive])\n        crowding_distances = np.zeros(len(archive))\n\n        for m in range(2):  # For each objective\n            sorted_idx = np.argsort(objectives[:, m])\n            crowding_distances[sorted_idx[0]] = np.inf\n            crowding_distances[sorted_idx[-1]] = np.inf\n            for i in range(1, len(archive)-1):\n                crowding_distances[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m])\n\n        # Select solution with highest crowding distance\n        selected_idx = np.argmax(crowding_distances)\n    else:\n        selected_idx = random.randint(0, len(archive)-1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random swaps with value-based selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # First, try to add items with high marginal value\n    for _ in range(min(5, num_items)):\n        candidates = np.where(base_solution == 0)[0]\n        if len(candidates) == 0:\n            break\n\n        # Calculate marginal values for each candidate\n        marginal_values = []\n        for item in candidates:\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                # Use a weighted sum of both objectives for selection\n                marginal_value = (value1_lst[item] + value2_lst[item]) / (weight_lst[item] + 1e-6)\n                marginal_values.append((marginal_value, item))\n            else:\n                marginal_values.append((-np.inf, item))\n\n        if not marginal_values:\n            break\n\n        _, best_item = max(marginal_values)\n        if marginal_values[np.argmax([v[0] for v in marginal_values])][0] > 0:\n            new_solution[best_item] = 1\n            current_weight += weight_lst[best_item]\n\n    # Then, try to remove items with low marginal value\n    for _ in range(min(3, num_items)):\n        candidates = np.where(base_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n\n        # Calculate marginal values for each candidate\n        marginal_values = []\n        for item in candidates:\n            # Use a weighted sum of both objectives for selection\n            marginal_value = (value1_lst[item] + value2_lst[item]) / (weight_lst[item] + 1e-6)\n            marginal_values.append((marginal_value, item))\n\n        if not marginal_values:\n            break\n\n        _, worst_item = min(marginal_values)\n        if marginal_values[np.argmin([v[0] for v in marginal_values])][0] > 0:\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Final check for feasibility\n    if np.sum(weight_lst[new_solution == 1]) > capacity:\n        # If not feasible, try to remove items randomly until feasible\n        while np.sum(weight_lst[new_solution == 1]) > capacity:\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) == 0:\n                break\n            item_to_remove = random.choice(candidates)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 141,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not at the extreme of both objectives)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the \"dominance score\" to identify solutions that are not extreme in both objectives\n    dominance_scores = []\n    for i, (v1, v2) in enumerate(archive_objectives):\n        # Count how many solutions dominate this one\n        dominated_count = sum(\n            (v1 <= v1_other and v2 <= v2_other and (v1 < v1_other or v2 < v2_other))\n            for v1_other, v2_other in archive_objectives\n        )\n        dominance_scores.append(dominated_count)\n\n    # Select a solution with the highest dominance score (most dominated, indicating potential for improvement)\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search strategy: Randomly select a subset of items and swap their inclusion status\n    # while ensuring feasibility and improving both objectives\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for swapping\n    subset_size = min(5, n_items)  # Limit to avoid excessive computation\n    candidate_indices = random.sample(range(n_items), subset_size)\n\n    for idx in candidate_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to exclude it (if feasible)\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to include it (if feasible)\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Additional refinement: If the solution is unchanged, perform a random swap\n    if np.array_equal(new_solution, base_solution):\n        # Select two random items and swap their inclusion status\n        idx1, idx2 = random.sample(range(n_items), 2)\n        if (new_solution[idx1] == 1 and total_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity) or \\\n           (new_solution[idx1] == 0 and total_weight + weight_lst[idx1] - weight_lst[idx2] <= capacity):\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "score": [
            -0.8748975000171474,
            2.3302098214626312
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not at the extreme of both objectives)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the \"dominance score\" to identify solutions that are not extreme in both objectives\n    dominance_scores = []\n    for i, (v1, v2) in enumerate(archive_objectives):\n        # Count how many solutions dominate this one\n        dominated_count = sum(\n            (v1 <= v1_other and v2 <= v2_other and (v1 < v1_other or v2 < v2_other))\n            for v1_other, v2_other in archive_objectives\n        )\n        dominance_scores.append(dominated_count)\n\n    # Select a solution with the highest dominance score (most dominated, indicating potential for improvement)\n    selected_idx = np.argmax(dominance_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search strategy: Randomly select a subset of items and swap their inclusion status\n    # while ensuring feasibility and improving both objectives\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider for swapping\n    subset_size = min(5, n_items)  # Limit to avoid excessive computation\n    candidate_indices = random.sample(range(n_items), subset_size)\n\n    for idx in candidate_indices:\n        if new_solution[idx] == 1:\n            # If item is included, try to exclude it (if feasible)\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n        else:\n            # If item is excluded, try to include it (if feasible)\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Additional refinement: If the solution is unchanged, perform a random swap\n    if np.array_equal(new_solution, base_solution):\n        # Select two random items and swap their inclusion status\n        idx1, idx2 = random.sample(range(n_items), 2)\n        if (new_solution[idx1] == 1 and total_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity) or \\\n           (new_solution[idx1] == 0 and total_weight + weight_lst[idx1] - weight_lst[idx2] <= capacity):\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 142,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: Combine bit-flip with value-based swaps\n    # Step 1: Randomly flip a bit (with feasibility check)\n    flip_idx = np.random.randint(0, len(weight_lst))\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    # Step 2: Value-based swap (swap an included item with an excluded one that improves both objectives)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Find the item with the lowest marginal value in the knapsack\n        marginal_value1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_value2 = value2_lst[included_items] / weight_lst[included_items]\n        worst_item_idx = included_items[np.argmin(marginal_value1 + marginal_value2)]\n\n        # Find the best item to swap in (highest marginal value among excluded items)\n        marginal_value1_excluded = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_value2_excluded = value2_lst[excluded_items] / weight_lst[excluded_items]\n        best_candidate_idx = excluded_items[np.argmax(marginal_value1_excluded + marginal_value2_excluded)]\n\n        # Check if swap is feasible\n        weight_diff = weight_lst[best_candidate_idx] - weight_lst[worst_item_idx]\n        if current_weight + weight_diff <= capacity:\n            new_solution[worst_item_idx] = 0\n            new_solution[best_candidate_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3125794118167081,
            5.820219874382019
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: Combine bit-flip with value-based swaps\n    # Step 1: Randomly flip a bit (with feasibility check)\n    flip_idx = np.random.randint(0, len(weight_lst))\n    if new_solution[flip_idx] == 1:\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    # Step 2: Value-based swap (swap an included item with an excluded one that improves both objectives)\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Find the item with the lowest marginal value in the knapsack\n        marginal_value1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_value2 = value2_lst[included_items] / weight_lst[included_items]\n        worst_item_idx = included_items[np.argmin(marginal_value1 + marginal_value2)]\n\n        # Find the best item to swap in (highest marginal value among excluded items)\n        marginal_value1_excluded = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_value2_excluded = value2_lst[excluded_items] / weight_lst[excluded_items]\n        best_candidate_idx = excluded_items[np.argmax(marginal_value1_excluded + marginal_value2_excluded)]\n\n        # Check if swap is feasible\n        weight_diff = weight_lst[best_candidate_idx] - weight_lst[worst_item_idx]\n        if current_weight + weight_diff <= capacity:\n            new_solution[worst_item_idx] = 0\n            new_solution[best_candidate_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 143,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Intelligently select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the boundary (not too full or too empty)\n    # and have a balanced improvement potential in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        utilization = total_weight / capacity\n        # Prefer solutions that are neither too full nor too empty\n        if 0.3 <= utilization <= 0.7:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if no good candidates\n\n    # Randomly select a candidate solution with a bias towards better solutions\n    # Here, we use a simple roulette wheel selection based on the sum of objectives\n    weights = [obj[0] + obj[1] for _, obj in candidates]\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution, _ = candidates[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search operator\n    # We use a combination of:\n    # 1. Random flip of items (basic local search)\n    # 2. A more sophisticated operator that considers both objectives simultaneously\n    # 3. A weight-adjusting operator that prioritizes items with higher value-to-weight ratios\n\n    # Operator 1: Random flip with objective-aware replacement\n    if random.random() < 0.5:\n        # Flip a random item and replace it with another if it improves both objectives\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # If flipping made it infeasible, try to replace with another item\n        current_weight = np.sum(new_solution * weight_lst)\n        if current_weight > capacity:\n            # Find an item to remove that would make it feasible\n            excess = current_weight - capacity\n            # Find items with weight <= excess that are in the solution\n            removable = [i for i in range(len(new_solution)) if new_solution[i] == 1 and weight_lst[i] <= excess]\n            if removable:\n                remove_idx = random.choice(removable)\n                new_solution[remove_idx] = 0\n    else:\n        # Operator 2: Weight-adjusting operator\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Combine ratios with some randomness to explore different trade-offs\n        combined_ratio = v1_ratio + v2_ratio + np.random.uniform(0, 0.1, len(weight_lst))\n\n        # Sort items by combined ratio in descending order\n        sorted_indices = np.argsort(-combined_ratio)\n\n        # Try to add the best items not currently in the solution\n        current_weight = np.sum(new_solution * weight_lst)\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Then try to remove the worst items currently in the solution\n        # Calculate the \"worst\" items based on their contribution to both objectives\n        item_contributions = (value1_lst * new_solution) + (value2_lst * new_solution)\n        sorted_contributions = np.argsort(item_contributions)\n\n        for idx in sorted_contributions:\n            if new_solution[idx] == 1:\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight >= 0:  # Ensure non-negative weight (though capacity check is more important)\n                    new_solution[idx] = 0\n                    current_weight = new_weight\n\n    # Ensure the solution is feasible (this is a safety check)\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Randomly remove items until feasible\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable = [i for i in range(len(new_solution)) if new_solution[i] == 1 and weight_lst[i] <= excess]\n        if removable:\n            remove_idx = random.choice(removable)\n            new_solution[remove_idx] = 0\n        else:\n            # If no single item can be removed, remove the heaviest item\n            max_weight_idx = np.argmax(new_solution * weight_lst)\n            new_solution[max_weight_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5673558512696438,
            3.7526898980140686
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Intelligently select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the boundary (not too full or too empty)\n    # and have a balanced improvement potential in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        utilization = total_weight / capacity\n        # Prefer solutions that are neither too full nor too empty\n        if 0.3 <= utilization <= 0.7:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if no good candidates\n\n    # Randomly select a candidate solution with a bias towards better solutions\n    # Here, we use a simple roulette wheel selection based on the sum of objectives\n    weights = [obj[0] + obj[1] for _, obj in candidates]\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution, _ = candidates[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search operator\n    # We use a combination of:\n    # 1. Random flip of items (basic local search)\n    # 2. A more sophisticated operator that considers both objectives simultaneously\n    # 3. A weight-adjusting operator that prioritizes items with higher value-to-weight ratios\n\n    # Operator 1: Random flip with objective-aware replacement\n    if random.random() < 0.5:\n        # Flip a random item and replace it with another if it improves both objectives\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # If flipping made it infeasible, try to replace with another item\n        current_weight = np.sum(new_solution * weight_lst)\n        if current_weight > capacity:\n            # Find an item to remove that would make it feasible\n            excess = current_weight - capacity\n            # Find items with weight <= excess that are in the solution\n            removable = [i for i in range(len(new_solution)) if new_solution[i] == 1 and weight_lst[i] <= excess]\n            if removable:\n                remove_idx = random.choice(removable)\n                new_solution[remove_idx] = 0\n    else:\n        # Operator 2: Weight-adjusting operator\n        # Calculate value-to-weight ratios for both objectives\n        v1_ratio = value1_lst / weight_lst\n        v2_ratio = value2_lst / weight_lst\n\n        # Combine ratios with some randomness to explore different trade-offs\n        combined_ratio = v1_ratio + v2_ratio + np.random.uniform(0, 0.1, len(weight_lst))\n\n        # Sort items by combined ratio in descending order\n        sorted_indices = np.argsort(-combined_ratio)\n\n        # Try to add the best items not currently in the solution\n        current_weight = np.sum(new_solution * weight_lst)\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Then try to remove the worst items currently in the solution\n        # Calculate the \"worst\" items based on their contribution to both objectives\n        item_contributions = (value1_lst * new_solution) + (value2_lst * new_solution)\n        sorted_contributions = np.argsort(item_contributions)\n\n        for idx in sorted_contributions:\n            if new_solution[idx] == 1:\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight >= 0:  # Ensure non-negative weight (though capacity check is more important)\n                    new_solution[idx] = 0\n                    current_weight = new_weight\n\n    # Ensure the solution is feasible (this is a safety check)\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Randomly remove items until feasible\n        excess = np.sum(new_solution * weight_lst) - capacity\n        removable = [i for i in range(len(new_solution)) if new_solution[i] == 1 and weight_lst[i] <= excess]\n        if removable:\n            remove_idx = random.choice(removable)\n            new_solution[remove_idx] = 0\n        else:\n            # If no single item can be removed, remove the heaviest item\n            max_weight_idx = np.argmax(new_solution * weight_lst)\n            new_solution[max_weight_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 144,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher values\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select items to swap or flip\n    indices = np.random.permutation(len(new_solution))\n    for idx in indices:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if new_solution[idx] == 1:\n                # If removing, ensure the solution remains feasible or improves feasibility\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                # If adding, ensure the solution remains feasible\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Additional heuristic: swap two items if it improves both objectives\n    for _ in range(5):  # Limit the number of swaps to avoid excessive computation\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility after swap\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                delta_weight = weight_lst[j] - weight_lst[i]\n                if current_weight + delta_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight += delta_weight\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                delta_weight = weight_lst[i] - weight_lst[j]\n                if current_weight + delta_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight += delta_weight\n\n    return new_solution\n\n",
        "score": [
            -0.4732179659205388,
            3.6414582431316376
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher values\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select items to swap or flip\n    indices = np.random.permutation(len(new_solution))\n    for idx in indices:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if new_solution[idx] == 1:\n                # If removing, ensure the solution remains feasible or improves feasibility\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                # If adding, ensure the solution remains feasible\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Additional heuristic: swap two items if it improves both objectives\n    for _ in range(5):  # Limit the number of swaps to avoid excessive computation\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility after swap\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                delta_weight = weight_lst[j] - weight_lst[i]\n                if current_weight + delta_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight += delta_weight\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                delta_weight = weight_lst[i] - weight_lst[j]\n                if current_weight + delta_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight += delta_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 145,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution based on potential for improvement\n    # Here, we select a solution with the highest sum of normalized objectives (simplistic but effective)\n    scores = [sum(obj) for _, obj in archive]\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Hybrid local search with weighted random flips\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Determine flip candidates: items that can be added or removed without violating capacity\n    # We consider flipping items that are either:\n    # 1. Currently in the knapsack and have high marginal contribution\n    # 2. Currently not in the knapsack and have high potential contribution\n    in_knapsack = base_solution == 1\n    marginal_value1 = value1_lst[in_knapsack]\n    marginal_value2 = value2_lst[in_knapsack]\n    total_value1, total_value2 = archive[selected_idx][1]\n\n    # Calculate weights for flipping (higher value items are more likely to be flipped)\n    flip_weights = np.zeros(n_items)\n    flip_weights[in_knapsack] = marginal_value1 + marginal_value2\n    flip_weights[~in_knapsack] = value1_lst[~in_knapsack] + value2_lst[~in_knapsack]\n\n    # Normalize weights to create a probability distribution\n    flip_weights = flip_weights / np.sum(flip_weights)\n\n    # Perform a number of flips proportional to the solution size\n    num_flips = max(1, int(0.1 * n_items))\n\n    for _ in range(num_flips):\n        # Select a candidate to flip based on weights\n        candidate = np.random.choice(n_items, p=flip_weights)\n\n        # Try flipping the candidate\n        temp_solution = new_solution.copy()\n        temp_solution[candidate] = 1 - temp_solution[candidate]\n\n        # Check feasibility\n        new_weight = np.sum(weight_lst[temp_solution == 1])\n        if new_weight <= capacity:\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.5025051011156292,
            7.066862136125565
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution based on potential for improvement\n    # Here, we select a solution with the highest sum of normalized objectives (simplistic but effective)\n    scores = [sum(obj) for _, obj in archive]\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Hybrid local search with weighted random flips\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Determine flip candidates: items that can be added or removed without violating capacity\n    # We consider flipping items that are either:\n    # 1. Currently in the knapsack and have high marginal contribution\n    # 2. Currently not in the knapsack and have high potential contribution\n    in_knapsack = base_solution == 1\n    marginal_value1 = value1_lst[in_knapsack]\n    marginal_value2 = value2_lst[in_knapsack]\n    total_value1, total_value2 = archive[selected_idx][1]\n\n    # Calculate weights for flipping (higher value items are more likely to be flipped)\n    flip_weights = np.zeros(n_items)\n    flip_weights[in_knapsack] = marginal_value1 + marginal_value2\n    flip_weights[~in_knapsack] = value1_lst[~in_knapsack] + value2_lst[~in_knapsack]\n\n    # Normalize weights to create a probability distribution\n    flip_weights = flip_weights / np.sum(flip_weights)\n\n    # Perform a number of flips proportional to the solution size\n    num_flips = max(1, int(0.1 * n_items))\n\n    for _ in range(num_flips):\n        # Select a candidate to flip based on weights\n        candidate = np.random.choice(n_items, p=flip_weights)\n\n        # Try flipping the candidate\n        temp_solution = new_solution.copy()\n        temp_solution[candidate] = 1 - temp_solution[candidate]\n\n        # Check feasibility\n        new_weight = np.sum(weight_lst[temp_solution == 1])\n        if new_weight <= capacity:\n            new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 146,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We define potential as solutions that are not too close to the Pareto front\n    # and have a good balance between the two objectives\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n\n    # Calculate the \"potential score\" for each solution\n    potential_scores = []\n    for i, (sol, obj, weight) in enumerate(zip(archive_solutions, archive_objectives, archive_weights)):\n        # Score is based on the balance between the two objectives and the remaining capacity\n        remaining_capacity = capacity - weight\n        balance_score = (obj[0] + obj[1]) / (1 + abs(obj[0] - obj[1]))  # Higher for balanced solutions\n        capacity_score = remaining_capacity / capacity  # Higher for solutions with more remaining capacity\n        potential_score = balance_score * capacity_score\n        potential_scores.append(potential_score)\n\n    # Select the solution with the highest potential score\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = archive_weights[selected_idx]\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Randomly select a subset of items to perturb\n    n_items = len(base_solution)\n    perturb_size = min(5, n_items)  # Perturb at most 5 items\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n\n    # For each perturbed item, decide whether to flip it based on value and weight\n    for idx in perturb_indices:\n        if base_solution[idx] == 1:\n            # If item is included, consider removing it if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                # Remove the item if it doesn't drastically change the objectives\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not included, consider adding it if it fits and improves the objectives\n            if current_weight + weight_lst[idx] <= capacity:\n                # Add the item if it improves the balance between the two objectives\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 3: Apply a value-based greedy improvement step\n    # Sort items by the ratio of the sum of values to weight\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratios)[::-1]  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Add the most valuable item that fits\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            # Remove the least valuable item if it's not critical\n            # This is a placeholder - in practice, you might want to track which items are critical\n            if np.random.rand() < 0.3:  # 30% chance to remove\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.46494985711781683,
            3.4192682206630707
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # We define potential as solutions that are not too close to the Pareto front\n    # and have a good balance between the two objectives\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n\n    # Calculate the \"potential score\" for each solution\n    potential_scores = []\n    for i, (sol, obj, weight) in enumerate(zip(archive_solutions, archive_objectives, archive_weights)):\n        # Score is based on the balance between the two objectives and the remaining capacity\n        remaining_capacity = capacity - weight\n        balance_score = (obj[0] + obj[1]) / (1 + abs(obj[0] - obj[1]))  # Higher for balanced solutions\n        capacity_score = remaining_capacity / capacity  # Higher for solutions with more remaining capacity\n        potential_score = balance_score * capacity_score\n        potential_scores.append(potential_score)\n\n    # Select the solution with the highest potential score\n    selected_idx = np.argmax(potential_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = archive_weights[selected_idx]\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Randomly select a subset of items to perturb\n    n_items = len(base_solution)\n    perturb_size = min(5, n_items)  # Perturb at most 5 items\n    perturb_indices = np.random.choice(n_items, size=perturb_size, replace=False)\n\n    # For each perturbed item, decide whether to flip it based on value and weight\n    for idx in perturb_indices:\n        if base_solution[idx] == 1:\n            # If item is included, consider removing it if it's not critical\n            if current_weight - weight_lst[idx] >= 0:\n                # Remove the item if it doesn't drastically change the objectives\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If item is not included, consider adding it if it fits and improves the objectives\n            if current_weight + weight_lst[idx] <= capacity:\n                # Add the item if it improves the balance between the two objectives\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 3: Apply a value-based greedy improvement step\n    # Sort items by the ratio of the sum of values to weight\n    value_ratios = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_ratios)[::-1]  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Add the most valuable item that fits\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            # Remove the least valuable item if it's not critical\n            # This is a placeholder - in practice, you might want to track which items are critical\n            if np.random.rand() < 0.3:  # 30% chance to remove\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 147,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.argmin([np.sum(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine random flips with value-based swaps\n    new_solution = base_solution.copy()\n\n    # Random flips (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Value-based swaps (exploitation)\n    if np.random.rand() < 0.5:  # 50% chance to perform swaps\n        # Find items with high marginal value ratios\n        marginal_ratio1 = value1_lst / (weight_lst + 1e-6)\n        marginal_ratio2 = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = marginal_ratio1 + marginal_ratio2\n\n        # Sort items by combined marginal ratio (descending)\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8196930489426816,
            2.2912239730358124
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.argmin([np.sum(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine random flips with value-based swaps\n    new_solution = base_solution.copy()\n\n    # Random flips (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Value-based swaps (exploitation)\n    if np.random.rand() < 0.5:  # 50% chance to perform swaps\n        # Find items with high marginal value ratios\n        marginal_ratio1 = value1_lst / (weight_lst + 1e-6)\n        marginal_ratio2 = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = marginal_ratio1 + marginal_ratio2\n\n        # Sort items by combined marginal ratio (descending)\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        for idx in sorted_indices:\n            if base_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif base_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 148,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already at the Pareto front)\n    # Here, we prioritize solutions with lower total weight utilization (more room for improvement)\n    selected_idx = np.argmin([np.sum(weight_lst * sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: Combine random flip with value-based swap\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip with value-based bias\n    if random.random() < 0.7:  # 70% chance for flip-based move\n        # Identify items with high marginal value-to-weight ratio in either objective\n        current_weight = np.sum(weight_lst * new_solution)\n        available_weight = capacity - current_weight\n\n        # Calculate marginal value-to-weight ratios\n        marginal1 = value1_lst / weight_lst\n        marginal2 = value2_lst / weight_lst\n\n        # Combine marginal values\n        combined_marginal = marginal1 + marginal2\n\n        # Sort items by combined marginal value (descending)\n        sorted_indices = np.argsort(-combined_marginal)\n\n        # Try to flip items in order of importance\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight >= 0:\n                    new_solution[idx] = 0\n                    current_weight = new_weight\n            else:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n                    current_weight = new_weight\n    else:  # 30% chance for swap-based move\n        # Select two items to swap (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items based on value-to-weight ratio\n            in_idx = random.choice(in_items)\n            out_idx = random.choice(out_items)\n\n            # Calculate new weight\n            new_weight = np.sum(weight_lst * new_solution) - weight_lst[in_idx] + weight_lst[out_idx]\n\n            if new_weight <= capacity:\n                new_solution[in_idx] = 0\n                new_solution[out_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.7616287509549446,
            2.751645714044571
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already at the Pareto front)\n    # Here, we prioritize solutions with lower total weight utilization (more room for improvement)\n    selected_idx = np.argmin([np.sum(weight_lst * sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: Combine random flip with value-based swap\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip with value-based bias\n    if random.random() < 0.7:  # 70% chance for flip-based move\n        # Identify items with high marginal value-to-weight ratio in either objective\n        current_weight = np.sum(weight_lst * new_solution)\n        available_weight = capacity - current_weight\n\n        # Calculate marginal value-to-weight ratios\n        marginal1 = value1_lst / weight_lst\n        marginal2 = value2_lst / weight_lst\n\n        # Combine marginal values\n        combined_marginal = marginal1 + marginal2\n\n        # Sort items by combined marginal value (descending)\n        sorted_indices = np.argsort(-combined_marginal)\n\n        # Try to flip items in order of importance\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight >= 0:\n                    new_solution[idx] = 0\n                    current_weight = new_weight\n            else:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_solution[idx] = 1\n                    current_weight = new_weight\n    else:  # 30% chance for swap-based move\n        # Select two items to swap (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items based on value-to-weight ratio\n            in_idx = random.choice(in_items)\n            out_idx = random.choice(out_items)\n\n            # Calculate new weight\n            new_weight = np.sum(weight_lst * new_solution) - weight_lst[in_idx] + weight_lst[out_idx]\n\n            if new_weight <= capacity:\n                new_solution[in_idx] = 0\n                new_solution[out_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 149,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Intelligently select a solution: prioritize those that are not dominated by many others\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random bit flipping followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random bit flipping (exploration)\n    for _ in range(min(5, len(new_solution))):  # Flip up to 5 random bits\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            # Try to remove the item if feasible\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            # Try to add the item if feasible\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Sort items by the ratio of (value1 + value2) / weight to prioritize high-value, low-weight items\n    item_ratios = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-item_ratios)  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            # Check if removing the item improves the solution (e.g., if it's a low-value item)\n            if random.random() < 0.3:  # 30% chance to remove low-value items\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.32695334839005896,
            1.9944835305213928
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Intelligently select a solution: prioritize those that are not dominated by many others\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random bit flipping followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random bit flipping (exploration)\n    for _ in range(min(5, len(new_solution))):  # Flip up to 5 random bits\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            # Try to remove the item if feasible\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            # Try to add the item if feasible\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Sort items by the ratio of (value1 + value2) / weight to prioritize high-value, low-weight items\n    item_ratios = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-item_ratios)  # Descending order\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] <= capacity:\n            # Check if removing the item improves the solution (e.g., if it's a low-value item)\n            if random.random() < 0.3:  # 30% chance to remove low-value items\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 150,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply a greedy improvement step (exploitation)\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing excess weight if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until weight is within capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for idx in excess_items:\n            new_solution[idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight <= capacity:\n                break\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4165008308942102,
            1.746885895729065
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply a greedy improvement step (exploitation)\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing excess weight if necessary\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until weight is within capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for idx in excess_items:\n            new_solution[idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n            if current_weight <= capacity:\n                break\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 151,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Intelligent selection: prioritize solutions that are not dominated in either objective\n    selected_sol = random.choice(candidates)\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search strategy: combine item swaps and value-based perturbations\n    num_items = len(weight_lst)\n    for _ in range(min(5, num_items // 2)):  # Limit the number of perturbations\n        # Value-based perturbation: flip items with high marginal contribution\n        marginal_contribution1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        marginal_contribution2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine marginal contributions with current solution\n        combined_contribution = marginal_contribution1 + marginal_contribution2\n        combined_contribution[new_solution == 1] *= 0.5  # Reduce contribution of already selected items\n\n        # Select item to flip based on combined contribution\n        candidate_indices = np.where(combined_contribution > 0)[0]\n        if len(candidate_indices) == 0:\n            break\n\n        flip_idx = random.choice(candidate_indices)\n\n        # Check feasibility before flipping\n        if new_solution[flip_idx] == 0:\n            if np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        else:\n            new_solution[flip_idx] = 0\n\n    # Additional perturbation: randomly swap two items if feasible\n    if num_items >= 2:\n        i, j = random.sample(range(num_items), 2)\n        if new_solution[i] != new_solution[j]:\n            temp_weight = np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j]\n            if temp_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3849090734642813,
            3.249998688697815
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Intelligent selection: prioritize solutions that are not dominated in either objective\n    selected_sol = random.choice(candidates)\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search strategy: combine item swaps and value-based perturbations\n    num_items = len(weight_lst)\n    for _ in range(min(5, num_items // 2)):  # Limit the number of perturbations\n        # Value-based perturbation: flip items with high marginal contribution\n        marginal_contribution1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        marginal_contribution2 = value2_lst / (weight_lst + 1e-6)\n\n        # Combine marginal contributions with current solution\n        combined_contribution = marginal_contribution1 + marginal_contribution2\n        combined_contribution[new_solution == 1] *= 0.5  # Reduce contribution of already selected items\n\n        # Select item to flip based on combined contribution\n        candidate_indices = np.where(combined_contribution > 0)[0]\n        if len(candidate_indices) == 0:\n            break\n\n        flip_idx = random.choice(candidate_indices)\n\n        # Check feasibility before flipping\n        if new_solution[flip_idx] == 0:\n            if np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        else:\n            new_solution[flip_idx] = 0\n\n    # Additional perturbation: randomly swap two items if feasible\n    if num_items >= 2:\n        i, j = random.sample(range(num_items), 2)\n        if new_solution[i] != new_solution[j]:\n            temp_weight = np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j]\n            if temp_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 152,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with bias towards higher potential\n    def potential_score(solution, obj1, obj2):\n        current_weight = np.sum(weight_lst * solution)\n        excluded_items = np.where(solution == 0)[0]\n        if len(excluded_items) == 0:\n            return 0.0\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        max_marginal_gain = np.max(np.maximum(marginal_gains1, marginal_gains2))\n\n        # Potential score is based on marginal gain and remaining capacity\n        remaining_capacity = capacity - current_weight\n        return max_marginal_gain * remaining_capacity\n\n    # Assign scores to each solution in the archive\n    scored_solutions = []\n    for sol, (obj1, obj2) in archive:\n        score = potential_score(sol, obj1, obj2)\n        scored_solutions.append((score, sol))\n\n    # Select the solution with the highest potential (with some randomness)\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n    if len(scored_solutions) > 1:\n        # Introduce randomness to avoid always picking the same solution\n        selected_idx = min(int(len(scored_solutions) * 0.3), len(scored_solutions) - 1)\n        selected_solution = random.choice(scored_solutions[:selected_idx + 1])[1]\n    else:\n        selected_solution = scored_solutions[0][1]\n\n    # Step 2: Generate a neighbor using a hybrid local search operator\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded)\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    # Calculate marginal gains for excluded items (to potentially add)\n    if len(excluded_items) > 0:\n        marginal_gains1_excluded = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2_excluded = value2_lst[excluded_items] / weight_lst[excluded_items]\n        combined_gains_excluded = marginal_gains1_excluded + marginal_gains2_excluded\n\n        # Select top-k items with highest marginal gains\n        k = min(3, len(excluded_items))\n        top_k_excluded = np.argsort(combined_gains_excluded)[-k:]\n\n        # Try to add these items if feasible\n        for idx in top_k_excluded:\n            item_idx = excluded_items[idx]\n            if current_weight + weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Calculate marginal gains for included items (to potentially remove)\n    if len(included_items) > 0:\n        marginal_gains1_included = value1_lst[included_items] / weight_lst[included_items]\n        marginal_gains2_included = value2_lst[included_items] / weight_lst[included_items]\n        combined_gains_included = marginal_gains1_included + marginal_gains2_included\n\n        # Select top-k items with lowest marginal gains\n        k = min(3, len(included_items))\n        top_k_included = np.argsort(combined_gains_included)[:k]\n\n        # Try to remove these items\n        for idx in top_k_included:\n            item_idx = included_items[idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure the solution is feasible (shouldn't be needed due to checks above, but just in case)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, revert to the original solution\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7482871997332456,
            5.038969188928604
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution with bias towards higher potential\n    def potential_score(solution, obj1, obj2):\n        current_weight = np.sum(weight_lst * solution)\n        excluded_items = np.where(solution == 0)[0]\n        if len(excluded_items) == 0:\n            return 0.0\n\n        # Calculate marginal gains for excluded items\n        marginal_gains1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        max_marginal_gain = np.max(np.maximum(marginal_gains1, marginal_gains2))\n\n        # Potential score is based on marginal gain and remaining capacity\n        remaining_capacity = capacity - current_weight\n        return max_marginal_gain * remaining_capacity\n\n    # Assign scores to each solution in the archive\n    scored_solutions = []\n    for sol, (obj1, obj2) in archive:\n        score = potential_score(sol, obj1, obj2)\n        scored_solutions.append((score, sol))\n\n    # Select the solution with the highest potential (with some randomness)\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n    if len(scored_solutions) > 1:\n        # Introduce randomness to avoid always picking the same solution\n        selected_idx = min(int(len(scored_solutions) * 0.3), len(scored_solutions) - 1)\n        selected_solution = random.choice(scored_solutions[:selected_idx + 1])[1]\n    else:\n        selected_solution = scored_solutions[0][1]\n\n    # Step 2: Generate a neighbor using a hybrid local search operator\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either included or excluded)\n    excluded_items = np.where(new_solution == 0)[0]\n    included_items = np.where(new_solution == 1)[0]\n\n    # Calculate marginal gains for excluded items (to potentially add)\n    if len(excluded_items) > 0:\n        marginal_gains1_excluded = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gains2_excluded = value2_lst[excluded_items] / weight_lst[excluded_items]\n        combined_gains_excluded = marginal_gains1_excluded + marginal_gains2_excluded\n\n        # Select top-k items with highest marginal gains\n        k = min(3, len(excluded_items))\n        top_k_excluded = np.argsort(combined_gains_excluded)[-k:]\n\n        # Try to add these items if feasible\n        for idx in top_k_excluded:\n            item_idx = excluded_items[idx]\n            if current_weight + weight_lst[item_idx] <= capacity:\n                new_solution[item_idx] = 1\n                current_weight += weight_lst[item_idx]\n\n    # Calculate marginal gains for included items (to potentially remove)\n    if len(included_items) > 0:\n        marginal_gains1_included = value1_lst[included_items] / weight_lst[included_items]\n        marginal_gains2_included = value2_lst[included_items] / weight_lst[included_items]\n        combined_gains_included = marginal_gains1_included + marginal_gains2_included\n\n        # Select top-k items with lowest marginal gains\n        k = min(3, len(included_items))\n        top_k_included = np.argsort(combined_gains_included)[:k]\n\n        # Try to remove these items\n        for idx in top_k_included:\n            item_idx = included_items[idx]\n            new_solution[item_idx] = 0\n            current_weight -= weight_lst[item_idx]\n\n    # Ensure the solution is feasible (shouldn't be needed due to checks above, but just in case)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, revert to the original solution\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 153,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 0.9, len(archive)) / np.linspace(0.1, 0.9, len(archive)).sum())\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random swaps + value-based flips\n    new_solution = base_solution.copy()\n\n    # First, perform random swaps between items\n    for _ in range(3):  # Perform 3 random swaps\n        i, j = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility and adjust if needed\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        while new_weight > capacity:\n            ratios = (value1_lst + value2_lst) / weight_lst\n            items_in = np.where(new_solution == 1)[0]\n            if len(items_in) == 0:\n                break\n            to_remove = items_in[np.argmin(ratios[items_in])]\n            new_solution[to_remove] = 0\n            new_weight -= weight_lst[to_remove]\n\n    # Then perform value-based flips to improve both objectives\n    for _ in range(5):  # Perform 5 value-based flips\n        # Find items not in the solution with potential to improve both objectives\n        items_out = np.where(new_solution == 0)[0]\n        if len(items_out) == 0:\n            break\n\n        # Calculate potential improvement for each objective\n        potential_value1 = value1_lst[items_out]\n        potential_value2 = value2_lst[items_out]\n        potential_weights = weight_lst[items_out]\n\n        # Select items that can be added without exceeding capacity\n        feasible_mask = potential_weights <= (capacity - new_weight)\n        if not np.any(feasible_mask):\n            break\n\n        # Select item with highest combined value (normalized)\n        combined_value = (potential_value1 + potential_value2) / (potential_weights + 1e-6)\n        best_item = items_out[feasible_mask][np.argmax(combined_value[feasible_mask])]\n\n        # Add the best item\n        new_solution[best_item] = 1\n        new_weight += weight_lst[best_item]\n\n    return new_solution\n\n",
        "score": [
            -0.3954045717302215,
            9.111547619104385
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 0.9, len(archive)) / np.linspace(0.1, 0.9, len(archive)).sum())\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: random swaps + value-based flips\n    new_solution = base_solution.copy()\n\n    # First, perform random swaps between items\n    for _ in range(3):  # Perform 3 random swaps\n        i, j = np.random.choice(len(new_solution), size=2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility and adjust if needed\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        while new_weight > capacity:\n            ratios = (value1_lst + value2_lst) / weight_lst\n            items_in = np.where(new_solution == 1)[0]\n            if len(items_in) == 0:\n                break\n            to_remove = items_in[np.argmin(ratios[items_in])]\n            new_solution[to_remove] = 0\n            new_weight -= weight_lst[to_remove]\n\n    # Then perform value-based flips to improve both objectives\n    for _ in range(5):  # Perform 5 value-based flips\n        # Find items not in the solution with potential to improve both objectives\n        items_out = np.where(new_solution == 0)[0]\n        if len(items_out) == 0:\n            break\n\n        # Calculate potential improvement for each objective\n        potential_value1 = value1_lst[items_out]\n        potential_value2 = value2_lst[items_out]\n        potential_weights = weight_lst[items_out]\n\n        # Select items that can be added without exceeding capacity\n        feasible_mask = potential_weights <= (capacity - new_weight)\n        if not np.any(feasible_mask):\n            break\n\n        # Select item with highest combined value (normalized)\n        combined_value = (potential_value1 + potential_value2) / (potential_weights + 1e-6)\n        best_item = items_out[feasible_mask][np.argmax(combined_value[feasible_mask])]\n\n        # Add the best item\n        new_solution[best_item] = 1\n        new_weight += weight_lst[best_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 154,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with higher potential for improvement\n    # Solutions with lower current objective values are prioritized\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selected_idx = min(int(len(sorted_archive) * 0.3), len(sorted_archive) - 1)\n    base_solution, base_objective = sorted_archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially swap\n    # 2. For each selected item, consider adding/removing based on objective improvement\n    num_items = len(new_solution)\n    swap_candidates = random.sample(range(num_items), min(5, num_items))\n\n    for idx in swap_candidates:\n        if new_solution[idx] == 1:\n            # Consider removing item if it doesn't improve objectives\n            if (value1_lst[idx] <= 0 and value2_lst[idx] <= 0) or random.random() < 0.3:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Consider adding item if it improves at least one objective and doesn't exceed capacity\n            if (value1_lst[idx] > 0 or value2_lst[idx] > 0) and (current_weight + weight_lst[idx] <= capacity):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional improvement: try to add items that improve both objectives\n    for idx in np.where(new_solution == 0)[0]:\n        if (value1_lst[idx] > 0 and value2_lst[idx] > 0) and (current_weight + weight_lst[idx] <= capacity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.49666422209862426,
            2.4800796806812286
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards those with higher potential for improvement\n    # Solutions with lower current objective values are prioritized\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selected_idx = min(int(len(sorted_archive) * 0.3), len(sorted_archive) - 1)\n    base_solution, base_objective = sorted_archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to potentially swap\n    # 2. For each selected item, consider adding/removing based on objective improvement\n    num_items = len(new_solution)\n    swap_candidates = random.sample(range(num_items), min(5, num_items))\n\n    for idx in swap_candidates:\n        if new_solution[idx] == 1:\n            # Consider removing item if it doesn't improve objectives\n            if (value1_lst[idx] <= 0 and value2_lst[idx] <= 0) or random.random() < 0.3:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Consider adding item if it improves at least one objective and doesn't exceed capacity\n            if (value1_lst[idx] > 0 or value2_lst[idx] > 0) and (current_weight + weight_lst[idx] <= capacity):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional improvement: try to add items that improve both objectives\n    for idx in np.where(new_solution == 0)[0]:\n        if (value1_lst[idx] > 0 and value2_lst[idx] > 0) and (current_weight + weight_lst[idx] <= capacity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 155,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (could also use other metrics)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 10% of solutions\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 10)]\n        # Randomly select one from the top solutions\n        base_solution, _ = top_solutions[np.random.randint(len(top_solutions))]\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small subset of items (1-3 items)\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 4), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Ensure feasibility by removing the heaviest items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Calculate the weight reduction needed\n        excess_weight = total_weight - capacity\n        # Get indices of items currently in the knapsack\n        in_knapsack = np.where(new_solution == 1)[0]\n        # Sort by weight/value ratio (could use other criteria)\n        # Here we use weight/value1 ratio for simplicity\n        ratios = weight_lst[in_knapsack] / (value1_lst[in_knapsack] + 1e-10)  # Avoid division by zero\n        sorted_indices = np.argsort(ratios)[::-1]  # Sort in descending order\n        # Remove items until feasible\n        for idx in sorted_indices:\n            if excess_weight <= 0:\n                break\n            item_idx = in_knapsack[idx]\n            new_solution[item_idx] = 0\n            excess_weight -= weight_lst[item_idx]\n\n    # 3. Optional: Add a small number of new items if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Get indices of items not in the knapsack\n        out_of_knapsack = np.where(new_solution == 0)[0]\n        # Sort by value1/weight ratio (could use other criteria)\n        ratios = value1_lst[out_of_knapsack] / (weight_lst[out_of_knapsack] + 1e-10)\n        sorted_indices = np.argsort(ratios)[::-1]\n        # Add items until capacity is full or no more items can be added\n        for idx in sorted_indices:\n            item_idx = out_of_knapsack[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n            else:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.3373773856747302,
            5.665137499570847
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by the sum of their objectives (could also use other metrics)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select top 10% of solutions\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 10)]\n        # Randomly select one from the top solutions\n        base_solution, _ = top_solutions[np.random.randint(len(top_solutions))]\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small subset of items (1-3 items)\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 4), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # 2. Ensure feasibility by removing the heaviest items if capacity is exceeded\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Calculate the weight reduction needed\n        excess_weight = total_weight - capacity\n        # Get indices of items currently in the knapsack\n        in_knapsack = np.where(new_solution == 1)[0]\n        # Sort by weight/value ratio (could use other criteria)\n        # Here we use weight/value1 ratio for simplicity\n        ratios = weight_lst[in_knapsack] / (value1_lst[in_knapsack] + 1e-10)  # Avoid division by zero\n        sorted_indices = np.argsort(ratios)[::-1]  # Sort in descending order\n        # Remove items until feasible\n        for idx in sorted_indices:\n            if excess_weight <= 0:\n                break\n            item_idx = in_knapsack[idx]\n            new_solution[item_idx] = 0\n            excess_weight -= weight_lst[item_idx]\n\n    # 3. Optional: Add a small number of new items if there's remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Get indices of items not in the knapsack\n        out_of_knapsack = np.where(new_solution == 0)[0]\n        # Sort by value1/weight ratio (could use other criteria)\n        ratios = value1_lst[out_of_knapsack] / (weight_lst[out_of_knapsack] + 1e-10)\n        sorted_indices = np.argsort(ratios)[::-1]\n        # Add items until capacity is full or no more items can be added\n        for idx in sorted_indices:\n            item_idx = out_of_knapsack[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n            else:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 156,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.linalg.norm(objectives[:, np.newaxis] - objectives, axis=2).mean(axis=1)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine flip-based and swap-based moves\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Flip-based move: randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Swap-based move: swap items between included and excluded\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        swap_in = np.random.choice(included)\n        swap_out = np.random.choice(excluded)\n        if (current_weight - weight_lst[swap_in] + weight_lst[swap_out]) <= capacity:\n            new_solution[swap_in], new_solution[swap_out] = 0, 1\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess = np.sum(weight_lst * new_solution) - capacity\n        if excess <= 0:\n            break\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        remove_idx = np.random.choice(candidates)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7327245951525645,
            3.016506642103195
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.linalg.norm(objectives[:, np.newaxis] - objectives, axis=2).mean(axis=1)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine flip-based and swap-based moves\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Flip-based move: randomly flip a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Swap-based move: swap items between included and excluded\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        swap_in = np.random.choice(included)\n        swap_out = np.random.choice(excluded)\n        if (current_weight - weight_lst[swap_in] + weight_lst[swap_out]) <= capacity:\n            new_solution[swap_in], new_solution[swap_out] = 0, 1\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        excess = np.sum(weight_lst * new_solution) - capacity\n        if excess <= 0:\n            break\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        remove_idx = np.random.choice(candidates)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 157,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher total value\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, base_obj = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(5):  # Number of local search iterations\n        # Random swap between two items\n        if len(new_solution) >= 2:\n            i, j = random.sample(range(len(new_solution)), 2)\n            temp = new_solution[i]\n            new_solution[i] = new_solution[j]\n            new_solution[j] = temp\n\n        # Flip items with high value-to-weight ratios\n        value_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_ratios)[::-1]\n        for idx in sorted_indices[:min(3, len(sorted_indices))]:\n            if random.random() < 0.3:  # 30% chance to flip\n                if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif new_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Ensure feasibility\n        if current_weight > capacity:\n            # Remove items with lowest value-to-weight ratio until feasible\n            value_ratios = (value1_lst + value2_lst) / weight_lst\n            sorted_indices = np.argsort(value_ratios)\n            for idx in sorted_indices:\n                if new_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    if current_weight <= capacity:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.541861452558961,
            1.943565309047699
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher total value\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / np.sum(total_values)\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, base_obj = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(5):  # Number of local search iterations\n        # Random swap between two items\n        if len(new_solution) >= 2:\n            i, j = random.sample(range(len(new_solution)), 2)\n            temp = new_solution[i]\n            new_solution[i] = new_solution[j]\n            new_solution[j] = temp\n\n        # Flip items with high value-to-weight ratios\n        value_ratios = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_ratios)[::-1]\n        for idx in sorted_indices[:min(3, len(sorted_indices))]:\n            if random.random() < 0.3:  # 30% chance to flip\n                if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                elif new_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n        # Ensure feasibility\n        if current_weight > capacity:\n            # Remove items with lowest value-to-weight ratio until feasible\n            value_ratios = (value1_lst + value2_lst) / weight_lst\n            sorted_indices = np.argsort(value_ratios)\n            for idx in sorted_indices:\n                if new_solution[idx] == 1:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    if current_weight <= capacity:\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 158,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (simple heuristic)\n    selected_idx = min(len(archive) // 2, len(archive) - 1)  # Select from top half\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with bias toward lower weight items)\n    flip_indices = np.where(base_solution == 1)[0]\n    if len(flip_indices) > 0:\n        # Prioritize flipping items with lower weight/value ratio\n        weights = weight_lst[flip_indices]\n        values1 = value1_lst[flip_indices]\n        values2 = value2_lst[flip_indices]\n        ratios = (weights + 1e-6) / (values1 + values2 + 1e-6)  # Avoid division by zero\n        probs = ratios / np.sum(ratios)\n        flip_candidates = np.random.choice(flip_indices, size=min(3, len(flip_indices)), replace=False, p=probs)\n\n        for idx in flip_candidates:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                # Try to add a new item with high value/weight ratio\n                available_indices = np.where(base_solution == 0)[0]\n                if len(available_indices) > 0:\n                    available_weights = weight_lst[available_indices]\n                    available_values1 = value1_lst[available_indices]\n                    available_values2 = value2_lst[available_indices]\n                    available_ratios = (available_values1 + available_values2 + 1e-6) / (available_weights + 1e-6)\n                    probs_add = available_ratios / np.sum(available_ratios)\n                    add_idx = np.random.choice(available_indices, p=probs_add)\n                    if np.sum(weight_lst[new_solution == 1]) + weight_lst[add_idx] <= capacity:\n                        new_solution[add_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_weights = weight_lst[excess_items]\n        excess_ratios = (value1_lst[excess_items] + value2_lst[excess_items] + 1e-6) / (excess_weights + 1e-6)\n        sorted_indices = np.argsort(excess_ratios)\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            new_solution[excess_items[i]] = 0\n            excess -= excess_weights[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8116946263210633,
            1.6229429244995117
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives (simple heuristic)\n    selected_idx = min(len(archive) // 2, len(archive) - 1)  # Select from top half\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (with bias toward lower weight items)\n    flip_indices = np.where(base_solution == 1)[0]\n    if len(flip_indices) > 0:\n        # Prioritize flipping items with lower weight/value ratio\n        weights = weight_lst[flip_indices]\n        values1 = value1_lst[flip_indices]\n        values2 = value2_lst[flip_indices]\n        ratios = (weights + 1e-6) / (values1 + values2 + 1e-6)  # Avoid division by zero\n        probs = ratios / np.sum(ratios)\n        flip_candidates = np.random.choice(flip_indices, size=min(3, len(flip_indices)), replace=False, p=probs)\n\n        for idx in flip_candidates:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n            else:\n                # Try to add a new item with high value/weight ratio\n                available_indices = np.where(base_solution == 0)[0]\n                if len(available_indices) > 0:\n                    available_weights = weight_lst[available_indices]\n                    available_values1 = value1_lst[available_indices]\n                    available_values2 = value2_lst[available_indices]\n                    available_ratios = (available_values1 + available_values2 + 1e-6) / (available_weights + 1e-6)\n                    probs_add = available_ratios / np.sum(available_ratios)\n                    add_idx = np.random.choice(available_indices, p=probs_add)\n                    if np.sum(weight_lst[new_solution == 1]) + weight_lst[add_idx] <= capacity:\n                        new_solution[add_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_weights = weight_lst[excess_items]\n        excess_ratios = (value1_lst[excess_items] + value2_lst[excess_items] + 1e-6) / (excess_weights + 1e-6)\n        sorted_indices = np.argsort(excess_ratios)\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            new_solution[excess_items[i]] = 0\n            excess -= excess_weights[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 159,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    # or have high potential for improvement (e.g., solutions with high marginal gains)\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for swapping\n    # 2. Evaluate potential swaps based on both objectives\n    # 3. Apply the best feasible swap\n\n    # Step 1: Randomly select a subset of items (20% of items)\n    n_items = len(weight_lst)\n    subset_size = max(1, int(0.2 * n_items))\n    candidate_indices = random.sample(range(n_items), subset_size)\n\n    best_new_solution = None\n    best_improvement = -np.inf\n\n    for i in candidate_indices:\n        # Consider flipping the item (0 to 1 or 1 to 0)\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n\n        # Check feasibility\n        temp_weight = current_weight - weight_lst[i] * base_solution[i] + weight_lst[i] * temp_solution[i]\n        if temp_weight > capacity:\n            continue\n\n        # Evaluate the new solution based on both objectives\n        # We use a weighted sum to balance both objectives (can be adjusted)\n        temp_value1 = np.sum(value1_lst * temp_solution)\n        temp_value2 = np.sum(value2_lst * temp_solution)\n        improvement = 0.5 * temp_value1 + 0.5 * temp_value2\n\n        # Track the best improvement\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_new_solution = temp_solution\n\n    # If no improvement found, perform a random feasible swap\n    if best_new_solution is None:\n        feasible_indices = [i for i in range(n_items) if (base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity) or\n                           (base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity)]\n        if feasible_indices:\n            i = random.choice(feasible_indices)\n            best_new_solution = new_solution.copy()\n            best_new_solution[i] = 1 - best_new_solution[i]\n\n    return best_new_solution if best_new_solution is not None else new_solution\n\n",
        "score": [
            -0.8369913553186248,
            2.2833495438098907
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    # or have high potential for improvement (e.g., solutions with high marginal gains)\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to consider for swapping\n    # 2. Evaluate potential swaps based on both objectives\n    # 3. Apply the best feasible swap\n\n    # Step 1: Randomly select a subset of items (20% of items)\n    n_items = len(weight_lst)\n    subset_size = max(1, int(0.2 * n_items))\n    candidate_indices = random.sample(range(n_items), subset_size)\n\n    best_new_solution = None\n    best_improvement = -np.inf\n\n    for i in candidate_indices:\n        # Consider flipping the item (0 to 1 or 1 to 0)\n        temp_solution = new_solution.copy()\n        temp_solution[i] = 1 - temp_solution[i]\n\n        # Check feasibility\n        temp_weight = current_weight - weight_lst[i] * base_solution[i] + weight_lst[i] * temp_solution[i]\n        if temp_weight > capacity:\n            continue\n\n        # Evaluate the new solution based on both objectives\n        # We use a weighted sum to balance both objectives (can be adjusted)\n        temp_value1 = np.sum(value1_lst * temp_solution)\n        temp_value2 = np.sum(value2_lst * temp_solution)\n        improvement = 0.5 * temp_value1 + 0.5 * temp_value2\n\n        # Track the best improvement\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_new_solution = temp_solution\n\n    # If no improvement found, perform a random feasible swap\n    if best_new_solution is None:\n        feasible_indices = [i for i in range(n_items) if (base_solution[i] == 1 and (current_weight - weight_lst[i]) <= capacity) or\n                           (base_solution[i] == 0 and (current_weight + weight_lst[i]) <= capacity)]\n        if feasible_indices:\n            i = random.choice(feasible_indices)\n            best_new_solution = new_solution.copy()\n            best_new_solution[i] = 1 - best_new_solution[i]\n\n    return best_new_solution if best_new_solution is not None else new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 160,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed or not fully excluded)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and margins\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution (candidates for addition)\n    not_in_solution = np.where(new_solution == 0)[0]\n\n    # Identify items in the solution (candidates for removal)\n    in_solution = np.where(new_solution == 1)[0]\n\n    # Hybrid local search strategy:\n    # 1. Swap a low-value item with a high-value item from the opposite category\n    if len(in_solution) > 0 and len(not_in_solution) > 0:\n        # Calculate value ratios for items in the solution\n        value1_ratios = value1_lst[in_solution] / weight_lst[in_solution]\n        value2_ratios = value2_lst[in_solution] / weight_lst[in_solution]\n\n        # Find the item with the lowest value ratio in the solution\n        lowest_ratio_idx = np.argmin(value1_ratios + value2_ratios)\n        item_to_remove = in_solution[lowest_ratio_idx]\n\n        # Find the item with the highest value ratio not in the solution\n        value1_ratios_not_in = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n        value2_ratios_not_in = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n        highest_ratio_idx = np.argmax(value1_ratios_not_in + value2_ratios_not_in)\n        item_to_add = not_in_solution[highest_ratio_idx]\n\n        # Check if the swap is feasible\n        if weight_lst[item_to_add] - weight_lst[item_to_remove] <= remaining_capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # 2. If no swap was made, perform a random perturbation\n    if np.array_equal(new_solution, base_solution):\n        # Randomly flip a small number of items (1-3) to maintain diversity\n        num_flips = np.random.randint(1, min(4, len(new_solution)))\n        flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n\n        # Ensure the perturbation is feasible\n        for idx in flip_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n\n    # Ensure the solution is feasible (in case of any errors)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        in_solution = np.where(new_solution == 1)[0]\n        while excess > 0 and len(in_solution) > 0:\n            # Remove the item with the smallest value ratio\n            value_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n            item_to_remove = in_solution[np.argmin(value_ratios)]\n            new_solution[item_to_remove] = 0\n            excess = np.sum(weight_lst * new_solution) - capacity\n            in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.42427685172371243,
            1.8550959527492523
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed or not fully excluded)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and margins\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items not in the solution (candidates for addition)\n    not_in_solution = np.where(new_solution == 0)[0]\n\n    # Identify items in the solution (candidates for removal)\n    in_solution = np.where(new_solution == 1)[0]\n\n    # Hybrid local search strategy:\n    # 1. Swap a low-value item with a high-value item from the opposite category\n    if len(in_solution) > 0 and len(not_in_solution) > 0:\n        # Calculate value ratios for items in the solution\n        value1_ratios = value1_lst[in_solution] / weight_lst[in_solution]\n        value2_ratios = value2_lst[in_solution] / weight_lst[in_solution]\n\n        # Find the item with the lowest value ratio in the solution\n        lowest_ratio_idx = np.argmin(value1_ratios + value2_ratios)\n        item_to_remove = in_solution[lowest_ratio_idx]\n\n        # Find the item with the highest value ratio not in the solution\n        value1_ratios_not_in = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n        value2_ratios_not_in = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n        highest_ratio_idx = np.argmax(value1_ratios_not_in + value2_ratios_not_in)\n        item_to_add = not_in_solution[highest_ratio_idx]\n\n        # Check if the swap is feasible\n        if weight_lst[item_to_add] - weight_lst[item_to_remove] <= remaining_capacity:\n            new_solution[item_to_remove] = 0\n            new_solution[item_to_add] = 1\n\n    # 2. If no swap was made, perform a random perturbation\n    if np.array_equal(new_solution, base_solution):\n        # Randomly flip a small number of items (1-3) to maintain diversity\n        num_flips = np.random.randint(1, min(4, len(new_solution)))\n        flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n\n        # Ensure the perturbation is feasible\n        for idx in flip_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n            elif new_solution[idx] == 1:\n                new_solution[idx] = 0\n\n    # Ensure the solution is feasible (in case of any errors)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        in_solution = np.where(new_solution == 1)[0]\n        while excess > 0 and len(in_solution) > 0:\n            # Remove the item with the smallest value ratio\n            value_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n            item_to_remove = in_solution[np.argmin(value_ratios)]\n            new_solution[item_to_remove] = 0\n            excess = np.sum(weight_lst * new_solution) - capacity\n            in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 161,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance for each solution to identify less crowded regions\n    crowding_distances = np.zeros(len(archive))\n    objectives_array = np.array(archive_objectives)\n\n    for i in range(objectives_array.shape[1]):\n        sorted_indices = np.argsort(objectives_array[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (objectives_array[sorted_indices[j+1], i] - objectives_array[sorted_indices[j-1], i])\n\n    # Select a solution with low crowding distance (promising for improvement)\n    selected_index = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_index].copy()\n\n    # Generate a neighbor using a hybrid strategy: random perturbation + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a few random bits)\n    num_perturbations = min(3, len(new_solution))  # Limit the number of perturbations\n    perturbation_indices = random.sample(range(len(new_solution)), num_perturbations)\n    for idx in perturbation_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Step 2: Greedy improvement (add items that improve at least one objective)\n    current_weight = np.sum(new_solution * weight_lst)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            # Check if adding the item improves at least one objective\n            if (value1_lst[i] > 0 or value2_lst[i] > 0):\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 3: Remove items that do not contribute to either objective (if possible)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and (value1_lst[i] == 0 and value2_lst[i] == 0):\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3507313182342693,
            1.9554247558116913
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance for each solution to identify less crowded regions\n    crowding_distances = np.zeros(len(archive))\n    objectives_array = np.array(archive_objectives)\n\n    for i in range(objectives_array.shape[1]):\n        sorted_indices = np.argsort(objectives_array[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (objectives_array[sorted_indices[j+1], i] - objectives_array[sorted_indices[j-1], i])\n\n    # Select a solution with low crowding distance (promising for improvement)\n    selected_index = np.argmin(crowding_distances)\n    base_solution = archive_solutions[selected_index].copy()\n\n    # Generate a neighbor using a hybrid strategy: random perturbation + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation (flip a few random bits)\n    num_perturbations = min(3, len(new_solution))  # Limit the number of perturbations\n    perturbation_indices = random.sample(range(len(new_solution)), num_perturbations)\n    for idx in perturbation_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Step 2: Greedy improvement (add items that improve at least one objective)\n    current_weight = np.sum(new_solution * weight_lst)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            # Check if adding the item improves at least one objective\n            if (value1_lst[i] > 0 or value2_lst[i] > 0):\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n    # Step 3: Remove items that do not contribute to either objective (if possible)\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and (value1_lst[i] == 0 and value2_lst[i] == 0):\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 162,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid large changes\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess items if capacity is exceeded\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items with the smallest ratio of (value1 + value2) / weight until feasible\n        while excess_weight > 0 and np.any(new_solution):\n            # Calculate the ratio for included items\n            ratios = (value1_lst + value2_lst) / weight_lst\n            included_indices = np.where(new_solution == 1)[0]\n            if len(included_indices) == 0:\n                break\n            min_ratio_idx = included_indices[np.argmin(ratios[included_indices])]\n            new_solution[min_ratio_idx] = 0\n            excess_weight -= weight_lst[min_ratio_idx]\n\n    # Greedy improvement step: Add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n\n    for idx in available_items:\n        if weight_lst[idx] <= remaining_capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n            # If the new solution dominates the current one, add the item\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[idx] = 1\n                current_value1 = new_value1\n                current_value2 = new_value2\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3750058932662196,
            3.412994861602783
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid large changes\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess items if capacity is exceeded\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items with the smallest ratio of (value1 + value2) / weight until feasible\n        while excess_weight > 0 and np.any(new_solution):\n            # Calculate the ratio for included items\n            ratios = (value1_lst + value2_lst) / weight_lst\n            included_indices = np.where(new_solution == 1)[0]\n            if len(included_indices) == 0:\n                break\n            min_ratio_idx = included_indices[np.argmin(ratios[included_indices])]\n            new_solution[min_ratio_idx] = 0\n            excess_weight -= weight_lst[min_ratio_idx]\n\n    # Greedy improvement step: Add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n\n    for idx in available_items:\n        if weight_lst[idx] <= remaining_capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = current_value1 + value1_lst[idx]\n            new_value2 = current_value2 + value2_lst[idx]\n            # If the new solution dominates the current one, add the item\n            if new_value1 > current_value1 and new_value2 > current_value2:\n                new_solution[idx] = 1\n                current_value1 = new_value1\n                current_value2 = new_value2\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 163,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            candidates.append((sol, obj, remaining_capacity))\n\n    if not candidates:\n        return archive[0][0].copy()  # Return a copy of the first solution if no candidates\n\n    # Sort candidates by a combination of objective values and remaining capacity\n    candidates.sort(key=lambda x: (x[1][0] + x[1][1]) * x[2], reverse=True)\n    selected_sol, selected_obj, remaining_capacity = candidates[0]\n\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a number of items to flip (1-3)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n\n    # 2. Identify items that can be added without exceeding capacity\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    # 3. For each flip:\n    for _ in range(num_flips):\n        # Option 1: Add a new item if possible\n        if zero_indices.size > 0 and remaining_capacity > 0:\n            candidate_idx = random.choice(zero_indices)\n            if weight_lst[candidate_idx] <= remaining_capacity:\n                new_solution[candidate_idx] = 1\n                remaining_capacity -= weight_lst[candidate_idx]\n                zero_indices = np.delete(zero_indices, np.where(zero_indices == candidate_idx))\n                continue\n\n        # Option 2: Remove an item if no addition is possible\n        if one_indices.size > 0:\n            candidate_idx = random.choice(one_indices)\n            new_solution[candidate_idx] = 0\n            remaining_capacity += weight_lst[candidate_idx]\n            one_indices = np.delete(one_indices, np.where(one_indices == candidate_idx))\n\n    return new_solution\n\n",
        "score": [
            -0.7104725462067004,
            1.9253873229026794
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            candidates.append((sol, obj, remaining_capacity))\n\n    if not candidates:\n        return archive[0][0].copy()  # Return a copy of the first solution if no candidates\n\n    # Sort candidates by a combination of objective values and remaining capacity\n    candidates.sort(key=lambda x: (x[1][0] + x[1][1]) * x[2], reverse=True)\n    selected_sol, selected_obj, remaining_capacity = candidates[0]\n\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a number of items to flip (1-3)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n\n    # 2. Identify items that can be added without exceeding capacity\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    # 3. For each flip:\n    for _ in range(num_flips):\n        # Option 1: Add a new item if possible\n        if zero_indices.size > 0 and remaining_capacity > 0:\n            candidate_idx = random.choice(zero_indices)\n            if weight_lst[candidate_idx] <= remaining_capacity:\n                new_solution[candidate_idx] = 1\n                remaining_capacity -= weight_lst[candidate_idx]\n                zero_indices = np.delete(zero_indices, np.where(zero_indices == candidate_idx))\n                continue\n\n        # Option 2: Remove an item if no addition is possible\n        if one_indices.size > 0:\n            candidate_idx = random.choice(one_indices)\n            new_solution[candidate_idx] = 0\n            remaining_capacity += weight_lst[candidate_idx]\n            one_indices = np.delete(one_indices, np.where(one_indices == candidate_idx))\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 164,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower total weight (more room for improvement)\n    weights = np.array([np.sum(weight_lst[sol[0] == 1]) for sol in archive])\n    probabilities = 1 / (weights + 1e-6)  # Avoid division by zero\n    probabilities /= np.sum(probabilities)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by swapping a random subset of items\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    swap_size = min(5, n_items)  # Limit the number of swaps to avoid excessive changes\n    swap_indices = random.sample(range(n_items), swap_size)\n\n    for i in swap_indices:\n        # Try adding the item if it's not in the solution\n        if new_solution[i] == 0:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n        # Try removing the item if it's in the solution\n        else:\n            new_solution[i] = 0\n\n    # Apply a greedy improvement step to maximize both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for i in range(n_items):\n        if new_solution[i] == 0:\n            # Check if adding item i improves both objectives\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n        else:\n            # Check if removing item i improves the solution\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = np.sum(weight_lst[temp_solution == 1])\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3991836317079135,
            7.096520334482193
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower total weight (more room for improvement)\n    weights = np.array([np.sum(weight_lst[sol[0] == 1]) for sol in archive])\n    probabilities = 1 / (weights + 1e-6)  # Avoid division by zero\n    probabilities /= np.sum(probabilities)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by swapping a random subset of items\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    swap_size = min(5, n_items)  # Limit the number of swaps to avoid excessive changes\n    swap_indices = random.sample(range(n_items), swap_size)\n\n    for i in swap_indices:\n        # Try adding the item if it's not in the solution\n        if new_solution[i] == 0:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n        # Try removing the item if it's in the solution\n        else:\n            new_solution[i] = 0\n\n    # Apply a greedy improvement step to maximize both objectives\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for i in range(n_items):\n        if new_solution[i] == 0:\n            # Check if adding item i improves both objectives\n            if current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n        else:\n            # Check if removing item i improves the solution\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = np.sum(weight_lst[temp_solution == 1])\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 165,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already fully packed)\n    selected_idx = np.argmax([np.sum(sol[0]) for sol in archive])\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation - flip a few items to explore the neighborhood\n    num_perturbations = min(3, len(new_solution) // 2)  # Limit perturbations to avoid excessive changes\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Calculate current weight and check feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Greedy repair: remove items with the lowest marginal value until feasible\n        while current_weight > capacity:\n            # Calculate marginal value per item (weighted sum of both objectives)\n            marginal_value = (value1_lst + value2_lst) * new_solution\n            # Find the item with the smallest marginal value that can be removed\n            removable_indices = np.where(new_solution == 1)[0]\n            if len(removable_indices) == 0:\n                break  # No items left to remove\n            remove_idx = removable_indices[np.argmin(marginal_value[removable_indices])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement - add items with the highest marginal value per weight\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Calculate marginal value per weight for all items not in the solution\n        marginal_value_per_weight = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Sort candidates by marginal value per weight in descending order\n            sorted_indices = candidate_indices[np.argsort(-marginal_value_per_weight[candidate_indices])]\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_weight:\n                    new_solution[idx] = 1\n                    remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3415306588100713,
            6.154745668172836
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already fully packed)\n    selected_idx = np.argmax([np.sum(sol[0]) for sol in archive])\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation - flip a few items to explore the neighborhood\n    num_perturbations = min(3, len(new_solution) // 2)  # Limit perturbations to avoid excessive changes\n    perturb_indices = np.random.choice(len(new_solution), size=num_perturbations, replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Calculate current weight and check feasibility\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Greedy repair: remove items with the lowest marginal value until feasible\n        while current_weight > capacity:\n            # Calculate marginal value per item (weighted sum of both objectives)\n            marginal_value = (value1_lst + value2_lst) * new_solution\n            # Find the item with the smallest marginal value that can be removed\n            removable_indices = np.where(new_solution == 1)[0]\n            if len(removable_indices) == 0:\n                break  # No items left to remove\n            remove_idx = removable_indices[np.argmin(marginal_value[removable_indices])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Step 2: Greedy improvement - add items with the highest marginal value per weight\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Calculate marginal value per weight for all items not in the solution\n        marginal_value_per_weight = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Sort candidates by marginal value per weight in descending order\n            sorted_indices = candidate_indices[np.argsort(-marginal_value_per_weight[candidate_indices])]\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_weight:\n                    new_solution[idx] = 1\n                    remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 166,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prefer solutions that are not too close to the boundary (to allow more room for swaps)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on current solution quality)\n    # 2. Perform objective-aware swaps between items of different objectives\n\n    # Step 1: Random flips with adaptive probability\n    flip_prob = 0.3 if current_weight < capacity * 0.8 else 0.1\n    for i in range(len(new_solution)):\n        if np.random.random() < flip_prob:\n            if new_solution[i] == 1:\n                # If item is included, check if removing it keeps solution feasible\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If item is excluded, check if adding it keeps solution feasible\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Objective-aware swaps\n    # Identify items that contribute differently to each objective\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate value ratios for included items\n    if len(included_items) > 0:\n        val1_ratio = value1_lst[included_items] / (value2_lst[included_items] + 1e-10)\n        val2_ratio = value2_lst[included_items] / (value1_lst[included_items] + 1e-10)\n\n        # Find items that are \"dominated\" in one objective but not the other\n        val1_dominated = np.where(val1_ratio < 1.0)[0]\n        val2_dominated = np.where(val2_ratio < 1.0)[0]\n\n        # For each dominated item, try to swap with a suitable excluded item\n        for i in val1_dominated:\n            if len(excluded_items) == 0:\n                break\n            # Find excluded items that could improve value1 when swapped\n            potential_swaps = excluded_items[value1_lst[excluded_items] > value1_lst[included_items[i]]]\n            if len(potential_swaps) > 0:\n                swap_item = np.random.choice(potential_swaps)\n                # Check feasibility of swap\n                if (current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]) <= capacity:\n                    new_solution[included_items[i]] = 0\n                    new_solution[swap_item] = 1\n                    current_weight = current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]\n                    break\n\n        for i in val2_dominated:\n            if len(excluded_items) == 0:\n                break\n            # Find excluded items that could improve value2 when swapped\n            potential_swaps = excluded_items[value2_lst[excluded_items] > value2_lst[included_items[i]]]\n            if len(potential_swaps) > 0:\n                swap_item = np.random.choice(potential_swaps)\n                # Check feasibility of swap\n                if (current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]) <= capacity:\n                    new_solution[included_items[i]] = 0\n                    new_solution[swap_item] = 1\n                    current_weight = current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.37153774751072377,
            3.0182333290576935
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prefer solutions that are not too close to the boundary (to allow more room for swaps)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on current solution quality)\n    # 2. Perform objective-aware swaps between items of different objectives\n\n    # Step 1: Random flips with adaptive probability\n    flip_prob = 0.3 if current_weight < capacity * 0.8 else 0.1\n    for i in range(len(new_solution)):\n        if np.random.random() < flip_prob:\n            if new_solution[i] == 1:\n                # If item is included, check if removing it keeps solution feasible\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If item is excluded, check if adding it keeps solution feasible\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Objective-aware swaps\n    # Identify items that contribute differently to each objective\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate value ratios for included items\n    if len(included_items) > 0:\n        val1_ratio = value1_lst[included_items] / (value2_lst[included_items] + 1e-10)\n        val2_ratio = value2_lst[included_items] / (value1_lst[included_items] + 1e-10)\n\n        # Find items that are \"dominated\" in one objective but not the other\n        val1_dominated = np.where(val1_ratio < 1.0)[0]\n        val2_dominated = np.where(val2_ratio < 1.0)[0]\n\n        # For each dominated item, try to swap with a suitable excluded item\n        for i in val1_dominated:\n            if len(excluded_items) == 0:\n                break\n            # Find excluded items that could improve value1 when swapped\n            potential_swaps = excluded_items[value1_lst[excluded_items] > value1_lst[included_items[i]]]\n            if len(potential_swaps) > 0:\n                swap_item = np.random.choice(potential_swaps)\n                # Check feasibility of swap\n                if (current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]) <= capacity:\n                    new_solution[included_items[i]] = 0\n                    new_solution[swap_item] = 1\n                    current_weight = current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]\n                    break\n\n        for i in val2_dominated:\n            if len(excluded_items) == 0:\n                break\n            # Find excluded items that could improve value2 when swapped\n            potential_swaps = excluded_items[value2_lst[excluded_items] > value2_lst[included_items[i]]]\n            if len(potential_swaps) > 0:\n                swap_item = np.random.choice(potential_swaps)\n                # Check feasibility of swap\n                if (current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]) <= capacity:\n                    new_solution[included_items[i]] = 0\n                    new_solution[swap_item] = 1\n                    current_weight = current_weight - weight_lst[included_items[i]] + weight_lst[swap_item]\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 167,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = [sol for sol, _ in archive]\n    if len(candidates) > 1:\n        # Sort candidates by the sum of their objective values (as a proxy for potential)\n        candidates.sort(key=lambda x: -(np.sum(value1_lst[x == 1]) + np.sum(value2_lst[x == 1])))\n        # Select top 30% candidates\n        top_candidates = candidates[:max(1, len(candidates) // 3)]\n        base_solution = random.choice(top_candidates).copy()\n    else:\n        base_solution = candidates[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of bit-flip and swap\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # First, try a bit-flip operation (flip a random bit if feasible)\n    if np.sum(base_solution) > 0:\n        zero_indices = np.where(base_solution == 0)[0]\n        one_indices = np.where(base_solution == 1)[0]\n\n        # Try adding an item if possible\n        if len(zero_indices) > 0:\n            candidate_idx = random.choice(zero_indices)\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                return new_solution\n\n        # Try removing an item if adding didn't work\n        if len(one_indices) > 0:\n            candidate_idx = random.choice(one_indices)\n            new_solution[candidate_idx] = 0\n            return new_solution\n\n    # If bit-flip didn't work, try a swap operation (swap two items if feasible)\n    if len(base_solution) >= 2:\n        zero_indices = np.where(base_solution == 0)[0]\n        one_indices = np.where(base_solution == 1)[0]\n\n        if len(zero_indices) > 0 and len(one_indices) > 0:\n            add_idx = random.choice(zero_indices)\n            remove_idx = random.choice(one_indices)\n\n            new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n            if new_weight <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                return new_solution\n\n    # If no improvement possible, return the original solution\n    return base_solution\n\n",
        "score": [
            -0.7825464912395554,
            3.5847810804843903
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = [sol for sol, _ in archive]\n    if len(candidates) > 1:\n        # Sort candidates by the sum of their objective values (as a proxy for potential)\n        candidates.sort(key=lambda x: -(np.sum(value1_lst[x == 1]) + np.sum(value2_lst[x == 1])))\n        # Select top 30% candidates\n        top_candidates = candidates[:max(1, len(candidates) // 3)]\n        base_solution = random.choice(top_candidates).copy()\n    else:\n        base_solution = candidates[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of bit-flip and swap\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # First, try a bit-flip operation (flip a random bit if feasible)\n    if np.sum(base_solution) > 0:\n        zero_indices = np.where(base_solution == 0)[0]\n        one_indices = np.where(base_solution == 1)[0]\n\n        # Try adding an item if possible\n        if len(zero_indices) > 0:\n            candidate_idx = random.choice(zero_indices)\n            if current_weight + weight_lst[candidate_idx] <= capacity:\n                new_solution[candidate_idx] = 1\n                return new_solution\n\n        # Try removing an item if adding didn't work\n        if len(one_indices) > 0:\n            candidate_idx = random.choice(one_indices)\n            new_solution[candidate_idx] = 0\n            return new_solution\n\n    # If bit-flip didn't work, try a swap operation (swap two items if feasible)\n    if len(base_solution) >= 2:\n        zero_indices = np.where(base_solution == 0)[0]\n        one_indices = np.where(base_solution == 1)[0]\n\n        if len(zero_indices) > 0 and len(one_indices) > 0:\n            add_idx = random.choice(zero_indices)\n            remove_idx = random.choice(one_indices)\n\n            new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n            if new_weight <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                return new_solution\n\n    # If no improvement possible, return the original solution\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 168,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine bit-flip with value-based swaps\n    # Step 1: Random bit-flip (with feasibility check)\n    flip_candidate = np.random.randint(0, len(base_solution))\n    if base_solution[flip_candidate] == 0:\n        if current_weight + weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 1\n    else:\n        new_solution[flip_candidate] = 0\n\n    # Step 2: Value-based swap (prioritize items with high marginal value)\n    # Calculate marginal value ratios for each objective\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal values and select top candidates\n    combined_marginal = marginal_value1 + marginal_value2\n    candidates = np.argsort(-combined_marginal)[:max(3, len(base_solution)//10)]\n\n    # Try to swap items with highest marginal value\n    for item in candidates:\n        if base_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                break\n        else:\n            new_solution[item] = 0\n            break\n\n    return new_solution\n\n",
        "score": [
            -0.8893038653142649,
            1.0810618996620178
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine bit-flip with value-based swaps\n    # Step 1: Random bit-flip (with feasibility check)\n    flip_candidate = np.random.randint(0, len(base_solution))\n    if base_solution[flip_candidate] == 0:\n        if current_weight + weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 1\n    else:\n        new_solution[flip_candidate] = 0\n\n    # Step 2: Value-based swap (prioritize items with high marginal value)\n    # Calculate marginal value ratios for each objective\n    marginal_value1 = value1_lst / (weight_lst + 1e-6)\n    marginal_value2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal values and select top candidates\n    combined_marginal = marginal_value1 + marginal_value2\n    candidates = np.argsort(-combined_marginal)[:max(3, len(base_solution)//10)]\n\n    # Try to swap items with highest marginal value\n    for item in candidates:\n        if base_solution[item] == 0:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                break\n        else:\n            new_solution[item] = 0\n            break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 169,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher total value in either objective\n    scores = [obj[0] + obj[1] for _, obj in archive]\n    total_score = sum(scores)\n    probabilities = [score / total_score for score in scores]\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_perturbations = min(3, len(new_solution))  # Limit perturbations to avoid excessive changes\n    perturb_indices = np.random.choice(len(new_solution), num_perturbations, replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Select items to remove based on their contribution to the objectives\n            item_contributions = (value1_lst + value2_lst) * new_solution\n            if np.sum(item_contributions) == 0:\n                break  # All items contribute nothing\n            remove_prob = item_contributions / np.sum(item_contributions)\n            remove_idx = np.random.choice(len(new_solution), p=remove_prob)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess -= weight_lst[remove_idx]\n                total_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement step: add items that improve both objectives without exceeding capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate potential improvement for each item not in the solution\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            # Sort by combined value-to-weight ratio\n            value_ratio = (value1_lst + value2_lst) / weight_lst\n            sorted_indices = potential_items[np.argsort(-value_ratio[potential_items])]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.37874492403927934,
            3.2219517529010773
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with a bias towards those with higher total value in either objective\n    scores = [obj[0] + obj[1] for _, obj in archive]\n    total_score = sum(scores)\n    probabilities = [score / total_score for score in scores]\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_perturbations = min(3, len(new_solution))  # Limit perturbations to avoid excessive changes\n    perturb_indices = np.random.choice(len(new_solution), num_perturbations, replace=False)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility by removing items that exceed capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Select items to remove based on their contribution to the objectives\n            item_contributions = (value1_lst + value2_lst) * new_solution\n            if np.sum(item_contributions) == 0:\n                break  # All items contribute nothing\n            remove_prob = item_contributions / np.sum(item_contributions)\n            remove_idx = np.random.choice(len(new_solution), p=remove_prob)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess -= weight_lst[remove_idx]\n                total_weight -= weight_lst[remove_idx]\n\n    # Greedy improvement step: add items that improve both objectives without exceeding capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate potential improvement for each item not in the solution\n        potential_items = np.where(new_solution == 0)[0]\n        if len(potential_items) > 0:\n            # Sort by combined value-to-weight ratio\n            value_ratio = (value1_lst + value2_lst) / weight_lst\n            sorted_indices = potential_items[np.argsort(-value_ratio[potential_items])]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 170,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random flip + Greedy improvement\n    # Step 1: Randomly flip a subset of items (to escape local optima)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement step to ensure feasibility and maximize both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the least \"benefit\" (ratio of value1 + value2 to weight) until feasible\n        while current_weight > capacity:\n            # Calculate benefit for each item: (value1 + value2) / weight\n            benefits = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n            benefits[new_solution == 0] = -np.inf  # Only consider items that are currently in the knapsack\n            worst_item = np.argmin(benefits)\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Step 3: Add items with the highest marginal benefit (value1 + value2) / weight until no more can be added\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal benefit for each item not in the knapsack\n        marginal_benefits = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        marginal_benefits[new_solution == 1] = -np.inf  # Only consider items not in the knapsack\n        candidate_items = np.where(marginal_benefits > 0)[0]\n\n        for item in candidate_items:\n            if weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.38405577850101424,
            1.1527834832668304
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too crowded in the objective space)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random flip + Greedy improvement\n    # Step 1: Randomly flip a subset of items (to escape local optima)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement step to ensure feasibility and maximize both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with the least \"benefit\" (ratio of value1 + value2 to weight) until feasible\n        while current_weight > capacity:\n            # Calculate benefit for each item: (value1 + value2) / weight\n            benefits = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n            benefits[new_solution == 0] = -np.inf  # Only consider items that are currently in the knapsack\n            worst_item = np.argmin(benefits)\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Step 3: Add items with the highest marginal benefit (value1 + value2) / weight until no more can be added\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal benefit for each item not in the knapsack\n        marginal_benefits = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n        marginal_benefits[new_solution == 1] = -np.inf  # Only consider items not in the knapsack\n        candidate_items = np.where(marginal_benefits > 0)[0]\n\n        for item in candidate_items:\n            if weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 171,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement by considering both objectives\n    # We prioritize solutions that are not too close to the Pareto front in either objective\n    # but have a good balance between the two objectives.\n    candidates = []\n    for sol, (v1, v2) in archive:\n        # Calculate the \"diversity\" score: how far the solution is from the current Pareto front\n        # in terms of both objectives\n        diversity_score = (v1 / np.max(value1_lst)) + (v2 / np.max(value2_lst))\n        candidates.append((sol, diversity_score, v1, v2))\n\n    # Sort candidates by diversity score (higher is better) and select top 30% or at least 1\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 3)]\n\n    # Randomly select one candidate from the top candidates\n    selected = random.choice(top_candidates)\n    base_solution = selected[0].copy()\n\n    # Generate a neighbor using a hybrid local search operator\n    # 1. Randomly select a subset of items to flip (1->0 or 0->1)\n    # 2. Use a greedy approach to select the best items to flip based on both objectives\n    # 3. Ensure the solution remains feasible\n\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Randomly select a number of items to flip (between 1 and min(5, n_items))\n    num_flips = random.randint(1, min(5, n_items))\n\n    # Get the current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_v1 = selected[2]\n    current_v2 = selected[3]\n\n    # Create a list of candidate flips (indices of items to potentially flip)\n    candidate_indices = list(np.where(base_solution == 1)[0]) + list(np.where(base_solution == 0)[0])\n\n    # Evaluate each candidate flip and keep the best ones based on both objectives\n    flip_scores = []\n    for idx in candidate_indices:\n        if base_solution[idx] == 1:\n            # If item is in the solution, evaluate removing it\n            new_weight = current_weight - weight_lst[idx]\n            new_v1 = current_v1 - value1_lst[idx]\n            new_v2 = current_v2 - value2_lst[idx]\n        else:\n            # If item is not in the solution, evaluate adding it\n            new_weight = current_weight + weight_lst[idx]\n            new_v1 = current_v1 + value1_lst[idx]\n            new_v2 = current_v2 + value2_lst[idx]\n\n        # Only consider feasible flips\n        if new_weight <= capacity:\n            # Score based on both objectives (normalized to [0,1])\n            score = (new_v1 / np.max(value1_lst)) + (new_v2 / np.max(value2_lst))\n            flip_scores.append((idx, score, new_weight, new_v1, new_v2))\n\n    # Sort by score (higher is better) and select the top num_flips\n    flip_scores.sort(key=lambda x: -x[1])\n    selected_flips = flip_scores[:num_flips]\n\n    # Apply the selected flips\n    for idx, _, _, _, _ in selected_flips:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.9497370982235445,
            8.597846508026123
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement by considering both objectives\n    # We prioritize solutions that are not too close to the Pareto front in either objective\n    # but have a good balance between the two objectives.\n    candidates = []\n    for sol, (v1, v2) in archive:\n        # Calculate the \"diversity\" score: how far the solution is from the current Pareto front\n        # in terms of both objectives\n        diversity_score = (v1 / np.max(value1_lst)) + (v2 / np.max(value2_lst))\n        candidates.append((sol, diversity_score, v1, v2))\n\n    # Sort candidates by diversity score (higher is better) and select top 30% or at least 1\n    candidates.sort(key=lambda x: -x[1])\n    top_candidates = candidates[:max(1, len(candidates) // 3)]\n\n    # Randomly select one candidate from the top candidates\n    selected = random.choice(top_candidates)\n    base_solution = selected[0].copy()\n\n    # Generate a neighbor using a hybrid local search operator\n    # 1. Randomly select a subset of items to flip (1->0 or 0->1)\n    # 2. Use a greedy approach to select the best items to flip based on both objectives\n    # 3. Ensure the solution remains feasible\n\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Randomly select a number of items to flip (between 1 and min(5, n_items))\n    num_flips = random.randint(1, min(5, n_items))\n\n    # Get the current total weight and values\n    current_weight = np.sum(weight_lst * base_solution)\n    current_v1 = selected[2]\n    current_v2 = selected[3]\n\n    # Create a list of candidate flips (indices of items to potentially flip)\n    candidate_indices = list(np.where(base_solution == 1)[0]) + list(np.where(base_solution == 0)[0])\n\n    # Evaluate each candidate flip and keep the best ones based on both objectives\n    flip_scores = []\n    for idx in candidate_indices:\n        if base_solution[idx] == 1:\n            # If item is in the solution, evaluate removing it\n            new_weight = current_weight - weight_lst[idx]\n            new_v1 = current_v1 - value1_lst[idx]\n            new_v2 = current_v2 - value2_lst[idx]\n        else:\n            # If item is not in the solution, evaluate adding it\n            new_weight = current_weight + weight_lst[idx]\n            new_v1 = current_v1 + value1_lst[idx]\n            new_v2 = current_v2 + value2_lst[idx]\n\n        # Only consider feasible flips\n        if new_weight <= capacity:\n            # Score based on both objectives (normalized to [0,1])\n            score = (new_v1 / np.max(value1_lst)) + (new_v2 / np.max(value2_lst))\n            flip_scores.append((idx, score, new_weight, new_v1, new_v2))\n\n    # Sort by score (higher is better) and select the top num_flips\n    flip_scores.sort(key=lambda x: -x[1])\n    selected_flips = flip_scores[:num_flips]\n\n    # Apply the selected flips\n    for idx, _, _, _, _ in selected_flips:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 172,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        # Calculate the \"distance\" to the Pareto front (simplified here)\n        # In practice, this could involve dominance checks or other metrics\n        distance = obj[0] + obj[1]  # Simple heuristic for potential\n        candidates.append((sol, distance))\n\n    # Sort candidates by distance (higher distance = more potential)\n    candidates.sort(key=lambda x: -x[1])\n    # Select top 30% of candidates for random selection\n    top_candidates = candidates[:max(1, len(candidates) // 3)]\n    base_solution = random.choice(top_candidates)[0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (exploration)\n    n_flips = min(3, len(new_solution))  # Flip up to 3 items randomly\n    flip_indices = random.sample(range(len(new_solution)), n_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Evaluate the current solution's weight and values\n    current_weight = np.sum(new_solution * weight_lst)\n    current_value1 = np.sum(new_solution * value1_lst)\n    current_value2 = np.sum(new_solution * value2_lst)\n\n    # Try to add items not in the solution that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_value1 = current_value1 + value1_lst[i]\n                new_value2 = current_value2 + value2_lst[i]\n                # Check if adding this item improves both objectives\n                if new_value1 > current_value1 and new_value2 > current_value2:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n    # Step 3: Randomly remove items to reduce weight if over capacity\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Identify items that can be removed to reduce weight\n        removable_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        random.shuffle(removable_items)\n        for i in removable_items:\n            if excess_weight <= 0:\n                break\n            new_solution[i] = 0\n            excess_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.32949238194446573,
            2.097800761461258
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        # Calculate the \"distance\" to the Pareto front (simplified here)\n        # In practice, this could involve dominance checks or other metrics\n        distance = obj[0] + obj[1]  # Simple heuristic for potential\n        candidates.append((sol, distance))\n\n    # Sort candidates by distance (higher distance = more potential)\n    candidates.sort(key=lambda x: -x[1])\n    # Select top 30% of candidates for random selection\n    top_candidates = candidates[:max(1, len(candidates) // 3)]\n    base_solution = random.choice(top_candidates)[0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a subset of items (exploration)\n    n_flips = min(3, len(new_solution))  # Flip up to 3 items randomly\n    flip_indices = random.sample(range(len(new_solution)), n_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Evaluate the current solution's weight and values\n    current_weight = np.sum(new_solution * weight_lst)\n    current_value1 = np.sum(new_solution * value1_lst)\n    current_value2 = np.sum(new_solution * value2_lst)\n\n    # Try to add items not in the solution that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                new_value1 = current_value1 + value1_lst[i]\n                new_value2 = current_value2 + value2_lst[i]\n                # Check if adding this item improves both objectives\n                if new_value1 > current_value1 and new_value2 > current_value2:\n                    new_solution[i] = 1\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n    # Step 3: Randomly remove items to reduce weight if over capacity\n    if current_weight > capacity:\n        excess_weight = current_weight - capacity\n        # Identify items that can be removed to reduce weight\n        removable_items = [i for i in range(len(new_solution)) if new_solution[i] == 1]\n        random.shuffle(removable_items)\n        for i in removable_items:\n            if excess_weight <= 0:\n                break\n            new_solution[i] = 0\n            excess_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 173,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, (current_value1, current_value2) = archive[selected_idx]\n    current_weight = np.dot(selected_solution, weight_lst)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their value)\n    for i in range(len(new_solution)):\n        if random.random() < 0.1:  # 10% chance to flip\n            # Flip item i if it doesn't exceed capacity or if it improves both objectives\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    # Check if flipping improves both objectives\n                    if (value1_lst[i] > 0) and (value2_lst[i] > 0):\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n            else:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # 2. Value-based swap: swap low-value items with high-value items\n    # Identify low-value items (in either objective) and high-value items\n    low_value_items = np.where((value1_lst < np.median(value1_lst)) | (value2_lst < np.median(value2_lst)))[0]\n    high_value_items = np.where((value1_lst > np.median(value1_lst)) & (value2_lst > np.median(value2_lst)))[0]\n\n    for i in low_value_items:\n        if new_solution[i] == 1:  # Only consider included items\n            for j in high_value_items:\n                if new_solution[j] == 0:  # Only consider excluded high-value items\n                    # Check if swapping improves both objectives and maintains feasibility\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        if (value1_lst[j] > value1_lst[i]) and (value2_lst[j] > value2_lst[i]):\n                            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                            current_weight += delta_weight\n                            break\n\n    # 3. Capacity adjustment: remove items until feasible if needed\n    while np.dot(new_solution, weight_lst) > capacity:\n        # Remove the item with the smallest ratio of (value1 + value2) / weight\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        remove_idx = included_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.34953026245328944,
            6.903861969709396
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, (current_value1, current_value2) = archive[selected_idx]\n    current_weight = np.dot(selected_solution, weight_lst)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their value)\n    for i in range(len(new_solution)):\n        if random.random() < 0.1:  # 10% chance to flip\n            # Flip item i if it doesn't exceed capacity or if it improves both objectives\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    # Check if flipping improves both objectives\n                    if (value1_lst[i] > 0) and (value2_lst[i] > 0):\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n            else:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # 2. Value-based swap: swap low-value items with high-value items\n    # Identify low-value items (in either objective) and high-value items\n    low_value_items = np.where((value1_lst < np.median(value1_lst)) | (value2_lst < np.median(value2_lst)))[0]\n    high_value_items = np.where((value1_lst > np.median(value1_lst)) & (value2_lst > np.median(value2_lst)))[0]\n\n    for i in low_value_items:\n        if new_solution[i] == 1:  # Only consider included items\n            for j in high_value_items:\n                if new_solution[j] == 0:  # Only consider excluded high-value items\n                    # Check if swapping improves both objectives and maintains feasibility\n                    delta_weight = weight_lst[j] - weight_lst[i]\n                    if current_weight + delta_weight <= capacity:\n                        if (value1_lst[j] > value1_lst[i]) and (value2_lst[j] > value2_lst[i]):\n                            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                            current_weight += delta_weight\n                            break\n\n    # 3. Capacity adjustment: remove items until feasible if needed\n    while np.dot(new_solution, weight_lst) > capacity:\n        # Remove the item with the smallest ratio of (value1 + value2) / weight\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        ratios = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        remove_idx = included_items[np.argmin(ratios)]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 174,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their combined objective value (ascending to prioritize less explored regions)\n        archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n        # Select a solution from the middle or lower half to encourage exploration\n        base_solution = archive_sorted[min(len(archive_sorted) // 2, len(archive_sorted) - 1)][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1 to 3 items)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    # 2. For each selected item, decide to flip it based on its marginal contribution\n    for idx in flip_indices:\n        current_weight = np.sum(new_solution * weight_lst)\n        if new_solution[idx] == 1:\n            # If item is included, remove it if it's not critical\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If item is excluded, add it if it fits and improves at least one objective\n            if current_weight + weight_lst[idx] <= capacity:\n                # Check if adding the item improves at least one objective\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n                if (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                    new_solution[idx] = 1\n\n    # 3. If no changes were made, perform a random flip to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.randint(0, len(new_solution) - 1)\n        current_weight = np.sum(new_solution * weight_lst)\n        if new_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8168552904013544,
            1.038217931985855
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their combined objective value (ascending to prioritize less explored regions)\n        archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n        # Select a solution from the middle or lower half to encourage exploration\n        base_solution = archive_sorted[min(len(archive_sorted) // 2, len(archive_sorted) - 1)][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (1 to 3 items)\n    num_flips = random.randint(1, min(3, len(new_solution)))\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    # 2. For each selected item, decide to flip it based on its marginal contribution\n    for idx in flip_indices:\n        current_weight = np.sum(new_solution * weight_lst)\n        if new_solution[idx] == 1:\n            # If item is included, remove it if it's not critical\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            # If item is excluded, add it if it fits and improves at least one objective\n            if current_weight + weight_lst[idx] <= capacity:\n                # Check if adding the item improves at least one objective\n                current_value1 = np.sum(new_solution * value1_lst)\n                current_value2 = np.sum(new_solution * value2_lst)\n                if (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                    new_solution[idx] = 1\n\n    # 3. If no changes were made, perform a random flip to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.randint(0, len(new_solution) - 1)\n        current_weight = np.sum(new_solution * weight_lst)\n        if new_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 175,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            candidates.append(sol)\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]  # Fallback to all solutions if no candidates\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combination of random perturbation and greedy improvement\n    # Step 1: Randomly flip a subset of items (with probability based on solution density)\n    density = np.sum(base_solution) / len(base_solution)\n    flip_prob = min(0.3, 0.1 + 0.2 * density)  # Higher density -> lower flip probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Greedy improvement for both objectives\n    # Try to add items that improve at least one objective without violating capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for both objectives\n    marginal_value1 = value1_lst * (1 - new_solution)\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_gain = marginal_value1 + marginal_value2  # Combined gain\n\n    # Sort items by combined marginal gain and weight\n    sorted_indices = np.argsort(marginal_gain)[::-1]  # Descending order\n    for i in sorted_indices:\n        if weight_lst[i] <= remaining_capacity and new_solution[i] == 0:\n            new_solution[i] = 1\n            remaining_capacity -= weight_lst[i]\n\n    # Step 3: Randomly remove items to escape local optima\n    if random.random() < 0.2:  # 20% chance to remove items\n        remove_indices = np.where(new_solution == 1)[0]\n        if len(remove_indices) > 1:  # Don't remove all items\n            num_to_remove = random.randint(1, min(3, len(remove_indices) - 1))\n            remove_candidates = random.sample(list(remove_indices), num_to_remove)\n            for i in remove_candidates:\n                new_solution[i] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        items_to_remove = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_to_remove)\n        for i in items_to_remove:\n            if total_weight <= capacity:\n                break\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.4039030395749455,
            2.1131680011749268
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < 0.9 * capacity:  # Avoid solutions that are too close to capacity\n            candidates.append(sol)\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]  # Fallback to all solutions if no candidates\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combination of random perturbation and greedy improvement\n    # Step 1: Randomly flip a subset of items (with probability based on solution density)\n    density = np.sum(base_solution) / len(base_solution)\n    flip_prob = min(0.3, 0.1 + 0.2 * density)  # Higher density -> lower flip probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Greedy improvement for both objectives\n    # Try to add items that improve at least one objective without violating capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for both objectives\n    marginal_value1 = value1_lst * (1 - new_solution)\n    marginal_value2 = value2_lst * (1 - new_solution)\n    marginal_gain = marginal_value1 + marginal_value2  # Combined gain\n\n    # Sort items by combined marginal gain and weight\n    sorted_indices = np.argsort(marginal_gain)[::-1]  # Descending order\n    for i in sorted_indices:\n        if weight_lst[i] <= remaining_capacity and new_solution[i] == 0:\n            new_solution[i] = 1\n            remaining_capacity -= weight_lst[i]\n\n    # Step 3: Randomly remove items to escape local optima\n    if random.random() < 0.2:  # 20% chance to remove items\n        remove_indices = np.where(new_solution == 1)[0]\n        if len(remove_indices) > 1:  # Don't remove all items\n            num_to_remove = random.randint(1, min(3, len(remove_indices) - 1))\n            remove_candidates = random.sample(list(remove_indices), num_to_remove)\n            for i in remove_candidates:\n                new_solution[i] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        items_to_remove = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_to_remove)\n        for i in items_to_remove:\n            if total_weight <= capacity:\n                break\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 176,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weights for selection based on objective values (higher values get higher chance)\n    weights = np.array([obj[0] + obj[1] for _, obj in archive])\n    if np.sum(weights) == 0:\n        weights = np.ones_like(weights) / len(weights)\n    else:\n        weights = weights / np.sum(weights)\n\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random bit flips with value-weighted selection\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # First, try to add items that have high value-to-weight ratio in either objective\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value_weight_ratio1 + value_weight_ratio2\n\n    # Sort items by combined value-to-weight ratio (descending)\n    sorted_items = np.argsort(-combined_ratio)\n\n    # Try to add top items that fit\n    for item in sorted_items:\n        if new_solution[item] == 0 and (current_weight + weight_lst[item]) <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Then, perform random bit flips to escape local optima\n    num_flips = min(3, n_items)  # Limit number of flips to avoid excessive changes\n    flip_indices = np.random.choice(n_items, size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if (current_weight - weight_lst[idx]) >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3100487195866134,
            2.6136824786663055
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weights for selection based on objective values (higher values get higher chance)\n    weights = np.array([obj[0] + obj[1] for _, obj in archive])\n    if np.sum(weights) == 0:\n        weights = np.ones_like(weights) / len(weights)\n    else:\n        weights = weights / np.sum(weights)\n\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random bit flips with value-weighted selection\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # First, try to add items that have high value-to-weight ratio in either objective\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-10)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = value_weight_ratio1 + value_weight_ratio2\n\n    # Sort items by combined value-to-weight ratio (descending)\n    sorted_items = np.argsort(-combined_ratio)\n\n    # Try to add top items that fit\n    for item in sorted_items:\n        if new_solution[item] == 0 and (current_weight + weight_lst[item]) <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Then, perform random bit flips to escape local optima\n    num_flips = min(3, n_items)  # Limit number of flips to avoid excessive changes\n    flip_indices = np.random.choice(n_items, size=num_flips, replace=False)\n\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if (current_weight - weight_lst[idx]) >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if (current_weight + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 177,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a random solution from the archive\n    base_solution, _ = archive[np.random.randint(len(archive))]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly flip a subset of bits (up to 3) to introduce diversity\n    num_flips = np.random.randint(1, min(4, len(new_solution)))\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n\n    for idx in flip_indices:\n        # Flip the bit\n        new_solution[idx] = 1 - new_solution[idx]\n\n        # Check feasibility and adjust if necessary\n        if new_solution[idx] == 1:\n            if current_weight + weight_lst[idx] > capacity:\n                new_solution[idx] = 0  # Revert if infeasible\n            else:\n                current_weight += weight_lst[idx]\n        else:\n            current_weight -= weight_lst[idx]\n\n    # Greedy improvement step: try to add items that improve both objectives\n    for idx in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3735599013036679,
            3.712486445903778
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a random solution from the archive\n    base_solution, _ = archive[np.random.randint(len(archive))]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly flip a subset of bits (up to 3) to introduce diversity\n    num_flips = np.random.randint(1, min(4, len(new_solution)))\n    flip_indices = np.random.choice(len(new_solution), num_flips, replace=False)\n\n    for idx in flip_indices:\n        # Flip the bit\n        new_solution[idx] = 1 - new_solution[idx]\n\n        # Check feasibility and adjust if necessary\n        if new_solution[idx] == 1:\n            if current_weight + weight_lst[idx] > capacity:\n                new_solution[idx] = 0  # Revert if infeasible\n            else:\n                current_weight += weight_lst[idx]\n        else:\n            current_weight -= weight_lst[idx]\n\n    # Greedy improvement step: try to add items that improve both objectives\n    for idx in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves both objectives\n            if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 178,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select a solution that has the highest sum of values but is not fully packed\n    selected_idx = 0\n    max_potential = -1\n    for i, (solution, (v1, v2)) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        potential = v1 + v2 - current_weight  # Simple heuristic for potential\n        if potential > max_potential and current_weight < capacity:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of bit flipping and weighted random selection\n    # Step 1: Identify items that could potentially improve both objectives\n    excluded_items = np.where(base_solution == 0)[0]\n    included_items = np.where(base_solution == 1)[0]\n\n    # Step 2: Calculate potential improvement for each excluded item\n    if len(excluded_items) > 0:\n        current_weight = np.sum(weight_lst[base_solution == 1])\n        remaining_capacity = capacity - current_weight\n\n        # Calculate potential value improvements\n        potential_value1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        potential_value2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n        # Combine potentials and select top candidates\n        combined_potential = potential_value1 + potential_value2\n        sorted_indices = np.argsort(combined_potential)[::-1]\n\n        # Try to add the most promising items first\n        for idx in sorted_indices:\n            item_idx = excluded_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n                break\n\n    # Step 3: Randomly flip some bits to escape local optima\n    if len(included_items) > 1:\n        # Randomly select 1-3 items to remove\n        num_to_remove = min(random.randint(1, 3), len(included_items))\n        items_to_remove = random.sample(list(included_items), num_to_remove)\n        for item in items_to_remove:\n            new_solution[item] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items until it is\n        included_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(included_items)\n        for item in included_items:\n            new_solution[item] = 0\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if current_weight <= capacity:\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.8619391625046595,
            2.8807963728904724
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select a solution that has the highest sum of values but is not fully packed\n    selected_idx = 0\n    max_potential = -1\n    for i, (solution, (v1, v2)) in enumerate(archive):\n        current_weight = np.sum(weight_lst[solution == 1])\n        potential = v1 + v2 - current_weight  # Simple heuristic for potential\n        if potential > max_potential and current_weight < capacity:\n            max_potential = potential\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of bit flipping and weighted random selection\n    # Step 1: Identify items that could potentially improve both objectives\n    excluded_items = np.where(base_solution == 0)[0]\n    included_items = np.where(base_solution == 1)[0]\n\n    # Step 2: Calculate potential improvement for each excluded item\n    if len(excluded_items) > 0:\n        current_weight = np.sum(weight_lst[base_solution == 1])\n        remaining_capacity = capacity - current_weight\n\n        # Calculate potential value improvements\n        potential_value1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        potential_value2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n\n        # Combine potentials and select top candidates\n        combined_potential = potential_value1 + potential_value2\n        sorted_indices = np.argsort(combined_potential)[::-1]\n\n        # Try to add the most promising items first\n        for idx in sorted_indices:\n            item_idx = excluded_items[idx]\n            if weight_lst[item_idx] <= remaining_capacity:\n                new_solution[item_idx] = 1\n                remaining_capacity -= weight_lst[item_idx]\n                break\n\n    # Step 3: Randomly flip some bits to escape local optima\n    if len(included_items) > 1:\n        # Randomly select 1-3 items to remove\n        num_to_remove = min(random.randint(1, 3), len(included_items))\n        items_to_remove = random.sample(list(included_items), num_to_remove)\n        for item in items_to_remove:\n            new_solution[item] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items until it is\n        included_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(included_items)\n        for item in included_items:\n            new_solution[item] = 0\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            if current_weight <= capacity:\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 179,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Compute marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal contributions for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Identify items to flip: those with high marginal contributions not currently in the solution\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_items) == 0:\n        # If no items can be added, try removing items with low marginal contributions\n        candidate_items = np.where(new_solution == 1)[0]\n\n    if len(candidate_items) == 0:\n        return new_solution  # No feasible moves\n\n    # Sort candidates by combined marginal contribution (descending)\n    sorted_candidates = sorted(candidate_items, key=lambda x: -combined_marginal[x])\n\n    # Select top K candidates (K=3) for flipping\n    K = min(3, len(sorted_candidates))\n    selected_items = np.random.choice(sorted_candidates[:K], size=1, replace=False)\n\n    # Flip the selected items\n    for item in selected_items:\n        if new_solution[item] == 0:\n            # Try to add the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            # Try to remove the item\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.829951558970312,
            1.3225830495357513
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Compute marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal contributions for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Identify items to flip: those with high marginal contributions not currently in the solution\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n    if len(candidate_items) == 0:\n        # If no items can be added, try removing items with low marginal contributions\n        candidate_items = np.where(new_solution == 1)[0]\n\n    if len(candidate_items) == 0:\n        return new_solution  # No feasible moves\n\n    # Sort candidates by combined marginal contribution (descending)\n    sorted_candidates = sorted(candidate_items, key=lambda x: -combined_marginal[x])\n\n    # Select top K candidates (K=3) for flipping\n    K = min(3, len(sorted_candidates))\n    selected_items = np.random.choice(sorted_candidates[:K], size=1, replace=False)\n\n    # Flip the selected items\n    for item in selected_items:\n        if new_solution[item] == 0:\n            # Try to add the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n        else:\n            # Try to remove the item\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 180,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidate_indices = []\n    for idx, (sol, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight < capacity:\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        return archive[0][0].copy()  # Fallback if no candidates\n\n    # Intelligently select a solution: prioritize those with high potential to improve both objectives\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine swap and insertion moves\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly select a subset of items to consider for swapping\n    swap_candidates = np.where(base_solution == 1)[0]\n    if len(swap_candidates) > 0:\n        i = np.random.choice(swap_candidates)\n        j = np.random.choice(np.where(base_solution == 0)[0])\n\n        # Check if swapping i and j is feasible\n        delta_weight = weight_lst[j] - weight_lst[i]\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: If no swap was performed, try a random insertion\n    if np.array_equal(new_solution, base_solution):\n        j = np.random.choice(np.where(base_solution == 0)[0])\n        if current_weight + weight_lst[j] <= capacity:\n            new_solution[j] = 1\n\n    # Step 3: If still no change, flip a random item (if feasible)\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.where((weight_lst <= (capacity - current_weight)) | (base_solution == 1))[0]\n        if len(flip_candidates) > 0:\n            k = np.random.choice(flip_candidates)\n            new_solution[k] = 1 - new_solution[k]\n\n    return new_solution\n\n",
        "score": [
            -0.38017910428959967,
            2.0150537192821503
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    candidate_indices = []\n    for idx, (sol, _) in enumerate(archive):\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight < capacity:\n            candidate_indices.append(idx)\n\n    if not candidate_indices:\n        return archive[0][0].copy()  # Fallback if no candidates\n\n    # Intelligently select a solution: prioritize those with high potential to improve both objectives\n    selected_idx = np.random.choice(candidate_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: combine swap and insertion moves\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly select a subset of items to consider for swapping\n    swap_candidates = np.where(base_solution == 1)[0]\n    if len(swap_candidates) > 0:\n        i = np.random.choice(swap_candidates)\n        j = np.random.choice(np.where(base_solution == 0)[0])\n\n        # Check if swapping i and j is feasible\n        delta_weight = weight_lst[j] - weight_lst[i]\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: If no swap was performed, try a random insertion\n    if np.array_equal(new_solution, base_solution):\n        j = np.random.choice(np.where(base_solution == 0)[0])\n        if current_weight + weight_lst[j] <= capacity:\n            new_solution[j] = 1\n\n    # Step 3: If still no change, flip a random item (if feasible)\n    if np.array_equal(new_solution, base_solution):\n        flip_candidates = np.where((weight_lst <= (capacity - current_weight)) | (base_solution == 1))[0]\n        if len(flip_candidates) > 0:\n            k = np.random.choice(flip_candidates)\n            new_solution[k] = 1 - new_solution[k]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 181,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a higher probability of being near the Pareto front\n    # by considering solutions with higher combined objective values\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Perform hybrid local search: random swaps + greedy item selection\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Random swaps to explore neighborhood\n    for _ in range(min(5, n_items // 2)):\n        i, j = np.random.choice(n_items, 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility of swap\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                if current_weight + weight_lst[i] - weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight + weight_lst[i] - weight_lst[j]\n\n    # Greedy selection of items based on marginal utility\n    for _ in range(min(3, n_items // 4)):\n        # Calculate marginal utility for each item not in the solution\n        marginal_utility1 = value1_lst - (value1_lst * new_solution)\n        marginal_utility2 = value2_lst - (value2_lst * new_solution)\n        combined_marginal = marginal_utility1 + marginal_utility2\n\n        # Select items with highest combined marginal utility that fit\n        potential_items = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(potential_items) > 0:\n            best_item = potential_items[np.argmax(combined_marginal[potential_items])]\n            if combined_marginal[best_item] > 0:\n                new_solution[best_item] = 1\n                current_weight += weight_lst[best_item]\n\n    return new_solution\n\n",
        "score": [
            -0.3109363581649297,
            8.31677371263504
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a higher probability of being near the Pareto front\n    # by considering solutions with higher combined objective values\n    combined_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = combined_values / np.sum(combined_values)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Perform hybrid local search: random swaps + greedy item selection\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Random swaps to explore neighborhood\n    for _ in range(min(5, n_items // 2)):\n        i, j = np.random.choice(n_items, 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility of swap\n            if new_solution[i] == 1 and new_solution[j] == 0:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n            elif new_solution[i] == 0 and new_solution[j] == 1:\n                if current_weight + weight_lst[i] - weight_lst[j] <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight + weight_lst[i] - weight_lst[j]\n\n    # Greedy selection of items based on marginal utility\n    for _ in range(min(3, n_items // 4)):\n        # Calculate marginal utility for each item not in the solution\n        marginal_utility1 = value1_lst - (value1_lst * new_solution)\n        marginal_utility2 = value2_lst - (value2_lst * new_solution)\n        combined_marginal = marginal_utility1 + marginal_utility2\n\n        # Select items with highest combined marginal utility that fit\n        potential_items = np.where((new_solution == 0) & (weight_lst <= capacity - current_weight))[0]\n        if len(potential_items) > 0:\n            best_item = potential_items[np.argmax(combined_marginal[potential_items])]\n            if combined_marginal[best_item] > 0:\n                new_solution[best_item] = 1\n                current_weight += weight_lst[best_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 182,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate potential improvement score for each solution\n    scores = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst[sol == 1])\n        remaining_capacity = capacity - current_weight\n        # Potential items that can be added\n        potential_items = (weight_lst <= remaining_capacity) & (sol == 0)\n        # Score based on potential value improvement\n        score = np.sum(value1_lst[potential_items]) + np.sum(value2_lst[potential_items])\n        scores.append(score)\n\n    # Select a solution with high score (high potential for improvement)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Randomly flip a subset of items (intensification)\n    flip_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add the item\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: Add the most valuable item not in the solution (diversification)\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Consider both objectives for selection\n        combined_value = value1_lst + value2_lst\n        best_item = remaining_items[np.argmax(combined_value[remaining_items])]\n        if np.sum(weight_lst[new_solution == 1] + weight_lst[best_item]) <= capacity:\n            new_solution[best_item] = 1\n\n    # Strategy 3: Remove the least valuable item in the solution (diversification)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Consider both objectives for removal\n        combined_value = value1_lst + value2_lst\n        worst_item = included_items[np.argmin(combined_value[included_items])]\n        if np.sum(weight_lst[new_solution == 1] - weight_lst[worst_item]) <= capacity:\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7959589823025133,
            4.683681398630142
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Calculate potential improvement score for each solution\n    scores = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst[sol == 1])\n        remaining_capacity = capacity - current_weight\n        # Potential items that can be added\n        potential_items = (weight_lst <= remaining_capacity) & (sol == 0)\n        # Score based on potential value improvement\n        score = np.sum(value1_lst[potential_items]) + np.sum(value2_lst[potential_items])\n        scores.append(score)\n\n    # Select a solution with high score (high potential for improvement)\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Randomly flip a subset of items (intensification)\n    flip_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add the item\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # Strategy 2: Add the most valuable item not in the solution (diversification)\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Consider both objectives for selection\n        combined_value = value1_lst + value2_lst\n        best_item = remaining_items[np.argmax(combined_value[remaining_items])]\n        if np.sum(weight_lst[new_solution == 1] + weight_lst[best_item]) <= capacity:\n            new_solution[best_item] = 1\n\n    # Strategy 3: Remove the least valuable item in the solution (diversification)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Consider both objectives for removal\n        combined_value = value1_lst + value2_lst\n        worst_item = included_items[np.argmin(combined_value[included_items])]\n        if np.sum(weight_lst[new_solution == 1] - weight_lst[worst_item]) <= capacity:\n            new_solution[worst_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 183,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.dot(base_solution, weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_perturbations = min(3, len(new_solution))\n    perturb_indices = random.sample(range(len(new_solution)), num_perturbations)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess items if needed\n    while np.dot(new_solution, weight_lst) > capacity:\n        excess_indices = np.where(new_solution == 1)[0]\n        if len(excess_indices) == 0:\n            break  # No items to remove, solution is infeasible\n        remove_idx = random.choice(excess_indices)\n        new_solution[remove_idx] = 0\n\n    # Greedy improvement phase: add items with high marginal utility\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if weight_lst[idx] <= remaining_capacity:\n            # Calculate marginal utility for both objectives\n            marginal_value1 = value1_lst[idx]\n            marginal_value2 = value2_lst[idx]\n            # Simple greedy: accept if at least one objective improves\n            if marginal_value1 > 0 or marginal_value2 > 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3487466017464759,
            1.5591258108615875
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.dot(base_solution, weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Randomly perturb the solution (flip a few bits)\n    new_solution = base_solution.copy()\n    num_perturbations = min(3, len(new_solution))\n    perturb_indices = random.sample(range(len(new_solution)), num_perturbations)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing excess items if needed\n    while np.dot(new_solution, weight_lst) > capacity:\n        excess_indices = np.where(new_solution == 1)[0]\n        if len(excess_indices) == 0:\n            break  # No items to remove, solution is infeasible\n        remove_idx = random.choice(excess_indices)\n        new_solution[remove_idx] = 0\n\n    # Greedy improvement phase: add items with high marginal utility\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n    for idx in remaining_items:\n        if weight_lst[idx] <= remaining_capacity:\n            # Calculate marginal utility for both objectives\n            marginal_value1 = value1_lst[idx]\n            marginal_value2 = value2_lst[idx]\n            # Simple greedy: accept if at least one objective improves\n            if marginal_value1 > 0 or marginal_value2 > 0:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 184,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Identify solutions with the highest potential for improvement (e.g., not dominated by others)\n    non_dominated = []\n    for i, (obj_i, sol_i) in enumerate(zip(archive_objectives, archive_solutions)):\n        is_dominated = False\n        for j, (obj_j, sol_j) in enumerate(zip(archive_objectives, archive_solutions)):\n            if i != j and obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1] and (obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol_i, obj_i))\n\n    if not non_dominated:\n        non_dominated = archive  # Fallback to all solutions if no non-dominated ones\n\n    # Randomly select a solution from the non-dominated ones\n    selected_sol, _ = random.choice(non_dominated)\n    base_solution = selected_sol.copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly flip a subset of items (exploration)\n    flip_indices = random.sample(range(n_items), min(n_items, random.randint(1, n_items // 2)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to add or remove items to improve both objectives\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        improved = False\n        for idx in range(n_items):\n            if new_solution[idx] == 1:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 - value1_lst[idx]\n                    new_value2 = current_value2 - value2_lst[idx]\n                    # Check if both objectives improve or at least one improves significantly\n                    if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n                       (new_value1 > current_value1 and (new_value2 + 0.1 * current_value2) > current_value2) or \\\n                       (new_value2 > current_value2 and (new_value1 + 0.1 * current_value1) > current_value1):\n                        new_solution[idx] = 0\n                        current_weight = new_weight\n                        current_value1 = new_value1\n                        current_value2 = new_value2\n                        improved = True\n                        break\n            else:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 + value1_lst[idx]\n                    new_value2 = current_value2 + value2_lst[idx]\n                    # Check if both objectives improve or at least one improves significantly\n                    if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n                       (new_value1 > current_value1 and (new_value2 + 0.1 * current_value2) > current_value2) or \\\n                       (new_value2 > current_value2 and (new_value1 + 0.1 * current_value1) > current_value1):\n                        new_solution[idx] = 1\n                        current_weight = new_weight\n                        current_value1 = new_value1\n                        current_value2 = new_value2\n                        improved = True\n                        break\n        if not improved:\n            break  # Exit if no improvement is found\n\n    return new_solution\n\n",
        "score": [
            -0.3928033983945733,
            2.0970703065395355
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Identify solutions with the highest potential for improvement (e.g., not dominated by others)\n    non_dominated = []\n    for i, (obj_i, sol_i) in enumerate(zip(archive_objectives, archive_solutions)):\n        is_dominated = False\n        for j, (obj_j, sol_j) in enumerate(zip(archive_objectives, archive_solutions)):\n            if i != j and obj_j[0] >= obj_i[0] and obj_j[1] >= obj_i[1] and (obj_j[0] > obj_i[0] or obj_j[1] > obj_i[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol_i, obj_i))\n\n    if not non_dominated:\n        non_dominated = archive  # Fallback to all solutions if no non-dominated ones\n\n    # Randomly select a solution from the non-dominated ones\n    selected_sol, _ = random.choice(non_dominated)\n    base_solution = selected_sol.copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly flip a subset of items (exploration)\n    flip_indices = random.sample(range(n_items), min(n_items, random.randint(1, n_items // 2)))\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement (exploitation)\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to add or remove items to improve both objectives\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        improved = False\n        for idx in range(n_items):\n            if new_solution[idx] == 1:\n                # Try removing the item\n                new_weight = current_weight - weight_lst[idx]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 - value1_lst[idx]\n                    new_value2 = current_value2 - value2_lst[idx]\n                    # Check if both objectives improve or at least one improves significantly\n                    if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n                       (new_value1 > current_value1 and (new_value2 + 0.1 * current_value2) > current_value2) or \\\n                       (new_value2 > current_value2 and (new_value1 + 0.1 * current_value1) > current_value1):\n                        new_solution[idx] = 0\n                        current_weight = new_weight\n                        current_value1 = new_value1\n                        current_value2 = new_value2\n                        improved = True\n                        break\n            else:\n                # Try adding the item\n                new_weight = current_weight + weight_lst[idx]\n                if new_weight <= capacity:\n                    new_value1 = current_value1 + value1_lst[idx]\n                    new_value2 = current_value2 + value2_lst[idx]\n                    # Check if both objectives improve or at least one improves significantly\n                    if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n                       (new_value1 > current_value1 and (new_value2 + 0.1 * current_value2) > current_value2) or \\\n                       (new_value2 > current_value2 and (new_value1 + 0.1 * current_value1) > current_value1):\n                        new_solution[idx] = 1\n                        current_weight = new_weight\n                        current_value1 = new_value1\n                        current_value2 = new_value2\n                        improved = True\n                        break\n        if not improved:\n            break  # Exit if no improvement is found\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 185,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on its dominance and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Identify items that can be added (not in solution and fit within remaining capacity)\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If no items can be added, try removing items with low value-to-weight ratio\n    if len(candidate_items) == 0:\n        # Calculate value-to-weight ratios for items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) == 0:\n            return new_solution  # No items to remove\n\n        # Remove items with lowest value-to-weight ratio (weighted sum of both objectives)\n        value_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        remove_idx = in_solution[np.argmin(value_ratios)]\n        new_solution[remove_idx] = 0\n    else:\n        # Select items to add based on value-to-weight ratio and randomness\n        if len(candidate_items) > 1:\n            # Weighted random selection based on value-to-weight ratio\n            weights = (value1_lst[candidate_items] + value2_lst[candidate_items]) / weight_lst[candidate_items]\n            weights = np.maximum(weights, 0.01)  # Ensure no zero weights\n            selected_item = random.choices(candidate_items, weights=weights, k=1)[0]\n        else:\n            selected_item = candidate_items[0]\n\n        # Add the selected item\n        new_solution[selected_item] = 1\n\n    # Optional: Perform a small random swap to explore more neighbors\n    if random.random() < 0.3:  # 30% chance of swap\n        in_solution = np.where(new_solution == 1)[0]\n        not_in_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(not_in_solution) > 0:\n            # Swap a random item in with a random item out\n            swap_out = random.choice(in_solution)\n            swap_in = random.choice(not_in_solution)\n\n            # Check if swap is feasible\n            if weight_lst[swap_in] - weight_lst[swap_out] <= remaining_capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.28274292673750934,
            0.6590487658977509
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on its dominance and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Identify items that can be added (not in solution and fit within remaining capacity)\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If no items can be added, try removing items with low value-to-weight ratio\n    if len(candidate_items) == 0:\n        # Calculate value-to-weight ratios for items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) == 0:\n            return new_solution  # No items to remove\n\n        # Remove items with lowest value-to-weight ratio (weighted sum of both objectives)\n        value_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        remove_idx = in_solution[np.argmin(value_ratios)]\n        new_solution[remove_idx] = 0\n    else:\n        # Select items to add based on value-to-weight ratio and randomness\n        if len(candidate_items) > 1:\n            # Weighted random selection based on value-to-weight ratio\n            weights = (value1_lst[candidate_items] + value2_lst[candidate_items]) / weight_lst[candidate_items]\n            weights = np.maximum(weights, 0.01)  # Ensure no zero weights\n            selected_item = random.choices(candidate_items, weights=weights, k=1)[0]\n        else:\n            selected_item = candidate_items[0]\n\n        # Add the selected item\n        new_solution[selected_item] = 1\n\n    # Optional: Perform a small random swap to explore more neighbors\n    if random.random() < 0.3:  # 30% chance of swap\n        in_solution = np.where(new_solution == 1)[0]\n        not_in_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(not_in_solution) > 0:\n            # Swap a random item in with a random item out\n            swap_out = random.choice(in_solution)\n            swap_in = random.choice(not_in_solution)\n\n            # Check if swap is feasible\n            if weight_lst[swap_in] - weight_lst[swap_out] <= remaining_capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 185,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on its dominance and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Identify items that can be added (not in solution and fit within remaining capacity)\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If no items can be added, try removing items with low value-to-weight ratio\n    if len(candidate_items) == 0:\n        # Calculate value-to-weight ratios for items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) == 0:\n            return new_solution  # No items to remove\n\n        # Remove items with lowest value-to-weight ratio (weighted sum of both objectives)\n        value_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        remove_idx = in_solution[np.argmin(value_ratios)]\n        new_solution[remove_idx] = 0\n    else:\n        # Select items to add based on value-to-weight ratio and randomness\n        if len(candidate_items) > 1:\n            # Weighted random selection based on value-to-weight ratio\n            weights = (value1_lst[candidate_items] + value2_lst[candidate_items]) / weight_lst[candidate_items]\n            weights = np.maximum(weights, 0.01)  # Ensure no zero weights\n            selected_item = random.choices(candidate_items, weights=weights, k=1)[0]\n        else:\n            selected_item = candidate_items[0]\n\n        # Add the selected item\n        new_solution[selected_item] = 1\n\n    # Optional: Perform a small random swap to explore more neighbors\n    if random.random() < 0.3:  # 30% chance of swap\n        in_solution = np.where(new_solution == 1)[0]\n        not_in_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(not_in_solution) > 0:\n            # Swap a random item in with a random item out\n            swap_out = random.choice(in_solution)\n            swap_in = random.choice(not_in_solution)\n\n            # Check if swap is feasible\n            if weight_lst[swap_in] - weight_lst[swap_out] <= remaining_capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.28274292673750934,
            0.6590487658977509
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on its dominance and potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Identify items that can be added (not in solution and fit within remaining capacity)\n    candidate_items = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n\n    # If no items can be added, try removing items with low value-to-weight ratio\n    if len(candidate_items) == 0:\n        # Calculate value-to-weight ratios for items in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) == 0:\n            return new_solution  # No items to remove\n\n        # Remove items with lowest value-to-weight ratio (weighted sum of both objectives)\n        value_ratios = (value1_lst[in_solution] + value2_lst[in_solution]) / weight_lst[in_solution]\n        remove_idx = in_solution[np.argmin(value_ratios)]\n        new_solution[remove_idx] = 0\n    else:\n        # Select items to add based on value-to-weight ratio and randomness\n        if len(candidate_items) > 1:\n            # Weighted random selection based on value-to-weight ratio\n            weights = (value1_lst[candidate_items] + value2_lst[candidate_items]) / weight_lst[candidate_items]\n            weights = np.maximum(weights, 0.01)  # Ensure no zero weights\n            selected_item = random.choices(candidate_items, weights=weights, k=1)[0]\n        else:\n            selected_item = candidate_items[0]\n\n        # Add the selected item\n        new_solution[selected_item] = 1\n\n    # Optional: Perform a small random swap to explore more neighbors\n    if random.random() < 0.3:  # 30% chance of swap\n        in_solution = np.where(new_solution == 1)[0]\n        not_in_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(not_in_solution) > 0:\n            # Swap a random item in with a random item out\n            swap_out = random.choice(in_solution)\n            swap_in = random.choice(not_in_solution)\n\n            # Check if swap is feasible\n            if weight_lst[swap_in] - weight_lst[swap_out] <= remaining_capacity:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 186,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # and have high potential for improvement\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random bit flips with a greedy improvement\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select a number of items to flip (between 1 and min(10, num_items))\n    num_flips = random.randint(1, min(10, num_items))\n\n    # Track the best candidate solution found during the search\n    best_candidate = new_solution.copy()\n    best_weight = current_weight\n    best_value1 = current_value1\n    best_value2 = current_value2\n\n    for _ in range(num_flips):\n        # Select a random item to flip\n        item_idx = random.randint(0, num_items - 1)\n\n        # Calculate the new weight and values if we flip this item\n        if new_solution[item_idx] == 1:\n            new_weight = current_weight - weight_lst[item_idx]\n            new_value1 = current_value1 - value1_lst[item_idx]\n            new_value2 = current_value2 - value2_lst[item_idx]\n        else:\n            new_weight = current_weight + weight_lst[item_idx]\n            new_value1 = current_value1 + value1_lst[item_idx]\n            new_value2 = current_value2 + value2_lst[item_idx]\n\n        # Check if the flip is feasible\n        if new_weight <= capacity:\n            # Update the solution\n            new_solution[item_idx] = 1 - new_solution[item_idx]\n            current_weight = new_weight\n            current_value1 = new_value1\n            current_value2 = new_value2\n\n            # Update best candidate if this flip improves both objectives\n            if (new_value1 > best_value1 and new_value2 > best_value2) or \\\n               (new_value1 >= best_value1 and new_value2 > best_value2 + 0.1 * best_value2) or \\\n               (new_value1 > best_value1 + 0.1 * best_value1 and new_value2 >= best_value2):\n                best_candidate = new_solution.copy()\n                best_weight = new_weight\n                best_value1 = new_value1\n                best_value2 = new_value2\n        else:\n            # If the flip is not feasible, try to find an alternative item to flip\n            # that would make the solution feasible while improving at least one objective\n            for alt_idx in range(num_items):\n                if new_solution[alt_idx] == 1:\n                    alt_weight = current_weight - weight_lst[alt_idx]\n                    if alt_weight <= capacity:\n                        alt_value1 = current_value1 - value1_lst[alt_idx]\n                        alt_value2 = current_value2 - value2_lst[alt_idx]\n                        if (alt_value1 > current_value1 or alt_value2 > current_value2) and \\\n                           (alt_value1 >= current_value1 and alt_value2 >= current_value2):\n                            new_solution[alt_idx] = 0\n                            current_weight = alt_weight\n                            current_value1 = alt_value1\n                            current_value2 = alt_value2\n                            break\n\n    # Return the best candidate found during the search\n    return best_candidate\n\n",
        "score": [
            -0.2681148956531546,
            9.442377001047134
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards solutions that are not too crowded in the archive\n    # and have high potential for improvement\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random bit flips with a greedy improvement\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select a number of items to flip (between 1 and min(10, num_items))\n    num_flips = random.randint(1, min(10, num_items))\n\n    # Track the best candidate solution found during the search\n    best_candidate = new_solution.copy()\n    best_weight = current_weight\n    best_value1 = current_value1\n    best_value2 = current_value2\n\n    for _ in range(num_flips):\n        # Select a random item to flip\n        item_idx = random.randint(0, num_items - 1)\n\n        # Calculate the new weight and values if we flip this item\n        if new_solution[item_idx] == 1:\n            new_weight = current_weight - weight_lst[item_idx]\n            new_value1 = current_value1 - value1_lst[item_idx]\n            new_value2 = current_value2 - value2_lst[item_idx]\n        else:\n            new_weight = current_weight + weight_lst[item_idx]\n            new_value1 = current_value1 + value1_lst[item_idx]\n            new_value2 = current_value2 + value2_lst[item_idx]\n\n        # Check if the flip is feasible\n        if new_weight <= capacity:\n            # Update the solution\n            new_solution[item_idx] = 1 - new_solution[item_idx]\n            current_weight = new_weight\n            current_value1 = new_value1\n            current_value2 = new_value2\n\n            # Update best candidate if this flip improves both objectives\n            if (new_value1 > best_value1 and new_value2 > best_value2) or \\\n               (new_value1 >= best_value1 and new_value2 > best_value2 + 0.1 * best_value2) or \\\n               (new_value1 > best_value1 + 0.1 * best_value1 and new_value2 >= best_value2):\n                best_candidate = new_solution.copy()\n                best_weight = new_weight\n                best_value1 = new_value1\n                best_value2 = new_value2\n        else:\n            # If the flip is not feasible, try to find an alternative item to flip\n            # that would make the solution feasible while improving at least one objective\n            for alt_idx in range(num_items):\n                if new_solution[alt_idx] == 1:\n                    alt_weight = current_weight - weight_lst[alt_idx]\n                    if alt_weight <= capacity:\n                        alt_value1 = current_value1 - value1_lst[alt_idx]\n                        alt_value2 = current_value2 - value2_lst[alt_idx]\n                        if (alt_value1 > current_value1 or alt_value2 > current_value2) and \\\n                           (alt_value1 >= current_value1 and alt_value2 >= current_value2):\n                            new_solution[alt_idx] = 0\n                            current_weight = alt_weight\n                            current_value1 = alt_value1\n                            current_value2 = alt_value2\n                            break\n\n    # Return the best candidate found during the search\n    return best_candidate\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 187,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (not on the Pareto frontier)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Hybrid local search: flip bits based on combined value-to-weight ratio\n    for _ in range(min(3, len(new_solution))):  # Limit the number of flips to avoid excessive changes\n        # Select candidate items to flip based on combined ratio\n        combined_ratio = ratio1 + ratio2\n        candidates = np.argsort(combined_ratio)[::-1]  # Sort in descending order\n\n        for item in candidates:\n            if new_solution[item] == 1:\n                # Try removing the item (flip to 0)\n                if current_weight - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n            else:\n                # Try adding the item (flip to 1)\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8185750604091003,
            1.135193407535553
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (not on the Pareto frontier)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Compute value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Hybrid local search: flip bits based on combined value-to-weight ratio\n    for _ in range(min(3, len(new_solution))):  # Limit the number of flips to avoid excessive changes\n        # Select candidate items to flip based on combined ratio\n        combined_ratio = ratio1 + ratio2\n        candidates = np.argsort(combined_ratio)[::-1]  # Sort in descending order\n\n        for item in candidates:\n            if new_solution[item] == 1:\n                # Try removing the item (flip to 0)\n                if current_weight - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n            else:\n                # Try adding the item (flip to 1)\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 188,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential_weight = min(current_weight + np.sum(weight_lst), capacity)\n        if current_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select a random candidate with bias towards solutions with more room for improvement\n    weights = [1.0 / (1 + np.sum(weight_lst * sol)) for sol in candidates]\n    selected_sol = random.choices(candidates, weights=weights, k=1)[0].copy()\n\n    # Hybrid local search: combine swap and flip operations\n    new_solution = selected_sol.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # First, try to swap items between included and excluded\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        i = random.choice(included)\n        j = random.choice(excluded)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            return new_solution\n\n    # If swap didn't work, try a flip operation\n    if random.random() < 0.3:  # 30% chance for flip\n        for _ in range(min(3, n_items)):  # Try up to 3 random flips\n            idx = random.randint(0, n_items - 1)\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.4654960429311019,
            8.968370825052261
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential_weight = min(current_weight + np.sum(weight_lst), capacity)\n        if current_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select a random candidate with bias towards solutions with more room for improvement\n    weights = [1.0 / (1 + np.sum(weight_lst * sol)) for sol in candidates]\n    selected_sol = random.choices(candidates, weights=weights, k=1)[0].copy()\n\n    # Hybrid local search: combine swap and flip operations\n    new_solution = selected_sol.copy()\n    n_items = len(new_solution)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # First, try to swap items between included and excluded\n    included = np.where(new_solution == 1)[0]\n    excluded = np.where(new_solution == 0)[0]\n\n    if len(included) > 0 and len(excluded) > 0:\n        i = random.choice(included)\n        j = random.choice(excluded)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            return new_solution\n\n    # If swap didn't work, try a flip operation\n    if random.random() < 0.3:  # 30% chance for flip\n        for _ in range(min(3, n_items)):  # Try up to 3 random flips\n            idx = random.randint(0, n_items - 1)\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    break\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 189,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = sorted(archive, key=lambda x: -sum(x[1]))  # Prioritize solutions with higher total value\n    selected = random.choice(candidates[:max(3, len(candidates) // 2)])  # Intelligently select from top candidates\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation (flip a small number of randomly selected items)\n    num_perturbations = min(3, len(base_solution) // 2)  # Limit perturbation to avoid excessive changes\n    perturb_indices = random.sample(range(len(base_solution)), num_perturbations)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the item\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_weights = weight_lst[excess_items]\n        sorted_indices = np.argsort(excess_weights)\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            new_solution[excess_items[i]] = 0\n            excess -= excess_weights[i]\n\n    # Step 2: Greedy improvement (add items that improve at least one objective)\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    for item in remaining_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Check if adding the item improves at least one objective\n            new_value1 = selected[1][0] + value1_lst[item]\n            new_value2 = selected[1][1] + value2_lst[item]\n            if new_value1 > selected[1][0] or new_value2 > selected[1][1]:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3503124030244637,
            1.3527752757072449
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = sorted(archive, key=lambda x: -sum(x[1]))  # Prioritize solutions with higher total value\n    selected = random.choice(candidates[:max(3, len(candidates) // 2)])  # Intelligently select from top candidates\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation (flip a small number of randomly selected items)\n    num_perturbations = min(3, len(base_solution) // 2)  # Limit perturbation to avoid excessive changes\n    perturb_indices = random.sample(range(len(base_solution)), num_perturbations)\n    for idx in perturb_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the item\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        excess = total_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        excess_weights = weight_lst[excess_items]\n        sorted_indices = np.argsort(excess_weights)\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            new_solution[excess_items[i]] = 0\n            excess -= excess_weights[i]\n\n    # Step 2: Greedy improvement (add items that improve at least one objective)\n    remaining_items = np.where(new_solution == 0)[0]\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    for item in remaining_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Check if adding the item improves at least one objective\n            new_value1 = selected[1][0] + value1_lst[item]\n            new_value2 = selected[1][1] + value2_lst[item]\n            if new_value1 > selected[1][0] or new_value2 > selected[1][1]:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 190,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (with high crowding distance or high marginal gains)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, (current_value1, current_value2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst[selected_solution == 1])\n\n    # Step 2: Hybrid local search operator\n    new_solution = selected_solution.copy()\n\n    # Randomly flip a subset of items (to escape local optima)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after flipping\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal gains (in both objectives)\n        while excess > 0:\n            # Calculate marginal gains for all items\n            marginal_gains = (value1_lst + value2_lst) * new_solution\n            if np.sum(marginal_gains) == 0:\n                break\n            # Remove the item with the smallest marginal gain\n            min_gain_idx = np.argmin(marginal_gains)\n            if new_solution[min_gain_idx] == 1:\n                new_solution[min_gain_idx] = 0\n                excess -= weight_lst[min_gain_idx]\n            else:\n                break\n\n    # Greedily add items with high marginal gains (to improve solution quality)\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_weight > 0:\n        # Calculate marginal gains for all items not in the solution\n        marginal_gains = (value1_lst + value2_lst) * (1 - new_solution)\n        # Sort items by marginal gains in descending order\n        sorted_indices = np.argsort(-marginal_gains)\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    # Swap items between objectives to balance both objectives\n    if np.random.rand() < 0.3:\n        # Identify items that can be swapped to improve both objectives\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Try removing this item and see if we can add another\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = np.sum(weight_lst[temp_solution == 1])\n                if temp_weight < capacity:\n                    # Find the best item to add that improves both objectives\n                    best_candidate = -1\n                    best_gain = 0\n                    for j in range(len(new_solution)):\n                        if new_solution[j] == 0 and (temp_weight + weight_lst[j]) <= capacity:\n                            gain = value1_lst[j] + value2_lst[j]\n                            if gain > best_gain:\n                                best_gain = gain\n                                best_candidate = j\n                    if best_candidate != -1:\n                        temp_solution[best_candidate] = 1\n                        # Accept the swap if it improves both objectives\n                        if (value1_lst[best_candidate] + value2_lst[best_candidate]) > (value1_lst[i] + value2_lst[i]):\n                            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.3792481435080589,
            2.8806082606315613
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (with high crowding distance or high marginal gains)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, (current_value1, current_value2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst[selected_solution == 1])\n\n    # Step 2: Hybrid local search operator\n    new_solution = selected_solution.copy()\n\n    # Randomly flip a subset of items (to escape local optima)\n    flip_mask = np.random.rand(len(new_solution)) < 0.2\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Ensure feasibility after flipping\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal gains (in both objectives)\n        while excess > 0:\n            # Calculate marginal gains for all items\n            marginal_gains = (value1_lst + value2_lst) * new_solution\n            if np.sum(marginal_gains) == 0:\n                break\n            # Remove the item with the smallest marginal gain\n            min_gain_idx = np.argmin(marginal_gains)\n            if new_solution[min_gain_idx] == 1:\n                new_solution[min_gain_idx] = 0\n                excess -= weight_lst[min_gain_idx]\n            else:\n                break\n\n    # Greedily add items with high marginal gains (to improve solution quality)\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n    if remaining_weight > 0:\n        # Calculate marginal gains for all items not in the solution\n        marginal_gains = (value1_lst + value2_lst) * (1 - new_solution)\n        # Sort items by marginal gains in descending order\n        sorted_indices = np.argsort(-marginal_gains)\n        for idx in sorted_indices:\n            if weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    # Swap items between objectives to balance both objectives\n    if np.random.rand() < 0.3:\n        # Identify items that can be swapped to improve both objectives\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Try removing this item and see if we can add another\n                temp_solution = new_solution.copy()\n                temp_solution[i] = 0\n                temp_weight = np.sum(weight_lst[temp_solution == 1])\n                if temp_weight < capacity:\n                    # Find the best item to add that improves both objectives\n                    best_candidate = -1\n                    best_gain = 0\n                    for j in range(len(new_solution)):\n                        if new_solution[j] == 0 and (temp_weight + weight_lst[j]) <= capacity:\n                            gain = value1_lst[j] + value2_lst[j]\n                            if gain > best_gain:\n                                best_gain = gain\n                                best_candidate = j\n                    if best_candidate != -1:\n                        temp_solution[best_candidate] = 1\n                        # Accept the swap if it improves both objectives\n                        if (value1_lst[best_candidate] + value2_lst[best_candidate]) > (value1_lst[i] + value2_lst[i]):\n                            new_solution = temp_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 191,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by value ratios)\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        # Calculate normalized value ratios to prioritize solutions with balanced improvement potential\n        ratio1 = val1 / (total_weight + 1e-6)\n        ratio2 = val2 / (total_weight + 1e-6)\n        candidates.append((sol, ratio1 + ratio2))\n\n    if not candidates:\n        # Fallback: select a random solution if no candidates found\n        return archive[np.random.randint(len(archive))][0].copy()\n\n    # Select the candidate with the highest combined ratio (promising for improvement)\n    selected_sol, _ = max(candidates, key=lambda x: x[1])\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search: flip items based on value-to-weight ratios and randomness\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) == 0:\n        # If no items are selected, randomly add one\n        candidate_indices = np.where(weight_lst <= capacity)[0]\n        if len(candidate_indices) > 0:\n            new_solution[np.random.choice(candidate_indices)] = 1\n        return new_solution\n\n    # Calculate value-to-weight ratios for all items\n    value_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_ratio1 + value_ratio2\n\n    # Flip items with low combined ratio (potential for improvement)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_item = np.random.choice(flip_candidates)\n        new_solution[flip_item] = 0\n\n    # Add an item with high combined ratio if feasible\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    add_candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(add_candidates) > 0:\n        add_item = np.random.choice(add_candidates)\n        new_solution[add_item] = 1\n\n    # Ensure feasibility (fallback if infeasible)\n    while np.sum(weight_lst * new_solution) > capacity:\n        remove_candidates = np.where(new_solution == 1)[0]\n        if len(remove_candidates) == 0:\n            break  # No items left to remove\n        remove_item = np.random.choice(remove_candidates)\n        new_solution[remove_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.49229249942286624,
            2.5825448632240295
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by value ratios)\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        # Calculate normalized value ratios to prioritize solutions with balanced improvement potential\n        ratio1 = val1 / (total_weight + 1e-6)\n        ratio2 = val2 / (total_weight + 1e-6)\n        candidates.append((sol, ratio1 + ratio2))\n\n    if not candidates:\n        # Fallback: select a random solution if no candidates found\n        return archive[np.random.randint(len(archive))][0].copy()\n\n    # Select the candidate with the highest combined ratio (promising for improvement)\n    selected_sol, _ = max(candidates, key=lambda x: x[1])\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search: flip items based on value-to-weight ratios and randomness\n    flip_indices = np.where(new_solution == 1)[0]\n    if len(flip_indices) == 0:\n        # If no items are selected, randomly add one\n        candidate_indices = np.where(weight_lst <= capacity)[0]\n        if len(candidate_indices) > 0:\n            new_solution[np.random.choice(candidate_indices)] = 1\n        return new_solution\n\n    # Calculate value-to-weight ratios for all items\n    value_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_ratio1 + value_ratio2\n\n    # Flip items with low combined ratio (potential for improvement)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_item = np.random.choice(flip_candidates)\n        new_solution[flip_item] = 0\n\n    # Add an item with high combined ratio if feasible\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    add_candidates = np.where((weight_lst <= remaining_capacity) & (new_solution == 0))[0]\n    if len(add_candidates) > 0:\n        add_item = np.random.choice(add_candidates)\n        new_solution[add_item] = 1\n\n    # Ensure feasibility (fallback if infeasible)\n    while np.sum(weight_lst * new_solution) > capacity:\n        remove_candidates = np.where(new_solution == 1)[0]\n        if len(remove_candidates) == 0:\n            break  # No items left to remove\n        remove_item = np.random.choice(remove_candidates)\n        new_solution[remove_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 192,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of objective values and solution diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their marginal contribution)\n    # 2. Apply a greedy improvement step for one objective while maintaining feasibility\n    # 3. Randomly swap items between the two objectives to balance improvement\n\n    # Step 1: Random flip with marginal contribution probability\n    n_items = len(weight_lst)\n    for i in range(n_items):\n        if random.random() < 0.3:  # 30% chance to consider flipping\n            if new_solution[i] == 1:\n                # If item is in solution, consider removing it\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If item is not in solution, consider adding it\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Greedy improvement for one objective\n    if random.random() < 0.5:  # 50% chance to do greedy improvement\n        objective_to_improve = random.choice([0, 1])  # 0 for value1, 1 for value2\n\n        if objective_to_improve == 0:\n            # Greedy improvement for value1\n            for i in range(n_items):\n                if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    # Check if adding this item improves value1\n                    if value1_lst[i] > 0:  # Only consider positive contributions\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n        else:\n            # Greedy improvement for value2\n            for i in range(n_items):\n                if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    # Check if adding this item improves value2\n                    if value2_lst[i] > 0:  # Only consider positive contributions\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Step 3: Random swap between objectives to balance improvement\n    if random.random() < 0.4:  # 40% chance to do random swap\n        for i in range(n_items):\n            if new_solution[i] == 1 and random.random() < 0.2:  # 20% chance to consider swapping\n                # Find an item not in solution to swap with\n                candidates = [j for j in range(n_items) if new_solution[j] == 0 and\n                            (current_weight - weight_lst[i] + weight_lst[j]) <= capacity]\n\n                if candidates:\n                    j = random.choice(candidates)\n                    # Swap items i and j\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.37058923662624466,
            6.663856863975525
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of objective values and solution diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their marginal contribution)\n    # 2. Apply a greedy improvement step for one objective while maintaining feasibility\n    # 3. Randomly swap items between the two objectives to balance improvement\n\n    # Step 1: Random flip with marginal contribution probability\n    n_items = len(weight_lst)\n    for i in range(n_items):\n        if random.random() < 0.3:  # 30% chance to consider flipping\n            if new_solution[i] == 1:\n                # If item is in solution, consider removing it\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # If item is not in solution, consider adding it\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Step 2: Greedy improvement for one objective\n    if random.random() < 0.5:  # 50% chance to do greedy improvement\n        objective_to_improve = random.choice([0, 1])  # 0 for value1, 1 for value2\n\n        if objective_to_improve == 0:\n            # Greedy improvement for value1\n            for i in range(n_items):\n                if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    # Check if adding this item improves value1\n                    if value1_lst[i] > 0:  # Only consider positive contributions\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n        else:\n            # Greedy improvement for value2\n            for i in range(n_items):\n                if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    # Check if adding this item improves value2\n                    if value2_lst[i] > 0:  # Only consider positive contributions\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n\n    # Step 3: Random swap between objectives to balance improvement\n    if random.random() < 0.4:  # 40% chance to do random swap\n        for i in range(n_items):\n            if new_solution[i] == 1 and random.random() < 0.2:  # 20% chance to consider swapping\n                # Find an item not in solution to swap with\n                candidates = [j for j in range(n_items) if new_solution[j] == 0 and\n                            (current_weight - weight_lst[i] + weight_lst[j]) <= capacity]\n\n                if candidates:\n                    j = random.choice(candidates)\n                    # Swap items i and j\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 193,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a probability weighted by its objective values\n    objectives = np.array([obj for _, obj in archive])\n    total_value1 = objectives[:, 0].sum()\n    total_value2 = objectives[:, 1].sum()\n\n    # Normalize objectives to create a selection probability distribution\n    if total_value1 == 0 or total_value2 == 0:\n        probs = np.ones(len(archive)) / len(archive)\n    else:\n        normalized_value1 = objectives[:, 0] / total_value1\n        normalized_value2 = objectives[:, 1] / total_value2\n        probs = (normalized_value1 + normalized_value2) / 2  # Average normalized values\n\n    # Select a base solution with weighted probability\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    # Flip items in order of highest combined ratio, ensuring feasibility\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flips to escape local optima\n    for _ in range(min(3, n_items // 2)):  # Limit random flips to avoid excessive changes\n        idx = np.random.choice(n_items)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.6034462423278132,
            2.9505871534347534
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a probability weighted by its objective values\n    objectives = np.array([obj for _, obj in archive])\n    total_value1 = objectives[:, 0].sum()\n    total_value2 = objectives[:, 1].sum()\n\n    # Normalize objectives to create a selection probability distribution\n    if total_value1 == 0 or total_value2 == 0:\n        probs = np.ones(len(archive)) / len(archive)\n    else:\n        normalized_value1 = objectives[:, 0] / total_value1\n        normalized_value2 = objectives[:, 1] / total_value2\n        probs = (normalized_value1 + normalized_value2) / 2  # Average normalized values\n\n    # Select a base solution with weighted probability\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n\n    # Hybrid local search: flip items based on value-to-weight ratio and randomness\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate value-to-weight ratios for both objectives\n    ratio1 = value1_lst / weight_lst\n    ratio2 = value2_lst / weight_lst\n\n    # Combine ratios and sort by combined score\n    combined_ratio = ratio1 + ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]  # Descending order\n\n    # Flip items in order of highest combined ratio, ensuring feasibility\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flips to escape local optima\n    for _ in range(min(3, n_items // 2)):  # Limit random flips to avoid excessive changes\n        idx = np.random.choice(n_items)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 194,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with higher potential for improvement (lower density or higher marginal value)\n    densities = [np.sum(value1_lst[s[0]] + value2_lst[s[0]]) / np.sum(weight_lst[s[0]]) for s in archive]\n    weights = [1 / (d + 1e-6) for d in densities]  # Higher weight for lower density\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate neighbor by flipping items with high marginal value\n    new_solution = base_solution.copy()\n    candidate_items = np.where(base_solution == 0)[0]  # Items not in the solution\n    if len(candidate_items) > 0:\n        # Weighted random selection based on marginal value\n        marginal_values = (value1_lst[candidate_items] + value2_lst[candidate_items]) / (weight_lst[candidate_items] + 1e-6)\n        weights = marginal_values / np.sum(marginal_values)\n        selected_item = random.choices(candidate_items, weights=weights, k=1)[0]\n\n        # Check if adding the item keeps the solution feasible\n        if current_weight + weight_lst[selected_item] <= capacity:\n            new_solution[selected_item] = 1\n\n    # Additional local search: remove items with lowest marginal value\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_values = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        min_idx = np.argmin(marginal_values)\n        if len(included_items) > 1:  # Ensure at least one item remains\n            new_solution[included_items[min_idx]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9454196417605067,
            2.845672070980072
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with higher potential for improvement (lower density or higher marginal value)\n    densities = [np.sum(value1_lst[s[0]] + value2_lst[s[0]]) / np.sum(weight_lst[s[0]]) for s in archive]\n    weights = [1 / (d + 1e-6) for d in densities]  # Higher weight for lower density\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate neighbor by flipping items with high marginal value\n    new_solution = base_solution.copy()\n    candidate_items = np.where(base_solution == 0)[0]  # Items not in the solution\n    if len(candidate_items) > 0:\n        # Weighted random selection based on marginal value\n        marginal_values = (value1_lst[candidate_items] + value2_lst[candidate_items]) / (weight_lst[candidate_items] + 1e-6)\n        weights = marginal_values / np.sum(marginal_values)\n        selected_item = random.choices(candidate_items, weights=weights, k=1)[0]\n\n        # Check if adding the item keeps the solution feasible\n        if current_weight + weight_lst[selected_item] <= capacity:\n            new_solution[selected_item] = 1\n\n    # Additional local search: remove items with lowest marginal value\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        marginal_values = (value1_lst[included_items] + value2_lst[included_items]) / (weight_lst[included_items] + 1e-6)\n        min_idx = np.argmin(marginal_values)\n        if len(included_items) > 1:  # Ensure at least one item remains\n            new_solution[included_items[min_idx]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 195,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Normalize objectives to avoid bias\n    max_value1 = max(obj[0] for _, obj in archive) if any(archive) else 1.0\n    max_value2 = max(obj[1] for _, obj in archive) if any(archive) else 1.0\n\n    # Calculate normalized scores and select top candidates\n    candidates = []\n    for sol, obj in archive:\n        normalized_score = (obj[0] / max_value1) + (obj[1] / max_value2)\n        candidates.append((sol, normalized_score))\n\n    # Sort by normalized score and pick top 10% or at least 1\n    candidates.sort(key=lambda x: -x[1])\n    top_n = max(1, len(candidates) // 10)\n    selected = random.choice(candidates[:top_n])[0].copy()\n\n    # Hybrid local search strategy\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Randomly flip items to improve both objectives\n    for _ in range(3):  # Number of attempts\n        # Identify items to potentially flip\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        # Strategy 1a: Flip a random included item if possible\n        if len(included) > 0:\n            flip_idx = random.choice(included)\n            new_weight = current_weight - weight_lst[flip_idx]\n            if new_weight >= 0:\n                new_solution[flip_idx] = 0\n                current_weight = new_weight\n\n        # Strategy 1b: Flip a random excluded item if possible\n        if len(excluded) > 0:\n            flip_idx = random.choice(excluded)\n            new_weight = current_weight + weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight = new_weight\n\n    # Strategy 2: Focus on improving the weaker objective\n    obj1, obj2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n    if obj1 < obj2:\n        # Improve objective 1 by adding high-value1 items\n        excluded = np.where(new_solution == 0)[0]\n        sorted_items = sorted(excluded, key=lambda x: -value1_lst[x])\n        for idx in sorted_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n    else:\n        # Improve objective 2 by adding high-value2 items\n        excluded = np.where(new_solution == 0)[0]\n        sorted_items = sorted(excluded, key=lambda x: -value2_lst[x])\n        for idx in sorted_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.332449997734569,
            3.099229007959366
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Normalize objectives to avoid bias\n    max_value1 = max(obj[0] for _, obj in archive) if any(archive) else 1.0\n    max_value2 = max(obj[1] for _, obj in archive) if any(archive) else 1.0\n\n    # Calculate normalized scores and select top candidates\n    candidates = []\n    for sol, obj in archive:\n        normalized_score = (obj[0] / max_value1) + (obj[1] / max_value2)\n        candidates.append((sol, normalized_score))\n\n    # Sort by normalized score and pick top 10% or at least 1\n    candidates.sort(key=lambda x: -x[1])\n    top_n = max(1, len(candidates) // 10)\n    selected = random.choice(candidates[:top_n])[0].copy()\n\n    # Hybrid local search strategy\n    new_solution = selected.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Randomly flip items to improve both objectives\n    for _ in range(3):  # Number of attempts\n        # Identify items to potentially flip\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        # Strategy 1a: Flip a random included item if possible\n        if len(included) > 0:\n            flip_idx = random.choice(included)\n            new_weight = current_weight - weight_lst[flip_idx]\n            if new_weight >= 0:\n                new_solution[flip_idx] = 0\n                current_weight = new_weight\n\n        # Strategy 1b: Flip a random excluded item if possible\n        if len(excluded) > 0:\n            flip_idx = random.choice(excluded)\n            new_weight = current_weight + weight_lst[flip_idx]\n            if new_weight <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight = new_weight\n\n    # Strategy 2: Focus on improving the weaker objective\n    obj1, obj2 = np.sum(value1_lst * new_solution), np.sum(value2_lst * new_solution)\n    if obj1 < obj2:\n        # Improve objective 1 by adding high-value1 items\n        excluded = np.where(new_solution == 0)[0]\n        sorted_items = sorted(excluded, key=lambda x: -value1_lst[x])\n        for idx in sorted_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n    else:\n        # Improve objective 2 by adding high-value2 items\n        excluded = np.where(new_solution == 0)[0]\n        sorted_items = sorted(excluded, key=lambda x: -value2_lst[x])\n        for idx in sorted_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 196,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate dominance counts for each solution in the archive\n        dominance_counts = []\n        for i, (sol_i, obj_i) in enumerate(archive):\n            count = 0\n            for j, (sol_j, obj_j) in enumerate(archive):\n                if i != j:\n                    if (obj_i[0] >= obj_j[0] and obj_i[1] > obj_j[1]) or (obj_i[0] > obj_j[0] and obj_i[1] >= obj_j[1]):\n                        count += 1\n            dominance_counts.append(count)\n\n        # Select a solution with probability inversely proportional to its dominance count\n        probabilities = [1.0 / (1 + count) for count in dominance_counts]\n        total_prob = sum(probabilities)\n        probabilities = [p / total_prob for p in probabilities]\n        selected_index = np.random.choice(len(archive), p=probabilities)\n        base_solution = archive[selected_index][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Novel local search operator: Hybrid of random flip and objective-guided flip\n    # First, perform a random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Then, perform an objective-guided flip to improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for each item not in the solution\n    marginal_value1 = value1_lst - np.sum(value1_lst * new_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * new_solution)\n    marginal_ratio1 = marginal_value1 / weight_lst\n    marginal_ratio2 = marginal_value2 / weight_lst\n\n    # Combine both objectives into a single score\n    combined_score = marginal_value1 + marginal_value2\n\n    # Select items to flip based on combined score, ensuring feasibility\n    feasible_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(feasible_indices) > 0:\n        feasible_scores = combined_score[feasible_indices]\n        top_indices = feasible_indices[np.argsort(feasible_scores)[-min(2, len(feasible_indices)):]]\n        for idx in top_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3605742253827487,
            1.563462108373642
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate dominance counts for each solution in the archive\n        dominance_counts = []\n        for i, (sol_i, obj_i) in enumerate(archive):\n            count = 0\n            for j, (sol_j, obj_j) in enumerate(archive):\n                if i != j:\n                    if (obj_i[0] >= obj_j[0] and obj_i[1] > obj_j[1]) or (obj_i[0] > obj_j[0] and obj_i[1] >= obj_j[1]):\n                        count += 1\n            dominance_counts.append(count)\n\n        # Select a solution with probability inversely proportional to its dominance count\n        probabilities = [1.0 / (1 + count) for count in dominance_counts]\n        total_prob = sum(probabilities)\n        probabilities = [p / total_prob for p in probabilities]\n        selected_index = np.random.choice(len(archive), p=probabilities)\n        base_solution = archive[selected_index][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Novel local search operator: Hybrid of random flip and objective-guided flip\n    # First, perform a random flip of a subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Then, perform an objective-guided flip to improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for each item not in the solution\n    marginal_value1 = value1_lst - np.sum(value1_lst * new_solution)\n    marginal_value2 = value2_lst - np.sum(value2_lst * new_solution)\n    marginal_ratio1 = marginal_value1 / weight_lst\n    marginal_ratio2 = marginal_value2 / weight_lst\n\n    # Combine both objectives into a single score\n    combined_score = marginal_value1 + marginal_value2\n\n    # Select items to flip based on combined score, ensuring feasibility\n    feasible_indices = np.where((new_solution == 0) & (weight_lst <= remaining_capacity))[0]\n    if len(feasible_indices) > 0:\n        feasible_scores = combined_score[feasible_indices]\n        top_indices = feasible_indices[np.argsort(feasible_scores)[-min(2, len(feasible_indices)):]]\n        for idx in top_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 197,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully dominated)\n    candidates = [sol for sol, _ in archive if np.sum(sol) > 0 and np.sum(sol) < len(sol)]\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random flips with value-based selection\n    n_items = len(base_solution)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Randomly select a subset of items to flip\n    flip_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional value-based improvement: add items with high marginal value\n    available_items = np.where(new_solution == 0)[0]\n    for idx in available_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Add item if it improves both objectives\n            if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4127438916821019,
            5.3149765729904175
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully dominated)\n    candidates = [sol for sol, _ in archive if np.sum(sol) > 0 and np.sum(sol) < len(sol)]\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random flips with value-based selection\n    n_items = len(base_solution)\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Randomly select a subset of items to flip\n    flip_indices = np.random.choice(n_items, size=min(5, n_items), replace=False)\n\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional value-based improvement: add items with high marginal value\n    available_items = np.where(new_solution == 0)[0]\n    for idx in available_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Add item if it improves both objectives\n            if (value1_lst[idx] > 0) and (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 198,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Step 1: Select a promising solution with higher potential for improvement\n    # We select solutions that are not on the extreme fronts in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    mean_obj = np.mean(objectives, axis=0)\n    distances = np.linalg.norm(objectives - mean_obj, axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2a: Swap operator - try to swap two items\n    if n_items >= 2:\n        # Find candidate items to swap (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select a random item to remove and a random item to add\n            remove_idx = random.choice(in_items)\n            add_idx = random.choice(out_items)\n\n            # Calculate potential new weight\n            new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n            # If feasible, perform the swap\n            if new_weight <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                return new_solution\n\n    # Step 2b: Flip operator - try to flip a single bit if swap didn't work\n    if n_items >= 1:\n        # Calculate marginal gains for each item\n        marginal_gains1 = value1_lst - value1_lst * new_solution\n        marginal_gains2 = value2_lst - value2_lst * new_solution\n        marginal_gains = marginal_gains1 + marginal_gains2  # Combined marginal gain\n\n        # Prioritize items that are:\n        # 1. Currently not in the solution (marginal gain positive)\n        # 2. Have higher marginal gain\n        candidates = np.where((marginal_gains > 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n        if len(candidates) > 0:\n            # Select the item with highest marginal gain\n            best_candidate = candidates[np.argmax(marginal_gains[candidates])]\n            new_solution[best_candidate] = 1\n            return new_solution\n\n        # If no positive marginal gain, try removing the worst item\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Select the item with lowest marginal gain (most negative)\n            worst_candidate = candidates[np.argmin(marginal_gains[candidates])]\n            new_solution[worst_candidate] = 0\n            return new_solution\n\n    # If no improvement found, return the original solution\n    return base_solution\n\n",
        "score": [
            -0.745636431469645,
            1.4107268452644348
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros(len(weight_lst), dtype=int)\n\n    # Step 1: Select a promising solution with higher potential for improvement\n    # We select solutions that are not on the extreme fronts in both objectives\n    objectives = np.array([obj for _, obj in archive])\n    mean_obj = np.mean(objectives, axis=0)\n    distances = np.linalg.norm(objectives - mean_obj, axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2a: Swap operator - try to swap two items\n    if n_items >= 2:\n        # Find candidate items to swap (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select a random item to remove and a random item to add\n            remove_idx = random.choice(in_items)\n            add_idx = random.choice(out_items)\n\n            # Calculate potential new weight\n            new_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n\n            # If feasible, perform the swap\n            if new_weight <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n                return new_solution\n\n    # Step 2b: Flip operator - try to flip a single bit if swap didn't work\n    if n_items >= 1:\n        # Calculate marginal gains for each item\n        marginal_gains1 = value1_lst - value1_lst * new_solution\n        marginal_gains2 = value2_lst - value2_lst * new_solution\n        marginal_gains = marginal_gains1 + marginal_gains2  # Combined marginal gain\n\n        # Prioritize items that are:\n        # 1. Currently not in the solution (marginal gain positive)\n        # 2. Have higher marginal gain\n        candidates = np.where((marginal_gains > 0) & (weight_lst <= (capacity - current_weight)))[0]\n\n        if len(candidates) > 0:\n            # Select the item with highest marginal gain\n            best_candidate = candidates[np.argmax(marginal_gains[candidates])]\n            new_solution[best_candidate] = 1\n            return new_solution\n\n        # If no positive marginal gain, try removing the worst item\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Select the item with lowest marginal gain (most negative)\n            worst_candidate = candidates[np.argmin(marginal_gains[candidates])]\n            new_solution[worst_candidate] = 0\n            return new_solution\n\n    # If no improvement found, return the original solution\n    return base_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 199,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Prefer solutions with significant room for improvement\n            candidates.append((sol, obj))\n\n    if not candidates:\n        # If no candidates found, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest combined potential (e.g., highest sum of normalized objectives)\n        base_solution = max(candidates, key=lambda x: x[1][0] + x[1][1])[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items to escape local optima\n    n_items = len(new_solution)\n    swap_indices = random.sample(range(n_items), min(3, n_items))  # Swap up to 3 items\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with the highest marginal benefit for the most underperforming objective\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal benefits\n    marginal_benefits1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n    marginal_benefits2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n\n    # Combine benefits based on which objective is underperforming\n    if np.sum(value1_lst * new_solution) < np.sum(value2_lst * new_solution):\n        combined_benefits = marginal_benefits1\n    else:\n        combined_benefits = marginal_benefits2\n\n    # Flip items with the highest marginal benefits that fit in the knapsack\n    for idx in np.argsort(combined_benefits)[::-1]:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1 - new_solution[idx]\n            remaining_capacity -= weight_lst[idx]\n            if remaining_capacity <= 0:\n                break\n\n    # 3. Local fine-tuning: Flip items with negative marginal benefit if they improve the other objective\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            if marginal_benefits1[idx] < 0 and marginal_benefits2[idx] > 0:\n                new_solution[idx] = 0\n            elif marginal_benefits2[idx] < 0 and marginal_benefits1[idx] > 0:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            idx = random.choice(np.where(new_solution == 1)[0])\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3081419066172343,
            3.322502613067627
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Prefer solutions with significant room for improvement\n            candidates.append((sol, obj))\n\n    if not candidates:\n        # If no candidates found, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest combined potential (e.g., highest sum of normalized objectives)\n        base_solution = max(candidates, key=lambda x: x[1][0] + x[1][1])[0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a subset of items to escape local optima\n    n_items = len(new_solution)\n    swap_indices = random.sample(range(n_items), min(3, n_items))  # Swap up to 3 items\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Flip items with the highest marginal benefit for the most underperforming objective\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal benefits\n    marginal_benefits1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n    marginal_benefits2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n\n    # Combine benefits based on which objective is underperforming\n    if np.sum(value1_lst * new_solution) < np.sum(value2_lst * new_solution):\n        combined_benefits = marginal_benefits1\n    else:\n        combined_benefits = marginal_benefits2\n\n    # Flip items with the highest marginal benefits that fit in the knapsack\n    for idx in np.argsort(combined_benefits)[::-1]:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1 - new_solution[idx]\n            remaining_capacity -= weight_lst[idx]\n            if remaining_capacity <= 0:\n                break\n\n    # 3. Local fine-tuning: Flip items with negative marginal benefit if they improve the other objective\n    for idx in range(n_items):\n        if new_solution[idx] == 1:\n            if marginal_benefits1[idx] < 0 and marginal_benefits2[idx] > 0:\n                new_solution[idx] = 0\n            elif marginal_benefits2[idx] < 0 and marginal_benefits1[idx] > 0:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            idx = random.choice(np.where(new_solution == 1)[0])\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 200,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_solution, (current_value1, current_value2) = max(\n        archive,\n        key=lambda x: np.sum(x[0])  # Prefer solutions with more items (higher potential)\n    )\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap items with high marginal value\n    # 2. If feasible, keep the swap; otherwise, try another item\n\n    # Calculate marginal values (value per unit weight)\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Combine marginal values for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Sort items by combined marginal value (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Try to swap top items with lower-value items\n    for i in range(min(5, len(sorted_indices))):  # Limit to top 5 items for efficiency\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 1:\n            # Try to remove this item\n            temp_solution = new_solution.copy()\n            temp_solution[item_idx] = 0\n            temp_weight = current_weight - weight_lst[item_idx]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # If no removal helped, try adding items with high marginal value\n    if new_solution is selected_solution:\n        for i in range(len(sorted_indices)):\n            item_idx = sorted_indices[i]\n            if new_solution[item_idx] == 0:\n                temp_weight = current_weight + weight_lst[item_idx]\n                if temp_weight <= capacity:\n                    new_solution[item_idx] = 1\n                    current_weight = temp_weight\n                    break\n\n    # If still no change, perform a random swap\n    if new_solution is selected_solution:\n        # Find all items that can be swapped (included or excluded)\n        candidates = np.where((new_solution == 1) | (new_solution == 0))[0]\n        if len(candidates) > 0:\n            item_idx = np.random.choice(candidates)\n            new_solution[item_idx] = 1 - new_solution[item_idx]  # Flip the bit\n            # Ensure feasibility by checking weight\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[item_idx] = 1 - new_solution[item_idx]  # Revert if infeasible\n\n    return new_solution\n\n",
        "score": [
            -0.8718183859277897,
            1.5369272828102112
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    selected_solution, (current_value1, current_value2) = max(\n        archive,\n        key=lambda x: np.sum(x[0])  # Prefer solutions with more items (higher potential)\n    )\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap items with high marginal value\n    # 2. If feasible, keep the swap; otherwise, try another item\n\n    # Calculate marginal values (value per unit weight)\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Combine marginal values for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Sort items by combined marginal value (descending)\n    sorted_indices = np.argsort(-combined_marginal)\n\n    # Try to swap top items with lower-value items\n    for i in range(min(5, len(sorted_indices))):  # Limit to top 5 items for efficiency\n        item_idx = sorted_indices[i]\n        if new_solution[item_idx] == 1:\n            # Try to remove this item\n            temp_solution = new_solution.copy()\n            temp_solution[item_idx] = 0\n            temp_weight = current_weight - weight_lst[item_idx]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n                break\n\n    # If no removal helped, try adding items with high marginal value\n    if new_solution is selected_solution:\n        for i in range(len(sorted_indices)):\n            item_idx = sorted_indices[i]\n            if new_solution[item_idx] == 0:\n                temp_weight = current_weight + weight_lst[item_idx]\n                if temp_weight <= capacity:\n                    new_solution[item_idx] = 1\n                    current_weight = temp_weight\n                    break\n\n    # If still no change, perform a random swap\n    if new_solution is selected_solution:\n        # Find all items that can be swapped (included or excluded)\n        candidates = np.where((new_solution == 1) | (new_solution == 0))[0]\n        if len(candidates) > 0:\n            item_idx = np.random.choice(candidates)\n            new_solution[item_idx] = 1 - new_solution[item_idx]  # Flip the bit\n            # Ensure feasibility by checking weight\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[item_idx] = 1 - new_solution[item_idx]  # Revert if infeasible\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 201,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the boundary (not all items selected or all excluded)\n    candidates = []\n    for sol, obj in archive:\n        if 0 < np.sum(sol) < len(sol):\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if none are in the middle\n\n    # Select a random candidate with probability inversely proportional to its dominance\n    # (Solutions with higher diversity are more likely to be selected)\n    weights = [1.0 / (1 + np.sum(sol)) for sol, obj in candidates]\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution = candidates[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Strategy 1: Flip a random item (if feasible)\n    if random.random() < 0.3:\n        item_to_flip = random.randint(0, n_items - 1)\n        if new_solution[item_to_flip] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[item_to_flip] <= capacity:\n                new_solution[item_to_flip] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[item_to_flip] <= capacity:\n                new_solution[item_to_flip] = 1\n\n    # Strategy 2: Swap two items (if feasible)\n    elif random.random() < 0.6:\n        item1, item2 = random.sample(range(n_items), 2)\n        if new_solution[item1] != new_solution[item2]:\n            # Calculate new weight after swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            delta_weight = (weight_lst[item2] - weight_lst[item1]) if new_solution[item1] == 1 else (weight_lst[item1] - weight_lst[item2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    # Strategy 3: Objective-biased flip (flip items with high marginal value)\n    else:\n        # Calculate marginal values for all items\n        marginal_value1 = value1_lst - np.sum(value1_lst[new_solution == 1]) / np.sum(new_solution)\n        marginal_value2 = value2_lst - np.sum(value2_lst[new_solution == 1]) / np.sum(new_solution)\n\n        # Select items with highest marginal value in either objective\n        top_items = np.argsort(-marginal_value1 - marginal_value2)[:max(1, n_items // 10)]\n\n        for item in top_items:\n            if new_solution[item] == 1:\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    break\n            else:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.41936525452535905,
            8.365101426839828
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the boundary (not all items selected or all excluded)\n    candidates = []\n    for sol, obj in archive:\n        if 0 < np.sum(sol) < len(sol):\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if none are in the middle\n\n    # Select a random candidate with probability inversely proportional to its dominance\n    # (Solutions with higher diversity are more likely to be selected)\n    weights = [1.0 / (1 + np.sum(sol)) for sol, obj in candidates]\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution = candidates[selected_idx][0].copy()\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Strategy 1: Flip a random item (if feasible)\n    if random.random() < 0.3:\n        item_to_flip = random.randint(0, n_items - 1)\n        if new_solution[item_to_flip] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[item_to_flip] <= capacity:\n                new_solution[item_to_flip] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[item_to_flip] <= capacity:\n                new_solution[item_to_flip] = 1\n\n    # Strategy 2: Swap two items (if feasible)\n    elif random.random() < 0.6:\n        item1, item2 = random.sample(range(n_items), 2)\n        if new_solution[item1] != new_solution[item2]:\n            # Calculate new weight after swap\n            current_weight = np.sum(weight_lst[new_solution == 1])\n            delta_weight = (weight_lst[item2] - weight_lst[item1]) if new_solution[item1] == 1 else (weight_lst[item1] - weight_lst[item2])\n            if current_weight + delta_weight <= capacity:\n                new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    # Strategy 3: Objective-biased flip (flip items with high marginal value)\n    else:\n        # Calculate marginal values for all items\n        marginal_value1 = value1_lst - np.sum(value1_lst[new_solution == 1]) / np.sum(new_solution)\n        marginal_value2 = value2_lst - np.sum(value2_lst[new_solution == 1]) / np.sum(new_solution)\n\n        # Select items with highest marginal value in either objective\n        top_items = np.argsort(-marginal_value1 - marginal_value2)[:max(1, n_items // 10)]\n\n        for item in top_items:\n            if new_solution[item] == 1:\n                if np.sum(weight_lst[new_solution == 1]) - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    break\n            else:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 202,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot generate neighbor solution.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    # Here, we select a solution that is not already optimal in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in the archive.\")\n\n    # Randomly select a candidate with a bias towards solutions with higher total value\n    # This helps in exploring promising regions of the solution space\n    weights = [obj[0] + obj[1] for sol, obj in candidates]\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution = candidates[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Randomly flip a subset of bits (items) to create diversity\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0 and np.sum(new_solution) > 0:\n            # Select items to remove based on the least contribution to both objectives\n            contributions = (value1_lst * new_solution + value2_lst * new_solution) / (weight_lst + 1e-6)\n            remove_idx = np.argmin(contributions)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n            else:\n                break\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate the marginal gain for each item not in the solution\n        marginal_gain = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by marginal gain in descending order\n        sorted_candidates = sorted(candidates, key=lambda x: -marginal_gain[x])\n\n        for idx in sorted_candidates:\n            if weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.33579745083398177,
            4.333144843578339
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty. Cannot generate neighbor solution.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    # Here, we select a solution that is not already optimal in both objectives\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append((sol, obj))\n\n    if not candidates:\n        raise ValueError(\"No feasible solutions in the archive.\")\n\n    # Randomly select a candidate with a bias towards solutions with higher total value\n    # This helps in exploring promising regions of the solution space\n    weights = [obj[0] + obj[1] for sol, obj in candidates]\n    selected_idx = random.choices(range(len(candidates)), weights=weights, k=1)[0]\n    base_solution = candidates[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Randomly flip a subset of bits (items) to create diversity\n    num_flips = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(new_solution)), num_flips)\n\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Ensure feasibility after random flips\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0 and np.sum(new_solution) > 0:\n            # Select items to remove based on the least contribution to both objectives\n            contributions = (value1_lst * new_solution + value2_lst * new_solution) / (weight_lst + 1e-6)\n            remove_idx = np.argmin(contributions)\n            if new_solution[remove_idx] == 1:\n                new_solution[remove_idx] = 0\n                excess_weight -= weight_lst[remove_idx]\n            else:\n                break\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate the marginal gain for each item not in the solution\n        marginal_gain = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by marginal gain in descending order\n        sorted_candidates = sorted(candidates, key=lambda x: -marginal_gain[x])\n\n        for idx in sorted_candidates:\n            if weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 203,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the Pareto front or have high diversity\n    selected_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Example: select a solution with high density\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation - flip a small number of bits\n    num_flips = min(3, len(new_solution))  # Flip up to 3 bits\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            # Find items to remove (prioritize low value items)\n            remove_candidates = np.where(new_solution == 1)[0]\n            if len(remove_candidates) == 0:\n                break\n            # Remove the item with the smallest combined value\n            values = value1_lst[remove_candidates] + value2_lst[remove_candidates]\n            remove_idx = remove_candidates[np.argmin(values)]\n            new_solution[remove_idx] = 0\n            excess = np.sum(weight_lst * new_solution) - capacity\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_indices = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_indices]\n        feasible_indices = candidate_indices[candidate_weights <= remaining_capacity]\n\n        if len(feasible_indices) > 0:\n            # Evaluate candidates based on a combined objective (e.g., weighted sum)\n            values1 = value1_lst[feasible_indices]\n            values2 = value2_lst[feasible_indices]\n            # Use a simple weighted sum for selection (could be more sophisticated)\n            combined_values = values1 + values2\n            best_idx = feasible_indices[np.argmax(combined_values)]\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3470159347070586,
            2.1718498170375824
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    # Prioritize solutions that are not too close to the Pareto front or have high diversity\n    selected_solution, _ = max(archive, key=lambda x: np.sum(x[0]) / len(x[0]))  # Example: select a solution with high density\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: Random perturbation followed by greedy improvement\n    # Step 1: Random perturbation - flip a small number of bits\n    num_flips = min(3, len(new_solution))  # Flip up to 3 bits\n    flip_indices = np.random.choice(len(new_solution), size=num_flips, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        while excess > 0:\n            # Find items to remove (prioritize low value items)\n            remove_candidates = np.where(new_solution == 1)[0]\n            if len(remove_candidates) == 0:\n                break\n            # Remove the item with the smallest combined value\n            values = value1_lst[remove_candidates] + value2_lst[remove_candidates]\n            remove_idx = remove_candidates[np.argmin(values)]\n            new_solution[remove_idx] = 0\n            excess = np.sum(weight_lst * new_solution) - capacity\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_indices = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_indices]\n        feasible_indices = candidate_indices[candidate_weights <= remaining_capacity]\n\n        if len(feasible_indices) > 0:\n            # Evaluate candidates based on a combined objective (e.g., weighted sum)\n            values1 = value1_lst[feasible_indices]\n            values2 = value2_lst[feasible_indices]\n            # Use a simple weighted sum for selection (could be more sophisticated)\n            combined_values = values1 + values2\n            best_idx = feasible_indices[np.argmax(combined_values)]\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 204,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate the potential for improvement: items not in the solution that could be added\n            remaining_weight = capacity - total_weight\n            potential_items = (weight_lst <= remaining_weight) & (sol == 0)\n            potential_val1 = np.sum(value1_lst[potential_items])\n            potential_val2 = np.sum(value2_lst[potential_items])\n            # Items in the solution that could be removed\n            removable_items = sol == 1\n            removable_val1 = np.sum(value1_lst[removable_items])\n            removable_val2 = np.sum(value2_lst[removable_items])\n            # Score based on potential improvement and current objective values\n            score = (potential_val1 + potential_val2) / (1 + removable_val1 + removable_val2)\n            candidates.append((score, sol))\n\n    if not candidates:\n        # Fallback to random selection if no candidates found\n        base_solution = archive[np.random.randint(len(archive))][0].copy()\n    else:\n        # Select the solution with the highest score\n        candidates.sort(key=lambda x: x[0], reverse=True)\n        base_solution = candidates[0][1].copy()\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_weight = capacity - total_weight\n\n    # Strategy 1: Randomly select items to add (if there is remaining weight)\n    if remaining_weight > 0:\n        potential_items = (weight_lst <= remaining_weight) & (new_solution == 0)\n        if np.any(potential_items):\n            # Randomly select a subset of potential items to add\n            num_to_add = min(np.random.randint(1, np.sum(potential_items) + 1), np.sum(potential_items))\n            selected_items = np.random.choice(np.where(potential_items)[0], size=num_to_add, replace=False)\n            new_solution[selected_items] = 1\n\n    # Strategy 2: Randomly select items to remove (to make space for new items)\n    if np.sum(new_solution) > 0:\n        removable_items = new_solution == 1\n        num_to_remove = min(np.random.randint(1, np.sum(removable_items) + 1), np.sum(removable_items))\n        selected_items = np.random.choice(np.where(removable_items)[0], size=num_to_remove, replace=False)\n        new_solution[selected_items] = 0\n\n    # Ensure feasibility (though the above steps should already ensure it)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove the heaviest items until feasible\n        while total_weight > capacity:\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_item = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_item] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.8591596133092637,
            6.913371801376343
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate the potential for improvement: items not in the solution that could be added\n            remaining_weight = capacity - total_weight\n            potential_items = (weight_lst <= remaining_weight) & (sol == 0)\n            potential_val1 = np.sum(value1_lst[potential_items])\n            potential_val2 = np.sum(value2_lst[potential_items])\n            # Items in the solution that could be removed\n            removable_items = sol == 1\n            removable_val1 = np.sum(value1_lst[removable_items])\n            removable_val2 = np.sum(value2_lst[removable_items])\n            # Score based on potential improvement and current objective values\n            score = (potential_val1 + potential_val2) / (1 + removable_val1 + removable_val2)\n            candidates.append((score, sol))\n\n    if not candidates:\n        # Fallback to random selection if no candidates found\n        base_solution = archive[np.random.randint(len(archive))][0].copy()\n    else:\n        # Select the solution with the highest score\n        candidates.sort(key=lambda x: x[0], reverse=True)\n        base_solution = candidates[0][1].copy()\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n    remaining_weight = capacity - total_weight\n\n    # Strategy 1: Randomly select items to add (if there is remaining weight)\n    if remaining_weight > 0:\n        potential_items = (weight_lst <= remaining_weight) & (new_solution == 0)\n        if np.any(potential_items):\n            # Randomly select a subset of potential items to add\n            num_to_add = min(np.random.randint(1, np.sum(potential_items) + 1), np.sum(potential_items))\n            selected_items = np.random.choice(np.where(potential_items)[0], size=num_to_add, replace=False)\n            new_solution[selected_items] = 1\n\n    # Strategy 2: Randomly select items to remove (to make space for new items)\n    if np.sum(new_solution) > 0:\n        removable_items = new_solution == 1\n        num_to_remove = min(np.random.randint(1, np.sum(removable_items) + 1), np.sum(removable_items))\n        selected_items = np.random.choice(np.where(removable_items)[0], size=num_to_remove, replace=False)\n        new_solution[selected_items] = 0\n\n    # Ensure feasibility (though the above steps should already ensure it)\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove the heaviest items until feasible\n        while total_weight > capacity:\n            heavy_items = np.where(new_solution == 1)[0]\n            heaviest_item = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_item] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 205,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., one with high marginal gains)\n    selected = max(archive, key=lambda x: (x[1][0] + x[1][1]) / np.sum(weight_lst[x[0] == 1]) if np.sum(weight_lst[x[0] == 1]) > 0 else 0)\n    base_solution = selected[0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = selected[1][0]\n    current_value2 = selected[1][1]\n\n    # Hybrid local search strategy: combine swap and insertion moves\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly select a subset of items to consider for swap\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    if len(items_in) > 0 and len(items_out) > 0:\n        # Swap one item from the knapsack with one item outside\n        swap_in = random.choice(items_out)\n        swap_out = random.choice(items_in)\n\n        # Check feasibility of swap\n        new_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n        if new_weight <= capacity:\n            new_solution[swap_out] = 0\n            new_solution[swap_in] = 1\n\n    # Step 2: Consider adding items with high marginal gains in either objective\n    for item in items_out:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate marginal gains\n            marginal1 = value1_lst[item]\n            marginal2 = value2_lst[item]\n\n            # If the item provides significant improvement in either objective, add it\n            if marginal1 > 0.1 * current_value1 or marginal2 > 0.1 * current_value2:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Step 3: Randomly remove items to create diversity\n    if random.random() < 0.3 and len(items_in) > 0:\n        remove_item = random.choice(items_in)\n        new_solution[remove_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5884241018340173,
            4.095070153474808
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., one with high marginal gains)\n    selected = max(archive, key=lambda x: (x[1][0] + x[1][1]) / np.sum(weight_lst[x[0] == 1]) if np.sum(weight_lst[x[0] == 1]) > 0 else 0)\n    base_solution = selected[0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = selected[1][0]\n    current_value2 = selected[1][1]\n\n    # Hybrid local search strategy: combine swap and insertion moves\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly select a subset of items to consider for swap\n    items_in = np.where(new_solution == 1)[0]\n    items_out = np.where(new_solution == 0)[0]\n\n    if len(items_in) > 0 and len(items_out) > 0:\n        # Swap one item from the knapsack with one item outside\n        swap_in = random.choice(items_out)\n        swap_out = random.choice(items_in)\n\n        # Check feasibility of swap\n        new_weight = current_weight - weight_lst[swap_out] + weight_lst[swap_in]\n        if new_weight <= capacity:\n            new_solution[swap_out] = 0\n            new_solution[swap_in] = 1\n\n    # Step 2: Consider adding items with high marginal gains in either objective\n    for item in items_out:\n        if current_weight + weight_lst[item] <= capacity:\n            # Calculate marginal gains\n            marginal1 = value1_lst[item]\n            marginal2 = value2_lst[item]\n\n            # If the item provides significant improvement in either objective, add it\n            if marginal1 > 0.1 * current_value1 or marginal2 > 0.1 * current_value2:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Step 3: Randomly remove items to create diversity\n    if random.random() < 0.3 and len(items_in) > 0:\n        remove_item = random.choice(items_in)\n        new_solution[remove_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 206,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    weights = np.array([sum(weight_lst[sol]) for sol, _ in archive])\n    normalized_weights = (weights - min(weights)) / (max(weights) - min(weights) + 1e-10)\n    probabilities = 1 - normalized_weights  # Higher probability for solutions with lower weight\n    probabilities = probabilities / sum(probabilities)  # Normalize to sum to 1\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swaps and random flips\n    n_items = len(weight_lst)\n    current_weight = sum(weight_lst[new_solution == 1])\n\n    # Step 1: Perform a random number of item swaps (items in vs out)\n    for _ in range(random.randint(1, min(5, n_items // 2))):\n        # Select items to swap: one in and one out\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            item_in = random.choice(in_items)\n            item_out = random.choice(out_items)\n\n            # Check if swapping makes the solution feasible\n            if current_weight - weight_lst[item_in] + weight_lst[item_out] <= capacity:\n                new_solution[item_in] = 0\n                new_solution[item_out] = 1\n                current_weight = current_weight - weight_lst[item_in] + weight_lst[item_out]\n\n    # Step 2: Perform random flips with a probability based on item value ratios\n    for i in range(n_items):\n        if random.random() < 0.1:  # 10% chance to consider flipping\n            if new_solution[i] == 1:\n                # Consider removing item if it doesn't significantly affect both objectives\n                if (value1_lst[i] / sum(value1_lst) < 0.1 and\n                    value2_lst[i] / sum(value2_lst) < 0.1):\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Consider adding item if it fits and improves at least one objective\n                if (current_weight + weight_lst[i] <= capacity and\n                    (value1_lst[i] > 0 or value2_lst[i] > 0)):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.39213942585198797,
            6.6868279576301575
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    weights = np.array([sum(weight_lst[sol]) for sol, _ in archive])\n    normalized_weights = (weights - min(weights)) / (max(weights) - min(weights) + 1e-10)\n    probabilities = 1 - normalized_weights  # Higher probability for solutions with lower weight\n    probabilities = probabilities / sum(probabilities)  # Normalize to sum to 1\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of item swaps and random flips\n    n_items = len(weight_lst)\n    current_weight = sum(weight_lst[new_solution == 1])\n\n    # Step 1: Perform a random number of item swaps (items in vs out)\n    for _ in range(random.randint(1, min(5, n_items // 2))):\n        # Select items to swap: one in and one out\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            item_in = random.choice(in_items)\n            item_out = random.choice(out_items)\n\n            # Check if swapping makes the solution feasible\n            if current_weight - weight_lst[item_in] + weight_lst[item_out] <= capacity:\n                new_solution[item_in] = 0\n                new_solution[item_out] = 1\n                current_weight = current_weight - weight_lst[item_in] + weight_lst[item_out]\n\n    # Step 2: Perform random flips with a probability based on item value ratios\n    for i in range(n_items):\n        if random.random() < 0.1:  # 10% chance to consider flipping\n            if new_solution[i] == 1:\n                # Consider removing item if it doesn't significantly affect both objectives\n                if (value1_lst[i] / sum(value1_lst) < 0.1 and\n                    value2_lst[i] / sum(value2_lst) < 0.1):\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Consider adding item if it fits and improves at least one objective\n                if (current_weight + weight_lst[i] <= capacity and\n                    (value1_lst[i] > 0 or value2_lst[i] > 0)):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 207,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution to identify promising ones\n    crowding_distances = []\n    for i, (sol, _) in enumerate(archive):\n        left = archive[i-1][1] if i > 0 else archive[-1][1]\n        right = archive[(i+1) % len(archive)][1] if i < len(archive)-1 else archive[0][1]\n        distance = abs(left[0] - right[0]) + abs(left[1] - right[1])\n        crowding_distances.append(distance)\n\n    # Select solutions with above-average crowding distance (potentially on the Pareto front)\n    avg_distance = np.mean(crowding_distances)\n    candidates = [sol for sol, dist in zip(archive, crowding_distances) if dist >= avg_distance]\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if no candidates\n\n    # Randomly select a candidate solution\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search operator\n    # Strategy: Combine random flip with value-based flip to improve both objectives\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly select a subset of items to flip (1-3 items)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # Try to remove item if it doesn't violate capacity\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n        else:\n            # Try to add item if it fits within capacity\n            if total_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    # Additional: Flip items with highest marginal value for both objectives\n    # Calculate marginal values (value/weight ratio)\n    marginal1 = value1_lst / (weight_lst + 1e-10)  # Add small epsilon to avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by combined marginal value\n    combined_marginal = marginal1 + marginal2\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Flip top 2 items (if they fit)\n    for i in sorted_indices[:2]:\n        if new_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3899800250898286,
            1.2238350212574005
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution to identify promising ones\n    crowding_distances = []\n    for i, (sol, _) in enumerate(archive):\n        left = archive[i-1][1] if i > 0 else archive[-1][1]\n        right = archive[(i+1) % len(archive)][1] if i < len(archive)-1 else archive[0][1]\n        distance = abs(left[0] - right[0]) + abs(left[1] - right[1])\n        crowding_distances.append(distance)\n\n    # Select solutions with above-average crowding distance (potentially on the Pareto front)\n    avg_distance = np.mean(crowding_distances)\n    candidates = [sol for sol, dist in zip(archive, crowding_distances) if dist >= avg_distance]\n\n    if not candidates:\n        candidates = archive  # Fallback to all solutions if no candidates\n\n    # Randomly select a candidate solution\n    base_solution, _ = random.choice(candidates)\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search operator\n    # Strategy: Combine random flip with value-based flip to improve both objectives\n    n_items = len(weight_lst)\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly select a subset of items to flip (1-3 items)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # Try to remove item if it doesn't violate capacity\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n        else:\n            # Try to add item if it fits within capacity\n            if total_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    # Additional: Flip items with highest marginal value for both objectives\n    # Calculate marginal values (value/weight ratio)\n    marginal1 = value1_lst / (weight_lst + 1e-10)  # Add small epsilon to avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by combined marginal value\n    combined_marginal = marginal1 + marginal2\n    sorted_indices = np.argsort(combined_marginal)[::-1]\n\n    # Flip top 2 items (if they fit)\n    for i in sorted_indices[:2]:\n        if new_solution[i] == 0 and total_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n            total_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 208,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of objective values and diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap a subset of items\n    n_items = len(weight_lst)\n    n_swaps = min(3, n_items // 2)  # Limit the number of swaps\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Flip items with high value-to-weight ratios for both objectives\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_weight_ratio1 + value_weight_ratio2\n\n    # Sort items by combined ratio and flip the top 20% with probability\n    sorted_indices = np.argsort(-combined_ratio)\n    n_flip = max(1, int(0.2 * n_items))\n    for idx in sorted_indices[:n_flip]:\n        if random.random() < 0.5:  # 50% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 3: Ensure feasibility by removing excess weight\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items with lowest value-to-weight ratio until feasible\n        sorted_indices = np.argsort(combined_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess_weight > 0:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.44204881351554465,
            1.2432710826396942
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of objective values and diversity\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly swap a subset of items\n    n_items = len(weight_lst)\n    n_swaps = min(3, n_items // 2)  # Limit the number of swaps\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Flip items with high value-to-weight ratios for both objectives\n    value_weight_ratio1 = value1_lst / (weight_lst + 1e-6)\n    value_weight_ratio2 = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = value_weight_ratio1 + value_weight_ratio2\n\n    # Sort items by combined ratio and flip the top 20% with probability\n    sorted_indices = np.argsort(-combined_ratio)\n    n_flip = max(1, int(0.2 * n_items))\n    for idx in sorted_indices[:n_flip]:\n        if random.random() < 0.5:  # 50% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 3: Ensure feasibility by removing excess weight\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items with lowest value-to-weight ratio until feasible\n        sorted_indices = np.argsort(combined_ratio)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess_weight > 0:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 209,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    current_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    current_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    current_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate \"potential\" as a combination of value density and capacity utilization\n    potentials = []\n    for sol, w, v1, v2 in zip(archive_solutions, current_weights, current_values1, current_values2):\n        value_density1 = v1 / (w + 1e-6)\n        value_density2 = v2 / (w + 1e-6)\n        capacity_util = w / capacity\n        potential = (value_density1 + value_density2) * (1 - capacity_util)\n        potentials.append(potential)\n\n    # Select the solution with the highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random item swaps (for diversification)\n    swap_indices = random.sample(range(len(weight_lst)), min(3, len(weight_lst)))\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Value-driven flips (for intensification)\n    # Flip items that improve both objectives when added, or improve the worse objective when removed\n    total_weight = np.sum(weight_lst * new_solution)\n    for idx in range(len(weight_lst)):\n        if new_solution[idx] == 0:\n            if total_weight + weight_lst[idx] <= capacity:\n                # Check if adding this item improves both objectives\n                delta_v1 = value1_lst[idx]\n                delta_v2 = value2_lst[idx]\n                if delta_v1 > 0 and delta_v2 > 0:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n        else:\n            # Check if removing this item doesn't worsen both objectives too much\n            delta_v1 = -value1_lst[idx]\n            delta_v2 = -value2_lst[idx]\n            if not (delta_v1 > 0 and delta_v2 > 0):\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the smallest ratio of (value1 + value2) / weight\n        item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        item_ratios[new_solution == 0] = np.inf\n        remove_idx = np.argmin(item_ratios)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.32493165067726937,
            3.155859887599945
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    archive_solutions = [sol for sol, _ in archive]\n    current_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    current_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    current_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate \"potential\" as a combination of value density and capacity utilization\n    potentials = []\n    for sol, w, v1, v2 in zip(archive_solutions, current_weights, current_values1, current_values2):\n        value_density1 = v1 / (w + 1e-6)\n        value_density2 = v2 / (w + 1e-6)\n        capacity_util = w / capacity\n        potential = (value_density1 + value_density2) * (1 - capacity_util)\n        potentials.append(potential)\n\n    # Select the solution with the highest potential\n    selected_idx = np.argmax(potentials)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Random item swaps (for diversification)\n    swap_indices = random.sample(range(len(weight_lst)), min(3, len(weight_lst)))\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Value-driven flips (for intensification)\n    # Flip items that improve both objectives when added, or improve the worse objective when removed\n    total_weight = np.sum(weight_lst * new_solution)\n    for idx in range(len(weight_lst)):\n        if new_solution[idx] == 0:\n            if total_weight + weight_lst[idx] <= capacity:\n                # Check if adding this item improves both objectives\n                delta_v1 = value1_lst[idx]\n                delta_v2 = value2_lst[idx]\n                if delta_v1 > 0 and delta_v2 > 0:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n        else:\n            # Check if removing this item doesn't worsen both objectives too much\n            delta_v1 = -value1_lst[idx]\n            delta_v2 = -value2_lst[idx]\n            if not (delta_v1 > 0 and delta_v2 > 0):\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the smallest ratio of (value1 + value2) / weight\n        item_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n        item_ratios[new_solution == 0] = np.inf\n        remove_idx = np.argmin(item_ratios)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 210,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (to allow more room for local search)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their value)\n    # 2. Ensure feasibility by limiting flips based on remaining capacity\n\n    # Calculate value-to-weight ratios for each item\n    v1_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    v2_ratio = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = v1_ratio + v2_ratio  # Combined heuristic for both objectives\n\n    # Probability of flipping each item is proportional to its combined value-to-weight ratio\n    flip_probs = combined_ratio / np.sum(combined_ratio)\n    flip_mask = np.random.rand(len(new_solution)) < flip_probs\n\n    # Determine which items can be flipped (either included or excluded)\n    for i in range(len(new_solution)):\n        if flip_mask[i]:\n            if new_solution[i] == 1:\n                # Try to exclude this item\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to include this item\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Additional local search: try to include high-value items not currently in the solution\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Get items not in the solution sorted by combined value-to-weight ratio\n        available_items = np.where(new_solution == 0)[0]\n        sorted_items = available_items[np.argsort(combined_ratio[available_items])[::-1]]\n\n        for i in sorted_items:\n            if weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3746799697420734,
            7.6473380625247955
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    # Here, we prioritize solutions that are not too close to the boundary (to allow more room for local search)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their value)\n    # 2. Ensure feasibility by limiting flips based on remaining capacity\n\n    # Calculate value-to-weight ratios for each item\n    v1_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    v2_ratio = value2_lst / (weight_lst + 1e-10)\n    combined_ratio = v1_ratio + v2_ratio  # Combined heuristic for both objectives\n\n    # Probability of flipping each item is proportional to its combined value-to-weight ratio\n    flip_probs = combined_ratio / np.sum(combined_ratio)\n    flip_mask = np.random.rand(len(new_solution)) < flip_probs\n\n    # Determine which items can be flipped (either included or excluded)\n    for i in range(len(new_solution)):\n        if flip_mask[i]:\n            if new_solution[i] == 1:\n                # Try to exclude this item\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to include this item\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Additional local search: try to include high-value items not currently in the solution\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Get items not in the solution sorted by combined value-to-weight ratio\n        available_items = np.where(new_solution == 0)[0]\n        sorted_items = available_items[np.argsort(combined_ratio[available_items])[::-1]]\n\n        for i in sorted_items:\n            if weight_lst[i] <= remaining_capacity:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 211,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = max(archive, key=lambda x: np.sum(weight_lst[x[0] == 1]) / capacity)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on weight)\n    # 2. Apply a greedy improvement step for one objective\n    # 3. Ensure feasibility\n\n    # Step 1: Random flip with weight-based probability\n    flip_prob = 0.1  # Base flip probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob * (1 - weight_lst[i] / capacity):  # Higher chance to flip lighter items\n            new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Greedy improvement for one objective (alternating between objectives)\n    if random.random() < 0.5:\n        # Improve value1\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n    else:\n        # Improve value2\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Step 3: Ensure feasibility by removing the heaviest items if needed\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        while current_weight > capacity:\n            # Find the heaviest item in the solution\n            heavy_items = np.where(new_solution == 1)[0]\n            if len(heavy_items) == 0:\n                break\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight -= weight_lst[heaviest_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3447276981247827,
            9.903176456689835
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_solution, _ = max(archive, key=lambda x: np.sum(weight_lst[x[0] == 1]) / capacity)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on weight)\n    # 2. Apply a greedy improvement step for one objective\n    # 3. Ensure feasibility\n\n    # Step 1: Random flip with weight-based probability\n    flip_prob = 0.1  # Base flip probability\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob * (1 - weight_lst[i] / capacity):  # Higher chance to flip lighter items\n            new_solution[i] = 1 - new_solution[i]\n\n    # Step 2: Greedy improvement for one objective (alternating between objectives)\n    if random.random() < 0.5:\n        # Improve value1\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n    else:\n        # Improve value2\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if np.sum(weight_lst[new_solution == 1]) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    # Step 3: Ensure feasibility by removing the heaviest items if needed\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        while current_weight > capacity:\n            # Find the heaviest item in the solution\n            heavy_items = np.where(new_solution == 1)[0]\n            if len(heavy_items) == 0:\n                break\n            heaviest_idx = heavy_items[np.argmax(weight_lst[heavy_items])]\n            new_solution[heaviest_idx] = 0\n            current_weight -= weight_lst[heaviest_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 212,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Prefer solutions that are not dominated by others (higher potential for improvement)\n        dominated = np.zeros(len(archive), dtype=bool)\n        for i in range(len(archive)):\n            for j in range(len(archive)):\n                if i != j:\n                    if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1]) and \\\n                       (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1]):\n                        dominated[i] = True\n                        break\n        non_dominated_indices = np.where(~dominated)[0]\n        if len(non_dominated_indices) > 0:\n            selected_idx = random.choice(non_dominated_indices)\n        else:\n            selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: random perturbation + greedy improvement\n    # Step 1: Random perturbation - flip a small number of bits randomly\n    num_flips = min(3, len(base_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(base_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement - add or remove items to improve both objectives\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Try to add items that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item improves both objectives\n            if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2) or \\\n               (new_value1 > current_value1 and new_value2 >= current_value2):\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Try to remove items that don't contribute to both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            new_weight = current_weight - weight_lst[i]\n            new_value1 = current_value1 - value1_lst[i]\n            new_value2 = current_value2 - value2_lst[i]\n\n            # Check if removing this item doesn't hurt both objectives\n            if (new_value1 >= current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[i] = 0\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.4151243599333856,
            2.1430522203445435
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Prefer solutions that are not dominated by others (higher potential for improvement)\n        dominated = np.zeros(len(archive), dtype=bool)\n        for i in range(len(archive)):\n            for j in range(len(archive)):\n                if i != j:\n                    if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1]) and \\\n                       (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1]):\n                        dominated[i] = True\n                        break\n        non_dominated_indices = np.where(~dominated)[0]\n        if len(non_dominated_indices) > 0:\n            selected_idx = random.choice(non_dominated_indices)\n        else:\n            selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: random perturbation + greedy improvement\n    # Step 1: Random perturbation - flip a small number of bits randomly\n    num_flips = min(3, len(base_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = random.sample(range(len(base_solution)), num_flips)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedy improvement - add or remove items to improve both objectives\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Try to add items that improve both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_weight = current_weight + weight_lst[i]\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n\n            # Check if adding this item improves both objectives\n            if (new_value1 > current_value1 and new_value2 > current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2) or \\\n               (new_value1 > current_value1 and new_value2 >= current_value2):\n                new_solution[i] = 1\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # Try to remove items that don't contribute to both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            new_weight = current_weight - weight_lst[i]\n            new_value1 = current_value1 - value1_lst[i]\n            new_value2 = current_value2 - value2_lst[i]\n\n            # Check if removing this item doesn't hurt both objectives\n            if (new_value1 >= current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 > current_value1 and new_value2 >= current_value2) or \\\n               (new_value1 >= current_value1 and new_value2 > current_value2):\n                new_solution[i] = 0\n                current_weight = new_weight\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 213,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    selected_idx = np.random.choice(len(archive), p=np.array([sum(obj) for _, obj in archive]) / sum(sum(obj) for _, obj in archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Get current total weight and item indices\n    current_weight = np.sum(weight_lst * new_solution)\n    item_indices = np.arange(len(weight_lst))\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip items with high value ratios\n    value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    high_value_items = item_indices[value_ratio > np.median(value_ratio)]\n\n    for idx in high_value_items:\n        if random.random() < 0.3:  # 30% chance to flip high-value items\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # 2. Add items that improve both objectives\n    excluded_items = item_indices[new_solution == 0]\n    for idx in excluded_items:\n        if (current_weight + weight_lst[idx] <= capacity and\n            (value1_lst[idx] > 0 or value2_lst[idx] > 0)):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # 3. Remove items that don't contribute to either objective\n    included_items = item_indices[new_solution == 1]\n    for idx in included_items:\n        if (value1_lst[idx] == 0 and value2_lst[idx] == 0 and\n            random.random() < 0.2):  # 20% chance to remove useless items\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # 4. Random swap to escape local optima\n    if len(included_items) >= 2 and random.random() < 0.4:  # 40% chance for swap\n        i, j = random.sample(list(included_items), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.40686582412803973,
            2.6948464810848236
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    selected_idx = np.random.choice(len(archive), p=np.array([sum(obj) for _, obj in archive]) / sum(sum(obj) for _, obj in archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Get current total weight and item indices\n    current_weight = np.sum(weight_lst * new_solution)\n    item_indices = np.arange(len(weight_lst))\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip items with high value ratios\n    value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    high_value_items = item_indices[value_ratio > np.median(value_ratio)]\n\n    for idx in high_value_items:\n        if random.random() < 0.3:  # 30% chance to flip high-value items\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # 2. Add items that improve both objectives\n    excluded_items = item_indices[new_solution == 0]\n    for idx in excluded_items:\n        if (current_weight + weight_lst[idx] <= capacity and\n            (value1_lst[idx] > 0 or value2_lst[idx] > 0)):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # 3. Remove items that don't contribute to either objective\n    included_items = item_indices[new_solution == 1]\n    for idx in included_items:\n        if (value1_lst[idx] == 0 and value2_lst[idx] == 0 and\n            random.random() < 0.2):  # 20% chance to remove useless items\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # 4. Random swap to escape local optima\n    if len(included_items) >= 2 and random.random() < 0.4:  # 40% chance for swap\n        i, j = random.sample(list(included_items), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 214,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    # Step 1: Randomly select a subset of items to consider flipping\n    num_items = len(base_solution)\n    subset_size = min(5, num_items)  # Consider flipping up to 5 items\n    flip_indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n    # Step 2: For each candidate flip, evaluate the impact on both objectives\n    best_improvement = -np.inf\n    best_flip = None\n\n    for idx in flip_indices:\n        # Calculate the new solution if we flip this item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]  # Flip the item\n\n        # Calculate new weight and values\n        new_weight = np.sum(weight_lst[temp_solution == 1])\n        if new_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        new_value1 = np.sum(value1_lst[temp_solution == 1])\n        new_value2 = np.sum(value2_lst[temp_solution == 1])\n\n        # Evaluate improvement (weighted sum of improvements in both objectives)\n        improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n\n        # Track the best improvement\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_flip = idx\n\n    # Apply the best flip if found\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    # If no improvement found, perform a random flip within capacity constraints\n    if best_flip is None:\n        feasible_indices = []\n        for idx in range(num_items):\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n            new_weight = np.sum(weight_lst[temp_solution == 1])\n            if new_weight <= capacity:\n                feasible_indices.append(idx)\n\n        if feasible_indices:\n            random_flip = np.random.choice(feasible_indices)\n            new_solution[random_flip] = 1 - new_solution[random_flip]\n\n    return new_solution\n\n",
        "score": [
            -0.9469373354540787,
            4.774133265018463
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flip with value-based selection\n    # Step 1: Randomly select a subset of items to consider flipping\n    num_items = len(base_solution)\n    subset_size = min(5, num_items)  # Consider flipping up to 5 items\n    flip_indices = np.random.choice(num_items, size=subset_size, replace=False)\n\n    # Step 2: For each candidate flip, evaluate the impact on both objectives\n    best_improvement = -np.inf\n    best_flip = None\n\n    for idx in flip_indices:\n        # Calculate the new solution if we flip this item\n        temp_solution = new_solution.copy()\n        temp_solution[idx] = 1 - temp_solution[idx]  # Flip the item\n\n        # Calculate new weight and values\n        new_weight = np.sum(weight_lst[temp_solution == 1])\n        if new_weight > capacity:\n            continue  # Skip infeasible solutions\n\n        new_value1 = np.sum(value1_lst[temp_solution == 1])\n        new_value2 = np.sum(value2_lst[temp_solution == 1])\n\n        # Evaluate improvement (weighted sum of improvements in both objectives)\n        improvement = (new_value1 - current_value1) + (new_value2 - current_value2)\n\n        # Track the best improvement\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_flip = idx\n\n    # Apply the best flip if found\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    # If no improvement found, perform a random flip within capacity constraints\n    if best_flip is None:\n        feasible_indices = []\n        for idx in range(num_items):\n            temp_solution = new_solution.copy()\n            temp_solution[idx] = 1 - temp_solution[idx]\n            new_weight = np.sum(weight_lst[temp_solution == 1])\n            if new_weight <= capacity:\n                feasible_indices.append(idx)\n\n        if feasible_indices:\n            random_flip = np.random.choice(feasible_indices)\n            new_solution[random_flip] = 1 - new_solution[random_flip]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 215,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append((sol, v1, v2))\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback if no candidates\n\n    # Intelligent selection: prioritize solutions with high potential (e.g., high value but not max)\n    candidates.sort(key=lambda x: -(x[1] + x[2]))  # Sort by combined value (descending)\n    selected_sol = candidates[0][0].copy()\n\n    # Hybrid local search strategy\n    new_solution = selected_sol.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly flip a subset of items (with bias toward objective weights)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Objective-weighted flip (higher probability for items with high marginal contribution)\n    marginal_contrib1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_contrib2 = value2_lst / (weight_lst + 1e-6)\n    combined_contrib = marginal_contrib1 + marginal_contrib2\n\n    # Normalize to get probabilities\n    probs = combined_contrib / np.sum(combined_contrib)\n    weighted_flip = np.random.choice(n_items, p=probs)\n\n    if new_solution[weighted_flip] == 1:\n        new_solution[weighted_flip] = 0\n    else:\n        if np.sum(weight_lst * new_solution) + weight_lst[weighted_flip] <= capacity:\n            new_solution[weighted_flip] = 1\n\n    # Step 3: Capacity-aware perturbation (swap two items if it improves feasibility)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Find items to remove to restore feasibility\n        excess = np.sum(weight_lst * new_solution) - capacity\n        candidate_remove = np.where(new_solution == 1)[0]\n        if len(candidate_remove) > 0:\n            # Remove items with lowest combined marginal contribution\n            remove_indices = np.argsort(combined_contrib[candidate_remove])[:min(2, len(candidate_remove))]\n            new_solution[candidate_remove[remove_indices]] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3694272592249652,
            1.9795343577861786
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not already optimal)\n    candidates = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append((sol, v1, v2))\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback if no candidates\n\n    # Intelligent selection: prioritize solutions with high potential (e.g., high value but not max)\n    candidates.sort(key=lambda x: -(x[1] + x[2]))  # Sort by combined value (descending)\n    selected_sol = candidates[0][0].copy()\n\n    # Hybrid local search strategy\n    new_solution = selected_sol.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly flip a subset of items (with bias toward objective weights)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Objective-weighted flip (higher probability for items with high marginal contribution)\n    marginal_contrib1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_contrib2 = value2_lst / (weight_lst + 1e-6)\n    combined_contrib = marginal_contrib1 + marginal_contrib2\n\n    # Normalize to get probabilities\n    probs = combined_contrib / np.sum(combined_contrib)\n    weighted_flip = np.random.choice(n_items, p=probs)\n\n    if new_solution[weighted_flip] == 1:\n        new_solution[weighted_flip] = 0\n    else:\n        if np.sum(weight_lst * new_solution) + weight_lst[weighted_flip] <= capacity:\n            new_solution[weighted_flip] = 1\n\n    # Step 3: Capacity-aware perturbation (swap two items if it improves feasibility)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Find items to remove to restore feasibility\n        excess = np.sum(weight_lst * new_solution) - capacity\n        candidate_remove = np.where(new_solution == 1)[0]\n        if len(candidate_remove) > 0:\n            # Remove items with lowest combined marginal contribution\n            remove_indices = np.argsort(combined_contrib[candidate_remove])[:min(2, len(candidate_remove))]\n            new_solution[candidate_remove[remove_indices]] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 216,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution based on potential improvement\n    # Prioritize solutions that are likely to improve both objectives or have high marginal gains\n    potential_solutions = []\n    for sol, obj in archive:\n        current_weight = np.dot(sol, weight_lst)\n        if current_weight >= capacity:\n            continue  # Skip infeasible solutions (shouldn't happen for archive)\n\n        # Calculate marginal gains for items not in the solution\n        marginal_gains1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n        marginal_gains = (marginal_gains1 + marginal_gains2) / 2\n\n        # Score based on potential improvement and current weight utilization\n        score = np.sum(marginal_gains * (1 - sol)) + (capacity - current_weight) / capacity\n        potential_solutions.append((sol, score))\n\n    if not potential_solutions:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select the top 10% solutions and pick one randomly\n    potential_solutions.sort(key=lambda x: -x[1])\n    top_solutions = potential_solutions[:max(1, len(potential_solutions) // 10)]\n    selected_sol, _ = random.choice(top_solutions)\n    new_solution = selected_sol.copy()\n\n    # Step 2: Apply hybrid local search\n    # Strategy 1: Randomly swap items (with value/weight awareness)\n    for _ in range(3):  # Number of swaps\n        # Find items to swap: one in the solution, one out\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) == 0 or len(out_items) == 0:\n            break\n\n        # Select items based on value/weight ratio\n        in_item = random.choice(in_items)\n        out_item = random.choice(out_items)\n\n        # Check feasibility of swap\n        current_weight = np.dot(new_solution, weight_lst)\n        delta_weight = weight_lst[out_item] - weight_lst[in_item]\n        if current_weight + delta_weight <= capacity:\n            new_solution[in_item], new_solution[out_item] = 0, 1\n\n    # Strategy 2: Flip items based on marginal gains\n    for _ in range(2):  # Number of flips\n        # Calculate marginal gains for all items\n        marginal_gains1 = value1_lst / (weight_lst + 1e-6)\n        marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n        marginal_gains = (marginal_gains1 + marginal_gains2) / 2\n\n        # Identify items to flip (randomly weighted by marginal gains)\n        items = np.arange(len(new_solution))\n        weights = marginal_gains * (1 - 2 * new_solution)  # Higher weight for items that can improve objectives\n        weights = np.maximum(weights, 0)  # Only consider positive contributions\n\n        if np.sum(weights) == 0:\n            break\n\n        # Select item to flip\n        selected_item = random.choices(items, weights=weights, k=1)[0]\n\n        # Check feasibility of flip\n        current_weight = np.dot(new_solution, weight_lst)\n        delta_weight = weight_lst[selected_item] * (1 - 2 * new_solution[selected_item])\n        if current_weight + delta_weight <= capacity:\n            new_solution[selected_item] = 1 - new_solution[selected_item]\n\n    # Strategy 3: Weight-aware adjustments\n    current_weight = np.dot(new_solution, weight_lst)\n    if current_weight > capacity:\n        # Remove items until feasible (weighted by value/weight ratio)\n        excess_weight = current_weight - capacity\n        in_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0:\n            # Remove items with lowest value/weight ratio until feasible\n            value_weight_ratio = value1_lst[in_items] / (weight_lst[in_items] + 1e-6)\n            sorted_items = in_items[np.argsort(value_weight_ratio)]\n            removed_weight = 0\n\n            for item in sorted_items:\n                if removed_weight >= excess_weight:\n                    break\n                new_solution[item] = 0\n                removed_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8184985056268811,
            7.344226241111755
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution based on potential improvement\n    # Prioritize solutions that are likely to improve both objectives or have high marginal gains\n    potential_solutions = []\n    for sol, obj in archive:\n        current_weight = np.dot(sol, weight_lst)\n        if current_weight >= capacity:\n            continue  # Skip infeasible solutions (shouldn't happen for archive)\n\n        # Calculate marginal gains for items not in the solution\n        marginal_gains1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n        marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n        marginal_gains = (marginal_gains1 + marginal_gains2) / 2\n\n        # Score based on potential improvement and current weight utilization\n        score = np.sum(marginal_gains * (1 - sol)) + (capacity - current_weight) / capacity\n        potential_solutions.append((sol, score))\n\n    if not potential_solutions:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select the top 10% solutions and pick one randomly\n    potential_solutions.sort(key=lambda x: -x[1])\n    top_solutions = potential_solutions[:max(1, len(potential_solutions) // 10)]\n    selected_sol, _ = random.choice(top_solutions)\n    new_solution = selected_sol.copy()\n\n    # Step 2: Apply hybrid local search\n    # Strategy 1: Randomly swap items (with value/weight awareness)\n    for _ in range(3):  # Number of swaps\n        # Find items to swap: one in the solution, one out\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) == 0 or len(out_items) == 0:\n            break\n\n        # Select items based on value/weight ratio\n        in_item = random.choice(in_items)\n        out_item = random.choice(out_items)\n\n        # Check feasibility of swap\n        current_weight = np.dot(new_solution, weight_lst)\n        delta_weight = weight_lst[out_item] - weight_lst[in_item]\n        if current_weight + delta_weight <= capacity:\n            new_solution[in_item], new_solution[out_item] = 0, 1\n\n    # Strategy 2: Flip items based on marginal gains\n    for _ in range(2):  # Number of flips\n        # Calculate marginal gains for all items\n        marginal_gains1 = value1_lst / (weight_lst + 1e-6)\n        marginal_gains2 = value2_lst / (weight_lst + 1e-6)\n        marginal_gains = (marginal_gains1 + marginal_gains2) / 2\n\n        # Identify items to flip (randomly weighted by marginal gains)\n        items = np.arange(len(new_solution))\n        weights = marginal_gains * (1 - 2 * new_solution)  # Higher weight for items that can improve objectives\n        weights = np.maximum(weights, 0)  # Only consider positive contributions\n\n        if np.sum(weights) == 0:\n            break\n\n        # Select item to flip\n        selected_item = random.choices(items, weights=weights, k=1)[0]\n\n        # Check feasibility of flip\n        current_weight = np.dot(new_solution, weight_lst)\n        delta_weight = weight_lst[selected_item] * (1 - 2 * new_solution[selected_item])\n        if current_weight + delta_weight <= capacity:\n            new_solution[selected_item] = 1 - new_solution[selected_item]\n\n    # Strategy 3: Weight-aware adjustments\n    current_weight = np.dot(new_solution, weight_lst)\n    if current_weight > capacity:\n        # Remove items until feasible (weighted by value/weight ratio)\n        excess_weight = current_weight - capacity\n        in_items = np.where(new_solution == 1)[0]\n\n        if len(in_items) > 0:\n            # Remove items with lowest value/weight ratio until feasible\n            value_weight_ratio = value1_lst[in_items] / (weight_lst[in_items] + 1e-6)\n            sorted_items = in_items[np.argsort(value_weight_ratio)]\n            removed_weight = 0\n\n            for item in sorted_items:\n                if removed_weight >= excess_weight:\n                    break\n                new_solution[item] = 0\n                removed_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 217,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.argmax([np.sum(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution (flip some bits)\n    perturbation_size = min(5, len(base_solution) // 2)\n    flip_indices = random.sample(range(len(base_solution)), perturbation_size)\n    new_solution = base_solution.copy()\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing items that exceed capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items in order of least contribution to the most valuable objective\n        items_sorted = np.argsort(value1_lst + value2_lst)\n        for idx in items_sorted[::-1]:\n            if new_solution[idx] == 1 and excess_weight > 0:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Sort items by the sum of normalized values (to balance both objectives)\n        normalized_value = (value1_lst / np.max(value1_lst)) + (value2_lst / np.max(value2_lst))\n        candidate_items = np.where(new_solution == 0)[0]\n        sorted_candidates = np.argsort(normalized_value[candidate_items])[::-1]\n\n        for idx in sorted_candidates:\n            if weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.4200772359393925,
            1.5050571858882904
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.argmax([np.sum(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Randomly perturb the solution (flip some bits)\n    perturbation_size = min(5, len(base_solution) // 2)\n    flip_indices = random.sample(range(len(base_solution)), perturbation_size)\n    new_solution = base_solution.copy()\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing items that exceed capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess_weight = new_weight - capacity\n        # Remove items in order of least contribution to the most valuable objective\n        items_sorted = np.argsort(value1_lst + value2_lst)\n        for idx in items_sorted[::-1]:\n            if new_solution[idx] == 1 and excess_weight > 0:\n                new_solution[idx] = 0\n                excess_weight -= weight_lst[idx]\n                if excess_weight <= 0:\n                    break\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Sort items by the sum of normalized values (to balance both objectives)\n        normalized_value = (value1_lst / np.max(value1_lst)) + (value2_lst / np.max(value2_lst))\n        candidate_items = np.where(new_solution == 0)[0]\n        sorted_candidates = np.argsort(normalized_value[candidate_items])[::-1]\n\n        for idx in sorted_candidates:\n            if weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 218,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Calculate combined value for each solution\n    combined_values = [sum(obj) for _, obj in archive]\n    total_combined = sum(combined_values)\n    probabilities = [val / total_combined for val in combined_values]\n\n    # Select a base solution with probability proportional to its combined value\n    selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a neighbor by flipping items with a bias towards high-value items\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n\n    # Determine number of flips (between 1 and 5)\n    num_flips = random.randint(1, min(5, num_items))\n\n    for _ in range(num_flips):\n        # Calculate value-to-weight ratios for all items\n        v1_ratio = value1_lst / (weight_lst + 1e-6)\n        v2_ratio = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = v1_ratio + v2_ratio\n\n        # Select items to flip with probability proportional to their combined ratio\n        flip_probs = combined_ratio / np.sum(combined_ratio)\n        flip_idx = random.choices(range(num_items), weights=flip_probs, k=1)[0]\n\n        # Flip the selected item\n        if new_solution[flip_idx] == 1:\n            # If item is in the solution, remove it if feasible\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            # If item is not in the solution, add it if feasible\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5105930965297525,
            2.986321121454239
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Calculate combined value for each solution\n    combined_values = [sum(obj) for _, obj in archive]\n    total_combined = sum(combined_values)\n    probabilities = [val / total_combined for val in combined_values]\n\n    # Select a base solution with probability proportional to its combined value\n    selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate a neighbor by flipping items with a bias towards high-value items\n    new_solution = base_solution.copy()\n    num_items = len(weight_lst)\n\n    # Determine number of flips (between 1 and 5)\n    num_flips = random.randint(1, min(5, num_items))\n\n    for _ in range(num_flips):\n        # Calculate value-to-weight ratios for all items\n        v1_ratio = value1_lst / (weight_lst + 1e-6)\n        v2_ratio = value2_lst / (weight_lst + 1e-6)\n        combined_ratio = v1_ratio + v2_ratio\n\n        # Select items to flip with probability proportional to their combined ratio\n        flip_probs = combined_ratio / np.sum(combined_ratio)\n        flip_idx = random.choices(range(num_items), weights=flip_probs, k=1)[0]\n\n        # Flip the selected item\n        if new_solution[flip_idx] == 1:\n            # If item is in the solution, remove it if feasible\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            # If item is not in the solution, add it if feasible\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 219,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score (sum of normalized objectives)\n        objectives = np.array([obj for _, obj in archive])\n        normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        scores = normalized_obj.sum(axis=1)\n        # Select top 30% solutions and pick one randomly\n        top_indices = np.argsort(scores)[-max(1, len(scores) // 3):]\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combination of flip, swap, and cluster-based moves\n    n_items = len(base_solution)\n\n    # 1. Cluster-based move: flip items in a cluster that has high marginal value/weight ratio\n    if n_items > 1:\n        # Identify clusters based on value/weight ratios\n        v1_ratio = value1_lst / (weight_lst + 1e-10)\n        v2_ratio = value2_lst / (weight_lst + 1e-10)\n        combined_ratio = v1_ratio + v2_ratio\n\n        # Sort items by combined ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        # Select a cluster of top 20% items\n        cluster_size = max(1, n_items // 5)\n        cluster_indices = sorted_indices[:cluster_size]\n\n        # Flip items in the cluster\n        for idx in cluster_indices:\n            if random.random() < 0.3:  # 30% chance to flip\n                new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Swap move: swap two items with high value/weight ratios\n    if n_items > 1:\n        # Select two items to swap\n        swap_indices = np.random.choice(n_items, size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # 3. Flip move: flip a random item\n    flip_idx = random.randint(0, n_items - 1)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        while current_weight > capacity:\n            selected_items = np.where(new_solution == 1)[0]\n            if len(selected_items) == 0:\n                break\n            remove_idx = random.choice(selected_items)\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.34048973150941514,
            1.3983557522296906
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by a combined score (sum of normalized objectives)\n        objectives = np.array([obj for _, obj in archive])\n        normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n        scores = normalized_obj.sum(axis=1)\n        # Select top 30% solutions and pick one randomly\n        top_indices = np.argsort(scores)[-max(1, len(scores) // 3):]\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: combination of flip, swap, and cluster-based moves\n    n_items = len(base_solution)\n\n    # 1. Cluster-based move: flip items in a cluster that has high marginal value/weight ratio\n    if n_items > 1:\n        # Identify clusters based on value/weight ratios\n        v1_ratio = value1_lst / (weight_lst + 1e-10)\n        v2_ratio = value2_lst / (weight_lst + 1e-10)\n        combined_ratio = v1_ratio + v2_ratio\n\n        # Sort items by combined ratio\n        sorted_indices = np.argsort(combined_ratio)[::-1]\n\n        # Select a cluster of top 20% items\n        cluster_size = max(1, n_items // 5)\n        cluster_indices = sorted_indices[:cluster_size]\n\n        # Flip items in the cluster\n        for idx in cluster_indices:\n            if random.random() < 0.3:  # 30% chance to flip\n                new_solution[idx] = 1 - new_solution[idx]\n\n    # 2. Swap move: swap two items with high value/weight ratios\n    if n_items > 1:\n        # Select two items to swap\n        swap_indices = np.random.choice(n_items, size=2, replace=False)\n        new_solution[swap_indices[0]], new_solution[swap_indices[1]] = new_solution[swap_indices[1]], new_solution[swap_indices[0]]\n\n    # 3. Flip move: flip a random item\n    flip_idx = random.randint(0, n_items - 1)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        while current_weight > capacity:\n            selected_items = np.where(new_solution == 1)[0]\n            if len(selected_items) == 0:\n                break\n            remove_idx = random.choice(selected_items)\n            new_solution[remove_idx] = 0\n            current_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 220,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution, _ = archive[0]\n    else:\n        # Calculate the \"potential\" of each solution (distance to the ideal point)\n        ideal_value1 = max(obj[1][0] for obj in archive)\n        ideal_value2 = max(obj[1][1] for obj in archive)\n        potentials = []\n        for sol, (v1, v2) in archive:\n            # Potential is based on how close the solution is to the ideal point\n            potential = (ideal_value1 - v1) + (ideal_value2 - v2)\n            potentials.append(potential)\n        # Select a solution with high potential (low distance to ideal)\n        selected_idx = np.argmin(potentials)\n        base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Novel local search strategy: \"Weighted Random Flip\" with objective-aware selection\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either added or removed)\n    candidate_indices = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        # If no candidates, return the original solution\n        return new_solution\n\n    # Select a candidate with probability proportional to its \"improvement potential\"\n    # For items currently in the solution, potential is based on marginal contribution to both objectives\n    # For items not in the solution, potential is based on their value/weight ratio\n    potentials = []\n    for i in candidate_indices:\n        if new_solution[i] == 1:\n            # Potential of removing item i\n            marginal_value1 = value1_lst[i]\n            marginal_value2 = value2_lst[i]\n            # Higher potential if the item contributes significantly to both objectives\n            potential = marginal_value1 * marginal_value2\n        else:\n            # Potential of adding item i\n            # Higher potential if the item has good value/weight ratio for both objectives\n            potential = (value1_lst[i] / weight_lst[i]) + (value2_lst[i] / weight_lst[i])\n        potentials.append(potential)\n\n    # Normalize potentials to form a probability distribution\n    if sum(potentials) == 0:\n        probabilities = [1.0 / len(potentials)] * len(potentials)\n    else:\n        probabilities = [p / sum(potentials) for p in potentials]\n\n    # Select the flip candidate\n    selected_idx = np.random.choice(candidate_indices, p=probabilities)\n    new_solution[selected_idx] = 1 - new_solution[selected_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.7853229933726168,
            4.829803317785263
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) == 1:\n        base_solution, _ = archive[0]\n    else:\n        # Calculate the \"potential\" of each solution (distance to the ideal point)\n        ideal_value1 = max(obj[1][0] for obj in archive)\n        ideal_value2 = max(obj[1][1] for obj in archive)\n        potentials = []\n        for sol, (v1, v2) in archive:\n            # Potential is based on how close the solution is to the ideal point\n            potential = (ideal_value1 - v1) + (ideal_value2 - v2)\n            potentials.append(potential)\n        # Select a solution with high potential (low distance to ideal)\n        selected_idx = np.argmin(potentials)\n        base_solution, _ = archive[selected_idx]\n\n    new_solution = base_solution.copy()\n\n    # Novel local search strategy: \"Weighted Random Flip\" with objective-aware selection\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (either added or removed)\n    candidate_indices = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Check if removing this item keeps the solution feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n        else:\n            # Check if adding this item keeps the solution feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_indices.append(i)\n\n    if not candidate_indices:\n        # If no candidates, return the original solution\n        return new_solution\n\n    # Select a candidate with probability proportional to its \"improvement potential\"\n    # For items currently in the solution, potential is based on marginal contribution to both objectives\n    # For items not in the solution, potential is based on their value/weight ratio\n    potentials = []\n    for i in candidate_indices:\n        if new_solution[i] == 1:\n            # Potential of removing item i\n            marginal_value1 = value1_lst[i]\n            marginal_value2 = value2_lst[i]\n            # Higher potential if the item contributes significantly to both objectives\n            potential = marginal_value1 * marginal_value2\n        else:\n            # Potential of adding item i\n            # Higher potential if the item has good value/weight ratio for both objectives\n            potential = (value1_lst[i] / weight_lst[i]) + (value2_lst[i] / weight_lst[i])\n        potentials.append(potential)\n\n    # Normalize potentials to form a probability distribution\n    if sum(potentials) == 0:\n        probabilities = [1.0 / len(potentials)] * len(potentials)\n    else:\n        probabilities = [p / sum(potentials) for p in potentials]\n\n    # Select the flip candidate\n    selected_idx = np.random.choice(candidate_indices, p=probabilities)\n    new_solution[selected_idx] = 1 - new_solution[selected_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 221,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by total value (sum of both objectives) to prioritize less dominant solutions\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select the top 20% of solutions with the highest potential\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 5)]\n        # Randomly select one from the top solutions\n        base_solution, _ = random.choice(top_solutions)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (intensification)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item if feasible\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add the item if feasible\n            if (np.sum(weight_lst[new_solution == 1]) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # 2. Add a random item from the excluded ones (diversification)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        random_excluded = random.choice(excluded_items)\n        if (np.sum(weight_lst[new_solution == 1]) + weight_lst[random_excluded]) <= capacity:\n            new_solution[random_excluded] = 1\n\n    # 3. Remove a random item from the included ones (diversification)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        random_included = random.choice(included_items)\n        if (np.sum(weight_lst[new_solution == 1]) - weight_lst[random_included]) <= capacity:\n            new_solution[random_included] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.33518382989984635,
            1.3815974295139313
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by total value (sum of both objectives) to prioritize less dominant solutions\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select the top 20% of solutions with the highest potential\n        top_solutions = archive_sorted[:max(1, len(archive_sorted) // 5)]\n        # Randomly select one from the top solutions\n        base_solution, _ = random.choice(top_solutions)\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (intensification)\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item if feasible\n            if (np.sum(weight_lst[new_solution == 1]) - weight_lst[idx]) <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Try to add the item if feasible\n            if (np.sum(weight_lst[new_solution == 1]) + weight_lst[idx]) <= capacity:\n                new_solution[idx] = 1\n\n    # 2. Add a random item from the excluded ones (diversification)\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        random_excluded = random.choice(excluded_items)\n        if (np.sum(weight_lst[new_solution == 1]) + weight_lst[random_excluded]) <= capacity:\n            new_solution[random_excluded] = 1\n\n    # 3. Remove a random item from the included ones (diversification)\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        random_included = random.choice(included_items)\n        if (np.sum(weight_lst[new_solution == 1]) - weight_lst[random_included]) <= capacity:\n            new_solution[random_included] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 222,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol_obj[0] for sol_obj in archive]\n    archive_values = np.array([sol_obj[1] for sol_obj in archive])\n\n    # Calculate potential improvement: distance to ideal point\n    ideal_values = np.max(archive_values, axis=0)\n    distances = np.linalg.norm(archive_values - ideal_values, axis=1)\n    probabilities = 1 / (1 + distances)  # Higher probability for solutions farther from ideal\n    probabilities /= probabilities.sum()  # Normalize\n\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps followed by value-based improvement\n    n_items = len(weight_lst)\n    if n_items == 0:\n        return new_solution\n\n    # Random swaps (exploration)\n    n_swaps = min(3, n_items // 2)  # Limit swaps to avoid excessive changes\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Ensure feasibility after swap\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Value-based improvement (exploitation)\n    current_weight = np.dot(new_solution, weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Try adding items with high marginal value-to-weight ratio\n    excluded_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(excluded_items)\n\n    for item in excluded_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Evaluate both objectives for the item\n            marginal_value1 = value1_lst[item]\n            marginal_value2 = value2_lst[item]\n\n            # Accept if it improves at least one objective\n            if marginal_value1 > 0 or marginal_value2 > 0:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    # Try removing items with negative marginal value (if any)\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        if value1_lst[item] <= 0 and value2_lst[item] <= 0:\n            new_solution[item] = 0\n            remaining_capacity += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3361099327080162,
            8.715458989143372
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol_obj[0] for sol_obj in archive]\n    archive_values = np.array([sol_obj[1] for sol_obj in archive])\n\n    # Calculate potential improvement: distance to ideal point\n    ideal_values = np.max(archive_values, axis=0)\n    distances = np.linalg.norm(archive_values - ideal_values, axis=1)\n    probabilities = 1 / (1 + distances)  # Higher probability for solutions farther from ideal\n    probabilities /= probabilities.sum()  # Normalize\n\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random swaps followed by value-based improvement\n    n_items = len(weight_lst)\n    if n_items == 0:\n        return new_solution\n\n    # Random swaps (exploration)\n    n_swaps = min(3, n_items // 2)  # Limit swaps to avoid excessive changes\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Ensure feasibility after swap\n        if np.dot(new_solution, weight_lst) > capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Value-based improvement (exploitation)\n    current_weight = np.dot(new_solution, weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Try adding items with high marginal value-to-weight ratio\n    excluded_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(excluded_items)\n\n    for item in excluded_items:\n        if weight_lst[item] <= remaining_capacity:\n            # Evaluate both objectives for the item\n            marginal_value1 = value1_lst[item]\n            marginal_value2 = value2_lst[item]\n\n            # Accept if it improves at least one objective\n            if marginal_value1 > 0 or marginal_value2 > 0:\n                new_solution[item] = 1\n                remaining_capacity -= weight_lst[item]\n\n    # Try removing items with negative marginal value (if any)\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        if value1_lst[item] <= 0 and value2_lst[item] <= 0:\n            new_solution[item] = 0\n            remaining_capacity += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 223,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher objective values\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine bit-flip and swap operations\n    num_items = len(base_solution)\n    operation = random.choice(['bit_flip', 'swap', 'multi_flip'])\n\n    if operation == 'bit_flip':\n        # Randomly flip one item\n        idx = random.randint(0, num_items - 1)\n        if new_solution[idx] == 1:\n            # Ensure the solution remains feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    elif operation == 'swap':\n        # Randomly swap two items\n        idx1, idx2 = random.sample(range(num_items), 2)\n        if new_solution[idx1] != new_solution[idx2]:\n            # Check feasibility\n            if new_solution[idx1] == 1 and new_solution[idx2] == 0:\n                if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            elif new_solution[idx1] == 0 and new_solution[idx2] == 1:\n                if current_weight + weight_lst[idx1] - weight_lst[idx2] <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    elif operation == 'multi_flip':\n        # Flip multiple items (1-3) while maintaining feasibility\n        num_flips = random.randint(1, min(3, num_items))\n        candidates = [i for i in range(num_items) if base_solution[i] == 1]\n        if not candidates:\n            candidates = [i for i in range(num_items) if base_solution[i] == 0]\n\n        selected = random.sample(candidates, min(num_flips, len(candidates)))\n        for idx in selected:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.36854884100086277,
            2.6985368132591248
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher objective values\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine bit-flip and swap operations\n    num_items = len(base_solution)\n    operation = random.choice(['bit_flip', 'swap', 'multi_flip'])\n\n    if operation == 'bit_flip':\n        # Randomly flip one item\n        idx = random.randint(0, num_items - 1)\n        if new_solution[idx] == 1:\n            # Ensure the solution remains feasible\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    elif operation == 'swap':\n        # Randomly swap two items\n        idx1, idx2 = random.sample(range(num_items), 2)\n        if new_solution[idx1] != new_solution[idx2]:\n            # Check feasibility\n            if new_solution[idx1] == 1 and new_solution[idx2] == 0:\n                if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            elif new_solution[idx1] == 0 and new_solution[idx2] == 1:\n                if current_weight + weight_lst[idx1] - weight_lst[idx2] <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    elif operation == 'multi_flip':\n        # Flip multiple items (1-3) while maintaining feasibility\n        num_flips = random.randint(1, min(3, num_items))\n        candidates = [i for i in range(num_items) if base_solution[i] == 1]\n        if not candidates:\n            candidates = [i for i in range(num_items) if base_solution[i] == 0]\n\n        selected = random.sample(candidates, min(num_flips, len(candidates)))\n        for idx in selected:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 224,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a higher probability for those with higher total values\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / total_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly flip k items to explore the neighborhood\n    k = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = np.random.choice(len(new_solution), size=k, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility: remove items that exceed capacity if any\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedily remove items with the lowest marginal contribution to the total value\n        excess_weight = total_weight - capacity\n        while excess_weight > 0 and np.any(new_solution):\n            # Calculate marginal contribution for each item (value1 + value2) per unit weight\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            # Find the item with the lowest marginal contribution that is currently included\n            candidate_indices = np.where(new_solution == 1)[0]\n            if len(candidate_indices) == 0:\n                break\n            remove_idx = candidate_indices[np.argmin(marginal_contribution[candidate_indices])]\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    return new_solution\n\n",
        "score": [
            -0.3845084443940739,
            1.8781189322471619
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with a higher probability for those with higher total values\n    total_values = np.array([obj[0] + obj[1] for _, obj in archive])\n    probabilities = total_values / total_values.sum()\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly flip k items to explore the neighborhood\n    k = min(3, len(new_solution))  # Limit the number of flips to avoid excessive changes\n    flip_indices = np.random.choice(len(new_solution), size=k, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility: remove items that exceed capacity if any\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Greedily remove items with the lowest marginal contribution to the total value\n        excess_weight = total_weight - capacity\n        while excess_weight > 0 and np.any(new_solution):\n            # Calculate marginal contribution for each item (value1 + value2) per unit weight\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            # Find the item with the lowest marginal contribution that is currently included\n            candidate_indices = np.where(new_solution == 1)[0]\n            if len(candidate_indices) == 0:\n                break\n            remove_idx = candidate_indices[np.argmin(marginal_contribution[candidate_indices])]\n            new_solution[remove_idx] = 0\n            excess_weight = np.sum(weight_lst * new_solution) - capacity\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 225,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed) without violating capacity\n    candidate_items = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Check if removing this item would still be feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_items.append((i, -1))  # -1 indicates removal\n        else:\n            # Check if adding this item would still be feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_items.append((i, 1))  # 1 indicates addition\n\n    if not candidate_items:\n        return new_solution\n\n    # Hybrid local search strategy: combine random selection with value-based selection\n    # 70% chance to select based on value improvement, 30% random\n    if np.random.rand() < 0.7:\n        # Select item that maximizes the sum of normalized value improvements\n        best_item = None\n        best_score = -float('inf')\n\n        for i, flip in candidate_items:\n            if flip == 1:\n                # Adding item i\n                delta_v1 = value1_lst[i]\n                delta_v2 = value2_lst[i]\n            else:\n                # Removing item i\n                delta_v1 = -value1_lst[i]\n                delta_v2 = -value2_lst[i]\n\n            # Normalize the deltas and combine them\n            score = (delta_v1 / (value1_lst.max() + 1e-6)) + (delta_v2 / (value2_lst.max() + 1e-6))\n\n            if score > best_score:\n                best_score = score\n                best_item = (i, flip)\n    else:\n        # Random selection\n        best_item = candidate_items[np.random.randint(len(candidate_items))]\n\n    # Apply the best flip\n    i, flip = best_item\n    new_solution[i] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
        "score": [
            -0.9608332393300909,
            3.641871750354767
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed) without violating capacity\n    candidate_items = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Check if removing this item would still be feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_items.append((i, -1))  # -1 indicates removal\n        else:\n            # Check if adding this item would still be feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_items.append((i, 1))  # 1 indicates addition\n\n    if not candidate_items:\n        return new_solution\n\n    # Hybrid local search strategy: combine random selection with value-based selection\n    # 70% chance to select based on value improvement, 30% random\n    if np.random.rand() < 0.7:\n        # Select item that maximizes the sum of normalized value improvements\n        best_item = None\n        best_score = -float('inf')\n\n        for i, flip in candidate_items:\n            if flip == 1:\n                # Adding item i\n                delta_v1 = value1_lst[i]\n                delta_v2 = value2_lst[i]\n            else:\n                # Removing item i\n                delta_v1 = -value1_lst[i]\n                delta_v2 = -value2_lst[i]\n\n            # Normalize the deltas and combine them\n            score = (delta_v1 / (value1_lst.max() + 1e-6)) + (delta_v2 / (value2_lst.max() + 1e-6))\n\n            if score > best_score:\n                best_score = score\n                best_item = (i, flip)\n    else:\n        # Random selection\n        best_item = candidate_items[np.random.randint(len(candidate_items))]\n\n    # Apply the best flip\n    i, flip = best_item\n    new_solution[i] = 1 if flip == 1 else 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 225,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed) without violating capacity\n    candidate_items = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Check if removing this item would still be feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_items.append((i, -1))  # -1 indicates removal\n        else:\n            # Check if adding this item would still be feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_items.append((i, 1))  # 1 indicates addition\n\n    if not candidate_items:\n        return new_solution\n\n    # Hybrid local search strategy: combine random selection with value-based selection\n    # 70% chance to select based on value improvement, 30% random\n    if np.random.rand() < 0.7:\n        # Select item that maximizes the sum of normalized value improvements\n        best_item = None\n        best_score = -float('inf')\n\n        for i, flip in candidate_items:\n            if flip == 1:\n                # Adding item i\n                delta_v1 = value1_lst[i]\n                delta_v2 = value2_lst[i]\n            else:\n                # Removing item i\n                delta_v1 = -value1_lst[i]\n                delta_v2 = -value2_lst[i]\n\n            # Normalize the deltas and combine them\n            score = (delta_v1 / (value1_lst.max() + 1e-6)) + (delta_v2 / (value2_lst.max() + 1e-6))\n\n            if score > best_score:\n                best_score = score\n                best_item = (i, flip)\n    else:\n        # Random selection\n        best_item = candidate_items[np.random.randint(len(candidate_items))]\n\n    # Apply the best flip\n    i, flip = best_item\n    new_solution[i] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
        "score": [
            -0.9608332393300909,
            3.641871750354767
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (added or removed) without violating capacity\n    candidate_items = []\n    for i in range(len(weight_lst)):\n        if new_solution[i] == 1:\n            # Check if removing this item would still be feasible\n            if current_weight - weight_lst[i] <= capacity:\n                candidate_items.append((i, -1))  # -1 indicates removal\n        else:\n            # Check if adding this item would still be feasible\n            if current_weight + weight_lst[i] <= capacity:\n                candidate_items.append((i, 1))  # 1 indicates addition\n\n    if not candidate_items:\n        return new_solution\n\n    # Hybrid local search strategy: combine random selection with value-based selection\n    # 70% chance to select based on value improvement, 30% random\n    if np.random.rand() < 0.7:\n        # Select item that maximizes the sum of normalized value improvements\n        best_item = None\n        best_score = -float('inf')\n\n        for i, flip in candidate_items:\n            if flip == 1:\n                # Adding item i\n                delta_v1 = value1_lst[i]\n                delta_v2 = value2_lst[i]\n            else:\n                # Removing item i\n                delta_v1 = -value1_lst[i]\n                delta_v2 = -value2_lst[i]\n\n            # Normalize the deltas and combine them\n            score = (delta_v1 / (value1_lst.max() + 1e-6)) + (delta_v2 / (value2_lst.max() + 1e-6))\n\n            if score > best_score:\n                best_score = score\n                best_item = (i, flip)\n    else:\n        # Random selection\n        best_item = candidate_items[np.random.randint(len(candidate_items))]\n\n    # Apply the best flip\n    i, flip = best_item\n    new_solution[i] = 1 if flip == 1 else 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 226,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the frontier)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):  # For both objectives\n        sorted_indices = np.argsort([obj[i] for obj in archive_objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (archive_objectives[sorted_indices[j+1]][i] - archive_objectives[sorted_indices[j-1]][i])\n\n    # Select a solution with high crowding distance (less crowded) for exploration\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search: Random perturbation + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random perturbation: Flip a small number of bits\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility: If perturbation violates capacity, undo it\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Greedy improvement: Remove items until feasible\n        items_sorted_by_ratio = np.argsort((value1_lst + value2_lst) / weight_lst)\n        for idx in reversed(items_sorted_by_ratio):\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight = np.sum(new_solution * weight_lst)\n                if total_weight <= capacity:\n                    break\n\n    # Greedy improvement: Add items that improve both objectives\n    remaining_capacity = capacity - np.sum(new_solution * weight_lst)\n    items_sorted_by_value = np.argsort(value1_lst + value2_lst)[::-1]\n    for idx in items_sorted_by_value:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.2992777677293054,
            2.927787333726883
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the frontier)\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n\n    # Calculate the crowding distance to identify less crowded solutions\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):  # For both objectives\n        sorted_indices = np.argsort([obj[i] for obj in archive_objectives])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (archive_objectives[sorted_indices[j+1]][i] - archive_objectives[sorted_indices[j-1]][i])\n\n    # Select a solution with high crowding distance (less crowded) for exploration\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Hybrid local search: Random perturbation + greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random perturbation: Flip a small number of bits\n    n_items = len(base_solution)\n    flip_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility: If perturbation violates capacity, undo it\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Greedy improvement: Remove items until feasible\n        items_sorted_by_ratio = np.argsort((value1_lst + value2_lst) / weight_lst)\n        for idx in reversed(items_sorted_by_ratio):\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight = np.sum(new_solution * weight_lst)\n                if total_weight <= capacity:\n                    break\n\n    # Greedy improvement: Add items that improve both objectives\n    remaining_capacity = capacity - np.sum(new_solution * weight_lst)\n    items_sorted_by_value = np.argsort(value1_lst + value2_lst)[::-1]\n    for idx in items_sorted_by_value:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 227,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards those with higher combined value\n    combined_values = np.array([sum(obj) for _, obj in archive])\n    selection_probs = combined_values / np.sum(combined_values)\n    base_solution, _ = random.choices(archive, weights=selection_probs, k=1)[0]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    if random.random() < 0.5:  # 50% chance for random flip\n        # Randomly flip items, ensuring feasibility\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = random.choice(candidate_indices)\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n    else:  # 50% chance for weight-based or value-based operation\n        if random.random() < 0.5:  # Weight-based operation\n            # Find items to swap: one in knapsack, one out\n            in_indices = np.where(new_solution == 1)[0]\n            out_indices = np.where(new_solution == 0)[0]\n\n            if len(in_indices) > 0 and len(out_indices) > 0:\n                # Select lightest item in knapsack and heaviest item out\n                lightest_in = in_indices[np.argmin(weight_lst[in_indices])]\n                heaviest_out = out_indices[np.argmax(weight_lst[out_indices])]\n\n                if current_weight - weight_lst[lightest_in] + weight_lst[heaviest_out] <= capacity:\n                    new_solution[lightest_in] = 0\n                    new_solution[heaviest_out] = 1\n        else:  # Value-based operation\n            # Find items to swap based on value ratios\n            in_indices = np.where(new_solution == 1)[0]\n            out_indices = np.where(new_solution == 0)[0]\n\n            if len(in_indices) > 0 and len(out_indices) > 0:\n                # Calculate value ratios (value1/weight and value2/weight)\n                in_ratios1 = value1_lst[in_indices] / weight_lst[in_indices]\n                in_ratios2 = value2_lst[in_indices] / weight_lst[in_indices]\n                out_ratios1 = value1_lst[out_indices] / weight_lst[out_indices]\n                out_ratios2 = value2_lst[out_indices] / weight_lst[out_indices]\n\n                # Find worst item in knapsack (lowest combined ratio) and best item out (highest combined ratio)\n                worst_in = in_indices[np.argmin(in_ratios1 + in_ratios2)]\n                best_out = out_indices[np.argmax(out_ratios1 + out_ratios2)]\n\n                if current_weight - weight_lst[worst_in] + weight_lst[best_out] <= capacity:\n                    new_solution[worst_in] = 0\n                    new_solution[best_out] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3370515255488864,
            1.4318924248218536
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a base solution with a bias towards those with higher combined value\n    combined_values = np.array([sum(obj) for _, obj in archive])\n    selection_probs = combined_values / np.sum(combined_values)\n    base_solution, _ = random.choices(archive, weights=selection_probs, k=1)[0]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    if random.random() < 0.5:  # 50% chance for random flip\n        # Randomly flip items, ensuring feasibility\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = random.choice(candidate_indices)\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n    else:  # 50% chance for weight-based or value-based operation\n        if random.random() < 0.5:  # Weight-based operation\n            # Find items to swap: one in knapsack, one out\n            in_indices = np.where(new_solution == 1)[0]\n            out_indices = np.where(new_solution == 0)[0]\n\n            if len(in_indices) > 0 and len(out_indices) > 0:\n                # Select lightest item in knapsack and heaviest item out\n                lightest_in = in_indices[np.argmin(weight_lst[in_indices])]\n                heaviest_out = out_indices[np.argmax(weight_lst[out_indices])]\n\n                if current_weight - weight_lst[lightest_in] + weight_lst[heaviest_out] <= capacity:\n                    new_solution[lightest_in] = 0\n                    new_solution[heaviest_out] = 1\n        else:  # Value-based operation\n            # Find items to swap based on value ratios\n            in_indices = np.where(new_solution == 1)[0]\n            out_indices = np.where(new_solution == 0)[0]\n\n            if len(in_indices) > 0 and len(out_indices) > 0:\n                # Calculate value ratios (value1/weight and value2/weight)\n                in_ratios1 = value1_lst[in_indices] / weight_lst[in_indices]\n                in_ratios2 = value2_lst[in_indices] / weight_lst[in_indices]\n                out_ratios1 = value1_lst[out_indices] / weight_lst[out_indices]\n                out_ratios2 = value2_lst[out_indices] / weight_lst[out_indices]\n\n                # Find worst item in knapsack (lowest combined ratio) and best item out (highest combined ratio)\n                worst_in = in_indices[np.argmin(in_ratios1 + in_ratios2)]\n                best_out = out_indices[np.argmax(out_ratios1 + out_ratios2)]\n\n                if current_weight - weight_lst[worst_in] + weight_lst[best_out] <= capacity:\n                    new_solution[worst_in] = 0\n                    new_solution[best_out] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 228,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with a higher probability if it has more \"1\"s (indicating potential for improvement)\n    weights = [np.sum(sol) for sol, _ in archive]\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        probabilities = [w / total_weight for w in weights]\n        selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: flip a subset of items based on their marginal contribution\n    # Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / weight_lst\n    marginal2 = value2_lst / weight_lst\n\n    # Combine marginal contributions using a weighted sum\n    combined_marginal = 0.5 * marginal1 + 0.5 * marginal2\n\n    # Sort items by combined marginal contribution\n    sorted_items = np.argsort(combined_marginal)[::-1]\n\n    # Randomly select a subset of top items to flip\n    num_flips = min(3, len(sorted_items))\n    flip_indices = random.sample(range(num_flips), random.randint(1, num_flips))\n\n    for idx in flip_indices:\n        item = sorted_items[idx]\n        if new_solution[item] == 1:\n            # If item is included, try to exclude it\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[item]) <= capacity:\n                new_solution[item] = 0\n        else:\n            # If item is excluded, try to include it\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.5549372069372871,
            9.2174953520298
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with a higher probability if it has more \"1\"s (indicating potential for improvement)\n    weights = [np.sum(sol) for sol, _ in archive]\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        probabilities = [w / total_weight for w in weights]\n        selected_idx = random.choices(range(len(archive)), weights=probabilities, k=1)[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator: flip a subset of items based on their marginal contribution\n    # Calculate marginal contributions for both objectives\n    marginal1 = value1_lst / weight_lst\n    marginal2 = value2_lst / weight_lst\n\n    # Combine marginal contributions using a weighted sum\n    combined_marginal = 0.5 * marginal1 + 0.5 * marginal2\n\n    # Sort items by combined marginal contribution\n    sorted_items = np.argsort(combined_marginal)[::-1]\n\n    # Randomly select a subset of top items to flip\n    num_flips = min(3, len(sorted_items))\n    flip_indices = random.sample(range(num_flips), random.randint(1, num_flips))\n\n    for idx in flip_indices:\n        item = sorted_items[idx]\n        if new_solution[item] == 1:\n            # If item is included, try to exclude it\n            if np.sum(weight_lst[new_solution == 1] - weight_lst[item]) <= capacity:\n                new_solution[item] = 0\n        else:\n            # If item is excluded, try to include it\n            if np.sum(weight_lst[new_solution == 1] + weight_lst[item]) <= capacity:\n                new_solution[item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 229,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_solution = None\n    selected_obj = None\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Avoid solutions too close to capacity\n            selected_solution = sol.copy()\n            selected_obj = obj\n            break\n\n    if selected_solution is None:\n        selected_solution, selected_obj = archive[0]  # Fallback to first solution if none found\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: flip a subset of items based on value-to-weight ratio\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios and select top items to potentially flip\n    combined_ratio = value_ratio1 + value_ratio2\n    top_items = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):]  # Consider top 5 items\n\n    # Randomly flip a subset of the top items\n    for i in top_items:\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility by removing items if over capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest combined value-to-weight ratio until feasible\n        while total_weight > capacity:\n            lowest_ratio_idx = np.argmin(combined_ratio * new_solution)\n            if new_solution[lowest_ratio_idx] == 0:\n                break  # No items left to remove\n            new_solution[lowest_ratio_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.7554555791918931,
            4.267841339111328
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the boundary)\n    selected_solution = None\n    selected_obj = None\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Avoid solutions too close to capacity\n            selected_solution = sol.copy()\n            selected_obj = obj\n            break\n\n    if selected_solution is None:\n        selected_solution, selected_obj = archive[0]  # Fallback to first solution if none found\n\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: flip a subset of items based on value-to-weight ratio\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios and select top items to potentially flip\n    combined_ratio = value_ratio1 + value_ratio2\n    top_items = np.argsort(combined_ratio)[-min(5, len(combined_ratio)):]  # Consider top 5 items\n\n    # Randomly flip a subset of the top items\n    for i in top_items:\n        if np.random.rand() < 0.3:  # 30% chance to flip\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility by removing items if over capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest combined value-to-weight ratio until feasible\n        while total_weight > capacity:\n            lowest_ratio_idx = np.argmin(combined_ratio * new_solution)\n            if new_solution[lowest_ratio_idx] == 0:\n                break  # No items left to remove\n            new_solution[lowest_ratio_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 230,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not all items are included)\n    selected_idx = np.argmin([np.sum(sol) for sol, _ in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Flip-based move: randomly flip one item if feasible\n    if current_weight < capacity:\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            flip_idx = np.random.choice(candidate_items)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Swap-based move: swap two items if one is in and one is out\n    if np.sum(new_solution) > 0:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            swap_in = np.random.choice(in_items)\n            swap_out = np.random.choice(out_items)\n\n            if (current_weight - weight_lst[swap_in] + weight_lst[swap_out]) <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    # If no improvement possible, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            flip_idx = np.random.choice(available_items)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8621135122961878,
            1.7688764035701752
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not all items are included)\n    selected_idx = np.argmin([np.sum(sol) for sol, _ in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine flip-based and swap-based moves\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Flip-based move: randomly flip one item if feasible\n    if current_weight < capacity:\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            flip_idx = np.random.choice(candidate_items)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Swap-based move: swap two items if one is in and one is out\n    if np.sum(new_solution) > 0:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            swap_in = np.random.choice(in_items)\n            swap_out = np.random.choice(out_items)\n\n            if (current_weight - weight_lst[swap_in] + weight_lst[swap_out]) <= capacity:\n                new_solution[swap_in] = 0\n                new_solution[swap_out] = 1\n\n    # If no improvement possible, perform a random flip\n    if np.array_equal(new_solution, base_solution):\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            flip_idx = np.random.choice(available_items)\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 231,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate potential improvement scores (normalized)\n    potential_scores = []\n    for i in range(len(archive_solutions)):\n        # Score based on value density and remaining capacity\n        value_density1 = archive_values1[i] / max(archive_weights[i], 1)\n        value_density2 = archive_values2[i] / max(archive_weights[i], 1)\n        remaining_capacity = max(capacity - archive_weights[i], 0)\n        potential_score = (value_density1 + value_density2) * (1 + 0.1 * remaining_capacity / capacity)\n        potential_scores.append(potential_score)\n\n    # Select top 20% of solutions with highest potential\n    top_indices = np.argsort(potential_scores)[-max(1, len(archive) // 5):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = archive_weights[selected_idx]\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random swaps (exploration)\n    for _ in range(3):\n        i, j = random.sample(range(len(new_solution)), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Value-based flips (exploitation)\n    # Flip items with high value density in one objective and low in the other\n    for obj in [1, 2]:\n        if obj == 1:\n            value_lst = value1_lst\n        else:\n            value_lst = value2_lst\n\n        value_density = value_lst / np.maximum(weight_lst, 1)\n        sorted_indices = np.argsort(value_density)[::-1]\n\n        for idx in sorted_indices[:5]:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                # Consider removing low-value items\n                if value_density[idx] < np.median(value_density):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 3: Capacity adjustment (feasibility)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items with lowest value density in both objectives\n        combined_value_density = (value1_lst + value2_lst) / np.maximum(weight_lst, 1)\n        sorted_indices = np.argsort(combined_value_density)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.3689815355476954,
            9.482077568769455
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    archive_weights = [np.sum(weight_lst * sol) for sol in archive_solutions]\n    archive_values1 = [np.sum(value1_lst * sol) for sol in archive_solutions]\n    archive_values2 = [np.sum(value2_lst * sol) for sol in archive_solutions]\n\n    # Calculate potential improvement scores (normalized)\n    potential_scores = []\n    for i in range(len(archive_solutions)):\n        # Score based on value density and remaining capacity\n        value_density1 = archive_values1[i] / max(archive_weights[i], 1)\n        value_density2 = archive_values2[i] / max(archive_weights[i], 1)\n        remaining_capacity = max(capacity - archive_weights[i], 0)\n        potential_score = (value_density1 + value_density2) * (1 + 0.1 * remaining_capacity / capacity)\n        potential_scores.append(potential_score)\n\n    # Select top 20% of solutions with highest potential\n    top_indices = np.argsort(potential_scores)[-max(1, len(archive) // 5):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive_solutions[selected_idx].copy()\n    current_weight = archive_weights[selected_idx]\n\n    # Hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random swaps (exploration)\n    for _ in range(3):\n        i, j = random.sample(range(len(new_solution)), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Value-based flips (exploitation)\n    # Flip items with high value density in one objective and low in the other\n    for obj in [1, 2]:\n        if obj == 1:\n            value_lst = value1_lst\n        else:\n            value_lst = value2_lst\n\n        value_density = value_lst / np.maximum(weight_lst, 1)\n        sorted_indices = np.argsort(value_density)[::-1]\n\n        for idx in sorted_indices[:5]:\n            if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            elif new_solution[idx] == 1:\n                # Consider removing low-value items\n                if value_density[idx] < np.median(value_density):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n\n    # Step 3: Capacity adjustment (feasibility)\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items with lowest value density in both objectives\n        combined_value_density = (value1_lst + value2_lst) / np.maximum(weight_lst, 1)\n        sorted_indices = np.argsort(combined_value_density)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 232,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate the \"improvement potential\" as the sum of normalized differences from the max values\n    max_value1 = max(obj[0] for obj in objectives)\n    max_value2 = max(obj[1] for obj in objectives)\n\n    potentials = []\n    for sol, obj in zip(solutions, objectives):\n        # Calculate how far this solution is from the max values (normalized)\n        potential = (max_value1 - obj[0]) / max_value1 + (max_value2 - obj[1]) / max_value2\n        potentials.append(potential)\n\n    # Select the solution with the highest potential for improvement\n    selected_idx = np.argmax(potentials)\n    base_solution = solutions[selected_idx].copy()\n    current_value1, current_value2 = objectives[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Randomly flip items with a bias towards improving value1 or value2\n    new_solution = base_solution.copy()\n    num_items = len(base_solution)\n\n    # Randomly select a subset of items to flip (between 1 and 10% of items)\n    flip_count = min(max(1, int(0.1 * num_items)), num_items)\n    flip_indices = random.sample(range(num_items), flip_count)\n\n    # For each selected item, decide to flip based on a greedy criterion\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If item is included, consider removing it if it's not critical\n            if current_weight - weight_lst[idx] <= capacity:\n                # Greedy: Remove if it doesn't significantly impact the other objective\n                if (current_value1 - value1_lst[idx] >= 0.9 * current_value1 and\n                    current_value2 - value2_lst[idx] >= 0.9 * current_value2):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    current_value1 -= value1_lst[idx]\n                    current_value2 -= value2_lst[idx]\n        else:\n            # If item is excluded, consider adding it if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                # Greedy: Add if it improves at least one objective significantly\n                if (value1_lst[idx] > 0.1 * max_value1 or value2_lst[idx] > 0.1 * max_value2):\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    current_value1 += value1_lst[idx]\n                    current_value2 += value2_lst[idx]\n\n    # If no changes were made, perform a random flip to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.choice(range(num_items))\n        if base_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.8868752910486415,
            1.4164782166481018
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate the \"improvement potential\" as the sum of normalized differences from the max values\n    max_value1 = max(obj[0] for obj in objectives)\n    max_value2 = max(obj[1] for obj in objectives)\n\n    potentials = []\n    for sol, obj in zip(solutions, objectives):\n        # Calculate how far this solution is from the max values (normalized)\n        potential = (max_value1 - obj[0]) / max_value1 + (max_value2 - obj[1]) / max_value2\n        potentials.append(potential)\n\n    # Select the solution with the highest potential for improvement\n    selected_idx = np.argmax(potentials)\n    base_solution = solutions[selected_idx].copy()\n    current_value1, current_value2 = objectives[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search: Randomly flip items with a bias towards improving value1 or value2\n    new_solution = base_solution.copy()\n    num_items = len(base_solution)\n\n    # Randomly select a subset of items to flip (between 1 and 10% of items)\n    flip_count = min(max(1, int(0.1 * num_items)), num_items)\n    flip_indices = random.sample(range(num_items), flip_count)\n\n    # For each selected item, decide to flip based on a greedy criterion\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            # If item is included, consider removing it if it's not critical\n            if current_weight - weight_lst[idx] <= capacity:\n                # Greedy: Remove if it doesn't significantly impact the other objective\n                if (current_value1 - value1_lst[idx] >= 0.9 * current_value1 and\n                    current_value2 - value2_lst[idx] >= 0.9 * current_value2):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    current_value1 -= value1_lst[idx]\n                    current_value2 -= value2_lst[idx]\n        else:\n            # If item is excluded, consider adding it if it fits\n            if current_weight + weight_lst[idx] <= capacity:\n                # Greedy: Add if it improves at least one objective significantly\n                if (value1_lst[idx] > 0.1 * max_value1 or value2_lst[idx] > 0.1 * max_value2):\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    current_value1 += value1_lst[idx]\n                    current_value2 += value2_lst[idx]\n\n    # If no changes were made, perform a random flip to ensure progress\n    if np.array_equal(new_solution, base_solution):\n        random_idx = random.choice(range(num_items))\n        if base_solution[random_idx] == 1:\n            if current_weight - weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 0\n        else:\n            if current_weight + weight_lst[random_idx] <= capacity:\n                new_solution[random_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 233,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution: prioritize those with high potential for improvement\n    # Calculate potential improvement for each solution in the archive\n    potential = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        # Potential is based on the sum of values of items not in the solution that can fit\n        potential.append(np.sum((value1_lst + value2_lst) * (1 - sol) * (weight_lst <= remaining_capacity)))\n\n    # Select the solution with the highest potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid approach: random flips with value-based heuristic\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be added or removed\n    candidate_add = np.where((1 - new_solution) & (weight_lst <= (capacity - total_weight)))[0]\n    candidate_remove = np.where(new_solution)[0]\n\n    # Randomly select a subset of candidates to flip\n    if len(candidate_add) + len(candidate_remove) > 0:\n        # Heuristic: prefer adding items with high combined value or removing low-value items\n        if np.random.rand() < 0.7 and len(candidate_add) > 0:\n            # Add high-value item\n            high_value_items = np.argsort((value1_lst + value2_lst) * (weight_lst <= (capacity - total_weight)))[::-1]\n            for item in high_value_items:\n                if weight_lst[item] <= (capacity - total_weight):\n                    new_solution[item] = 1\n                    total_weight += weight_lst[item]\n                    break\n        else:\n            # Remove low-value item\n            low_value_items = np.argsort((value1_lst + value2_lst) * new_solution)\n            for item in low_value_items:\n                if new_solution[item] == 1:\n                    new_solution[item] = 0\n                    total_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.8559000412725516,
            4.86697855591774
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution: prioritize those with high potential for improvement\n    # Calculate potential improvement for each solution in the archive\n    potential = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - total_weight\n        # Potential is based on the sum of values of items not in the solution that can fit\n        potential.append(np.sum((value1_lst + value2_lst) * (1 - sol) * (weight_lst <= remaining_capacity)))\n\n    # Select the solution with the highest potential\n    selected_idx = np.argmax(potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a hybrid approach: random flips with value-based heuristic\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be added or removed\n    candidate_add = np.where((1 - new_solution) & (weight_lst <= (capacity - total_weight)))[0]\n    candidate_remove = np.where(new_solution)[0]\n\n    # Randomly select a subset of candidates to flip\n    if len(candidate_add) + len(candidate_remove) > 0:\n        # Heuristic: prefer adding items with high combined value or removing low-value items\n        if np.random.rand() < 0.7 and len(candidate_add) > 0:\n            # Add high-value item\n            high_value_items = np.argsort((value1_lst + value2_lst) * (weight_lst <= (capacity - total_weight)))[::-1]\n            for item in high_value_items:\n                if weight_lst[item] <= (capacity - total_weight):\n                    new_solution[item] = 1\n                    total_weight += weight_lst[item]\n                    break\n        else:\n            # Remove low-value item\n            low_value_items = np.argsort((value1_lst + value2_lst) * new_solution)\n            for item in low_value_items:\n                if new_solution[item] == 1:\n                    new_solution[item] = 0\n                    total_weight -= weight_lst[item]\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 234,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Calculate a score for each solution based on normalized objective values\n        max_value1 = max(obj[0] for _, obj in archive)\n        max_value2 = max(obj[1] for _, obj in archive)\n        scores = [(obj[0]/max_value1 + obj[1]/max_value2) for _, obj in archive]\n        selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip, swap, and multi-flip\n    operation = random.choice(['flip', 'swap', 'multi-flip'])\n\n    if operation == 'flip':\n        # Flip a random bit (add/remove an item)\n        candidate_indices = np.where(base_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = random.choice(candidate_indices)\n            current_weight = np.sum(weight_lst[base_solution == 1])\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        else:\n            # If no items can be added, remove a random item\n            candidate_indices = np.where(base_solution == 1)[0]\n            if len(candidate_indices) > 0:\n                flip_idx = random.choice(candidate_indices)\n                new_solution[flip_idx] = 0\n\n    elif operation == 'swap':\n        # Swap two items (one in, one out)\n        in_indices = np.where(base_solution == 0)[0]\n        out_indices = np.where(base_solution == 1)[0]\n\n        if len(in_indices) > 0 and len(out_indices) > 0:\n            in_idx = random.choice(in_indices)\n            out_idx = random.choice(out_indices)\n\n            current_weight = np.sum(weight_lst[base_solution == 1])\n            new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n\n            if new_weight <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n\n    elif operation == 'multi-flip':\n        # Flip multiple bits (add/remove multiple items)\n        n_flips = random.randint(1, min(3, len(base_solution)))\n        flip_indices = random.sample(range(len(base_solution)), n_flips)\n\n        current_weight = np.sum(weight_lst[base_solution == 1])\n        for idx in flip_indices:\n            if base_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.33319221165557883,
            3.6095714569091797
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Calculate a score for each solution based on normalized objective values\n        max_value1 = max(obj[0] for _, obj in archive)\n        max_value2 = max(obj[1] for _, obj in archive)\n        scores = [(obj[0]/max_value1 + obj[1]/max_value2) for _, obj in archive]\n        selected_idx = random.choices(range(len(archive)), weights=scores, k=1)[0]\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip, swap, and multi-flip\n    operation = random.choice(['flip', 'swap', 'multi-flip'])\n\n    if operation == 'flip':\n        # Flip a random bit (add/remove an item)\n        candidate_indices = np.where(base_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            flip_idx = random.choice(candidate_indices)\n            current_weight = np.sum(weight_lst[base_solution == 1])\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n        else:\n            # If no items can be added, remove a random item\n            candidate_indices = np.where(base_solution == 1)[0]\n            if len(candidate_indices) > 0:\n                flip_idx = random.choice(candidate_indices)\n                new_solution[flip_idx] = 0\n\n    elif operation == 'swap':\n        # Swap two items (one in, one out)\n        in_indices = np.where(base_solution == 0)[0]\n        out_indices = np.where(base_solution == 1)[0]\n\n        if len(in_indices) > 0 and len(out_indices) > 0:\n            in_idx = random.choice(in_indices)\n            out_idx = random.choice(out_indices)\n\n            current_weight = np.sum(weight_lst[base_solution == 1])\n            new_weight = current_weight - weight_lst[out_idx] + weight_lst[in_idx]\n\n            if new_weight <= capacity:\n                new_solution[out_idx] = 0\n                new_solution[in_idx] = 1\n\n    elif operation == 'multi-flip':\n        # Flip multiple bits (add/remove multiple items)\n        n_flips = random.randint(1, min(3, len(base_solution)))\n        flip_indices = random.sample(range(len(base_solution)), n_flips)\n\n        current_weight = np.sum(weight_lst[base_solution == 1])\n        for idx in flip_indices:\n            if base_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 235,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    base_solution, _ = random.choices(\n        archive,\n        weights=[1 - np.sum(sol[0]) / len(sol[0]) for sol in archive],\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: flip random bits and then apply a greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Random flip phase: flip a few random bits\n    flip_count = min(3, n_items)  # Limit the number of flips to avoid excessive changes\n    for _ in range(flip_count):\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement phase: try to add items that improve at least one objective\n    for idx in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure the solution is feasible\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Remove the item with the smallest total value (sum of value1 and value2)\n        total_values = value1_lst + value2_lst\n        remove_candidates = np.where(new_solution == 1)[0]\n        if len(remove_candidates) > 0:\n            item_to_remove = remove_candidates[np.argmin(total_values[remove_candidates])]\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3775746456359546,
            6.454380184412003
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not fully packed\n    base_solution, _ = random.choices(\n        archive,\n        weights=[1 - np.sum(sol[0]) / len(sol[0]) for sol in archive],\n        k=1\n    )[0]\n\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: flip random bits and then apply a greedy improvement\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Random flip phase: flip a few random bits\n    flip_count = min(3, n_items)  # Limit the number of flips to avoid excessive changes\n    for _ in range(flip_count):\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement phase: try to add items that improve at least one objective\n    for idx in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[idx] > 0) or (value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Ensure the solution is feasible\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        # Remove the item with the smallest total value (sum of value1 and value2)\n        total_values = value1_lst + value2_lst\n        remove_candidates = np.where(new_solution == 1)[0]\n        if len(remove_candidates) > 0:\n            item_to_remove = remove_candidates[np.argmin(total_values[remove_candidates])]\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 236,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate potential improvement: sum of marginal gains for items not in the solution\n            marginal_gains = (value1_lst + value2_lst) * (1 - sol)\n            potential = np.sum(marginal_gains[weight_lst <= (capacity - total_weight)])\n            candidates.append((sol, potential))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select the solution with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # First try to add the most valuable item not in the solution\n    available_items = np.where((1 - new_solution) & (weight_lst <= (capacity - total_weight)))[0]\n    if len(available_items) > 0:\n        # Select the item with highest combined value\n        combined_values = value1_lst[available_items] + value2_lst[available_items]\n        best_item = available_items[np.argmax(combined_values)]\n        new_solution[best_item] = 1\n        total_weight += weight_lst[best_item]\n\n    # Then try to remove the least valuable item in the solution\n    selected_items = np.where(new_solution)[0]\n    if len(selected_items) > 0:\n        # Select the item with lowest combined value\n        combined_values = value1_lst[selected_items] + value2_lst[selected_items]\n        worst_item = selected_items[np.argmin(combined_values)]\n        new_solution[worst_item] = 0\n        total_weight -= weight_lst[worst_item]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            selected_items = np.where(new_solution)[0]\n            if len(selected_items) == 0:\n                break\n            item_to_remove = random.choice(selected_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9726121144819037,
            3.8311592638492584
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate potential improvement: sum of marginal gains for items not in the solution\n            marginal_gains = (value1_lst + value2_lst) * (1 - sol)\n            potential = np.sum(marginal_gains[weight_lst <= (capacity - total_weight)])\n            candidates.append((sol, potential))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select the solution with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # First try to add the most valuable item not in the solution\n    available_items = np.where((1 - new_solution) & (weight_lst <= (capacity - total_weight)))[0]\n    if len(available_items) > 0:\n        # Select the item with highest combined value\n        combined_values = value1_lst[available_items] + value2_lst[available_items]\n        best_item = available_items[np.argmax(combined_values)]\n        new_solution[best_item] = 1\n        total_weight += weight_lst[best_item]\n\n    # Then try to remove the least valuable item in the solution\n    selected_items = np.where(new_solution)[0]\n    if len(selected_items) > 0:\n        # Select the item with lowest combined value\n        combined_values = value1_lst[selected_items] + value2_lst[selected_items]\n        worst_item = selected_items[np.argmin(combined_values)]\n        new_solution[worst_item] = 0\n        total_weight -= weight_lst[worst_item]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            selected_items = np.where(new_solution)[0]\n            if len(selected_items) == 0:\n                break\n            item_to_remove = random.choice(selected_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 236,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate potential improvement: sum of marginal gains for items not in the solution\n            marginal_gains = (value1_lst + value2_lst) * (1 - sol)\n            potential = np.sum(marginal_gains[weight_lst <= (capacity - total_weight)])\n            candidates.append((sol, potential))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select the solution with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # First try to add the most valuable item not in the solution\n    available_items = np.where((1 - new_solution) & (weight_lst <= (capacity - total_weight)))[0]\n    if len(available_items) > 0:\n        # Select the item with highest combined value\n        combined_values = value1_lst[available_items] + value2_lst[available_items]\n        best_item = available_items[np.argmax(combined_values)]\n        new_solution[best_item] = 1\n        total_weight += weight_lst[best_item]\n\n    # Then try to remove the least valuable item in the solution\n    selected_items = np.where(new_solution)[0]\n    if len(selected_items) > 0:\n        # Select the item with lowest combined value\n        combined_values = value1_lst[selected_items] + value2_lst[selected_items]\n        worst_item = selected_items[np.argmin(combined_values)]\n        new_solution[worst_item] = 0\n        total_weight -= weight_lst[worst_item]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            selected_items = np.where(new_solution)[0]\n            if len(selected_items) == 0:\n                break\n            item_to_remove = random.choice(selected_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.9726121144819037,
            3.8311592638492584
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate potential improvement: sum of marginal gains for items not in the solution\n            marginal_gains = (value1_lst + value2_lst) * (1 - sol)\n            potential = np.sum(marginal_gains[weight_lst <= (capacity - total_weight)])\n            candidates.append((sol, potential))\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select the solution with the highest potential\n    candidates.sort(key=lambda x: -x[1])\n    base_solution = candidates[0][0].copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # First try to add the most valuable item not in the solution\n    available_items = np.where((1 - new_solution) & (weight_lst <= (capacity - total_weight)))[0]\n    if len(available_items) > 0:\n        # Select the item with highest combined value\n        combined_values = value1_lst[available_items] + value2_lst[available_items]\n        best_item = available_items[np.argmax(combined_values)]\n        new_solution[best_item] = 1\n        total_weight += weight_lst[best_item]\n\n    # Then try to remove the least valuable item in the solution\n    selected_items = np.where(new_solution)[0]\n    if len(selected_items) > 0:\n        # Select the item with lowest combined value\n        combined_values = value1_lst[selected_items] + value2_lst[selected_items]\n        worst_item = selected_items[np.argmin(combined_values)]\n        new_solution[worst_item] = 0\n        total_weight -= weight_lst[worst_item]\n\n    # Ensure feasibility\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            selected_items = np.where(new_solution)[0]\n            if len(selected_items) == 0:\n                break\n            item_to_remove = random.choice(selected_items)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 237,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    archive_sorted = sorted(archive, key=lambda x: -np.sum(x[0] * value1_lst) - np.sum(x[0] * value2_lst))\n    selected_idx = random.randint(0, min(2, len(archive_sorted) - 1))  # Select from top 3 solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Hybrid local search: random perturbation followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a random subset of items\n    perturbation_size = max(1, int(len(weight_lst) * 0.1))  # Flip 10% of items\n    flip_indices = np.random.choice(len(weight_lst), size=perturbation_size, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Greedy removal to restore feasibility\n        excess = current_weight - capacity\n        while excess > 0:\n            # Remove items that contribute least to the total value (sum of both objectives)\n            item_contributions = (value1_lst + value2_lst) * new_solution\n            if np.all(item_contributions == 0):\n                break  # No items left to remove\n            remove_candidate = np.argmax(item_contributions)\n            if new_solution[remove_candidate] == 1:\n                new_solution[remove_candidate] = 0\n                excess -= weight_lst[remove_candidate]\n            else:\n                break\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n    current_weight = np.sum(new_solution * weight_lst)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = np.sum(new_solution * value1_lst) + value1_lst[item]\n            new_value2 = np.sum(new_solution * value2_lst) + value2_lst[item]\n            old_value1 = np.sum(new_solution * value1_lst)\n            old_value2 = np.sum(new_solution * value2_lst)\n\n            if (new_value1 > old_value1 and new_value2 > old_value2):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.39286527669603466,
            4.466805130243301
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligent selection: prioritize solutions with high potential for improvement\n    archive_sorted = sorted(archive, key=lambda x: -np.sum(x[0] * value1_lst) - np.sum(x[0] * value2_lst))\n    selected_idx = random.randint(0, min(2, len(archive_sorted) - 1))  # Select from top 3 solutions\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Hybrid local search: random perturbation followed by greedy improvement\n    new_solution = base_solution.copy()\n\n    # Random perturbation: flip a random subset of items\n    perturbation_size = max(1, int(len(weight_lst) * 0.1))  # Flip 10% of items\n    flip_indices = np.random.choice(len(weight_lst), size=perturbation_size, replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after perturbation\n    current_weight = np.sum(new_solution * weight_lst)\n    if current_weight > capacity:\n        # Greedy removal to restore feasibility\n        excess = current_weight - capacity\n        while excess > 0:\n            # Remove items that contribute least to the total value (sum of both objectives)\n            item_contributions = (value1_lst + value2_lst) * new_solution\n            if np.all(item_contributions == 0):\n                break  # No items left to remove\n            remove_candidate = np.argmax(item_contributions)\n            if new_solution[remove_candidate] == 1:\n                new_solution[remove_candidate] = 0\n                excess -= weight_lst[remove_candidate]\n            else:\n                break\n\n    # Greedy improvement: add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order for diversity\n    current_weight = np.sum(new_solution * weight_lst)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = np.sum(new_solution * value1_lst) + value1_lst[item]\n            new_value2 = np.sum(new_solution * value2_lst) + value2_lst[item]\n            old_value1 = np.sum(new_solution * value1_lst)\n            old_value2 = np.sum(new_solution * value2_lst)\n\n            if (new_value1 > old_value1 and new_value2 > old_value2):\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 238,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([(capacity - np.sum(weight_lst[s[0] == 1])) / capacity for s in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: combine swap and flip operations\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly select a subset of items to consider for swap\n    swap_candidates = np.random.choice(n_items, size=min(5, n_items), replace=False)\n    for i in swap_candidates:\n        if base_solution[i] == 1:\n            # Try to swap with an excluded item\n            excluded_items = np.where(base_solution == 0)[0]\n            if len(excluded_items) > 0:\n                j = np.random.choice(excluded_items)\n                temp_weight = current_weight - weight_lst[i] + weight_lst[j]\n                if temp_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = temp_weight\n                    break\n\n    # Step 2: Randomly flip a subset of items to escape local optima\n    flip_candidates = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for i in flip_candidates:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if base_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.6803398730439763,
            3.9956515431404114
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.argmax([(capacity - np.sum(weight_lst[s[0] == 1])) / capacity for s in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Hybrid local search: combine swap and flip operations\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Step 1: Randomly select a subset of items to consider for swap\n    swap_candidates = np.random.choice(n_items, size=min(5, n_items), replace=False)\n    for i in swap_candidates:\n        if base_solution[i] == 1:\n            # Try to swap with an excluded item\n            excluded_items = np.where(base_solution == 0)[0]\n            if len(excluded_items) > 0:\n                j = np.random.choice(excluded_items)\n                temp_weight = current_weight - weight_lst[i] + weight_lst[j]\n                if temp_weight <= capacity:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = temp_weight\n                    break\n\n    # Step 2: Randomly flip a subset of items to escape local optima\n    flip_candidates = np.random.choice(n_items, size=min(3, n_items), replace=False)\n    for i in flip_candidates:\n        if np.random.rand() < 0.5:  # 50% chance to flip\n            if base_solution[i] == 1:\n                if current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 239,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower total weight (more room for improvement)\n    base_solution, _ = max(archive, key=lambda x: (np.sum(weight_lst[x[0] == 1]) / capacity, -np.sum(x[0])))\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine bit-flipping and greedy addition\n    # Step 1: Randomly flip some bits (with probability based on current weight)\n    flip_prob = 0.1 + 0.4 * (1 - current_weight / capacity)\n    for i in range(len(new_solution)):\n        if np.random.rand() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility after flipping\n    new_weight = np.sum(weight_lst[new_solution == 1])\n    if new_weight > capacity:\n        # Remove excess items by greedily removing those with lowest \"value density\" (value1 + value2)/weight\n        excess_weight = new_weight - capacity\n        item_densities = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_densities)\n        for i in sorted_indices:\n            if new_solution[i] == 1 and excess_weight <= 0:\n                break\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                excess_weight -= weight_lst[i]\n\n    # Step 2: Greedily add items not in the solution with highest \"value density\"\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n    item_densities = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(item_densities)[::-1]\n\n    for i in sorted_indices:\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_weight:\n            new_solution[i] = 1\n            remaining_weight -= weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3616139009366497,
            4.427718102931976
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower total weight (more room for improvement)\n    base_solution, _ = max(archive, key=lambda x: (np.sum(weight_lst[x[0] == 1]) / capacity, -np.sum(x[0])))\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine bit-flipping and greedy addition\n    # Step 1: Randomly flip some bits (with probability based on current weight)\n    flip_prob = 0.1 + 0.4 * (1 - current_weight / capacity)\n    for i in range(len(new_solution)):\n        if np.random.rand() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility after flipping\n    new_weight = np.sum(weight_lst[new_solution == 1])\n    if new_weight > capacity:\n        # Remove excess items by greedily removing those with lowest \"value density\" (value1 + value2)/weight\n        excess_weight = new_weight - capacity\n        item_densities = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(item_densities)\n        for i in sorted_indices:\n            if new_solution[i] == 1 and excess_weight <= 0:\n                break\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                excess_weight -= weight_lst[i]\n\n    # Step 2: Greedily add items not in the solution with highest \"value density\"\n    remaining_weight = capacity - np.sum(weight_lst[new_solution == 1])\n    item_densities = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(item_densities)[::-1]\n\n    for i in sorted_indices:\n        if new_solution[i] == 0 and weight_lst[i] <= remaining_weight:\n            new_solution[i] = 1\n            remaining_weight -= weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 240,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine random perturbation with value-based swaps\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a small number of items (perturbation)\n    num_flips = min(3, len(base_solution))  # Limit flips to avoid excessive changes\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after flips\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        while new_weight > capacity and len(excess_indices) > 0:\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            new_weight -= weight_lst[remove_idx]\n            excess_indices = np.where(new_solution == 1)[0]\n\n    # Step 2: Value-based swaps to improve both objectives\n    # Calculate value ratios for each item\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by combined value ratio (weighted sum)\n    combined_ratio = 0.5 * value_ratio1 + 0.5 * value_ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Try to replace low-value items with high-value ones\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n            old_value1, old_value2 = archive[selected_idx][1]\n\n            if (new_value1 > old_value1 and new_value2 > old_value2) or \\\n               (np.random.random() < 0.3):  # Sometimes accept non-dominated swaps\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.37536481527008936,
            2.7341721951961517
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combine random perturbation with value-based swaps\n    new_solution = base_solution.copy()\n\n    # Step 1: Randomly flip a small number of items (perturbation)\n    num_flips = min(3, len(base_solution))  # Limit flips to avoid excessive changes\n    flip_indices = np.random.choice(len(base_solution), size=num_flips, replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after flips\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        while new_weight > capacity and len(excess_indices) > 0:\n            remove_idx = np.random.choice(excess_indices)\n            new_solution[remove_idx] = 0\n            new_weight -= weight_lst[remove_idx]\n            excess_indices = np.where(new_solution == 1)[0]\n\n    # Step 2: Value-based swaps to improve both objectives\n    # Calculate value ratios for each item\n    value_ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    value_ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by combined value ratio (weighted sum)\n    combined_ratio = 0.5 * value_ratio1 + 0.5 * value_ratio2\n    sorted_indices = np.argsort(combined_ratio)[::-1]\n\n    # Try to replace low-value items with high-value ones\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and (current_weight + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n            old_value1, old_value2 = archive[selected_idx][1]\n\n            if (new_value1 > old_value1 and new_value2 > old_value2) or \\\n               (np.random.random() < 0.3):  # Sometimes accept non-dominated swaps\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 241,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    # Prefer solutions that are not on the Pareto front (more room for improvement)\n    # and have a good balance between the two objectives\n    base_solution, (base_val1, base_val2) = max(\n        archive,\n        key=lambda x: (np.sum(x[0]) / len(x[0])) * (x[1][0] + x[1][1])  # Balance between density and objective sum\n    )\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly perturb the solution (add/remove items)\n    # 2. Apply guided local improvement based on objective dominance\n\n    # Step 1: Random perturbation\n    for _ in range(3):  # Number of perturbation attempts\n        idx = np.random.randint(0, len(new_solution))\n        if new_solution[idx] == 1:\n            # Try to remove item if feasible\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add item if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Guided local improvement\n    # Evaluate potential of each item based on both objectives\n    item_potential = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_indices = np.argsort(item_potential)[::-1]  # Sort by descending potential\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Add the most promising item if feasible\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            # Remove the least promising item if feasible\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5344260346594372,
            3.1024937331676483
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with high potential for improvement\n    # Prefer solutions that are not on the Pareto front (more room for improvement)\n    # and have a good balance between the two objectives\n    base_solution, (base_val1, base_val2) = max(\n        archive,\n        key=lambda x: (np.sum(x[0]) / len(x[0])) * (x[1][0] + x[1][1])  # Balance between density and objective sum\n    )\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly perturb the solution (add/remove items)\n    # 2. Apply guided local improvement based on objective dominance\n\n    # Step 1: Random perturbation\n    for _ in range(3):  # Number of perturbation attempts\n        idx = np.random.randint(0, len(new_solution))\n        if new_solution[idx] == 1:\n            # Try to remove item if feasible\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add item if feasible\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Guided local improvement\n    # Evaluate potential of each item based on both objectives\n    item_potential = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_indices = np.argsort(item_potential)[::-1]  # Sort by descending potential\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            # Add the most promising item if feasible\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            # Remove the least promising item if feasible\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 242,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not on the Pareto front)\n    # Here, we select a solution that is not dominated by any other solution in the archive\n    # and has a high potential for improvement in at least one objective\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight <= capacity:\n            # Check if this solution is not dominated by any other solution\n            is_non_dominated = True\n            for other_sol, other_obj in archive:\n                if (other_obj[0] >= archive[0][1][0] and other_obj[1] > archive[0][1][1]) or \\\n                   (other_obj[0] > archive[0][1][0] and other_obj[1] >= archive[0][1][1]):\n                    is_non_dominated = False\n                    break\n            if is_non_dominated:\n                candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest potential for improvement\n        # Here, we use a simple heuristic: select the solution with the highest sum of value1 and value2\n        base_solution = max(candidates, key=lambda sol: np.sum(value1_lst * sol) + np.sum(value2_lst * sol)).copy()\n\n    # Generate a neighbor solution using a hybrid local search strategy\n    # Strategy: Flip a random subset of items, then perform a greedy improvement step\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Flip a random subset of items (with probability 0.2 for each item)\n    for i in range(n_items):\n        if random.random() < 0.2:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break  # No items left to remove\n            item_to_remove = random.choice(items_in_solution)\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n\n    # Step 2: Greedy improvement - add items that improve at least one objective\n    remaining_items = np.where(new_solution == 0)[0]\n    random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[item] > 0) or (value2_lst[item] > 0):\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.29687209101160644,
            4.005657285451889
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not on the Pareto front)\n    # Here, we select a solution that is not dominated by any other solution in the archive\n    # and has a high potential for improvement in at least one objective\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight <= capacity:\n            # Check if this solution is not dominated by any other solution\n            is_non_dominated = True\n            for other_sol, other_obj in archive:\n                if (other_obj[0] >= archive[0][1][0] and other_obj[1] > archive[0][1][1]) or \\\n                   (other_obj[0] > archive[0][1][0] and other_obj[1] >= archive[0][1][1]):\n                    is_non_dominated = False\n                    break\n            if is_non_dominated:\n                candidates.append(sol)\n\n    if not candidates:\n        # If no candidates found, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest potential for improvement\n        # Here, we use a simple heuristic: select the solution with the highest sum of value1 and value2\n        base_solution = max(candidates, key=lambda sol: np.sum(value1_lst * sol) + np.sum(value2_lst * sol)).copy()\n\n    # Generate a neighbor solution using a hybrid local search strategy\n    # Strategy: Flip a random subset of items, then perform a greedy improvement step\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Step 1: Flip a random subset of items (with probability 0.2 for each item)\n    for i in range(n_items):\n        if random.random() < 0.2:\n            new_solution[i] = 1 - new_solution[i]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        while total_weight > capacity:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break  # No items left to remove\n            item_to_remove = random.choice(items_in_solution)\n            new_solution[item_to_remove] = 0\n            total_weight -= weight_lst[item_to_remove]\n\n    # Step 2: Greedy improvement - add items that improve at least one objective\n    remaining_items = np.where(new_solution == 0)[0]\n    random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Check if adding this item improves at least one objective\n            if (value1_lst[item] > 0) or (value2_lst[item] > 0):\n                new_solution[item] = 1\n                total_weight += weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 243,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: combine bit-flip with value-based selection\n    for _ in range(3):  # Perform 3 local search steps\n        # Identify items that can be flipped without exceeding capacity\n        excluded_items = np.where(new_solution == 0)[0]\n        included_items = np.where(new_solution == 1)[0]\n\n        # Calculate potential improvements\n        potential_additions = []\n        for item in excluded_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Calculate marginal gains for both objectives\n                marginal_value1 = value1_lst[item]\n                marginal_value2 = value2_lst[item]\n                potential_additions.append((item, marginal_value1, marginal_value2))\n\n        potential_removals = []\n        for item in included_items:\n            # Calculate marginal losses for both objectives\n            marginal_value1 = -value1_lst[item]\n            marginal_value2 = -value2_lst[item]\n            potential_removals.append((item, marginal_value1, marginal_value2))\n\n        # Combine potential moves and select the best one based on a weighted score\n        all_moves = potential_additions + potential_removals\n        if not all_moves:\n            break\n\n        # Weighted score: prioritize moves that improve both objectives\n        scores = [v1 + v2 for (_, v1, v2) in all_moves]\n        best_move_idx = np.argmax(scores)\n        best_item, _, _ = all_moves[best_move_idx]\n\n        # Apply the best move\n        if new_solution[best_item] == 0:\n            new_solution[best_item] = 1\n            current_weight += weight_lst[best_item]\n        else:\n            new_solution[best_item] = 0\n            current_weight -= weight_lst[best_item]\n\n    return new_solution\n\n",
        "score": [
            -0.21585293756706725,
            3.4709709882736206
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: combine bit-flip with value-based selection\n    for _ in range(3):  # Perform 3 local search steps\n        # Identify items that can be flipped without exceeding capacity\n        excluded_items = np.where(new_solution == 0)[0]\n        included_items = np.where(new_solution == 1)[0]\n\n        # Calculate potential improvements\n        potential_additions = []\n        for item in excluded_items:\n            if current_weight + weight_lst[item] <= capacity:\n                # Calculate marginal gains for both objectives\n                marginal_value1 = value1_lst[item]\n                marginal_value2 = value2_lst[item]\n                potential_additions.append((item, marginal_value1, marginal_value2))\n\n        potential_removals = []\n        for item in included_items:\n            # Calculate marginal losses for both objectives\n            marginal_value1 = -value1_lst[item]\n            marginal_value2 = -value2_lst[item]\n            potential_removals.append((item, marginal_value1, marginal_value2))\n\n        # Combine potential moves and select the best one based on a weighted score\n        all_moves = potential_additions + potential_removals\n        if not all_moves:\n            break\n\n        # Weighted score: prioritize moves that improve both objectives\n        scores = [v1 + v2 for (_, v1, v2) in all_moves]\n        best_move_idx = np.argmax(scores)\n        best_item, _, _ = all_moves[best_move_idx]\n\n        # Apply the best move\n        if new_solution[best_item] == 0:\n            new_solution[best_item] = 1\n            current_weight += weight_lst[best_item]\n        else:\n            new_solution[best_item] = 0\n            current_weight -= weight_lst[best_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 244,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Here, we select a solution that is not too close to the boundary (i.e., not all items are included or excluded)\n    # This helps in avoiding local optima\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor solution using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation - flip a random subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove excess items randomly until feasible\n        excess = total_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        while excess > 0 and len(excess_items) > 0:\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order to avoid bias\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = current_value1 + value1_lst[item]\n            new_value2 = current_value2 + value2_lst[item]\n            # If the solution is dominated by the current best, skip\n            dominated = False\n            for (_, (v1, v2)) in archive:\n                if v1 >= new_value1 and v2 >= new_value2 and (v1 > new_value1 or v2 > new_value2):\n                    dominated = True\n                    break\n            if not dominated:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.3424245742786115,
            2.273420959711075
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Here, we select a solution that is not too close to the boundary (i.e., not all items are included or excluded)\n    # This helps in avoiding local optima\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate a neighbor solution using a hybrid local search strategy\n    new_solution = base_solution.copy()\n\n    # Step 1: Random perturbation - flip a random subset of items\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility after perturbation\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove excess items randomly until feasible\n        excess = total_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        while excess > 0 and len(excess_items) > 0:\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            excess -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    # Step 2: Greedy improvement - add items that improve both objectives\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)  # Randomize order to avoid bias\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            # Check if adding the item improves both objectives\n            new_value1 = current_value1 + value1_lst[item]\n            new_value2 = current_value2 + value2_lst[item]\n            # If the solution is dominated by the current best, skip\n            dominated = False\n            for (_, (v1, v2)) in archive:\n                if v1 >= new_value1 and v2 >= new_value2 and (v1 > new_value1 or v2 > new_value2):\n                    dominated = True\n                    break\n            if not dominated:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 245,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prioritize solutions with lower total weight or higher objective values\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, (obj1, obj2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random swap of two items (if solution has at least 2 items)\n    if np.sum(new_solution) >= 2:\n        indices = np.where(new_solution == 1)[0]\n        if len(indices) >= 2:\n            i, j = np.random.choice(indices, 2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Objective-weighted flip: flip items based on their contribution to objectives\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)  # avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginals with current objectives\n    combined_marginal = (marginal1 * obj1) + (marginal2 * obj2)\n\n    # Flip items with low marginal contribution\n    flip_prob = np.exp(-combined_marginal / (np.max(combined_marginal) + 1e-6))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    flip_mask[new_solution == 0] = False  # only flip included items\n\n    # Apply flips while maintaining feasibility\n    for i in np.where(flip_mask)[0]:\n        if new_solution[i] == 1:\n            new_solution[i] = 0\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[i] = 1  # revert if infeasible\n\n    # 3. Capacity-aware perturbation: add/remove items based on remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Add items with high marginal value\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            candidate_values = (value1_lst + value2_lst)[available_items]\n            candidate_weights = weight_lst[available_items]\n            # Select items with high value-to-weight ratio and that fit in remaining capacity\n            candidates = available_items[np.logical_and(\n                candidate_values > np.percentile(candidate_values, 75),\n                candidate_weights <= remaining_capacity\n            )]\n            if len(candidates) > 0:\n                selected_item = np.random.choice(candidates)\n                new_solution[selected_item] = 1\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove random item if over capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            remove_item = np.random.choice(included_items)\n            new_solution[remove_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.892302692423665,
            5.732622981071472
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligently select a solution with potential for improvement\n    # Prioritize solutions with lower total weight or higher objective values\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, (obj1, obj2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * selected_solution)\n\n    # Create a copy of the selected solution\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random swap of two items (if solution has at least 2 items)\n    if np.sum(new_solution) >= 2:\n        indices = np.where(new_solution == 1)[0]\n        if len(indices) >= 2:\n            i, j = np.random.choice(indices, 2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Objective-weighted flip: flip items based on their contribution to objectives\n    # Calculate marginal contributions\n    marginal1 = value1_lst / (weight_lst + 1e-6)  # avoid division by zero\n    marginal2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginals with current objectives\n    combined_marginal = (marginal1 * obj1) + (marginal2 * obj2)\n\n    # Flip items with low marginal contribution\n    flip_prob = np.exp(-combined_marginal / (np.max(combined_marginal) + 1e-6))\n    flip_mask = np.random.rand(len(weight_lst)) < flip_prob\n    flip_mask[new_solution == 0] = False  # only flip included items\n\n    # Apply flips while maintaining feasibility\n    for i in np.where(flip_mask)[0]:\n        if new_solution[i] == 1:\n            new_solution[i] = 0\n            if np.sum(weight_lst * new_solution) > capacity:\n                new_solution[i] = 1  # revert if infeasible\n\n    # 3. Capacity-aware perturbation: add/remove items based on remaining capacity\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Add items with high marginal value\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            candidate_values = (value1_lst + value2_lst)[available_items]\n            candidate_weights = weight_lst[available_items]\n            # Select items with high value-to-weight ratio and that fit in remaining capacity\n            candidates = available_items[np.logical_and(\n                candidate_values > np.percentile(candidate_values, 75),\n                candidate_weights <= remaining_capacity\n            )]\n            if len(candidates) > 0:\n                selected_item = np.random.choice(candidates)\n                new_solution[selected_item] = 1\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove random item if over capacity\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            remove_item = np.random.choice(included_items)\n            new_solution[remove_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 246,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_solution, _ = archive[np.random.randint(len(archive))]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of bits (1 to 3) to introduce diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 4), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If removing, ensure weight doesn't exceed capacity\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If adding, ensure weight doesn't exceed capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Perform targeted swaps to improve both objectives\n    # Identify items not in the solution with high marginal value\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate marginal value for each objective\n        marginal_value1 = value1_lst[not_in_solution]\n        marginal_value2 = value2_lst[not_in_solution]\n\n        # Select top 2 items with highest marginal value for each objective\n        top1_indices = not_in_solution[np.argsort(marginal_value1)[-2:]]\n        top2_indices = not_in_solution[np.argsort(marginal_value2)[-2:]]\n\n        # Combine and consider unique candidates\n        candidate_indices = np.unique(np.concatenate([top1_indices, top2_indices]))\n\n        # Try to add these candidates if feasible\n        for idx in candidate_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 3. Remove low-value items to create space for higher-value items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal value for each objective\n        marginal_value1 = value1_lst[in_solution]\n        marginal_value2 = value2_lst[in_solution]\n\n        # Calculate normalized marginal values (to balance both objectives)\n        norm_value1 = marginal_value1 / (np.sum(marginal_value1) + 1e-10)\n        norm_value2 = marginal_value2 / (np.sum(marginal_value2) + 1e-10)\n        combined_value = norm_value1 + norm_value2\n\n        # Identify worst-performing items (lowest combined value)\n        worst_indices = in_solution[np.argsort(combined_value)[:2]]\n\n        # Try to remove these items\n        for idx in worst_indices:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.40912274521275316,
            1.5869017839431763
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_solution, _ = archive[np.random.randint(len(archive))]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a small number of bits (1 to 3) to introduce diversity\n    flip_indices = np.random.choice(len(new_solution), size=np.random.randint(1, 4), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # If removing, ensure weight doesn't exceed capacity\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # If adding, ensure weight doesn't exceed capacity\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 2. Perform targeted swaps to improve both objectives\n    # Identify items not in the solution with high marginal value\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate marginal value for each objective\n        marginal_value1 = value1_lst[not_in_solution]\n        marginal_value2 = value2_lst[not_in_solution]\n\n        # Select top 2 items with highest marginal value for each objective\n        top1_indices = not_in_solution[np.argsort(marginal_value1)[-2:]]\n        top2_indices = not_in_solution[np.argsort(marginal_value2)[-2:]]\n\n        # Combine and consider unique candidates\n        candidate_indices = np.unique(np.concatenate([top1_indices, top2_indices]))\n\n        # Try to add these candidates if feasible\n        for idx in candidate_indices:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # 3. Remove low-value items to create space for higher-value items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal value for each objective\n        marginal_value1 = value1_lst[in_solution]\n        marginal_value2 = value2_lst[in_solution]\n\n        # Calculate normalized marginal values (to balance both objectives)\n        norm_value1 = marginal_value1 / (np.sum(marginal_value1) + 1e-10)\n        norm_value2 = marginal_value2 / (np.sum(marginal_value2) + 1e-10)\n        combined_value = norm_value1 + norm_value2\n\n        # Identify worst-performing items (lowest combined value)\n        worst_indices = in_solution[np.argsort(combined_value)[:2]]\n\n        # Try to remove these items\n        for idx in worst_indices:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 247,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (not dominated by others in the archive)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: random walk with value-based swaps\n    for _ in range(5):  # Number of iterations can be adjusted\n        # Randomly select an item to flip\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(weight_lst))\n        item_to_flip = np.random.choice(candidate_indices)\n\n        # Calculate potential new weight\n        new_weight = current_weight - weight_lst[item_to_flip] if new_solution[item_to_flip] else current_weight + weight_lst[item_to_flip]\n\n        # Only proceed if feasible\n        if new_weight <= capacity:\n            # Flip the item\n            new_solution[item_to_flip] = 1 - new_solution[item_to_flip]\n\n            # Update current values\n            if new_solution[item_to_flip]:\n                current_value1 += value1_lst[item_to_flip]\n                current_value2 += value2_lst[item_to_flip]\n            else:\n                current_value1 -= value1_lst[item_to_flip]\n                current_value2 -= value2_lst[item_to_flip]\n\n            current_weight = new_weight\n\n            # Perform value-based swap if possible\n            if np.random.random() < 0.3:  # 30% chance to perform swap\n                other_items = np.where(new_solution == 0)[0]\n                if len(other_items) > 0:\n                    swap_item = np.random.choice(other_items)\n                    if current_weight - weight_lst[item_to_flip] + weight_lst[swap_item] <= capacity:\n                        new_solution[item_to_flip] = 0\n                        new_solution[swap_item] = 1\n                        current_weight = current_weight - weight_lst[item_to_flip] + weight_lst[swap_item]\n                        current_value1 = current_value1 - value1_lst[item_to_flip] + value1_lst[swap_item]\n                        current_value2 = current_value2 - value2_lst[item_to_flip] + value2_lst[swap_item]\n\n    return new_solution\n\n",
        "score": [
            -0.5926406582000103,
            1.6371799111366272
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (not dominated by others in the archive)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Hybrid local search: random walk with value-based swaps\n    for _ in range(5):  # Number of iterations can be adjusted\n        # Randomly select an item to flip\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) == 0:\n            candidate_indices = np.arange(len(weight_lst))\n        item_to_flip = np.random.choice(candidate_indices)\n\n        # Calculate potential new weight\n        new_weight = current_weight - weight_lst[item_to_flip] if new_solution[item_to_flip] else current_weight + weight_lst[item_to_flip]\n\n        # Only proceed if feasible\n        if new_weight <= capacity:\n            # Flip the item\n            new_solution[item_to_flip] = 1 - new_solution[item_to_flip]\n\n            # Update current values\n            if new_solution[item_to_flip]:\n                current_value1 += value1_lst[item_to_flip]\n                current_value2 += value2_lst[item_to_flip]\n            else:\n                current_value1 -= value1_lst[item_to_flip]\n                current_value2 -= value2_lst[item_to_flip]\n\n            current_weight = new_weight\n\n            # Perform value-based swap if possible\n            if np.random.random() < 0.3:  # 30% chance to perform swap\n                other_items = np.where(new_solution == 0)[0]\n                if len(other_items) > 0:\n                    swap_item = np.random.choice(other_items)\n                    if current_weight - weight_lst[item_to_flip] + weight_lst[swap_item] <= capacity:\n                        new_solution[item_to_flip] = 0\n                        new_solution[swap_item] = 1\n                        current_weight = current_weight - weight_lst[item_to_flip] + weight_lst[swap_item]\n                        current_value1 = current_value1 - value1_lst[item_to_flip] + value1_lst[swap_item]\n                        current_value2 = current_value2 - value2_lst[item_to_flip] + value2_lst[swap_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 248,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.argmin([np.sum(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip bits of items with low value-to-weight ratio\n    value_to_weight_ratio = (value1_lst + value2_lst) / weight_lst\n    low_value_items = np.where((value_to_weight_ratio < np.median(value_to_weight_ratio)) & (base_solution == 1))[0]\n    if len(low_value_items) > 0:\n        flip_idx = np.random.choice(low_value_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # 2. Add high-value items if capacity allows\n    high_value_items = np.where((value_to_weight_ratio > np.median(value_to_weight_ratio)) & (base_solution == 0))[0]\n    for item in high_value_items:\n        if weight_lst[item] <= remaining_capacity and new_solution[item] == 0:\n            new_solution[item] = 1\n            remaining_capacity -= weight_lst[item]\n\n    # 3. Perform a value-based swap if beneficial\n    if np.random.rand() < 0.3:  # 30% chance of swap\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            swap_out = np.random.choice(included_items)\n            swap_in = np.random.choice(excluded_items)\n\n            if (weight_lst[swap_in] - weight_lst[swap_out]) <= remaining_capacity + weight_lst[swap_out]:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        while excess_weight > 0 and len(included_items) > 0:\n            remove_idx = np.random.choice(included_items)\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n            included_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.9178837934140498,
            2.795653074979782
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (e.g., not fully packed)\n    selected_idx = np.argmin([np.sum(sol[0]) for sol in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip bits of items with low value-to-weight ratio\n    value_to_weight_ratio = (value1_lst + value2_lst) / weight_lst\n    low_value_items = np.where((value_to_weight_ratio < np.median(value_to_weight_ratio)) & (base_solution == 1))[0]\n    if len(low_value_items) > 0:\n        flip_idx = np.random.choice(low_value_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # 2. Add high-value items if capacity allows\n    high_value_items = np.where((value_to_weight_ratio > np.median(value_to_weight_ratio)) & (base_solution == 0))[0]\n    for item in high_value_items:\n        if weight_lst[item] <= remaining_capacity and new_solution[item] == 0:\n            new_solution[item] = 1\n            remaining_capacity -= weight_lst[item]\n\n    # 3. Perform a value-based swap if beneficial\n    if np.random.rand() < 0.3:  # 30% chance of swap\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            swap_out = np.random.choice(included_items)\n            swap_in = np.random.choice(excluded_items)\n\n            if (weight_lst[swap_in] - weight_lst[swap_out]) <= remaining_capacity + weight_lst[swap_out]:\n                new_solution[swap_out] = 0\n                new_solution[swap_in] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess_weight = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        while excess_weight > 0 and len(included_items) > 0:\n            remove_idx = np.random.choice(included_items)\n            new_solution[remove_idx] = 0\n            excess_weight -= weight_lst[remove_idx]\n            included_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 249,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (e.g., not already on the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of bit flipping, swap, and value-based selection\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Random bit flipping (with feasibility check)\n    flip_pos = random.randint(0, n_items - 1)\n    if new_solution[flip_pos] == 1:\n        if current_weight - weight_lst[flip_pos] <= capacity:\n            new_solution[flip_pos] = 0\n    else:\n        if current_weight + weight_lst[flip_pos] <= capacity:\n            new_solution[flip_pos] = 1\n\n    # Step 2: Swap with a random item that improves both objectives\n    if random.random() < 0.5:  # 50% chance to perform swap\n        swap_pos = random.randint(0, n_items - 1)\n        while swap_pos == flip_pos:\n            swap_pos = random.randint(0, n_items - 1)\n\n        # Calculate potential improvement\n        delta_weight = weight_lst[swap_pos] - weight_lst[flip_pos]\n        delta_value1 = value1_lst[swap_pos] - value1_lst[flip_pos]\n        delta_value2 = value2_lst[swap_pos] - value2_lst[flip_pos]\n\n        if (delta_weight <= 0 or current_weight + delta_weight <= capacity) and (delta_value1 > 0 or delta_value2 > 0):\n            new_solution[flip_pos], new_solution[swap_pos] = new_solution[swap_pos], new_solution[flip_pos]\n\n    # Step 3: Add or remove items with high marginal value-to-weight ratio\n    if random.random() < 0.3:  # 30% chance to perform this step\n        # Calculate marginal ratios for items not in the solution\n        marginal_ratios = (value1_lst + value2_lst) / weight_lst\n        candidate_items = np.where(new_solution == 0)[0]\n\n        if len(candidate_items) > 0:\n            best_item = candidate_items[np.argmax(marginal_ratios[candidate_items])]\n            if current_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n        # Remove low-value items\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) > 0:\n            worst_item = candidate_items[np.argmin((value1_lst + value2_lst)[candidate_items])]\n            if current_weight - weight_lst[worst_item] >= 0:\n                new_solution[worst_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3183629132163053,
            7.635005354881287
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with potential for improvement (e.g., not already on the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of bit flipping, swap, and value-based selection\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 1: Random bit flipping (with feasibility check)\n    flip_pos = random.randint(0, n_items - 1)\n    if new_solution[flip_pos] == 1:\n        if current_weight - weight_lst[flip_pos] <= capacity:\n            new_solution[flip_pos] = 0\n    else:\n        if current_weight + weight_lst[flip_pos] <= capacity:\n            new_solution[flip_pos] = 1\n\n    # Step 2: Swap with a random item that improves both objectives\n    if random.random() < 0.5:  # 50% chance to perform swap\n        swap_pos = random.randint(0, n_items - 1)\n        while swap_pos == flip_pos:\n            swap_pos = random.randint(0, n_items - 1)\n\n        # Calculate potential improvement\n        delta_weight = weight_lst[swap_pos] - weight_lst[flip_pos]\n        delta_value1 = value1_lst[swap_pos] - value1_lst[flip_pos]\n        delta_value2 = value2_lst[swap_pos] - value2_lst[flip_pos]\n\n        if (delta_weight <= 0 or current_weight + delta_weight <= capacity) and (delta_value1 > 0 or delta_value2 > 0):\n            new_solution[flip_pos], new_solution[swap_pos] = new_solution[swap_pos], new_solution[flip_pos]\n\n    # Step 3: Add or remove items with high marginal value-to-weight ratio\n    if random.random() < 0.3:  # 30% chance to perform this step\n        # Calculate marginal ratios for items not in the solution\n        marginal_ratios = (value1_lst + value2_lst) / weight_lst\n        candidate_items = np.where(new_solution == 0)[0]\n\n        if len(candidate_items) > 0:\n            best_item = candidate_items[np.argmax(marginal_ratios[candidate_items])]\n            if current_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n        # Remove low-value items\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) > 0:\n            worst_item = candidate_items[np.argmin((value1_lst + value2_lst)[candidate_items])]\n            if current_weight - weight_lst[worst_item] >= 0:\n                new_solution[worst_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 250,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal for both objectives)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a pair of items (if possible)\n    # 2. Flip a single item based on value density (value/weight ratio)\n    # 3. Ensure feasibility at each step\n\n    # Step 1: Random swap of two items\n    if len(new_solution) >= 2:\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Value-based flip\n    # Calculate value density for each item (combine both objectives)\n    density1 = value1_lst / weight_lst\n    density2 = value2_lst / weight_lst\n    combined_density = density1 + density2  # Simple combination for this example\n\n    # Identify items with highest density not currently in the knapsack\n    candidate_items = np.where(new_solution == 0)[0]\n    if len(candidate_items) > 0:\n        best_candidate = candidate_items[np.argmax(combined_density[candidate_items])]\n        if current_weight + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    # Step 3: If still under capacity, try to add more items\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Add items with highest combined density that fit\n        remaining_items = np.where(new_solution == 0)[0]\n        if len(remaining_items) > 0:\n            remaining_density = combined_density[remaining_items]\n            sorted_indices = np.argsort(-remaining_density)\n            for idx in sorted_indices:\n                item = remaining_items[idx]\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n                    if remaining_capacity <= 0:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.3338016640329329,
            3.812479555606842
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal for both objectives)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a pair of items (if possible)\n    # 2. Flip a single item based on value density (value/weight ratio)\n    # 3. Ensure feasibility at each step\n\n    # Step 1: Random swap of two items\n    if len(new_solution) >= 2:\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Value-based flip\n    # Calculate value density for each item (combine both objectives)\n    density1 = value1_lst / weight_lst\n    density2 = value2_lst / weight_lst\n    combined_density = density1 + density2  # Simple combination for this example\n\n    # Identify items with highest density not currently in the knapsack\n    candidate_items = np.where(new_solution == 0)[0]\n    if len(candidate_items) > 0:\n        best_candidate = candidate_items[np.argmax(combined_density[candidate_items])]\n        if current_weight + weight_lst[best_candidate] <= capacity:\n            new_solution[best_candidate] = 1\n\n    # Step 3: If still under capacity, try to add more items\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Add items with highest combined density that fit\n        remaining_items = np.where(new_solution == 0)[0]\n        if len(remaining_items) > 0:\n            remaining_density = combined_density[remaining_items]\n            sorted_indices = np.argsort(-remaining_density)\n            for idx in sorted_indices:\n                item = remaining_items[idx]\n                if weight_lst[item] <= remaining_capacity:\n                    new_solution[item] = 1\n                    remaining_capacity -= weight_lst[item]\n                    if remaining_capacity <= 0:\n                        break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 251,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort by sum of objectives to find solutions with high potential\n        archive_sorted = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n        # Randomly select from top 30% of solutions\n        selected_idx = random.randint(0, max(1, len(archive_sorted) // 3 - 1))\n        base_solution, _ = archive_sorted[selected_idx]\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random bit flips with objective-aware swaps\n    for _ in range(3):  # Number of iterations\n        # Random bit flip\n        if random.random() < 0.7:  # 70% chance to flip a random bit\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n        # Objective-aware swap: swap items based on which objective to improve\n        if random.random() < 0.4:  # 40% chance to perform a swap\n            # Choose which objective to prioritize (randomly)\n            prioritize_obj1 = random.random() < 0.5\n            if prioritize_obj1:\n                # Find items that can be swapped to improve objective 1\n                candidate_indices = np.where((new_solution == 1) & (value1_lst > 0))[0]\n            else:\n                candidate_indices = np.where((new_solution == 1) & (value2_lst > 0))[0]\n\n            if len(candidate_indices) >= 2:\n                # Randomly select two items to swap\n                i, j = random.sample(list(candidate_indices), 2)\n                # Check feasibility of swap\n                if (current_weight - weight_lst[i] + weight_lst[j] <= capacity and\n                    current_weight - weight_lst[j] + weight_lst[i] <= capacity):\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.31710470896063425,
            2.084634631872177
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort by sum of objectives to find solutions with high potential\n        archive_sorted = sorted(archive, key=lambda x: sum(x[1]), reverse=True)\n        # Randomly select from top 30% of solutions\n        selected_idx = random.randint(0, max(1, len(archive_sorted) // 3 - 1))\n        base_solution, _ = archive_sorted[selected_idx]\n    else:\n        base_solution, _ = archive[0]\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Hybrid local search: random bit flips with objective-aware swaps\n    for _ in range(3):  # Number of iterations\n        # Random bit flip\n        if random.random() < 0.7:  # 70% chance to flip a random bit\n            flip_idx = random.randint(0, len(new_solution) - 1)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 0\n                    current_weight -= weight_lst[flip_idx]\n            else:\n                if current_weight + weight_lst[flip_idx] <= capacity:\n                    new_solution[flip_idx] = 1\n                    current_weight += weight_lst[flip_idx]\n\n        # Objective-aware swap: swap items based on which objective to improve\n        if random.random() < 0.4:  # 40% chance to perform a swap\n            # Choose which objective to prioritize (randomly)\n            prioritize_obj1 = random.random() < 0.5\n            if prioritize_obj1:\n                # Find items that can be swapped to improve objective 1\n                candidate_indices = np.where((new_solution == 1) & (value1_lst > 0))[0]\n            else:\n                candidate_indices = np.where((new_solution == 1) & (value2_lst > 0))[0]\n\n            if len(candidate_indices) >= 2:\n                # Randomly select two items to swap\n                i, j = random.sample(list(candidate_indices), 2)\n                # Check feasibility of swap\n                if (current_weight - weight_lst[i] + weight_lst[j] <= capacity and\n                    current_weight - weight_lst[j] + weight_lst[i] <= capacity):\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 252,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with the highest sum of normalized objectives to prioritize promising candidates\n    selected_idx = np.argmax([(obj[0] + obj[1]) / (np.max(value1_lst) + np.max(value2_lst)) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: random swaps with value-based perturbation\n    n_items = len(base_solution)\n    if n_items < 2:\n        return new_solution  # No meaningful neighbors can be generated\n\n    # Randomly select a subset of items to swap\n    swap_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n\n    # For each selected item, decide whether to swap it based on value improvement potential\n    for idx in swap_indices:\n        current_value = new_solution[idx]\n        if current_value == 1:\n            # If item is included, consider removing it if it's not critical\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n            else:\n                # If removing it violates capacity, try to swap with another item\n                other_idx = np.random.choice([i for i in range(n_items) if i != idx and new_solution[i] == 0])\n                if weight_lst[other_idx] <= weight_lst[idx] and np.sum(weight_lst * new_solution) - weight_lst[idx] + weight_lst[other_idx] <= capacity:\n                    new_solution[idx], new_solution[other_idx] = new_solution[other_idx], new_solution[idx]\n        else:\n            # If item is excluded, consider adding it if it improves value and fits\n            if weight_lst[idx] <= capacity - np.sum(weight_lst * new_solution):\n                new_solution[idx] = 1\n\n    # Ensure feasibility by repairing if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while total_weight > capacity:\n            ratios = (value1_lst + value2_lst) / weight_lst\n            ratios[new_solution == 0] = np.inf  # Ignore excluded items\n            remove_idx = np.argmin(ratios)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.288965133196077,
            6.31253182888031
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with the highest sum of normalized objectives to prioritize promising candidates\n    selected_idx = np.argmax([(obj[0] + obj[1]) / (np.max(value1_lst) + np.max(value2_lst)) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Perform a hybrid local search: random swaps with value-based perturbation\n    n_items = len(base_solution)\n    if n_items < 2:\n        return new_solution  # No meaningful neighbors can be generated\n\n    # Randomly select a subset of items to swap\n    swap_indices = np.random.choice(n_items, size=min(3, n_items), replace=False)\n\n    # For each selected item, decide whether to swap it based on value improvement potential\n    for idx in swap_indices:\n        current_value = new_solution[idx]\n        if current_value == 1:\n            # If item is included, consider removing it if it's not critical\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n            else:\n                # If removing it violates capacity, try to swap with another item\n                other_idx = np.random.choice([i for i in range(n_items) if i != idx and new_solution[i] == 0])\n                if weight_lst[other_idx] <= weight_lst[idx] and np.sum(weight_lst * new_solution) - weight_lst[idx] + weight_lst[other_idx] <= capacity:\n                    new_solution[idx], new_solution[other_idx] = new_solution[other_idx], new_solution[idx]\n        else:\n            # If item is excluded, consider adding it if it improves value and fits\n            if weight_lst[idx] <= capacity - np.sum(weight_lst * new_solution):\n                new_solution[idx] = 1\n\n    # Ensure feasibility by repairing if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with the lowest value-to-weight ratio until feasible\n        while total_weight > capacity:\n            ratios = (value1_lst + value2_lst) / weight_lst\n            ratios[new_solution == 0] = np.inf  # Ignore excluded items\n            remove_idx = np.argmin(ratios)\n            new_solution[remove_idx] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 253,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a few items (local perturbation)\n    n_items = len(new_solution)\n    n_swaps = min(3, n_items)  # Limit number of swaps\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Greedily add high-value items (if space allows)\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        val1_ratio = value1_lst / weight_lst\n        val2_ratio = value2_lst / weight_lst\n\n        # Combine ratios using a weighted sum (could be adaptive)\n        combined_ratio = 0.5 * val1_ratio + 0.5 * val2_ratio\n\n        # Find items not in solution sorted by combined ratio\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            sorted_indices = candidate_indices[np.argsort(-combined_ratio[candidate_indices])]\n\n            # Add items until capacity is exceeded\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n                else:\n                    break\n\n    # 3. Remove low-value items to make space for better items\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Calculate value-to-weight ratios for items in solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            combined_ratio = 0.5 * value1_lst[in_solution] + 0.5 * value2_lst[in_solution]\n            # Sort by lowest ratio first\n            sorted_indices = in_solution[np.argsort(combined_ratio)]\n\n            # Remove items until feasible\n            for idx in sorted_indices:\n                if np.sum(weight_lst * new_solution) > capacity:\n                    new_solution[idx] = 0\n                else:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.34284982071765024,
            1.605771392583847
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a few items (local perturbation)\n    n_items = len(new_solution)\n    n_swaps = min(3, n_items)  # Limit number of swaps\n    for _ in range(n_swaps):\n        i, j = random.sample(range(n_items), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Greedily add high-value items (if space allows)\n    remaining_capacity = capacity - np.sum(weight_lst * new_solution)\n    if remaining_capacity > 0:\n        # Calculate value-to-weight ratios for both objectives\n        val1_ratio = value1_lst / weight_lst\n        val2_ratio = value2_lst / weight_lst\n\n        # Combine ratios using a weighted sum (could be adaptive)\n        combined_ratio = 0.5 * val1_ratio + 0.5 * val2_ratio\n\n        # Find items not in solution sorted by combined ratio\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            sorted_indices = candidate_indices[np.argsort(-combined_ratio[candidate_indices])]\n\n            # Add items until capacity is exceeded\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n                else:\n                    break\n\n    # 3. Remove low-value items to make space for better items\n    if np.sum(weight_lst * new_solution) > capacity:\n        # Calculate value-to-weight ratios for items in solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            combined_ratio = 0.5 * value1_lst[in_solution] + 0.5 * value2_lst[in_solution]\n            # Sort by lowest ratio first\n            sorted_indices = in_solution[np.argsort(combined_ratio)]\n\n            # Remove items until feasible\n            for idx in sorted_indices:\n                if np.sum(weight_lst * new_solution) > capacity:\n                    new_solution[idx] = 0\n                else:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 254,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (0 to 1 or 1 to 0) while maintaining feasibility\n    candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                candidates.append(i)\n        else:\n            candidates.append(i)\n\n    if not candidates:\n        return new_solution  # No valid moves, return current solution\n\n    # Select a random candidate to flip\n    flip_idx = np.random.choice(candidates)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Apply a novel local search operator: consider both objectives\n    # If the flipped item was included, try to swap it with another item that improves the Pareto front\n    if new_solution[flip_idx] == 0:  # Item was removed\n        # Find items that can be added without exceeding capacity when removing the flipped item\n        potential_adds = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0 and (current_weight - weight_lst[flip_idx] + weight_lst[i] <= capacity):\n                potential_adds.append(i)\n\n        if potential_adds:\n            add_idx = np.random.choice(potential_adds)\n            new_solution[add_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4131390074292311,
            2.634993314743042
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Identify items that can be flipped (0 to 1 or 1 to 0) while maintaining feasibility\n    candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                candidates.append(i)\n        else:\n            candidates.append(i)\n\n    if not candidates:\n        return new_solution  # No valid moves, return current solution\n\n    # Select a random candidate to flip\n    flip_idx = np.random.choice(candidates)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Apply a novel local search operator: consider both objectives\n    # If the flipped item was included, try to swap it with another item that improves the Pareto front\n    if new_solution[flip_idx] == 0:  # Item was removed\n        # Find items that can be added without exceeding capacity when removing the flipped item\n        potential_adds = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0 and (current_weight - weight_lst[flip_idx] + weight_lst[i] <= capacity):\n                potential_adds.append(i)\n\n        if potential_adds:\n            add_idx = np.random.choice(potential_adds)\n            new_solution[add_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 255,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_solution, _ = archive[np.argmax([np.sum(weight_lst[s[0] == 1]) for s in archive])]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal gains for each item (normalized by weight)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal gains for both objectives (simple average)\n    combined_gain = (marginal_gain1 + marginal_gain2) / 2\n\n    # Identify items that can be flipped (either added or removed)\n    # For added items: must fit within capacity\n    can_add = (weight_lst <= (capacity - current_weight)) & (new_solution == 0)\n    # For removed items: must be in the solution\n    can_remove = (new_solution == 1)\n\n    # Combine candidates and calculate probabilities based on marginal gains\n    candidates = np.where(can_add | can_remove)[0]\n    if len(candidates) == 0:\n        return new_solution  # No feasible moves\n\n    # Normalize gains for selection probabilities\n    gains = combined_gain[candidates]\n    probs = gains / np.sum(gains)\n\n    # Select a candidate with probability proportional to its gain\n    selected_idx = np.random.choice(candidates, p=probs)\n\n    # Flip the selected item\n    new_solution[selected_idx] = 1 - new_solution[selected_idx]\n\n    # Ensure feasibility (in case of floating point errors)\n    new_weight = np.sum(weight_lst[new_solution == 1])\n    if new_weight > capacity:\n        # If adding an item exceeds capacity, remove it\n        if new_solution[selected_idx] == 1:\n            new_solution[selected_idx] = 0\n        else:\n            # If removing an item still exceeds capacity, find another item to remove\n            excess = new_weight - capacity\n            items_in_solution = np.where(new_solution == 1)[0]\n            # Sort by weight (remove smallest items first to minimize impact on objectives)\n            items_in_solution_sorted = items_in_solution[np.argsort(weight_lst[items_in_solution])]\n            for item in items_in_solution_sorted:\n                if excess <= 0:\n                    break\n                new_solution[item] = 0\n                excess -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.8921604158156732,
            2.545450270175934
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to capacity)\n    selected_solution, _ = archive[np.argmax([np.sum(weight_lst[s[0] == 1]) for s in archive])]\n    new_solution = selected_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal gains for each item (normalized by weight)\n    marginal_gain1 = value1_lst / (weight_lst + 1e-6)  # Avoid division by zero\n    marginal_gain2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine marginal gains for both objectives (simple average)\n    combined_gain = (marginal_gain1 + marginal_gain2) / 2\n\n    # Identify items that can be flipped (either added or removed)\n    # For added items: must fit within capacity\n    can_add = (weight_lst <= (capacity - current_weight)) & (new_solution == 0)\n    # For removed items: must be in the solution\n    can_remove = (new_solution == 1)\n\n    # Combine candidates and calculate probabilities based on marginal gains\n    candidates = np.where(can_add | can_remove)[0]\n    if len(candidates) == 0:\n        return new_solution  # No feasible moves\n\n    # Normalize gains for selection probabilities\n    gains = combined_gain[candidates]\n    probs = gains / np.sum(gains)\n\n    # Select a candidate with probability proportional to its gain\n    selected_idx = np.random.choice(candidates, p=probs)\n\n    # Flip the selected item\n    new_solution[selected_idx] = 1 - new_solution[selected_idx]\n\n    # Ensure feasibility (in case of floating point errors)\n    new_weight = np.sum(weight_lst[new_solution == 1])\n    if new_weight > capacity:\n        # If adding an item exceeds capacity, remove it\n        if new_solution[selected_idx] == 1:\n            new_solution[selected_idx] = 0\n        else:\n            # If removing an item still exceeds capacity, find another item to remove\n            excess = new_weight - capacity\n            items_in_solution = np.where(new_solution == 1)[0]\n            # Sort by weight (remove smallest items first to minimize impact on objectives)\n            items_in_solution_sorted = items_in_solution[np.argsort(weight_lst[items_in_solution])]\n            for item in items_in_solution_sorted:\n                if excess <= 0:\n                    break\n                new_solution[item] = 0\n                excess -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 256,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity * 0.9:  # Prefer solutions with room for improvement\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive\n\n    # Select a random candidate with a bias towards solutions with high potential\n    selected = random.choices(\n        [sol for sol, _ in candidates],\n        weights=[1.0 / (1 + obj[0] + obj[1]) for _, obj in candidates],  # Higher weight for lower value solutions\n        k=1\n    )[0].copy()\n\n    # Hybrid local search strategy: combination of item swap and greedy addition\n    new_solution = selected.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly swap a few items (local perturbation)\n    swap_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedily add items that improve both objectives if feasible\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst - (new_solution * value1_lst)\n    marginal_gain2 = value2_lst - (new_solution * value2_lst)\n    marginal_ratio = (marginal_gain1 + marginal_gain2) / (weight_lst + 1e-6)  # Avoid division by zero\n\n    # Sort items by marginal ratio and add greedily\n    sorted_indices = np.argsort(-marginal_ratio)\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility (in case of floating point errors)\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break\n            idx_to_remove = random.choice(items_in_solution)\n            new_solution[idx_to_remove] = 0\n            excess -= weight_lst[idx_to_remove]\n\n    return new_solution\n\n",
        "score": [
            -0.35101477547213805,
            5.571278423070908
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight < capacity * 0.9:  # Prefer solutions with room for improvement\n            candidates.append((sol, obj))\n\n    if not candidates:\n        candidates = archive\n\n    # Select a random candidate with a bias towards solutions with high potential\n    selected = random.choices(\n        [sol for sol, _ in candidates],\n        weights=[1.0 / (1 + obj[0] + obj[1]) for _, obj in candidates],  # Higher weight for lower value solutions\n        k=1\n    )[0].copy()\n\n    # Hybrid local search strategy: combination of item swap and greedy addition\n    new_solution = selected.copy()\n    n_items = len(weight_lst)\n\n    # Step 1: Randomly swap a few items (local perturbation)\n    swap_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Step 2: Greedily add items that improve both objectives if feasible\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal gains for both objectives\n    marginal_gain1 = value1_lst - (new_solution * value1_lst)\n    marginal_gain2 = value2_lst - (new_solution * value2_lst)\n    marginal_ratio = (marginal_gain1 + marginal_gain2) / (weight_lst + 1e-6)  # Avoid division by zero\n\n    # Sort items by marginal ratio and add greedily\n    sorted_indices = np.argsort(-marginal_ratio)\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility (in case of floating point errors)\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove items randomly until feasible\n        excess = total_weight - capacity\n        while excess > 0:\n            items_in_solution = np.where(new_solution == 1)[0]\n            if len(items_in_solution) == 0:\n                break\n            idx_to_remove = random.choice(items_in_solution)\n            new_solution[idx_to_remove] = 0\n            excess -= weight_lst[idx_to_remove]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 257,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most promising solution (e.g., with highest combined value or diversity)\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[(v1 + v2) for (s, (v1, v2)) in archive],\n        k=1\n    )[0]\n    base_solution, (base_v1, base_v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with value-based greedy selection\n    n_items = len(base_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        # Calculate the effect of flipping this item\n        if new_solution[idx] == 1:\n            # Item is currently included; consider removing it\n            new_weight = np.sum(new_solution * weight_lst) - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Item is currently excluded; consider adding it\n            new_weight = np.sum(new_solution * weight_lst) + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n\n    # Additional greedy improvement: add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    for idx in available_items:\n        if (np.sum(new_solution * weight_lst) + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.411791640479187,
            8.660960465669632
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most promising solution (e.g., with highest combined value or diversity)\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[(v1 + v2) for (s, (v1, v2)) in archive],\n        k=1\n    )[0]\n    base_solution, (base_v1, base_v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: random flip with value-based greedy selection\n    n_items = len(base_solution)\n    flip_indices = random.sample(range(n_items), min(3, n_items))  # Flip up to 3 items\n\n    for idx in flip_indices:\n        # Calculate the effect of flipping this item\n        if new_solution[idx] == 1:\n            # Item is currently included; consider removing it\n            new_weight = np.sum(new_solution * weight_lst) - weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 0\n        else:\n            # Item is currently excluded; consider adding it\n            new_weight = np.sum(new_solution * weight_lst) + weight_lst[idx]\n            if new_weight <= capacity:\n                new_solution[idx] = 1\n\n    # Additional greedy improvement: add items that improve both objectives\n    available_items = np.where(new_solution == 0)[0]\n    for idx in available_items:\n        if (np.sum(new_solution * weight_lst) + weight_lst[idx]) <= capacity:\n            # Check if adding this item improves both objectives\n            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 258,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their distance from the Pareto front (simplified as sum of values)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution that is not the best but has room for improvement\n        selected_idx = min(1, len(archive_sorted) - 1)  # Avoid selecting the best solution if possible\n        base_solution, _ = archive_sorted[selected_idx]\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap two items (if feasible)\n    n_items = len(new_solution)\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            # Check feasibility\n            if np.dot(new_solution, weight_lst) > capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]  # Revert if infeasible\n\n    # 2. Flip items with high value-to-weight ratios (if feasible)\n    value_to_weight1 = value1_lst / (weight_lst + 1e-6)\n    value_to_weight2 = value2_lst / (weight_lst + 1e-6)\n    combined_vw = value_to_weight1 + value_to_weight2\n\n    # Sort items by combined value-to-weight ratio (descending)\n    sorted_items = np.argsort(-combined_vw)\n    for item in sorted_items:\n        if new_solution[item] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 0\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n                break\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 1\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n                break\n\n    # 3. Capacity-aware adjustment: remove the heaviest item if over capacity\n    if np.dot(new_solution, weight_lst) > capacity:\n        heaviest_item = np.argmax(weight_lst * new_solution)\n        new_solution[heaviest_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5699148564747787,
            1.105368584394455
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their distance from the Pareto front (simplified as sum of values)\n        archive_sorted = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution that is not the best but has room for improvement\n        selected_idx = min(1, len(archive_sorted) - 1)  # Avoid selecting the best solution if possible\n        base_solution, _ = archive_sorted[selected_idx]\n    else:\n        base_solution = archive[0][0]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap two items (if feasible)\n    n_items = len(new_solution)\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            # Check feasibility\n            if np.dot(new_solution, weight_lst) > capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]  # Revert if infeasible\n\n    # 2. Flip items with high value-to-weight ratios (if feasible)\n    value_to_weight1 = value1_lst / (weight_lst + 1e-6)\n    value_to_weight2 = value2_lst / (weight_lst + 1e-6)\n    combined_vw = value_to_weight1 + value_to_weight2\n\n    # Sort items by combined value-to-weight ratio (descending)\n    sorted_items = np.argsort(-combined_vw)\n    for item in sorted_items:\n        if new_solution[item] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 0\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n                break\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[item] = 1\n            if np.dot(temp_solution, weight_lst) <= capacity:\n                new_solution = temp_solution\n                break\n\n    # 3. Capacity-aware adjustment: remove the heaviest item if over capacity\n    if np.dot(new_solution, weight_lst) > capacity:\n        heaviest_item = np.argmax(weight_lst * new_solution)\n        new_solution[heaviest_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 259,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random flips with value-to-weight ratio\n    # Step 1: Randomly flip a subset of items\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 2: Ensure feasibility by removing worst items if over capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Calculate value-to-weight ratios for all items\n        ratio1 = value1_lst / weight_lst\n        ratio2 = value2_lst / weight_lst\n\n        # Sort items by combined ratio (prioritize items that contribute more to both objectives)\n        combined_ratio = ratio1 + ratio2\n        sorted_indices = np.argsort(combined_ratio)\n\n        # Remove items with lowest combined ratio until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and new_weight > capacity:\n                new_solution[idx] = 0\n                new_weight -= weight_lst[idx]\n\n    # Step 3: Add best items that fit if under capacity\n    if new_weight < capacity:\n        # Calculate remaining capacity\n        remaining_capacity = capacity - new_weight\n\n        # Calculate value-to-weight ratios for excluded items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            best_candidate = excluded_items[np.argmax(ratios)]\n\n            if weight_lst[best_candidate] <= remaining_capacity:\n                new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.37101946109544054,
            1.8365111649036407
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random flips with value-to-weight ratio\n    # Step 1: Randomly flip a subset of items\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # Step 2: Ensure feasibility by removing worst items if over capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Calculate value-to-weight ratios for all items\n        ratio1 = value1_lst / weight_lst\n        ratio2 = value2_lst / weight_lst\n\n        # Sort items by combined ratio (prioritize items that contribute more to both objectives)\n        combined_ratio = ratio1 + ratio2\n        sorted_indices = np.argsort(combined_ratio)\n\n        # Remove items with lowest combined ratio until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and new_weight > capacity:\n                new_solution[idx] = 0\n                new_weight -= weight_lst[idx]\n\n    # Step 3: Add best items that fit if under capacity\n    if new_weight < capacity:\n        # Calculate remaining capacity\n        remaining_capacity = capacity - new_weight\n\n        # Calculate value-to-weight ratios for excluded items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            ratios = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            best_candidate = excluded_items[np.argmax(ratios)]\n\n            if weight_lst[best_candidate] <= remaining_capacity:\n                new_solution[best_candidate] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 260,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the capacity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst[sol == 1])\n        if current_weight < capacity * 0.9:  # Avoid solutions too close to capacity\n            candidates.append(sol)\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly flip a few items (exploration)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # 2. Value-based flip: flip items with high marginal contribution\n    # Calculate marginal contributions for both objectives\n    marginal_value1 = value1_lst - np.sum(value1_lst[base_solution == 1]) / n_items\n    marginal_value2 = value2_lst - np.sum(value2_lst[base_solution == 1]) / n_items\n\n    # Combine marginal contributions for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top 5 items with highest combined marginal contribution\n    top_items = np.argsort(combined_marginal)[-5:]\n\n    for idx in top_items:\n        if base_solution[idx] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # 3. Capacity-aware adjustment: ensure solution is feasible\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items with lowest combined marginal contribution until feasible\n        combined_marginal = marginal_value1 + marginal_value2\n        sorted_indices = np.argsort(combined_marginal)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.6333970387288695,
            1.6925643980503082
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution with higher potential for improvement\n    # Here, we prioritize solutions that are not too close to the capacity\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst[sol == 1])\n        if current_weight < capacity * 0.9:  # Avoid solutions too close to capacity\n            candidates.append(sol)\n\n    if not candidates:\n        candidates = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidates).copy()\n    new_solution = base_solution.copy()\n    n_items = len(base_solution)\n\n    # Hybrid local search strategy\n    # 1. Randomly flip a few items (exploration)\n    flip_indices = random.sample(range(n_items), min(3, n_items))\n    for idx in flip_indices:\n        if base_solution[idx] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # 2. Value-based flip: flip items with high marginal contribution\n    # Calculate marginal contributions for both objectives\n    marginal_value1 = value1_lst - np.sum(value1_lst[base_solution == 1]) / n_items\n    marginal_value2 = value2_lst - np.sum(value2_lst[base_solution == 1]) / n_items\n\n    # Combine marginal contributions for both objectives\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Select top 5 items with highest combined marginal contribution\n    top_items = np.argsort(combined_marginal)[-5:]\n\n    for idx in top_items:\n        if base_solution[idx] == 1:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst[new_solution == 1]) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # 3. Capacity-aware adjustment: ensure solution is feasible\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items with lowest combined marginal contribution until feasible\n        combined_marginal = marginal_value1 + marginal_value2\n        sorted_indices = np.argsort(combined_marginal)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 261,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others in the archive)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # 2. Greedily improve the solution by adding items that improve both objectives\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to add items that improve both objectives\n    for i in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[i] <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n            if (new_value1 > current_value1 and new_value2 > current_value2):\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # 3. Greedily remove items that don't improve both objectives\n    for i in np.where(new_solution == 1)[0]:\n        # Check if removing this item doesn't hurt both objectives\n        new_value1 = current_value1 - value1_lst[i]\n        new_value2 = current_value2 - value2_lst[i]\n        if (new_value1 >= current_value1 and new_value2 >= current_value2):\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            current_value1 = new_value1\n            current_value2 = new_value2\n\n    return new_solution\n\n",
        "score": [
            -0.5449968629027021,
            1.718481034040451
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others in the archive)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # 2. Greedily improve the solution by adding items that improve both objectives\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Try to add items that improve both objectives\n    for i in np.where(new_solution == 0)[0]:\n        if current_weight + weight_lst[i] <= capacity:\n            # Check if adding this item improves both objectives\n            new_value1 = current_value1 + value1_lst[i]\n            new_value2 = current_value2 + value2_lst[i]\n            if (new_value1 > current_value1 and new_value2 > current_value2):\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                current_value1 = new_value1\n                current_value2 = new_value2\n\n    # 3. Greedily remove items that don't improve both objectives\n    for i in np.where(new_solution == 1)[0]:\n        # Check if removing this item doesn't hurt both objectives\n        new_value1 = current_value1 - value1_lst[i]\n        new_value2 = current_value2 - value2_lst[i]\n        if (new_value1 >= current_value1 and new_value2 >= current_value2):\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n            current_value1 = new_value1\n            current_value2 = new_value2\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 262,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with high potential for improvement\n    # Here, we select a solution that is not already at the Pareto front's extreme points\n    # and has a good balance between the two objectives\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly perturb the solution by flipping a few bits\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by checking the total weight\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If infeasible, revert the changes that caused the violation\n        for idx in flip_indices:\n            new_solution[idx] = base_solution[idx]\n        total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Greedily improve the solution by adding items that improve the most in either objective\n    remaining_items = np.where(new_solution == 0)[0]\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Calculate potential improvement in both objectives\n            potential_val1 = current_val1 + value1_lst[item]\n            potential_val2 = current_val2 + value2_lst[item]\n\n            # Accept the item if it improves at least one objective\n            if potential_val1 > current_val1 or potential_val2 > current_val2:\n                new_solution[item] = 1\n                current_val1 = potential_val1\n                current_val2 = potential_val2\n                total_weight += weight_lst[item]\n\n    # Ensure the solution is feasible after greedy improvement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If still infeasible, remove the heaviest items until feasible\n        while total_weight > capacity:\n            # Find the item with the highest weight in the solution\n            selected_items = np.where(new_solution == 1)[0]\n            if len(selected_items) == 0:\n                break\n            heaviest_item = selected_items[np.argmax(weight_lst[selected_items])]\n            new_solution[heaviest_item] = 0\n            total_weight -= weight_lst[heaviest_item]\n\n    return new_solution\n\n",
        "score": [
            -0.39112728311544265,
            3.5637325048446655
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Intelligently select a solution with high potential for improvement\n    # Here, we select a solution that is not already at the Pareto front's extreme points\n    # and has a good balance between the two objectives\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly perturb the solution by flipping a few bits\n    flip_indices = np.random.choice(len(base_solution), size=min(3, len(base_solution)), replace=False)\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by checking the total weight\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If infeasible, revert the changes that caused the violation\n        for idx in flip_indices:\n            new_solution[idx] = base_solution[idx]\n        total_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Greedily improve the solution by adding items that improve the most in either objective\n    remaining_items = np.where(new_solution == 0)[0]\n    for item in remaining_items:\n        if total_weight + weight_lst[item] <= capacity:\n            # Calculate potential improvement in both objectives\n            potential_val1 = current_val1 + value1_lst[item]\n            potential_val2 = current_val2 + value2_lst[item]\n\n            # Accept the item if it improves at least one objective\n            if potential_val1 > current_val1 or potential_val2 > current_val2:\n                new_solution[item] = 1\n                current_val1 = potential_val1\n                current_val2 = potential_val2\n                total_weight += weight_lst[item]\n\n    # Ensure the solution is feasible after greedy improvement\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If still infeasible, remove the heaviest items until feasible\n        while total_weight > capacity:\n            # Find the item with the highest weight in the solution\n            selected_items = np.where(new_solution == 1)[0]\n            if len(selected_items) == 0:\n                break\n            heaviest_item = selected_items[np.argmax(weight_lst[selected_items])]\n            new_solution[heaviest_item] = 0\n            total_weight -= weight_lst[heaviest_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 263,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower total weight (more room for improvement)\n    weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    probs = (capacity - weights) / np.sum(capacity - weights)  # Higher probability for solutions with lower total weight\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, (base_val1, base_val2) = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Generate candidate flips: items to flip (0->1 or 1->0)\n    items = np.arange(len(base_solution))\n    flipped_items = np.random.choice(items, size=min(5, len(items)), replace=False)  # Flip up to 5 random items\n\n    # Evaluate flips: prioritize those that improve both objectives or have high marginal gains\n    best_flip = None\n    best_improvement = (-np.inf, -np.inf)  # (improvement in val1, improvement in val2)\n\n    for item in flipped_items:\n        current_val = new_solution[item]\n        new_val = 1 - current_val\n\n        # Calculate new weight and values\n        new_weight = np.sum(weight_lst * new_solution) - current_val * weight_lst[item] + new_val * weight_lst[item]\n        if new_weight > capacity:\n            continue  # Skip if flip makes solution infeasible\n\n        new_val1 = base_val1 - current_val * value1_lst[item] + new_val * value1_lst[item]\n        new_val2 = base_val2 - current_val * value2_lst[item] + new_val * value2_lst[item]\n\n        # Calculate marginal improvements\n        improvement1 = new_val1 - base_val1\n        improvement2 = new_val2 - base_val2\n\n        # Prefer flips that improve both objectives or have high marginal gains\n        if (improvement1 > 0 and improvement2 > 0) or (improvement1 + improvement2 > best_improvement[0] + best_improvement[1]):\n            best_flip = item\n            best_improvement = (improvement1, improvement2)\n\n    # Apply the best flip if found\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    # If no improvement found, perform a random flip that keeps solution feasible\n    else:\n        feasible_items = [i for i in items if (base_solution[i] == 1 and np.sum(weight_lst * base_solution) - weight_lst[i] <= capacity) or\n                         (base_solution[i] == 0 and np.sum(weight_lst * base_solution) + weight_lst[i] <= capacity)]\n        if feasible_items:\n            random_item = np.random.choice(feasible_items)\n            new_solution[random_item] = 1 - new_solution[random_item]\n\n    return new_solution\n\n",
        "score": [
            -0.8592496767415205,
            5.247613608837128
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with lower total weight (more room for improvement)\n    weights = np.array([np.sum(weight_lst * sol[0]) for sol in archive])\n    probs = (capacity - weights) / np.sum(capacity - weights)  # Higher probability for solutions with lower total weight\n    base_idx = np.random.choice(len(archive), p=probs)\n    base_solution, (base_val1, base_val2) = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Generate candidate flips: items to flip (0->1 or 1->0)\n    items = np.arange(len(base_solution))\n    flipped_items = np.random.choice(items, size=min(5, len(items)), replace=False)  # Flip up to 5 random items\n\n    # Evaluate flips: prioritize those that improve both objectives or have high marginal gains\n    best_flip = None\n    best_improvement = (-np.inf, -np.inf)  # (improvement in val1, improvement in val2)\n\n    for item in flipped_items:\n        current_val = new_solution[item]\n        new_val = 1 - current_val\n\n        # Calculate new weight and values\n        new_weight = np.sum(weight_lst * new_solution) - current_val * weight_lst[item] + new_val * weight_lst[item]\n        if new_weight > capacity:\n            continue  # Skip if flip makes solution infeasible\n\n        new_val1 = base_val1 - current_val * value1_lst[item] + new_val * value1_lst[item]\n        new_val2 = base_val2 - current_val * value2_lst[item] + new_val * value2_lst[item]\n\n        # Calculate marginal improvements\n        improvement1 = new_val1 - base_val1\n        improvement2 = new_val2 - base_val2\n\n        # Prefer flips that improve both objectives or have high marginal gains\n        if (improvement1 > 0 and improvement2 > 0) or (improvement1 + improvement2 > best_improvement[0] + best_improvement[1]):\n            best_flip = item\n            best_improvement = (improvement1, improvement2)\n\n    # Apply the best flip if found\n    if best_flip is not None:\n        new_solution[best_flip] = 1 - new_solution[best_flip]\n\n    # If no improvement found, perform a random flip that keeps solution feasible\n    else:\n        feasible_items = [i for i in items if (base_solution[i] == 1 and np.sum(weight_lst * base_solution) - weight_lst[i] <= capacity) or\n                         (base_solution[i] == 0 and np.sum(weight_lst * base_solution) + weight_lst[i] <= capacity)]\n        if feasible_items:\n            random_item = np.random.choice(feasible_items)\n            new_solution[random_item] = 1 - new_solution[random_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 264,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flips with value-based selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select a subset of items to consider for flipping\n    candidate_indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n\n    for idx in candidate_indices:\n        if new_solution[idx] == 1:\n            # Consider removing the item if it doesn't improve both objectives significantly\n            if (value1_lst[idx] < 0.1 * current_value1) and (value2_lst[idx] < 0.1 * current_value2):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Consider adding the item if it would improve at least one objective\n            if (current_weight + weight_lst[idx] <= capacity) and \\\n               ((value1_lst[idx] > 0.1 * current_value1) or (value2_lst[idx] > 0.1 * current_value2)):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flip to ensure diversity\n    flip_idx = np.random.randint(0, num_items)\n    if new_solution[flip_idx] == 1:\n        new_solution[flip_idx] = 0\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.3981335464872027,
            1.2439005374908447
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., not already optimal in both objectives)\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random flips with value-based selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select a subset of items to consider for flipping\n    candidate_indices = np.random.choice(num_items, size=min(5, num_items), replace=False)\n\n    for idx in candidate_indices:\n        if new_solution[idx] == 1:\n            # Consider removing the item if it doesn't improve both objectives significantly\n            if (value1_lst[idx] < 0.1 * current_value1) and (value2_lst[idx] < 0.1 * current_value2):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Consider adding the item if it would improve at least one objective\n            if (current_weight + weight_lst[idx] <= capacity) and \\\n               ((value1_lst[idx] > 0.1 * current_value1) or (value2_lst[idx] > 0.1 * current_value2)):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Additional random flip to ensure diversity\n    flip_idx = np.random.randint(0, num_items)\n    if new_solution[flip_idx] == 1:\n        new_solution[flip_idx] = 0\n    else:\n        if current_weight + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 265,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prefer solutions that are not too close to the capacity to allow room for improvement\n    candidate_solutions = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Avoid solutions that are already near capacity\n            candidate_solutions.append(sol)\n\n    if not candidate_solutions:\n        candidate_solutions = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidate_solutions).copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    # Strategy 1: Random Swap - Swap two items to explore different combinations\n    if len(new_solution) >= 2:\n        idx1, idx2 = random.sample(range(len(new_solution)), 2)\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Strategy 2: Value-based Flip - Flip items with high value-to-weight ratio\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_vtw = value_to_weight1 + value_to_weight2\n\n    # Select items to flip based on high value-to-weight ratio\n    high_vtw_indices = np.argsort(combined_vtw)[-max(2, len(new_solution) // 5):]\n    for idx in high_vtw_indices:\n        if random.random() < 0.3:  # 30% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Strategy 3: Capacity-aware Adjustment - Remove items if over capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        sorted_indices = np.argsort(combined_vtw)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.3679015776817402,
            0.9360310733318329
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prefer solutions that are not too close to the capacity to allow room for improvement\n    candidate_solutions = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Avoid solutions that are already near capacity\n            candidate_solutions.append(sol)\n\n    if not candidate_solutions:\n        candidate_solutions = [sol for sol, _ in archive]\n\n    base_solution = random.choice(candidate_solutions).copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply a hybrid local search strategy\n    # Strategy 1: Random Swap - Swap two items to explore different combinations\n    if len(new_solution) >= 2:\n        idx1, idx2 = random.sample(range(len(new_solution)), 2)\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Strategy 2: Value-based Flip - Flip items with high value-to-weight ratio\n    value_to_weight1 = value1_lst / weight_lst\n    value_to_weight2 = value2_lst / weight_lst\n    combined_vtw = value_to_weight1 + value_to_weight2\n\n    # Select items to flip based on high value-to-weight ratio\n    high_vtw_indices = np.argsort(combined_vtw)[-max(2, len(new_solution) // 5):]\n    for idx in high_vtw_indices:\n        if random.random() < 0.3:  # 30% chance to flip\n            new_solution[idx] = 1 - new_solution[idx]\n\n    # Strategy 3: Capacity-aware Adjustment - Remove items if over capacity\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        sorted_indices = np.argsort(combined_vtw)\n        for idx in sorted_indices:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 266,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with high potential for improvement\n    # We prioritize solutions that are not too close to the capacity (to allow room for improvement)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Avoid solutions too close to capacity\n            candidates.append(sol)\n\n    if not candidates:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select a candidate with high potential for improvement\n        base_solution = np.random.choice(candidates)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # 2. Apply value-to-weight ratio-based selection to improve both objectives\n    # Calculate the ratio for each objective\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine ratios to prioritize items that are good for both objectives\n    combined_ratio = ratio1 + ratio2\n\n    # Select top-k items based on combined ratio\n    k = max(1, int(0.1 * len(new_solution)))  # Select top 10% of items\n    top_indices = np.argsort(-combined_ratio)[:k]\n\n    # Ensure the new solution remains feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    for idx in top_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.5664254350338104,
            1.8858904242515564
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards solutions with high potential for improvement\n    # We prioritize solutions that are not too close to the capacity (to allow room for improvement)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity * 0.9:  # Avoid solutions too close to capacity\n            candidates.append(sol)\n\n    if not candidates:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select a candidate with high potential for improvement\n        base_solution = np.random.choice(candidates)\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items to introduce diversity\n    flip_mask = np.random.rand(len(new_solution)) < 0.2  # 20% chance to flip each item\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n\n    # 2. Apply value-to-weight ratio-based selection to improve both objectives\n    # Calculate the ratio for each objective\n    ratio1 = value1_lst / (weight_lst + 1e-6)\n    ratio2 = value2_lst / (weight_lst + 1e-6)\n\n    # Combine ratios to prioritize items that are good for both objectives\n    combined_ratio = ratio1 + ratio2\n\n    # Select top-k items based on combined ratio\n    k = max(1, int(0.1 * len(new_solution)))  # Select top 10% of items\n    top_indices = np.argsort(-combined_ratio)[:k]\n\n    # Ensure the new solution remains feasible\n    current_weight = np.sum(weight_lst * new_solution)\n    for idx in top_indices:\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 267,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on a combination of objective values and diversity\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 0.9, len(archive)) / np.sum(np.linspace(0.1, 0.9, len(archive))))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(5):  # Number of local search iterations\n        # Step 1: Random swap between two items\n        if len(new_solution) > 1:\n            i, j = np.random.choice(len(new_solution), 2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Step 2: Flip items with high value-to-weight ratio for one objective\n        if random.random() < 0.5:\n            # Focus on value1\n            vw_ratio = value1_lst / (weight_lst + 1e-6)\n            candidate_items = np.where(new_solution == 0)[0]\n            if len(candidate_items) > 0:\n                best_item = candidate_items[np.argmax(vw_ratio[candidate_items])]\n                if current_weight + weight_lst[best_item] <= capacity:\n                    new_solution[best_item] = 1\n                    current_weight += weight_lst[best_item]\n        else:\n            # Focus on value2\n            vw_ratio = value2_lst / (weight_lst + 1e-6)\n            candidate_items = np.where(new_solution == 0)[0]\n            if len(candidate_items) > 0:\n                best_item = candidate_items[np.argmax(vw_ratio[candidate_items])]\n                if current_weight + weight_lst[best_item] <= capacity:\n                    new_solution[best_item] = 1\n                    current_weight += weight_lst[best_item]\n\n        # Step 3: Remove low-value items to free up capacity\n        if current_weight > capacity * 0.9:  # If near capacity\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                # Remove items with lowest combined value\n                combined_value = value1_lst + value2_lst\n                worst_item = included_items[np.argmin(combined_value[included_items])]\n                new_solution[worst_item] = 0\n                current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n",
        "score": [
            -0.438948798006778,
            3.5085796415805817
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on a combination of objective values and diversity\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 0.9, len(archive)) / np.sum(np.linspace(0.1, 0.9, len(archive))))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    for _ in range(5):  # Number of local search iterations\n        # Step 1: Random swap between two items\n        if len(new_solution) > 1:\n            i, j = np.random.choice(len(new_solution), 2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        # Step 2: Flip items with high value-to-weight ratio for one objective\n        if random.random() < 0.5:\n            # Focus on value1\n            vw_ratio = value1_lst / (weight_lst + 1e-6)\n            candidate_items = np.where(new_solution == 0)[0]\n            if len(candidate_items) > 0:\n                best_item = candidate_items[np.argmax(vw_ratio[candidate_items])]\n                if current_weight + weight_lst[best_item] <= capacity:\n                    new_solution[best_item] = 1\n                    current_weight += weight_lst[best_item]\n        else:\n            # Focus on value2\n            vw_ratio = value2_lst / (weight_lst + 1e-6)\n            candidate_items = np.where(new_solution == 0)[0]\n            if len(candidate_items) > 0:\n                best_item = candidate_items[np.argmax(vw_ratio[candidate_items])]\n                if current_weight + weight_lst[best_item] <= capacity:\n                    new_solution[best_item] = 1\n                    current_weight += weight_lst[best_item]\n\n        # Step 3: Remove low-value items to free up capacity\n        if current_weight > capacity * 0.9:  # If near capacity\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                # Remove items with lowest combined value\n                combined_value = value1_lst + value2_lst\n                worst_item = included_items[np.argmin(combined_value[included_items])]\n                new_solution[worst_item] = 0\n                current_weight -= weight_lst[worst_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 268,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher potential for improvement\n    base_solution = random.choices(\n        [sol for sol, _ in archive],\n        weights=[1.0 / (1.0 + obj[0] + obj[1]) for _, obj in archive],\n        k=1\n    )[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Randomly select a subset of items to consider for flipping\n    flip_candidates = random.sample(range(n_items), min(10, n_items))\n\n    for idx in flip_candidates:\n        if new_solution[idx] == 1:\n            # Consider removing the item\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            # Consider adding the item if it fits\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            else:\n                continue\n\n        # Evaluate the new solution's potential improvement\n        new_value1 = np.sum(value1_lst * new_solution)\n        new_value2 = np.sum(value2_lst * new_solution)\n\n        # Greedily accept the change if it improves at least one objective\n        found_improvement = False\n        for sol, obj in archive:\n            if new_value1 > obj[0] or new_value2 > obj[1]:\n                found_improvement = True\n                break\n\n        if not found_improvement:\n            # Revert if no improvement is found\n            if new_solution[idx] == 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Apply a secondary local search: flip items based on a weighted sum of objectives\n    alpha = random.uniform(0.1, 0.9)\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    sorted_indices = np.argsort(-weighted_values)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.46144647480361134,
            3.368639349937439
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards those with higher potential for improvement\n    base_solution = random.choices(\n        [sol for sol, _ in archive],\n        weights=[1.0 / (1.0 + obj[0] + obj[1]) for _, obj in archive],\n        k=1\n    )[0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate current total weight and remaining capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Randomly select a subset of items to consider for flipping\n    flip_candidates = random.sample(range(n_items), min(10, n_items))\n\n    for idx in flip_candidates:\n        if new_solution[idx] == 1:\n            # Consider removing the item\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n        else:\n            # Consider adding the item if it fits\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            else:\n                continue\n\n        # Evaluate the new solution's potential improvement\n        new_value1 = np.sum(value1_lst * new_solution)\n        new_value2 = np.sum(value2_lst * new_solution)\n\n        # Greedily accept the change if it improves at least one objective\n        found_improvement = False\n        for sol, obj in archive:\n            if new_value1 > obj[0] or new_value2 > obj[1]:\n                found_improvement = True\n                break\n\n        if not found_improvement:\n            # Revert if no improvement is found\n            if new_solution[idx] == 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Apply a secondary local search: flip items based on a weighted sum of objectives\n    alpha = random.uniform(0.1, 0.9)\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    sorted_indices = np.argsort(-weighted_values)\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif new_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 269,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential\n    # Sort solutions by their objective diversity (sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    diversity = np.sum(normalized, axis=1)\n    sorted_indices = np.argsort(-diversity)  # Descending order\n\n    # Select top 20% solutions with highest diversity\n    top_k = max(1, len(archive) // 5)\n    candidates = [archive[i] for i in sorted_indices[:top_k]]\n\n    # Randomly select one from the top candidates\n    base_solution, _ = random.choice(candidates)\n\n    # Step 2: Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Determine the number of items to flip (adaptive based on solution size)\n    flip_count = min(n_items, max(1, int(np.ceil(n_items * 0.2))))  # Flip 20% of items\n\n    # Randomly select items to flip\n    flip_indices = np.random.choice(n_items, flip_count, replace=False)\n\n    # Flip the selected items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If over capacity, remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            # Select an item to remove\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.3686122503469112,
            4.985838383436203
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high potential\n    # Sort solutions by their objective diversity (sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    diversity = np.sum(normalized, axis=1)\n    sorted_indices = np.argsort(-diversity)  # Descending order\n\n    # Select top 20% solutions with highest diversity\n    top_k = max(1, len(archive) // 5)\n    candidates = [archive[i] for i in sorted_indices[:top_k]]\n\n    # Randomly select one from the top candidates\n    base_solution, _ = random.choice(candidates)\n\n    # Step 2: Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Determine the number of items to flip (adaptive based on solution size)\n    flip_count = min(n_items, max(1, int(np.ceil(n_items * 0.2))))  # Flip 20% of items\n\n    # Randomly select items to flip\n    flip_indices = np.random.choice(n_items, flip_count, replace=False)\n\n    # Flip the selected items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If over capacity, remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            # Select an item to remove\n            remove_idx = np.random.choice(excess_items)\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 270,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a high probability of being close to the Pareto front\n    # We prioritize solutions that have a high value in at least one objective\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives\n    selected_idx = random.randint(0, min(2, len(archive) - 1))  # Select from top 3\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate candidate flips: items that can be toggled without violating capacity\n    # We consider both adding and removing items\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing this item\n            if current_weight - weight_lst[i] >= 0:\n                candidates.append((i, -1))  # -1 indicates removal\n        else:\n            # Consider adding this item\n            if current_weight + weight_lst[i] <= capacity:\n                candidates.append((i, 1))  # 1 indicates addition\n\n    if not candidates:\n        # If no candidates, try flipping a random item that maintains feasibility\n        # This is a fallback when no safe flips are available\n        safe_items = []\n        for i in range(len(base_solution)):\n            if base_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    safe_items.append(i)\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    safe_items.append(i)\n\n        if safe_items:\n            flip_idx = random.choice(safe_items)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Select flip candidates that promise high value improvement\n    # We use a hybrid of random selection and value-to-weight ratio\n    flip_candidates = []\n    for idx, direction in candidates:\n        if direction == 1:\n            # For addition, consider value-to-weight ratio\n            ratio1 = value1_lst[idx] / weight_lst[idx]\n            ratio2 = value2_lst[idx] / weight_lst[idx]\n            score = ratio1 + ratio2\n        else:\n            # For removal, consider negative value-to-weight ratio\n            ratio1 = -value1_lst[idx] / weight_lst[idx]\n            ratio2 = -value2_lst[idx] / weight_lst[idx]\n            score = ratio1 + ratio2\n\n        flip_candidates.append((idx, direction, score))\n\n    # Sort by score and select top 3 candidates\n    flip_candidates.sort(key=lambda x: -x[2])\n    selected_flips = flip_candidates[:min(3, len(flip_candidates))]\n\n    if selected_flips:\n        # Apply the best flip\n        best_flip = selected_flips[0]\n        new_solution[best_flip[0]] = 1 - new_solution[best_flip[0]]\n    else:\n        # If no good candidates, perform a random flip among safe items\n        safe_items = [idx for idx, _ in candidates]\n        if safe_items:\n            flip_idx = random.choice(safe_items)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n",
        "score": [
            -0.8013260678227629,
            2.4183061718940735
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a high probability of being close to the Pareto front\n    # We prioritize solutions that have a high value in at least one objective\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))  # Sort by sum of objectives\n    selected_idx = random.randint(0, min(2, len(archive) - 1))  # Select from top 3\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Generate candidate flips: items that can be toggled without violating capacity\n    # We consider both adding and removing items\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing this item\n            if current_weight - weight_lst[i] >= 0:\n                candidates.append((i, -1))  # -1 indicates removal\n        else:\n            # Consider adding this item\n            if current_weight + weight_lst[i] <= capacity:\n                candidates.append((i, 1))  # 1 indicates addition\n\n    if not candidates:\n        # If no candidates, try flipping a random item that maintains feasibility\n        # This is a fallback when no safe flips are available\n        safe_items = []\n        for i in range(len(base_solution)):\n            if base_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    safe_items.append(i)\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    safe_items.append(i)\n\n        if safe_items:\n            flip_idx = random.choice(safe_items)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Select flip candidates that promise high value improvement\n    # We use a hybrid of random selection and value-to-weight ratio\n    flip_candidates = []\n    for idx, direction in candidates:\n        if direction == 1:\n            # For addition, consider value-to-weight ratio\n            ratio1 = value1_lst[idx] / weight_lst[idx]\n            ratio2 = value2_lst[idx] / weight_lst[idx]\n            score = ratio1 + ratio2\n        else:\n            # For removal, consider negative value-to-weight ratio\n            ratio1 = -value1_lst[idx] / weight_lst[idx]\n            ratio2 = -value2_lst[idx] / weight_lst[idx]\n            score = ratio1 + ratio2\n\n        flip_candidates.append((idx, direction, score))\n\n    # Sort by score and select top 3 candidates\n    flip_candidates.sort(key=lambda x: -x[2])\n    selected_flips = flip_candidates[:min(3, len(flip_candidates))]\n\n    if selected_flips:\n        # Apply the best flip\n        best_flip = selected_flips[0]\n        new_solution[best_flip[0]] = 1 - new_solution[best_flip[0]]\n    else:\n        # If no good candidates, perform a random flip among safe items\n        safe_items = [idx for idx, _ in candidates]\n        if safe_items:\n            flip_idx = random.choice(safe_items)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 271,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with high potential to improve either objective\n            potential_val1 = np.sum(value1_lst * (1 - sol))\n            potential_val2 = np.sum(value2_lst * (1 - sol))\n            score = (potential_val1 + potential_val2) / remaining_capacity\n            candidates.append((sol, score))\n\n    if not candidates:\n        # If no candidates with remaining capacity, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with highest improvement potential\n        candidates.sort(key=lambda x: -x[1])\n        base_solution = candidates[0][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (more aggressive than single flips)\n    # 2. Use a probabilistic approach to balance exploration and exploitation\n    # 3. Ensure feasibility by checking capacity constraints\n\n    # Step 1: Select a random subset of items to consider flipping\n    subset_size = min(n_items, max(1, int(np.sqrt(n_items))))\n    flip_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    # Step 2: For each selected item, decide with probability based on value/weight ratio\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # Consider removing the item\n            if np.random.rand() < 0.3:  # 30% chance to remove\n                new_weight = np.sum(weight_lst * new_solution) - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n        else:\n            # Consider adding the item\n            value_ratio1 = value1_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n            value_ratio2 = value2_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n            prob = min(0.8, 0.1 + 0.7 * (value_ratio1 + value_ratio2))  # Higher value/weight ratio increases probability\n\n            if np.random.rand() < prob:\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n\n    # Step 3: Additional refinement - try to swap items between objectives\n    if np.random.rand() < 0.5:  # 50% chance to perform swap\n        # Find items that are in the solution but have low marginal value for both objectives\n        for i in np.where(new_solution == 1)[0]:\n            if (value1_lst[i] < 0.1 * np.mean(value1_lst) and\n                value2_lst[i] < 0.1 * np.mean(value2_lst)):\n                # Consider removing these items\n                if np.random.rand() < 0.2:  # 20% chance to remove\n                    new_weight = np.sum(weight_lst * new_solution) - weight_lst[i]\n                    if new_weight <= capacity:\n                        new_solution[i] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.5746232737537313,
            8.150424480438232
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, (val1, val2) in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with high potential to improve either objective\n            potential_val1 = np.sum(value1_lst * (1 - sol))\n            potential_val2 = np.sum(value2_lst * (1 - sol))\n            score = (potential_val1 + potential_val2) / remaining_capacity\n            candidates.append((sol, score))\n\n    if not candidates:\n        # If no candidates with remaining capacity, select a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with highest improvement potential\n        candidates.sort(key=lambda x: -x[1])\n        base_solution = candidates[0][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Randomly select a subset of items to flip (more aggressive than single flips)\n    # 2. Use a probabilistic approach to balance exploration and exploitation\n    # 3. Ensure feasibility by checking capacity constraints\n\n    # Step 1: Select a random subset of items to consider flipping\n    subset_size = min(n_items, max(1, int(np.sqrt(n_items))))\n    flip_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    # Step 2: For each selected item, decide with probability based on value/weight ratio\n    for i in flip_indices:\n        if new_solution[i] == 1:\n            # Consider removing the item\n            if np.random.rand() < 0.3:  # 30% chance to remove\n                new_weight = np.sum(weight_lst * new_solution) - weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 0\n        else:\n            # Consider adding the item\n            value_ratio1 = value1_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n            value_ratio2 = value2_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n            prob = min(0.8, 0.1 + 0.7 * (value_ratio1 + value_ratio2))  # Higher value/weight ratio increases probability\n\n            if np.random.rand() < prob:\n                new_weight = np.sum(weight_lst * new_solution) + weight_lst[i]\n                if new_weight <= capacity:\n                    new_solution[i] = 1\n\n    # Step 3: Additional refinement - try to swap items between objectives\n    if np.random.rand() < 0.5:  # 50% chance to perform swap\n        # Find items that are in the solution but have low marginal value for both objectives\n        for i in np.where(new_solution == 1)[0]:\n            if (value1_lst[i] < 0.1 * np.mean(value1_lst) and\n                value2_lst[i] < 0.1 * np.mean(value2_lst)):\n                # Consider removing these items\n                if np.random.rand() < 0.2:  # 20% chance to remove\n                    new_weight = np.sum(weight_lst * new_solution) - weight_lst[i]\n                    if new_weight <= capacity:\n                        new_solution[i] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 272,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards less explored regions\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine the type of local search to apply\n    search_type = random.choice(['flip', 'weight_swap', 'value_swap'])\n\n    if search_type == 'flip':\n        # Randomly flip a bit (add/remove an item)\n        candidate_items = np.where(new_solution == 0)[0] if current_weight < capacity else np.where(new_solution == 1)[0]\n        if len(candidate_items) > 0:\n            item_to_flip = random.choice(candidate_items)\n            new_solution[item_to_flip] = 1 - new_solution[item_to_flip]\n\n    elif search_type == 'weight_swap':\n        # Swap two items based on weight difference\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Find the heaviest included item and the lightest excluded item\n            heaviest_included = included_items[np.argmax(weight_lst[included_items])]\n            lightest_excluded = excluded_items[np.argmin(weight_lst[excluded_items])]\n\n            # Check if swapping would keep the solution feasible\n            if (current_weight - weight_lst[heaviest_included] + weight_lst[lightest_excluded]) <= capacity:\n                new_solution[heaviest_included] = 0\n                new_solution[lightest_excluded] = 1\n\n    elif search_type == 'value_swap':\n        # Swap two items based on value improvement potential\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Find the lowest value1 included item and highest value1 excluded item\n            lowest_value1_included = included_items[np.argmin(value1_lst[included_items])]\n            highest_value1_excluded = excluded_items[np.argmax(value1_lst[excluded_items])]\n\n            # Check if swapping would keep the solution feasible\n            if (current_weight - weight_lst[lowest_value1_included] + weight_lst[highest_value1_excluded]) <= capacity:\n                new_solution[lowest_value1_included] = 0\n                new_solution[highest_value1_excluded] = 1\n\n    # Ensure the solution remains feasible\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, randomly remove items until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            item_to_remove = random.choice(included_items)\n            new_solution[item_to_remove] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.3453952964861067,
            1.626048505306244
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards less explored regions\n    base_solution, _ = random.choice(archive)\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine the type of local search to apply\n    search_type = random.choice(['flip', 'weight_swap', 'value_swap'])\n\n    if search_type == 'flip':\n        # Randomly flip a bit (add/remove an item)\n        candidate_items = np.where(new_solution == 0)[0] if current_weight < capacity else np.where(new_solution == 1)[0]\n        if len(candidate_items) > 0:\n            item_to_flip = random.choice(candidate_items)\n            new_solution[item_to_flip] = 1 - new_solution[item_to_flip]\n\n    elif search_type == 'weight_swap':\n        # Swap two items based on weight difference\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Find the heaviest included item and the lightest excluded item\n            heaviest_included = included_items[np.argmax(weight_lst[included_items])]\n            lightest_excluded = excluded_items[np.argmin(weight_lst[excluded_items])]\n\n            # Check if swapping would keep the solution feasible\n            if (current_weight - weight_lst[heaviest_included] + weight_lst[lightest_excluded]) <= capacity:\n                new_solution[heaviest_included] = 0\n                new_solution[lightest_excluded] = 1\n\n    elif search_type == 'value_swap':\n        # Swap two items based on value improvement potential\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Find the lowest value1 included item and highest value1 excluded item\n            lowest_value1_included = included_items[np.argmin(value1_lst[included_items])]\n            highest_value1_excluded = excluded_items[np.argmax(value1_lst[excluded_items])]\n\n            # Check if swapping would keep the solution feasible\n            if (current_weight - weight_lst[lowest_value1_included] + weight_lst[highest_value1_excluded]) <= capacity:\n                new_solution[lowest_value1_included] = 0\n                new_solution[highest_value1_excluded] = 1\n\n    # Ensure the solution remains feasible\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If not feasible, randomly remove items until feasible\n        while total_weight > capacity:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n            item_to_remove = random.choice(included_items)\n            new_solution[item_to_remove] = 0\n            total_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 273,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on current weight)\n    flip_prob = 0.3 if current_weight < capacity * 0.7 else 0.1\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # 2. Perform objective-aware swaps to balance both objectives\n    # Find items that can be swapped to improve both objectives\n    candidate_items = np.where(new_solution == 1)[0]\n    if len(candidate_items) > 1:\n        # Select two random items to swap\n        i, j = random.sample(list(candidate_items), 2)\n        # Check if swapping improves both objectives\n        delta_value1 = value1_lst[j] - value1_lst[i]\n        delta_value2 = value2_lst[j] - value2_lst[i]\n        if delta_value1 > 0 and delta_value2 > 0:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility by removing excess items if necessary\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the smallest ratio of combined value to weight\n        combined_value = value1_lst + value2_lst\n        ratios = combined_value / (weight_lst + 1e-6)  # Avoid division by zero\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            item_to_remove = items_in_solution[np.argmin(ratios[items_in_solution])]\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.3578506040452091,
            2.13743656873703
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on current weight)\n    flip_prob = 0.3 if current_weight < capacity * 0.7 else 0.1\n    for i in range(len(new_solution)):\n        if random.random() < flip_prob:\n            new_solution[i] = 1 - new_solution[i]\n\n    # 2. Perform objective-aware swaps to balance both objectives\n    # Find items that can be swapped to improve both objectives\n    candidate_items = np.where(new_solution == 1)[0]\n    if len(candidate_items) > 1:\n        # Select two random items to swap\n        i, j = random.sample(list(candidate_items), 2)\n        # Check if swapping improves both objectives\n        delta_value1 = value1_lst[j] - value1_lst[i]\n        delta_value2 = value2_lst[j] - value2_lst[i]\n        if delta_value1 > 0 and delta_value2 > 0:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility by removing excess items if necessary\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the item with the smallest ratio of combined value to weight\n        combined_value = value1_lst + value2_lst\n        ratios = combined_value / (weight_lst + 1e-6)  # Avoid division by zero\n        items_in_solution = np.where(new_solution == 1)[0]\n        if len(items_in_solution) > 0:\n            item_to_remove = items_in_solution[np.argmin(ratios[items_in_solution])]\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 274,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the highest sum of values (promising for improvement)\n    selected_idx = np.argmax([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Flip a subset of items based on value-to-weight ratio and current solution\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Calculate value-to-weight ratios for all items\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios to identify high-potential items\n    combined_ratio = ratio1 + ratio2\n\n    # Select top-k items based on combined ratio (k is a fraction of total items)\n    k = max(1, int(0.1 * len(weight_lst)))\n    top_indices = np.argsort(combined_ratio)[-k:]\n\n    # Flip items in the selected subset if it improves feasibility\n    for idx in top_indices:\n        if base_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif base_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the least valuable item in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) == 0:\n            break\n        remove_idx = in_solution[np.argmin(combined_ratio[in_solution])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.7822545985269265,
            1.2625845670700073
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with the highest sum of values (promising for improvement)\n    selected_idx = np.argmax([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Flip a subset of items based on value-to-weight ratio and current solution\n    total_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - total_weight\n\n    # Calculate value-to-weight ratios for all items\n    ratio1 = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n    ratio2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine ratios to identify high-potential items\n    combined_ratio = ratio1 + ratio2\n\n    # Select top-k items based on combined ratio (k is a fraction of total items)\n    k = max(1, int(0.1 * len(weight_lst)))\n    top_indices = np.argsort(combined_ratio)[-k:]\n\n    # Flip items in the selected subset if it improves feasibility\n    for idx in top_indices:\n        if base_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n        elif base_solution[idx] == 1:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility by removing items if capacity exceeded\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove the least valuable item in the solution\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) == 0:\n            break\n        remove_idx = in_solution[np.argmin(combined_ratio[in_solution])]\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 275,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    # Here, we prioritize solutions that are not fully packed and have high value ratios\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate value ratios for both objectives\n            value_ratio1 = obj[0] / total_weight if total_weight > 0 else 0\n            value_ratio2 = obj[1] / total_weight if total_weight > 0 else 0\n            # Prefer solutions that are not fully packed and have high value ratios\n            candidates.append((sol, value_ratio1 + value_ratio2, total_weight))\n\n    if not candidates:\n        # Fallback to random selection if no candidates found\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest value ratio\n        candidates.sort(key=lambda x: -x[1])\n        base_solution = candidates[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip items to explore the neighborhood\n    # 2. Perform value-based swaps to improve both objectives\n    # 3. Ensure feasibility by adjusting for capacity\n\n    # Step 1: Random flips (exploration)\n    for _ in range(3):  # Number of random flips\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only add if it doesn't exceed capacity\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Value-based swaps (exploitation)\n    # Sort items by value-to-weight ratio for both objectives\n    items = list(range(len(weight_lst)))\n    # Sort by objective 1 value-to-weight ratio\n    items.sort(key=lambda x: value1_lst[x] / weight_lst[x] if weight_lst[x] > 0 else 0, reverse=True)\n    # Perform swaps between high-value items\n    for i in range(min(5, len(items))):\n        for j in range(i + 1, min(i + 3, len(items))):\n            if weight_lst[items[i]] + weight_lst[items[j]] <= capacity:\n                # Swap if it improves both objectives\n                if (value1_lst[items[i]] + value1_lst[items[j]] > value1_lst[items[i]] + value1_lst[items[j]]) and \\\n                   (value2_lst[items[i]] + value2_lst[items[j]] > value2_lst[items[i]] + value2_lst[items[j]]):\n                    new_solution[items[i]], new_solution[items[j]] = new_solution[items[j]], new_solution[items[i]]\n\n    # Step 3: Capacity adjustment (ensuring feasibility)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        items = list(range(len(weight_lst)))\n        items.sort(key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x] if weight_lst[x] > 0 else float('inf'))\n        for idx in items:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.307832549985671,
            5.785329908132553
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement\n    # Here, we prioritize solutions that are not fully packed and have high value ratios\n    candidates = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            # Calculate value ratios for both objectives\n            value_ratio1 = obj[0] / total_weight if total_weight > 0 else 0\n            value_ratio2 = obj[1] / total_weight if total_weight > 0 else 0\n            # Prefer solutions that are not fully packed and have high value ratios\n            candidates.append((sol, value_ratio1 + value_ratio2, total_weight))\n\n    if not candidates:\n        # Fallback to random selection if no candidates found\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the candidate with the highest value ratio\n        candidates.sort(key=lambda x: -x[1])\n        base_solution = candidates[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip items to explore the neighborhood\n    # 2. Perform value-based swaps to improve both objectives\n    # 3. Ensure feasibility by adjusting for capacity\n\n    # Step 1: Random flips (exploration)\n    for _ in range(3):  # Number of random flips\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            # Only add if it doesn't exceed capacity\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Step 2: Value-based swaps (exploitation)\n    # Sort items by value-to-weight ratio for both objectives\n    items = list(range(len(weight_lst)))\n    # Sort by objective 1 value-to-weight ratio\n    items.sort(key=lambda x: value1_lst[x] / weight_lst[x] if weight_lst[x] > 0 else 0, reverse=True)\n    # Perform swaps between high-value items\n    for i in range(min(5, len(items))):\n        for j in range(i + 1, min(i + 3, len(items))):\n            if weight_lst[items[i]] + weight_lst[items[j]] <= capacity:\n                # Swap if it improves both objectives\n                if (value1_lst[items[i]] + value1_lst[items[j]] > value1_lst[items[i]] + value1_lst[items[j]]) and \\\n                   (value2_lst[items[i]] + value2_lst[items[j]] > value2_lst[items[i]] + value2_lst[items[j]]):\n                    new_solution[items[i]], new_solution[items[j]] = new_solution[items[j]], new_solution[items[i]]\n\n    # Step 3: Capacity adjustment (ensuring feasibility)\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items with lowest value-to-weight ratio until feasible\n        items = list(range(len(weight_lst)))\n        items.sort(key=lambda x: (value1_lst[x] + value2_lst[x]) / weight_lst[x] if weight_lst[x] > 0 else float('inf'))\n        for idx in items:\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 276,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by dominance)\n    total_value1 = np.array([obj[0] for _, obj in archive])\n    total_value2 = np.array([obj[1] for _, obj in archive])\n    dominance_scores = total_value1 + total_value2\n    selection_probs = dominance_scores / np.sum(dominance_scores)\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random swaps + greedy improvement\n    for _ in range(5):  # Number of swap attempts\n        # Randomly select two items to swap (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) == 0 or len(out_items) == 0:\n            break\n\n        item_in = random.choice(in_items)\n        item_out = random.choice(out_items)\n\n        # Calculate new weight\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[item_in] + weight_lst[item_out]\n\n        if new_weight <= capacity:\n            # Perform swap\n            new_solution[item_in] = 0\n            new_solution[item_out] = 1\n\n            # Greedy improvement: Add items that improve both objectives\n            for item in out_items:\n                if new_solution[item] == 0:\n                    temp_weight = new_weight + weight_lst[item]\n                    if temp_weight <= capacity:\n                        # Check if adding this item improves both objectives\n                        if (value1_lst[item] > 0) and (value2_lst[item] > 0):\n                            new_solution[item] = 1\n                            new_weight = temp_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3592995662979454,
            6.786963939666748
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by dominance)\n    total_value1 = np.array([obj[0] for _, obj in archive])\n    total_value2 = np.array([obj[1] for _, obj in archive])\n    dominance_scores = total_value1 + total_value2\n    selection_probs = dominance_scores / np.sum(dominance_scores)\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: Random swaps + greedy improvement\n    for _ in range(5):  # Number of swap attempts\n        # Randomly select two items to swap (one in, one out)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) == 0 or len(out_items) == 0:\n            break\n\n        item_in = random.choice(in_items)\n        item_out = random.choice(out_items)\n\n        # Calculate new weight\n        current_weight = np.sum(weight_lst[new_solution == 1])\n        new_weight = current_weight - weight_lst[item_in] + weight_lst[item_out]\n\n        if new_weight <= capacity:\n            # Perform swap\n            new_solution[item_in] = 0\n            new_solution[item_out] = 1\n\n            # Greedy improvement: Add items that improve both objectives\n            for item in out_items:\n                if new_solution[item] == 0:\n                    temp_weight = new_weight + weight_lst[item]\n                    if temp_weight <= capacity:\n                        # Check if adding this item improves both objectives\n                        if (value1_lst[item] > 0) and (value2_lst[item] > 0):\n                            new_solution[item] = 1\n                            new_weight = temp_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 277,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = [sum(obj) for _, obj in archive]\n    if sum(weights) == 0:\n        weights = [1.0 for _ in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a pair of items (if they are different)\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high value-to-weight ratio in the opposite objective\n    #    (to potentially improve the other objective)\n    value_ratio1 = value1_lst / (weight_lst + 1e-8)\n    value_ratio2 = value2_lst / (weight_lst + 1e-8)\n\n    # Decide which objective to prioritize for flipping (alternate between objectives)\n    if random.random() < 0.5:\n        # Prioritize objective 1: flip items with high value2/weight if not in solution\n        candidate_items = np.where((new_solution == 0) & (value_ratio2 > np.percentile(value_ratio2, 75)))[0]\n    else:\n        # Prioritize objective 2: flip items with high value1/weight if not in solution\n        candidate_items = np.where((new_solution == 0) & (value_ratio1 > np.percentile(value_ratio1, 75)))[0]\n\n    if len(candidate_items) > 0:\n        flip_item = random.choice(candidate_items)\n        if current_weight + weight_lst[flip_item] <= capacity:\n            new_solution[flip_item] = 1 - new_solution[flip_item]\n\n    # 3. Remove low-value items to free up capacity for higher-value items\n    if current_weight > capacity * 0.9:  # If over 90% capacity\n        # Remove items with lowest value in either objective (alternate between objectives)\n        if random.random() < 0.5:\n            # Remove items with lowest value1\n            removal_candidates = np.where((new_solution == 1) & (value1_lst > 0))[0]\n            if len(removal_candidates) > 0:\n                remove_item = removal_candidates[np.argmin(value1_lst[removal_candidates])]\n                new_solution[remove_item] = 0\n        else:\n            # Remove items with lowest value2\n            removal_candidates = np.where((new_solution == 1) & (value2_lst > 0))[0]\n            if len(removal_candidates) > 0:\n                remove_item = removal_candidates[np.argmin(value2_lst[removal_candidates])]\n                new_solution[remove_item] = 0\n\n    # Ensure feasibility by removing random items if over capacity\n    while np.sum(weight_lst * new_solution) > capacity:\n        over_items = np.where(new_solution == 1)[0]\n        if len(over_items) == 0:\n            break\n        remove_item = random.choice(over_items)\n        new_solution[remove_item] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.38753145577214587,
            2.6820347011089325
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (randomly weighted by objective values)\n    weights = [sum(obj) for _, obj in archive]\n    if sum(weights) == 0:\n        weights = [1.0 for _ in archive]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Randomly swap a pair of items (if they are different)\n    if len(new_solution) >= 2:\n        i, j = random.sample(range(len(new_solution)), 2)\n        if new_solution[i] != new_solution[j]:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high value-to-weight ratio in the opposite objective\n    #    (to potentially improve the other objective)\n    value_ratio1 = value1_lst / (weight_lst + 1e-8)\n    value_ratio2 = value2_lst / (weight_lst + 1e-8)\n\n    # Decide which objective to prioritize for flipping (alternate between objectives)\n    if random.random() < 0.5:\n        # Prioritize objective 1: flip items with high value2/weight if not in solution\n        candidate_items = np.where((new_solution == 0) & (value_ratio2 > np.percentile(value_ratio2, 75)))[0]\n    else:\n        # Prioritize objective 2: flip items with high value1/weight if not in solution\n        candidate_items = np.where((new_solution == 0) & (value_ratio1 > np.percentile(value_ratio1, 75)))[0]\n\n    if len(candidate_items) > 0:\n        flip_item = random.choice(candidate_items)\n        if current_weight + weight_lst[flip_item] <= capacity:\n            new_solution[flip_item] = 1 - new_solution[flip_item]\n\n    # 3. Remove low-value items to free up capacity for higher-value items\n    if current_weight > capacity * 0.9:  # If over 90% capacity\n        # Remove items with lowest value in either objective (alternate between objectives)\n        if random.random() < 0.5:\n            # Remove items with lowest value1\n            removal_candidates = np.where((new_solution == 1) & (value1_lst > 0))[0]\n            if len(removal_candidates) > 0:\n                remove_item = removal_candidates[np.argmin(value1_lst[removal_candidates])]\n                new_solution[remove_item] = 0\n        else:\n            # Remove items with lowest value2\n            removal_candidates = np.where((new_solution == 1) & (value2_lst > 0))[0]\n            if len(removal_candidates) > 0:\n                remove_item = removal_candidates[np.argmin(value2_lst[removal_candidates])]\n                new_solution[remove_item] = 0\n\n    # Ensure feasibility by removing random items if over capacity\n    while np.sum(weight_lst * new_solution) > capacity:\n        over_items = np.where(new_solution == 1)[0]\n        if len(over_items) == 0:\n            break\n        remove_item = random.choice(over_items)\n        new_solution[remove_item] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 278,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher total value\n    objectives = np.array([obj for _, obj in archive])\n    total_values = objectives.sum(axis=1)\n    probabilities = total_values / total_values.sum()\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly flip a subset of bits to create diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items that exceed capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Calculate the \"value density\" (value1 + value2) per weight for each item\n        value_density = (value1_lst + value2_lst) / weight_lst\n        # Sort items by value density in descending order\n        sorted_indices = np.argsort(-value_density)\n        # Remove items with the lowest value density until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess > 0:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n                if excess <= 0:\n                    break\n\n    # Greedy improvement: add items with the highest marginal value density\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal value density (value1 + value2) per weight for items not in the solution\n        marginal_density = (value1_lst + value2_lst) / weight_lst\n        # Sort items by marginal value density in descending order\n        sorted_indices = np.argsort(-marginal_density)\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n                if remaining_weight <= 0:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.2951936000215423,
            2.9352655112743378
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards those with higher total value\n    objectives = np.array([obj for _, obj in archive])\n    total_values = objectives.sum(axis=1)\n    probabilities = total_values / total_values.sum()\n    base_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution, _ = archive[base_idx]\n    new_solution = base_solution.copy()\n\n    # Randomly flip a subset of bits to create diversity\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    new_solution[flip_indices] = 1 - new_solution[flip_indices]\n\n    # Ensure feasibility by removing items that exceed capacity\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Calculate the \"value density\" (value1 + value2) per weight for each item\n        value_density = (value1_lst + value2_lst) / weight_lst\n        # Sort items by value density in descending order\n        sorted_indices = np.argsort(-value_density)\n        # Remove items with the lowest value density until feasible\n        for idx in sorted_indices:\n            if new_solution[idx] == 1 and excess > 0:\n                new_solution[idx] = 0\n                excess -= weight_lst[idx]\n                if excess <= 0:\n                    break\n\n    # Greedy improvement: add items with the highest marginal value density\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal value density (value1 + value2) per weight for items not in the solution\n        marginal_density = (value1_lst + value2_lst) / weight_lst\n        # Sort items by marginal value density in descending order\n        sorted_indices = np.argsort(-marginal_density)\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_weight:\n                new_solution[idx] = 1\n                remaining_weight -= weight_lst[idx]\n                if remaining_weight <= 0:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 279,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on diversity and potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Random swap with objective-aware probability\n    # 2. Targeted flip based on marginal gains\n    # 3. Novel perturbation for multi-objective improvement\n\n    # Step 1: Random swap with objective-aware probability\n    for _ in range(2):  # Perform 2 random swaps\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) < 2:\n            break\n        i, j = np.random.choice(candidate_indices, 2, replace=False)\n\n        # Calculate potential weight change\n        delta_weight = weight_lst[j] - weight_lst[i]\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n\n    # Step 2: Targeted flip based on marginal gains\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst - np.dot(new_solution, value1_lst) / len(weight_lst)\n    marginal_gains2 = value2_lst - np.dot(new_solution, value2_lst) / len(weight_lst)\n\n    # Normalize gains\n    norm_gains = (marginal_gains1 + marginal_gains2) / (np.max(marginal_gains1) + np.max(marginal_gains2) + 1e-10)\n\n    # Flip items with highest normalized gains that fit\n    for idx in np.argsort(norm_gains)[-3:]:  # Consider top 3 items\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 3: Novel perturbation for multi-objective improvement\n    # Identify items that could improve both objectives\n    potential_items = []\n    for idx in range(len(weight_lst)):\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            potential_items.append(idx)\n\n    if potential_items:\n        # Select item that improves both objectives proportionally\n        best_idx = -1\n        best_ratio = -1\n        for idx in potential_items:\n            ratio = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            if ratio > best_ratio:\n                best_ratio = ratio\n                best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.4420664354472389,
            4.473994672298431
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on diversity and potential for improvement\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.dot(new_solution, weight_lst)\n\n    # Hybrid local search strategy:\n    # 1. Random swap with objective-aware probability\n    # 2. Targeted flip based on marginal gains\n    # 3. Novel perturbation for multi-objective improvement\n\n    # Step 1: Random swap with objective-aware probability\n    for _ in range(2):  # Perform 2 random swaps\n        candidate_indices = np.where(new_solution == 1)[0]\n        if len(candidate_indices) < 2:\n            break\n        i, j = np.random.choice(candidate_indices, 2, replace=False)\n\n        # Calculate potential weight change\n        delta_weight = weight_lst[j] - weight_lst[i]\n        if current_weight + delta_weight <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n\n    # Step 2: Targeted flip based on marginal gains\n    # Calculate marginal gains for each item\n    marginal_gains1 = value1_lst - np.dot(new_solution, value1_lst) / len(weight_lst)\n    marginal_gains2 = value2_lst - np.dot(new_solution, value2_lst) / len(weight_lst)\n\n    # Normalize gains\n    norm_gains = (marginal_gains1 + marginal_gains2) / (np.max(marginal_gains1) + np.max(marginal_gains2) + 1e-10)\n\n    # Flip items with highest normalized gains that fit\n    for idx in np.argsort(norm_gains)[-3:]:  # Consider top 3 items\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n        elif new_solution[idx] == 1 and current_weight - weight_lst[idx] >= 0:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # Step 3: Novel perturbation for multi-objective improvement\n    # Identify items that could improve both objectives\n    potential_items = []\n    for idx in range(len(weight_lst)):\n        if new_solution[idx] == 0 and current_weight + weight_lst[idx] <= capacity:\n            potential_items.append(idx)\n\n    if potential_items:\n        # Select item that improves both objectives proportionally\n        best_idx = -1\n        best_ratio = -1\n        for idx in potential_items:\n            ratio = (value1_lst[idx] + value2_lst[idx]) / (weight_lst[idx] + 1e-10)\n            if ratio > best_ratio:\n                best_ratio = ratio\n                best_idx = idx\n\n        if best_idx != -1:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 280,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Random swap of two items\n    if len(new_solution) >= 2:\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high value-to-weight ratio in a different objective\n    if np.random.rand() < 0.5:  # 50% chance to flip\n        # Choose which objective to prioritize (randomly)\n        if np.random.rand() < 0.5:\n            value_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n        else:\n            value_ratio = value2_lst / (weight_lst + 1e-10)\n\n        # Find items not in the solution with high value ratio\n        candidate_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n        if len(candidate_items) > 0:\n            best_candidate = candidate_items[np.argmax(value_ratio[candidate_items])]\n            new_solution[best_candidate] = 1\n\n    # 3. Capacity adjustment: remove low-value items if over capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Sort items in solution by value ratio of the other objective\n        in_solution = np.where(new_solution == 1)[0]\n        if np.random.rand() < 0.5:\n            value_ratio = value1_lst[in_solution] / (weight_lst[in_solution] + 1e-10)\n        else:\n            value_ratio = value2_lst[in_solution] / (weight_lst[in_solution] + 1e-10)\n\n        # Remove items with lowest value ratio until feasible\n        sorted_indices = np.argsort(value_ratio)\n        for idx in sorted_indices:\n            if new_weight <= capacity:\n                break\n            new_solution[in_solution[idx]] = 0\n            new_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.4224523590653013,
            2.4943298995494843
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy:\n    # 1. Random swap of two items\n    if len(new_solution) >= 2:\n        i, j = np.random.choice(len(new_solution), 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # 2. Flip items with high value-to-weight ratio in a different objective\n    if np.random.rand() < 0.5:  # 50% chance to flip\n        # Choose which objective to prioritize (randomly)\n        if np.random.rand() < 0.5:\n            value_ratio = value1_lst / (weight_lst + 1e-10)  # Avoid division by zero\n        else:\n            value_ratio = value2_lst / (weight_lst + 1e-10)\n\n        # Find items not in the solution with high value ratio\n        candidate_items = np.where((new_solution == 0) & (weight_lst <= (capacity - current_weight)))[0]\n        if len(candidate_items) > 0:\n            best_candidate = candidate_items[np.argmax(value_ratio[candidate_items])]\n            new_solution[best_candidate] = 1\n\n    # 3. Capacity adjustment: remove low-value items if over capacity\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # Sort items in solution by value ratio of the other objective\n        in_solution = np.where(new_solution == 1)[0]\n        if np.random.rand() < 0.5:\n            value_ratio = value1_lst[in_solution] / (weight_lst[in_solution] + 1e-10)\n        else:\n            value_ratio = value2_lst[in_solution] / (weight_lst[in_solution] + 1e-10)\n\n        # Remove items with lowest value ratio until feasible\n        sorted_indices = np.argsort(value_ratio)\n        for idx in sorted_indices:\n            if new_weight <= capacity:\n                break\n            new_solution[in_solution[idx]] = 0\n            new_weight = np.sum(weight_lst * new_solution)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 281,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher total value (sum of both objectives)\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine the number of items to flip (between 1 and 5)\n    num_flips = random.randint(1, min(5, len(new_solution)))\n\n    # Calculate the potential impact of flipping each item\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # If item is included, consider removing it (decrease weight, potentially increase value)\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n        else:\n            # If item is excluded, consider adding it (increase weight, potentially increase value)\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n\n        # Only consider flips that keep the solution feasible\n        if current_weight + delta_weight <= capacity:\n            # Calculate a weighted score for the flip (prioritize items that improve both objectives)\n            score = (delta_value1 + delta_value2) / (1 + abs(delta_weight))\n            flip_candidates.append((i, score))\n\n    # Sort candidates by score in descending order\n    flip_candidates.sort(key=lambda x: -x[1])\n\n    # Select the top candidates for flipping\n    selected_indices = [idx for idx, _ in flip_candidates[:num_flips]]\n\n    # Perform the flips\n    for i in selected_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Additional random swap to introduce diversity\n    if len(new_solution) > 1:\n        i, j = random.sample(range(len(new_solution)), 2)\n        # Check if swapping these items keeps the solution feasible\n        if (current_weight - weight_lst[i] + weight_lst[j] <= capacity and\n            current_weight - weight_lst[j] + weight_lst[i] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.2745020416853434,
            2.4382971227169037
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with a bias towards higher total value (sum of both objectives)\n    base_solution, _ = max(archive, key=lambda x: sum(x[1]))\n\n    # Create a copy of the base solution\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Determine the number of items to flip (between 1 and 5)\n    num_flips = random.randint(1, min(5, len(new_solution)))\n\n    # Calculate the potential impact of flipping each item\n    flip_candidates = []\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # If item is included, consider removing it (decrease weight, potentially increase value)\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n        else:\n            # If item is excluded, consider adding it (increase weight, potentially increase value)\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n\n        # Only consider flips that keep the solution feasible\n        if current_weight + delta_weight <= capacity:\n            # Calculate a weighted score for the flip (prioritize items that improve both objectives)\n            score = (delta_value1 + delta_value2) / (1 + abs(delta_weight))\n            flip_candidates.append((i, score))\n\n    # Sort candidates by score in descending order\n    flip_candidates.sort(key=lambda x: -x[1])\n\n    # Select the top candidates for flipping\n    selected_indices = [idx for idx, _ in flip_candidates[:num_flips]]\n\n    # Perform the flips\n    for i in selected_indices:\n        new_solution[i] = 1 - new_solution[i]\n\n    # Additional random swap to introduce diversity\n    if len(new_solution) > 1:\n        i, j = random.sample(range(len(new_solution)), 2)\n        # Check if swapping these items keeps the solution feasible\n        if (current_weight - weight_lst[i] + weight_lst[j] <= capacity and\n            current_weight - weight_lst[j] + weight_lst[i] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 282,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with a bias towards solutions that are not too similar\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    base_solution = selected_solution.copy()\n\n    # Generate a neighbor by performing a random swap of two items\n    n_items = len(base_solution)\n    if n_items < 2:\n        return base_solution\n\n    # Randomly select two distinct items to swap\n    i, j = random.sample(range(n_items), 2)\n    new_solution = base_solution.copy()\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove the heavier item if the swap violates capacity\n        if weight_lst[i] > weight_lst[j]:\n            new_solution[i] = 0\n        else:\n            new_solution[j] = 0\n\n    # Perform a greedy improvement step: add the most valuable item not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate the marginal value-to-weight ratio for remaining items\n        marginal_value1 = value1_lst[remaining_items] / weight_lst[remaining_items]\n        marginal_value2 = value2_lst[remaining_items] / weight_lst[remaining_items]\n\n        # Combine the two objectives into a single metric (e.g., weighted sum)\n        combined_metric = 0.5 * marginal_value1 + 0.5 * marginal_value2\n        best_item_idx = remaining_items[np.argmax(combined_metric)]\n\n        # Add the best item if it fits\n        if total_weight + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.36018233835722757,
            2.37934947013855
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a random solution from the archive with a bias towards solutions that are not too similar\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution, _ = archive[selected_idx]\n    base_solution = selected_solution.copy()\n\n    # Generate a neighbor by performing a random swap of two items\n    n_items = len(base_solution)\n    if n_items < 2:\n        return base_solution\n\n    # Randomly select two distinct items to swap\n    i, j = random.sample(range(n_items), 2)\n    new_solution = base_solution.copy()\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Remove the heavier item if the swap violates capacity\n        if weight_lst[i] > weight_lst[j]:\n            new_solution[i] = 0\n        else:\n            new_solution[j] = 0\n\n    # Perform a greedy improvement step: add the most valuable item not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    if len(remaining_items) > 0:\n        # Calculate the marginal value-to-weight ratio for remaining items\n        marginal_value1 = value1_lst[remaining_items] / weight_lst[remaining_items]\n        marginal_value2 = value2_lst[remaining_items] / weight_lst[remaining_items]\n\n        # Combine the two objectives into a single metric (e.g., weighted sum)\n        combined_metric = 0.5 * marginal_value1 + 0.5 * marginal_value2\n        best_item_idx = remaining_items[np.argmax(combined_metric)]\n\n        # Add the best item if it fits\n        if total_weight + weight_lst[best_item_idx] <= capacity:\n            new_solution[best_item_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 283,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.argmax([np.sum(sol[0]) for sol in archive])  # Select the most packed solution\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combination of addition and removal\n    new_solution = base_solution.copy()\n\n    # Step 1: Random addition of items not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Step 2: Random removal of items in the solution\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        if len(included_items) > 1:  # Ensure at least one item remains\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            included_items = np.where(new_solution == 1)[0]  # Update included items\n\n    return new_solution\n\n",
        "score": [
            -0.8384077372765949,
            3.798424333333969
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.argmax([np.sum(sol[0]) for sol in archive])  # Select the most packed solution\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: combination of addition and removal\n    new_solution = base_solution.copy()\n\n    # Step 1: Random addition of items not in the solution\n    remaining_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(remaining_items)\n\n    for item in remaining_items:\n        if current_weight + weight_lst[item] <= capacity:\n            new_solution[item] = 1\n            current_weight += weight_lst[item]\n\n    # Step 2: Random removal of items in the solution\n    included_items = np.where(new_solution == 1)[0]\n    np.random.shuffle(included_items)\n\n    for item in included_items:\n        if len(included_items) > 1:  # Ensure at least one item remains\n            new_solution[item] = 0\n            current_weight -= weight_lst[item]\n            included_items = np.where(new_solution == 1)[0]  # Update included items\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 284,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not completely full\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Determine the number of items to flip based on current capacity utilization\n    flip_count = max(1, int(0.1 * len(weight_lst)))  # Flip 10% of items by default\n    if current_weight > 0.8 * capacity:\n        flip_count = min(flip_count, int(0.2 * len(weight_lst)))  # Flip more if close to capacity\n\n    # Identify candidate items to flip (both included and excluded)\n    included_indices = np.where(new_solution == 1)[0]\n    excluded_indices = np.where(new_solution == 0)[0]\n\n    # Hybrid selection strategy: prioritize items that improve both objectives\n    candidate_indices = []\n    for idx in included_indices:\n        if current_weight - weight_lst[idx] >= 0:\n            candidate_indices.append(idx)\n    for idx in excluded_indices:\n        if current_weight + weight_lst[idx] <= capacity:\n            candidate_indices.append(idx)\n\n    # If no candidates, return the base solution\n    if not candidate_indices:\n        return new_solution\n\n    # Randomly select items to flip with a bias towards high-potential items\n    flip_indices = random.sample(candidate_indices, min(flip_count, len(candidate_indices)))\n\n    # Flip the selected items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing random items if capacity is exceeded\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess = new_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        while excess > 0 and len(excess_items) > 0:\n            idx = random.choice(excess_items)\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.9388584627724972,
            1.676060050725937
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with a bias towards solutions that are not completely full\n    base_solution, _ = random.choice(archive)\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Determine the number of items to flip based on current capacity utilization\n    flip_count = max(1, int(0.1 * len(weight_lst)))  # Flip 10% of items by default\n    if current_weight > 0.8 * capacity:\n        flip_count = min(flip_count, int(0.2 * len(weight_lst)))  # Flip more if close to capacity\n\n    # Identify candidate items to flip (both included and excluded)\n    included_indices = np.where(new_solution == 1)[0]\n    excluded_indices = np.where(new_solution == 0)[0]\n\n    # Hybrid selection strategy: prioritize items that improve both objectives\n    candidate_indices = []\n    for idx in included_indices:\n        if current_weight - weight_lst[idx] >= 0:\n            candidate_indices.append(idx)\n    for idx in excluded_indices:\n        if current_weight + weight_lst[idx] <= capacity:\n            candidate_indices.append(idx)\n\n    # If no candidates, return the base solution\n    if not candidate_indices:\n        return new_solution\n\n    # Randomly select items to flip with a bias towards high-potential items\n    flip_indices = random.sample(candidate_indices, min(flip_count, len(candidate_indices)))\n\n    # Flip the selected items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility by removing random items if capacity is exceeded\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        excess = new_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        while excess > 0 and len(excess_items) > 0:\n            idx = random.choice(excess_items)\n            new_solution[idx] = 0\n            excess -= weight_lst[idx]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 285,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Calculate diversity scores based on objective distances from archive centroid\n    objectives = np.array([obj for _, obj in archive])\n    centroid = np.mean(objectives, axis=0)\n    distances = np.linalg.norm(objectives - centroid, axis=1)\n    diversity_scores = distances / (np.max(distances) + 1e-8)\n\n    # Select solutions with top diversity scores (more potential for improvement)\n    top_indices = np.argsort(-diversity_scores)[:max(1, len(archive)//3)]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Try to add or remove items based on both objectives\n    for _ in range(min(10, n_items//2)):\n        # Randomly select an item to flip\n        item_idx = random.randint(0, n_items-1)\n\n        if new_solution[item_idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[item_idx]\n            if new_weight <= capacity:\n                new_solution[item_idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[item_idx]\n            if new_weight <= capacity:\n                # Evaluate the impact on both objectives\n                value1_gain = value1_lst[item_idx]\n                value2_gain = value2_lst[item_idx]\n\n                # Simple heuristic to decide whether to add based on both objectives\n                if (value1_gain > 0 or value2_gain > 0):\n                    new_solution[item_idx] = 1\n                    current_weight = new_weight\n\n    # Step 3: Ensure solution is feasible (shouldn't be needed due to checks above)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, perform a greedy repair\n        items_in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in_solution)\n        for item_idx in items_in_solution:\n            new_weight = total_weight - weight_lst[item_idx]\n            if new_weight <= capacity:\n                new_solution[item_idx] = 0\n                total_weight = new_weight\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
        "score": [
            -0.4113833239560333,
            1.4524554908275604
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution with high potential for improvement\n    # Calculate diversity scores based on objective distances from archive centroid\n    objectives = np.array([obj for _, obj in archive])\n    centroid = np.mean(objectives, axis=0)\n    distances = np.linalg.norm(objectives - centroid, axis=1)\n    diversity_scores = distances / (np.max(distances) + 1e-8)\n\n    # Select solutions with top diversity scores (more potential for improvement)\n    top_indices = np.argsort(-diversity_scores)[:max(1, len(archive)//3)]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n\n    # Step 2: Hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Try to add or remove items based on both objectives\n    for _ in range(min(10, n_items//2)):\n        # Randomly select an item to flip\n        item_idx = random.randint(0, n_items-1)\n\n        if new_solution[item_idx] == 1:\n            # Try removing the item\n            new_weight = current_weight - weight_lst[item_idx]\n            if new_weight <= capacity:\n                new_solution[item_idx] = 0\n                current_weight = new_weight\n        else:\n            # Try adding the item\n            new_weight = current_weight + weight_lst[item_idx]\n            if new_weight <= capacity:\n                # Evaluate the impact on both objectives\n                value1_gain = value1_lst[item_idx]\n                value2_gain = value2_lst[item_idx]\n\n                # Simple heuristic to decide whether to add based on both objectives\n                if (value1_gain > 0 or value2_gain > 0):\n                    new_solution[item_idx] = 1\n                    current_weight = new_weight\n\n    # Step 3: Ensure solution is feasible (shouldn't be needed due to checks above)\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        # If not feasible, perform a greedy repair\n        items_in_solution = np.where(new_solution == 1)[0]\n        np.random.shuffle(items_in_solution)\n        for item_idx in items_in_solution:\n            new_weight = total_weight - weight_lst[item_idx]\n            if new_weight <= capacity:\n                new_solution[item_idx] = 0\n                total_weight = new_weight\n                if total_weight <= capacity:\n                    break\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 286,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution from the archive (here, we select the one with the highest sum of objectives)\n    selected_idx = np.argmax([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip a random item and then greedily improve the solution\n    # Step 1: Randomly flip one item\n    flip_idx = np.random.randint(0, len(weight_lst))\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility after flip\n    new_weight = current_weight + (weight_lst[flip_idx] if new_solution[flip_idx] else -weight_lst[flip_idx])\n    if new_weight > capacity:\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]  # Revert if infeasible\n    else:\n        current_weight = new_weight\n\n    # Step 2: Greedily add items with the highest marginal value improvement\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal value improvement for each item\n        marginal_value1 = value1_lst / weight_lst\n        marginal_value2 = value2_lst / weight_lst\n\n        # Combine marginal values for both objectives (weighted sum)\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n\n        # Sort items by combined marginal value in descending order\n        sorted_indices = np.argsort(-combined_marginal)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Randomly flip a few items to escape local optima\n    flip_count = min(3, len(weight_lst) // 4)\n    flip_indices = np.random.choice(np.where(new_solution == 1)[0], size=flip_count, replace=False)\n    for idx in flip_indices:\n        new_weight = current_weight - weight_lst[idx]\n        if new_weight >= 0:\n            new_solution[idx] = 0\n            current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.3127602239695417,
            2.151103138923645
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution from the archive (here, we select the one with the highest sum of objectives)\n    selected_idx = np.argmax([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1, current_value2 = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: flip a random item and then greedily improve the solution\n    # Step 1: Randomly flip one item\n    flip_idx = np.random.randint(0, len(weight_lst))\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility after flip\n    new_weight = current_weight + (weight_lst[flip_idx] if new_solution[flip_idx] else -weight_lst[flip_idx])\n    if new_weight > capacity:\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]  # Revert if infeasible\n    else:\n        current_weight = new_weight\n\n    # Step 2: Greedily add items with the highest marginal value improvement\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        # Calculate marginal value improvement for each item\n        marginal_value1 = value1_lst / weight_lst\n        marginal_value2 = value2_lst / weight_lst\n\n        # Combine marginal values for both objectives (weighted sum)\n        combined_marginal = 0.5 * marginal_value1 + 0.5 * marginal_value2\n\n        # Sort items by combined marginal value in descending order\n        sorted_indices = np.argsort(-combined_marginal)\n\n        for idx in sorted_indices:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Randomly flip a few items to escape local optima\n    flip_count = min(3, len(weight_lst) // 4)\n    flip_indices = np.random.choice(np.where(new_solution == 1)[0], size=flip_count, replace=False)\n    for idx in flip_indices:\n        new_weight = current_weight - weight_lst[idx]\n        if new_weight >= 0:\n            new_solution[idx] = 0\n            current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 287,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the capacity\n    current_weights = [np.sum(weight_lst * sol[0]) for sol in archive]\n    current_utilization = [w / capacity for w in current_weights]\n    # Solutions that are neither too full nor too empty are more promising\n    promising_indices = [i for i, u in enumerate(current_utilization) if 0.3 <= u <= 0.7]\n    if not promising_indices:\n        promising_indices = list(range(len(archive)))\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip with weighted probability based on marginal contribution\n    for _ in range(3):  # Number of flips\n        # Calculate marginal contributions\n        marginal1 = value1_lst / weight_lst\n        marginal2 = value2_lst / weight_lst\n        # Combine marginal contributions (simple average)\n        combined_marginal = (marginal1 + marginal2) / 2\n        # Probability of flipping is proportional to marginal contribution\n        flip_probs = combined_marginal * (1 - new_solution) + combined_marginal * new_solution * 0.5\n        flip_probs = flip_probs / np.sum(flip_probs)\n        # Select item to flip\n        candidate = np.random.choice(len(weight_lst), p=flip_probs)\n        # Check feasibility\n        if new_solution[candidate] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n\n    # 2. Novel exchange-based operator: exchange two items with complementary values\n    # Find pairs of items where one is in the solution and the other is out\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Select a random pair\n        i_in = random.choice(in_items)\n        i_out = random.choice(out_items)\n        # Check feasibility of exchange\n        delta = weight_lst[i_out] - weight_lst[i_in]\n        if np.sum(weight_lst * new_solution) + delta <= capacity:\n            new_solution[i_in] = 0\n            new_solution[i_out] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.33606588868899245,
            3.6903627514839172
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    # We prioritize solutions that are not too close to the capacity\n    current_weights = [np.sum(weight_lst * sol[0]) for sol in archive]\n    current_utilization = [w / capacity for w in current_weights]\n    # Solutions that are neither too full nor too empty are more promising\n    promising_indices = [i for i, u in enumerate(current_utilization) if 0.3 <= u <= 0.7]\n    if not promising_indices:\n        promising_indices = list(range(len(archive)))\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy\n    # 1. Random flip with weighted probability based on marginal contribution\n    for _ in range(3):  # Number of flips\n        # Calculate marginal contributions\n        marginal1 = value1_lst / weight_lst\n        marginal2 = value2_lst / weight_lst\n        # Combine marginal contributions (simple average)\n        combined_marginal = (marginal1 + marginal2) / 2\n        # Probability of flipping is proportional to marginal contribution\n        flip_probs = combined_marginal * (1 - new_solution) + combined_marginal * new_solution * 0.5\n        flip_probs = flip_probs / np.sum(flip_probs)\n        # Select item to flip\n        candidate = np.random.choice(len(weight_lst), p=flip_probs)\n        # Check feasibility\n        if new_solution[candidate] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n\n    # 2. Novel exchange-based operator: exchange two items with complementary values\n    # Find pairs of items where one is in the solution and the other is out\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Select a random pair\n        i_in = random.choice(in_items)\n        i_out = random.choice(out_items)\n        # Check feasibility of exchange\n        delta = weight_lst[i_out] - weight_lst[i_in]\n        if np.sum(weight_lst * new_solution) + delta <= capacity:\n            new_solution[i_in] = 0\n            new_solution[i_out] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 288,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified: higher value1 + value2 is more promising)\n        sorted_solutions = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution that is not the best to encourage diversity\n        selected_idx = min(1, len(sorted_solutions) - 1)\n        base_solution = sorted_solutions[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their marginal contribution)\n    # 2. If feasible, perform a greedy improvement step\n    # 3. If not feasible, perform a repair step\n\n    # Step 1: Random flip with probability based on marginal contribution\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # Base probability\n            # Adjust probability based on marginal contribution\n            if new_solution[i] == 1:\n                # Probability to remove is higher if removing improves both objectives\n                prob_remove = 0.5 + (value1_lst[i] + value2_lst[i]) / (np.sum(value1_lst) + np.sum(value2_lst))\n                if random.random() < prob_remove:\n                    new_solution[i] = 0\n            else:\n                # Probability to add is higher if adding improves both objectives\n                prob_add = 0.5 + (value1_lst[i] + value2_lst[i]) / (np.sum(value1_lst) + np.sum(value2_lst))\n                if random.random() < prob_add:\n                    new_solution[i] = 1\n\n    # Check feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Step 3: Repair step - remove items with lowest marginal contribution until feasible\n        while total_weight > capacity:\n            # Calculate marginal contribution for each item (value1 + value2) / weight\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            # Remove the item with the lowest marginal contribution that is currently included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                item_to_remove = included_items[np.argmin(marginal_contribution[included_items])]\n                new_solution[item_to_remove] = 0\n                total_weight -= weight_lst[item_to_remove]\n            else:\n                break  # No items left to remove (shouldn't happen if capacity > min(weight_lst))\n    else:\n        # Step 2: Greedy improvement step - add items with highest marginal contribution\n        # Calculate marginal contribution for each item (value1 + value2) / weight\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        # Sort items by marginal contribution (descending)\n        sorted_items = np.argsort(-marginal_contribution)\n        for i in sorted_items:\n            if new_solution[i] == 0 and (total_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3748131178122512,
            6.322973340749741
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if len(archive) > 1:\n        # Sort solutions by their dominance (simplified: higher value1 + value2 is more promising)\n        sorted_solutions = sorted(archive, key=lambda x: -(x[1][0] + x[1][1]))\n        # Select a solution that is not the best to encourage diversity\n        selected_idx = min(1, len(sorted_solutions) - 1)\n        base_solution = sorted_solutions[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (with probability based on their marginal contribution)\n    # 2. If feasible, perform a greedy improvement step\n    # 3. If not feasible, perform a repair step\n\n    # Step 1: Random flip with probability based on marginal contribution\n    for i in range(len(new_solution)):\n        if random.random() < 0.3:  # Base probability\n            # Adjust probability based on marginal contribution\n            if new_solution[i] == 1:\n                # Probability to remove is higher if removing improves both objectives\n                prob_remove = 0.5 + (value1_lst[i] + value2_lst[i]) / (np.sum(value1_lst) + np.sum(value2_lst))\n                if random.random() < prob_remove:\n                    new_solution[i] = 0\n            else:\n                # Probability to add is higher if adding improves both objectives\n                prob_add = 0.5 + (value1_lst[i] + value2_lst[i]) / (np.sum(value1_lst) + np.sum(value2_lst))\n                if random.random() < prob_add:\n                    new_solution[i] = 1\n\n    # Check feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Step 3: Repair step - remove items with lowest marginal contribution until feasible\n        while total_weight > capacity:\n            # Calculate marginal contribution for each item (value1 + value2) / weight\n            marginal_contribution = (value1_lst + value2_lst) / weight_lst\n            # Remove the item with the lowest marginal contribution that is currently included\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) > 0:\n                item_to_remove = included_items[np.argmin(marginal_contribution[included_items])]\n                new_solution[item_to_remove] = 0\n                total_weight -= weight_lst[item_to_remove]\n            else:\n                break  # No items left to remove (shouldn't happen if capacity > min(weight_lst))\n    else:\n        # Step 2: Greedy improvement step - add items with highest marginal contribution\n        # Calculate marginal contribution for each item (value1 + value2) / weight\n        marginal_contribution = (value1_lst + value2_lst) / weight_lst\n        # Sort items by marginal contribution (descending)\n        sorted_items = np.argsort(-marginal_contribution)\n        for i in sorted_items:\n            if new_solution[i] == 0 and (total_weight + weight_lst[i]) <= capacity:\n                new_solution[i] = 1\n                total_weight += weight_lst[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 289,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution: prioritize those with high objective values\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of solutions\n    selected_solution = archive_sorted[random.randint(0, selected_idx)][0].copy()\n\n    # Generate a neighbor by flipping a random subset of items\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n\n    # Apply the flip and check feasibility\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # If infeasible, undo the flip for the heaviest items\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        excess_items = np.where((new_solution == 1) & (weight_lst > 0))[0]\n        excess_weights = weight_lst[excess_items]\n        sorted_excess = excess_items[np.argsort(excess_weights)[::-1]]\n\n        for item in sorted_excess:\n            if excess <= 0:\n                break\n            new_solution[item] = 0\n            excess -= weight_lst[item]\n\n    # Apply a greedy improvement step: add the most valuable items not in the solution\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n\n    # Sort remaining items by a combination of both objectives\n    combined_value = value1_lst + value2_lst\n    sorted_remaining = remaining_items[np.argsort(combined_value[remaining_items])[::-1]]\n\n    for item in sorted_remaining:\n        if remaining_weight >= weight_lst[item]:\n            new_solution[item] = 1\n            remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "score": [
            -0.3489059433475843,
            1.6158221065998077
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution: prioritize those with high objective values\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    selected_idx = min(int(len(archive) * 0.3), len(archive) - 1)  # Select from top 30% of solutions\n    selected_solution = archive_sorted[random.randint(0, selected_idx)][0].copy()\n\n    # Generate a neighbor by flipping a random subset of items\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n\n    # Apply the flip and check feasibility\n    new_solution[flip_mask] = 1 - new_solution[flip_mask]\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # If infeasible, undo the flip for the heaviest items\n    if total_weight > capacity:\n        excess = total_weight - capacity\n        excess_items = np.where((new_solution == 1) & (weight_lst > 0))[0]\n        excess_weights = weight_lst[excess_items]\n        sorted_excess = excess_items[np.argsort(excess_weights)[::-1]]\n\n        for item in sorted_excess:\n            if excess <= 0:\n                break\n            new_solution[item] = 0\n            excess -= weight_lst[item]\n\n    # Apply a greedy improvement step: add the most valuable items not in the solution\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    remaining_items = np.where(new_solution == 0)[0]\n\n    # Sort remaining items by a combination of both objectives\n    combined_value = value1_lst + value2_lst\n    sorted_remaining = remaining_items[np.argsort(combined_value[remaining_items])[::-1]]\n\n    for item in sorted_remaining:\n        if remaining_weight >= weight_lst[item]:\n            new_solution[item] = 1\n            remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 290,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Sort archive by a combination of objective values to prioritize solutions near the Pareto front\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution, _ = random.choice(archive_sorted[:max(1, len(archive_sorted) // 2)])\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random flip with targeted improvement\n    for _ in range(10):  # Number of attempts to improve\n        # Random flip with bias towards improving objectives\n        flip_indices = np.where(new_solution == 1)[0]\n        if len(flip_indices) > 0:\n            flip_idx = random.choice(flip_indices)\n            if random.random() < 0.7:  # Higher chance to remove items\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n            else:\n                # Try to add a new item that improves both objectives\n                possible_adds = np.where(new_solution == 0)[0]\n                if len(possible_adds) > 0:\n                    for idx in possible_adds:\n                        if current_weight + weight_lst[idx] <= capacity:\n                            # Check if adding this item improves both objectives\n                            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                                new_solution[idx] = 1\n                                current_weight += weight_lst[idx]\n                                break\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        if len(excess_indices) == 0:\n            break\n        remove_idx = random.choice(excess_indices)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "score": [
            -0.4746966047586874,
            1.8703905642032623
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Sort archive by a combination of objective values to prioritize solutions near the Pareto front\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1]), reverse=True)\n    base_solution, _ = random.choice(archive_sorted[:max(1, len(archive_sorted) // 2)])\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search: combine random flip with targeted improvement\n    for _ in range(10):  # Number of attempts to improve\n        # Random flip with bias towards improving objectives\n        flip_indices = np.where(new_solution == 1)[0]\n        if len(flip_indices) > 0:\n            flip_idx = random.choice(flip_indices)\n            if random.random() < 0.7:  # Higher chance to remove items\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n            else:\n                # Try to add a new item that improves both objectives\n                possible_adds = np.where(new_solution == 0)[0]\n                if len(possible_adds) > 0:\n                    for idx in possible_adds:\n                        if current_weight + weight_lst[idx] <= capacity:\n                            # Check if adding this item improves both objectives\n                            if (value1_lst[idx] > 0 and value2_lst[idx] > 0):\n                                new_solution[idx] = 1\n                                current_weight += weight_lst[idx]\n                                break\n\n    # Ensure feasibility\n    while np.sum(weight_lst * new_solution) > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        if len(excess_indices) == 0:\n            break\n        remove_idx = random.choice(excess_indices)\n        new_solution[remove_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 291,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., one that is not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip-based and swap-based moves\n    # Step 1: Flip-based move (flip a random item if feasible)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_item = random.choice(flip_candidates)\n        if (np.sum(weight_lst * new_solution) - weight_lst[flip_item]) <= capacity:\n            new_solution[flip_item] = 0\n        else:\n            # If flipping out makes it feasible, try adding a new item\n            add_candidates = np.where(new_solution == 0)[0]\n            if len(add_candidates) > 0:\n                add_item = random.choice(add_candidates)\n                if (np.sum(weight_lst * new_solution) + weight_lst[add_item]) <= capacity:\n                    new_solution[add_item] = 1\n\n    # Step 2: Swap-based move (swap two items if feasible)\n    swap_candidates = np.where(new_solution == 1)[0]\n    if len(swap_candidates) >= 2:\n        item1, item2 = random.sample(list(swap_candidates), 2)\n        if (np.sum(weight_lst * new_solution) - weight_lst[item1] + weight_lst[item2]) <= capacity:\n            new_solution[item1], new_solution[item2] = 0, 1\n\n    # Step 3: Add a new item if space allows (exploration)\n    if np.sum(weight_lst * new_solution) < capacity:\n        add_candidates = np.where(new_solution == 0)[0]\n        if len(add_candidates) > 0:\n            add_item = random.choice(add_candidates)\n            if (np.sum(weight_lst * new_solution) + weight_lst[add_item]) <= capacity:\n                new_solution[add_item] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.6129429060075657,
            1.2648641467094421
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., one that is not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combination of flip-based and swap-based moves\n    # Step 1: Flip-based move (flip a random item if feasible)\n    flip_candidates = np.where(new_solution == 1)[0]\n    if len(flip_candidates) > 0:\n        flip_item = random.choice(flip_candidates)\n        if (np.sum(weight_lst * new_solution) - weight_lst[flip_item]) <= capacity:\n            new_solution[flip_item] = 0\n        else:\n            # If flipping out makes it feasible, try adding a new item\n            add_candidates = np.where(new_solution == 0)[0]\n            if len(add_candidates) > 0:\n                add_item = random.choice(add_candidates)\n                if (np.sum(weight_lst * new_solution) + weight_lst[add_item]) <= capacity:\n                    new_solution[add_item] = 1\n\n    # Step 2: Swap-based move (swap two items if feasible)\n    swap_candidates = np.where(new_solution == 1)[0]\n    if len(swap_candidates) >= 2:\n        item1, item2 = random.sample(list(swap_candidates), 2)\n        if (np.sum(weight_lst * new_solution) - weight_lst[item1] + weight_lst[item2]) <= capacity:\n            new_solution[item1], new_solution[item2] = 0, 1\n\n    # Step 3: Add a new item if space allows (exploration)\n    if np.sum(weight_lst * new_solution) < capacity:\n        add_candidates = np.where(new_solution == 0)[0]\n        if len(add_candidates) > 0:\n            add_item = random.choice(add_candidates)\n            if (np.sum(weight_lst * new_solution) + weight_lst[add_item]) <= capacity:\n                new_solution[add_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 292,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: choose a solution with high total value in either objective\n    objectives = np.array([obj for _, obj in archive])\n    total_values = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(total_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Flip-based local search: randomly flip a subset of items\n    for _ in range(3):  # Try multiple flips\n        flip_idx = np.random.choice(len(new_solution), size=min(5, len(new_solution)), replace=False)\n        for idx in flip_idx:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Swap-based local search: swap items between different objectives\n    if len(new_solution) > 1:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        i, j = swap_indices[0], swap_indices[1]\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility before swapping\n            if (new_solution[i] == 1 and new_solution[j] == 0 and\n                current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            elif (new_solution[i] == 0 and new_solution[j] == 1 and\n                  current_weight + weight_lst[i] - weight_lst[j] <= capacity):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.3085739623838471,
            1.9743702411651611
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Intelligent selection: choose a solution with high total value in either objective\n    objectives = np.array([obj for _, obj in archive])\n    total_values = np.sum(objectives, axis=1)\n    selected_idx = np.argmax(total_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search strategy: combination of flip and swap\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Flip-based local search: randomly flip a subset of items\n    for _ in range(3):  # Try multiple flips\n        flip_idx = np.random.choice(len(new_solution), size=min(5, len(new_solution)), replace=False)\n        for idx in flip_idx:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    # Swap-based local search: swap items between different objectives\n    if len(new_solution) > 1:\n        swap_indices = np.random.choice(len(new_solution), size=2, replace=False)\n        i, j = swap_indices[0], swap_indices[1]\n        if new_solution[i] != new_solution[j]:\n            # Check feasibility before swapping\n            if (new_solution[i] == 1 and new_solution[j] == 0 and\n                current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            elif (new_solution[i] == 0 and new_solution[j] == 1 and\n                  current_weight + weight_lst[i] - weight_lst[j] <= capacity):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 293,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with potential for improvement (not dominated by others)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items that can be flipped (either included or excluded)\n    flip_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item would keep the solution feasible\n            if total_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(('remove', i))\n        else:\n            # Check if adding this item would keep the solution feasible\n            if total_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(('add', i))\n\n    if not flip_candidates:\n        return base_solution.copy()  # No feasible flips, return original\n\n    # Hybrid selection: prioritize items with high value-to-weight ratio in either objective\n    random.shuffle(flip_candidates)\n    best_candidate = None\n    best_improvement = -float('inf')\n\n    for action, i in flip_candidates:\n        if action == 'remove':\n            # Calculate improvement in both objectives\n            improvement1 = -value1_lst[i]\n            improvement2 = -value2_lst[i]\n            # Weighted improvement (can be adjusted)\n            total_improvement = improvement1 * 0.5 + improvement2 * 0.5\n        else:  # 'add'\n            improvement1 = value1_lst[i]\n            improvement2 = value2_lst[i]\n            total_improvement = improvement1 * 0.5 + improvement2 * 0.5\n\n        if total_improvement > best_improvement:\n            best_improvement = total_improvement\n            best_candidate = (action, i)\n\n    if best_candidate:\n        action, i = best_candidate\n        if action == 'remove':\n            new_solution[i] = 0\n        else:\n            new_solution[i] = 1\n\n    # Additional random flip to escape local optima\n    if len(flip_candidates) > 0 and random.random() < 0.3:  # 30% chance\n        action, i = random.choice(flip_candidates)\n        if action == 'remove':\n            new_solution[i] = 0\n        else:\n            new_solution[i] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.9298885975612141,
            2.1922498047351837
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with potential for improvement (not dominated by others)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_val1, current_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Identify items that can be flipped (either included or excluded)\n    flip_candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Check if removing this item would keep the solution feasible\n            if total_weight - weight_lst[i] <= capacity:\n                flip_candidates.append(('remove', i))\n        else:\n            # Check if adding this item would keep the solution feasible\n            if total_weight + weight_lst[i] <= capacity:\n                flip_candidates.append(('add', i))\n\n    if not flip_candidates:\n        return base_solution.copy()  # No feasible flips, return original\n\n    # Hybrid selection: prioritize items with high value-to-weight ratio in either objective\n    random.shuffle(flip_candidates)\n    best_candidate = None\n    best_improvement = -float('inf')\n\n    for action, i in flip_candidates:\n        if action == 'remove':\n            # Calculate improvement in both objectives\n            improvement1 = -value1_lst[i]\n            improvement2 = -value2_lst[i]\n            # Weighted improvement (can be adjusted)\n            total_improvement = improvement1 * 0.5 + improvement2 * 0.5\n        else:  # 'add'\n            improvement1 = value1_lst[i]\n            improvement2 = value2_lst[i]\n            total_improvement = improvement1 * 0.5 + improvement2 * 0.5\n\n        if total_improvement > best_improvement:\n            best_improvement = total_improvement\n            best_candidate = (action, i)\n\n    if best_candidate:\n        action, i = best_candidate\n        if action == 'remove':\n            new_solution[i] = 0\n        else:\n            new_solution[i] = 1\n\n    # Additional random flip to escape local optima\n    if len(flip_candidates) > 0 and random.random() < 0.3:  # 30% chance\n        action, i = random.choice(flip_candidates)\n        if action == 'remove':\n            new_solution[i] = 0\n        else:\n            new_solution[i] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 294,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution (higher probability for non-dominated solutions)\n    selected_solution = random.choice(archive)[0].copy()\n\n    # Step 2: Apply hybrid local search (value-weighted swap)\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select a subset of items to consider for swapping\n    subset_size = max(1, min(n_items // 5, 5))  # Dynamic subset size\n    candidate_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    for idx in candidate_indices:\n        # Calculate the \"value score\" for the item (weighted sum of normalized values)\n        value_score = (value1_lst[idx] / np.max(value1_lst)) + (value2_lst[idx] / np.max(value2_lst))\n\n        # Probabilistically decide to flip the item based on its value score\n        if random.random() < value_score:\n            if new_solution[idx] == 1:\n                # Remove the item if it's in the solution\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    current_value1 -= value1_lst[idx]\n                    current_value2 -= value2_lst[idx]\n            else:\n                # Add the item if it fits\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    current_value1 += value1_lst[idx]\n                    current_value2 += value2_lst[idx]\n\n    # Step 3: Ensure feasibility (fallback if needed)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            item_to_remove = random.choice(excess_items)\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "score": [
            -0.32519662490121876,
            1.6524919867515564
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution (higher probability for non-dominated solutions)\n    selected_solution = random.choice(archive)[0].copy()\n\n    # Step 2: Apply hybrid local search (value-weighted swap)\n    new_solution = selected_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select a subset of items to consider for swapping\n    subset_size = max(1, min(n_items // 5, 5))  # Dynamic subset size\n    candidate_indices = np.random.choice(n_items, size=subset_size, replace=False)\n\n    for idx in candidate_indices:\n        # Calculate the \"value score\" for the item (weighted sum of normalized values)\n        value_score = (value1_lst[idx] / np.max(value1_lst)) + (value2_lst[idx] / np.max(value2_lst))\n\n        # Probabilistically decide to flip the item based on its value score\n        if random.random() < value_score:\n            if new_solution[idx] == 1:\n                # Remove the item if it's in the solution\n                if current_weight - weight_lst[idx] >= 0:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    current_value1 -= value1_lst[idx]\n                    current_value2 -= value2_lst[idx]\n            else:\n                # Add the item if it fits\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    current_value1 += value1_lst[idx]\n                    current_value2 += value2_lst[idx]\n\n    # Step 3: Ensure feasibility (fallback if needed)\n    if current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_items = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(excess_items) > 0:\n            item_to_remove = random.choice(excess_items)\n            new_solution[item_to_remove] = 0\n            current_weight -= weight_lst[item_to_remove]\n            excess_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 295,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with significant remaining capacity\n            candidates.append(sol)\n\n    if not candidates:\n        # If no candidates with remaining capacity, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the highest remaining capacity\n        base_solution = max(candidates, key=lambda x: capacity - np.sum(weight_lst * x))\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply a greedy improvement step (exploitation)\n\n    # Step 1: Random flipping (exploration)\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    current_weight = np.sum(weight_lst * new_solution)\n    while current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        if len(excess_indices) == 0:\n            break  # No items to remove\n        remove_idx = random.choice(excess_indices)\n        new_solution[remove_idx] = 0\n        current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve at least one objective while maintaining feasibility\n    available_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(available_items)\n\n    for idx in available_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            # Check if adding this item improves at least one objective\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n\n            # Only add if it doesn't worsen both objectives\n            if (new_value1 >= np.sum(value1_lst * new_solution) or\n                new_value2 >= np.sum(value2_lst * new_solution)):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.25652797091764723,
            3.235495865345001
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        current_weight = np.sum(weight_lst * sol)\n        remaining_capacity = capacity - current_weight\n        if remaining_capacity > 0:\n            # Prioritize solutions with significant remaining capacity\n            candidates.append(sol)\n\n    if not candidates:\n        # If no candidates with remaining capacity, pick a random solution\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select the solution with the highest remaining capacity\n        base_solution = max(candidates, key=lambda x: capacity - np.sum(weight_lst * x))\n\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy:\n    # 1. Randomly flip a subset of items (exploration)\n    # 2. Apply a greedy improvement step (exploitation)\n\n    # Step 1: Random flipping (exploration)\n    num_items = len(new_solution)\n    flip_indices = random.sample(range(num_items), min(3, num_items))  # Flip up to 3 items\n    for idx in flip_indices:\n        new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility after random flips\n    current_weight = np.sum(weight_lst * new_solution)\n    while current_weight > capacity:\n        # Remove items randomly until feasible\n        excess_indices = np.where(new_solution == 1)[0]\n        if len(excess_indices) == 0:\n            break  # No items to remove\n        remove_idx = random.choice(excess_indices)\n        new_solution[remove_idx] = 0\n        current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Greedy improvement (exploitation)\n    # Try to add items that improve at least one objective while maintaining feasibility\n    available_items = np.where(new_solution == 0)[0]\n    np.random.shuffle(available_items)\n\n    for idx in available_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            # Check if adding this item improves at least one objective\n            new_value1 = np.sum(value1_lst * new_solution) + value1_lst[idx]\n            new_value2 = np.sum(value2_lst * new_solution) + value2_lst[idx]\n\n            # Only add if it doesn't worsen both objectives\n            if (new_value1 >= np.sum(value1_lst * new_solution) or\n                new_value2 >= np.sum(value2_lst * new_solution)):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 296,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution (biased towards knee of Pareto front)\n    def knee_distance(sol):\n        # Calculate distance to the ideal point\n        ideal1 = max(obj[1][0] for obj in archive)\n        ideal2 = max(obj[1][1] for obj in archive)\n        return np.sqrt((sol[1][0] - ideal1)**2 + (sol[1][1] - ideal2)**2)\n\n    archive_sorted = sorted(archive, key=knee_distance)\n    selection_pool = archive_sorted[:max(1, len(archive)//3)]  # Top 1/3 solutions by knee distance\n    base_solution, _ = random.choice(selection_pool)\n\n    # Step 2: Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Apply swap operator\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if (new_solution[i] != new_solution[j] and\n            np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply flip operator\n    flip_size = min(3, n_items)  # Flip up to 3 items\n    flip_indices = random.sample(range(n_items), flip_size)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "score": [
            -0.31675011264735814,
            8.260731369256973
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution (biased towards knee of Pareto front)\n    def knee_distance(sol):\n        # Calculate distance to the ideal point\n        ideal1 = max(obj[1][0] for obj in archive)\n        ideal2 = max(obj[1][1] for obj in archive)\n        return np.sqrt((sol[1][0] - ideal1)**2 + (sol[1][1] - ideal2)**2)\n\n    archive_sorted = sorted(archive, key=knee_distance)\n    selection_pool = archive_sorted[:max(1, len(archive)//3)]  # Top 1/3 solutions by knee distance\n    base_solution, _ = random.choice(selection_pool)\n\n    # Step 2: Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Apply swap operator\n    if n_items >= 2:\n        i, j = random.sample(range(n_items), 2)\n        if (new_solution[i] != new_solution[j] and\n            np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply flip operator\n    flip_size = min(3, n_items)  # Flip up to 3 items\n    flip_indices = random.sample(range(n_items), flip_size)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            if np.sum(weight_lst * new_solution) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        else:\n            if np.sum(weight_lst * new_solution) + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 297,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine bit-flip and swap operations\n    n_items = len(base_solution)\n    operations = ['bit_flip', 'swap', 'double_swap']\n\n    # Randomly choose an operation\n    operation = random.choice(operations)\n\n    if operation == 'bit_flip':\n        # Flip a random bit (if feasible)\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1:\n            # Check if removing the item keeps the solution feasible\n            if np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    elif operation == 'swap':\n        # Swap two items (if feasible)\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            # Calculate new weight\n            new_weight = np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j] if new_solution[i] == 1 else np.sum(weight_lst * new_solution) + weight_lst[j] - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    elif operation == 'double_swap':\n        # Swap two pairs of items (if feasible)\n        i, j, k, l = random.sample(range(n_items), 4)\n        if new_solution[i] != new_solution[j] and new_solution[k] != new_solution[l]:\n            # Calculate new weight\n            new_weight = np.sum(weight_lst * new_solution)\n            new_weight -= weight_lst[i] + weight_lst[k]\n            new_weight += weight_lst[j] + weight_lst[l]\n            if new_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                new_solution[k], new_solution[l] = new_solution[l], new_solution[k]\n\n    return new_solution\n\n",
        "score": [
            -0.2588285912328952,
            3.1352608501911163
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not too close to the Pareto front)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine bit-flip and swap operations\n    n_items = len(base_solution)\n    operations = ['bit_flip', 'swap', 'double_swap']\n\n    # Randomly choose an operation\n    operation = random.choice(operations)\n\n    if operation == 'bit_flip':\n        # Flip a random bit (if feasible)\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1:\n            # Check if removing the item keeps the solution feasible\n            if np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            # Check if adding the item keeps the solution feasible\n            if np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    elif operation == 'swap':\n        # Swap two items (if feasible)\n        i, j = random.sample(range(n_items), 2)\n        if new_solution[i] != new_solution[j]:\n            # Calculate new weight\n            new_weight = np.sum(weight_lst * new_solution) - weight_lst[i] + weight_lst[j] if new_solution[i] == 1 else np.sum(weight_lst * new_solution) + weight_lst[j] - weight_lst[i]\n            if new_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    elif operation == 'double_swap':\n        # Swap two pairs of items (if feasible)\n        i, j, k, l = random.sample(range(n_items), 4)\n        if new_solution[i] != new_solution[j] and new_solution[k] != new_solution[l]:\n            # Calculate new weight\n            new_weight = np.sum(weight_lst * new_solution)\n            new_weight -= weight_lst[i] + weight_lst[k]\n            new_weight += weight_lst[j] + weight_lst[l]\n            if new_weight <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                new_solution[k], new_solution[l] = new_solution[l], new_solution[k]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 298,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: bit-flip with probabilistic swap\n    new_solution = base_solution.copy()\n\n    # Step 1: Bit-flip operation (with probability)\n    if np.random.random() < 0.7:  # Higher probability for bit-flip\n        # Select items with the highest marginal value-to-weight ratio for potential inclusion\n        marginal_value1 = value1_lst / (weight_lst + 1e-10)\n        marginal_value2 = value2_lst / (weight_lst + 1e-10)\n        marginal_score = (marginal_value1 + marginal_value2) * (1 - new_solution)  # Focus on items not in solution\n\n        # Select top-k items to consider for flip\n        k = min(5, len(weight_lst))\n        top_items = np.argsort(marginal_score)[-k:]\n\n        for item in top_items:\n            if weight_lst[item] <= (capacity - current_weight + weight_lst[item]) and np.random.random() < 0.5:\n                new_solution[item] = 1 - new_solution[item]\n                current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Probabilistic swap operation (with probability)\n    if np.random.random() < 0.3:  # Lower probability for swap to maintain stability\n        # Select a pair of items: one in the solution and one not in the solution\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high potential for improvement\n            in_item = np.random.choice(in_items)\n            out_item = np.random.choice(out_items)\n\n            # Check feasibility of swap\n            if (current_weight - weight_lst[in_item] + weight_lst[out_item]) <= capacity:\n                new_solution[in_item], new_solution[out_item] = new_solution[out_item], new_solution[in_item]\n\n    return new_solution\n\n",
        "score": [
            -0.3013201496220107,
            2.710673898458481
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution, (current_value1, current_value2) = archive[selected_idx]\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Hybrid local search strategy: bit-flip with probabilistic swap\n    new_solution = base_solution.copy()\n\n    # Step 1: Bit-flip operation (with probability)\n    if np.random.random() < 0.7:  # Higher probability for bit-flip\n        # Select items with the highest marginal value-to-weight ratio for potential inclusion\n        marginal_value1 = value1_lst / (weight_lst + 1e-10)\n        marginal_value2 = value2_lst / (weight_lst + 1e-10)\n        marginal_score = (marginal_value1 + marginal_value2) * (1 - new_solution)  # Focus on items not in solution\n\n        # Select top-k items to consider for flip\n        k = min(5, len(weight_lst))\n        top_items = np.argsort(marginal_score)[-k:]\n\n        for item in top_items:\n            if weight_lst[item] <= (capacity - current_weight + weight_lst[item]) and np.random.random() < 0.5:\n                new_solution[item] = 1 - new_solution[item]\n                current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Probabilistic swap operation (with probability)\n    if np.random.random() < 0.3:  # Lower probability for swap to maintain stability\n        # Select a pair of items: one in the solution and one not in the solution\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Select items with high potential for improvement\n            in_item = np.random.choice(in_items)\n            out_item = np.random.choice(out_items)\n\n            # Check feasibility of swap\n            if (current_weight - weight_lst[in_item] + weight_lst[out_item]) <= capacity:\n                new_solution[in_item], new_solution[out_item] = new_solution[out_item], new_solution[in_item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 299,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., those with high marginal gains)\n    selected_idx = random.choices(range(len(archive)), weights=[obj[0] + obj[1] for (sol, obj) in archive], k=1)[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random bit flips with a greedy selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider flipping\n    flip_candidates = random.sample(range(num_items), min(5, num_items))\n\n    for item in flip_candidates:\n        if new_solution[item] == 1:\n            # Consider removing the item\n            new_weight = current_weight - weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 0\n                current_weight = new_weight\n        else:\n            # Consider adding the item\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                # Use a greedy criterion to decide whether to add the item\n                marginal_gain = (value1_lst[item] + value2_lst[item]) / weight_lst[item]\n                if marginal_gain > 0.5 * np.mean((value1_lst + value2_lst) / weight_lst):\n                    new_solution[item] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n",
        "score": [
            -0.43139624522606146,
            1.6958359777927399
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., those with high marginal gains)\n    selected_idx = random.choices(range(len(archive)), weights=[obj[0] + obj[1] for (sol, obj) in archive], k=1)[0]\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Hybrid local search strategy: combine random bit flips with a greedy selection\n    num_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Randomly select a subset of items to consider flipping\n    flip_candidates = random.sample(range(num_items), min(5, num_items))\n\n    for item in flip_candidates:\n        if new_solution[item] == 1:\n            # Consider removing the item\n            new_weight = current_weight - weight_lst[item]\n            if new_weight <= capacity:\n                new_solution[item] = 0\n                current_weight = new_weight\n        else:\n            # Consider adding the item\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                # Use a greedy criterion to decide whether to add the item\n                marginal_gain = (value1_lst[item] + value2_lst[item]) / weight_lst[item]\n                if marginal_gain > 0.5 * np.mean((value1_lst + value2_lst) / weight_lst):\n                    new_solution[item] = 1\n                    current_weight = new_weight\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems. Your response outputs Python code and nothing else. Format your code as a Python code string: \"```python ...```\"\nYou are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.  \ndef select_neighbor_v1(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n  \nImprove `select_neighbor_v1` to give `select_neighbor_v2`. Output code only and enclose your code with Python code block: ```python ...```.  \n",
        "sample_order": 300,
        "algorithm": "",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution\n    # Calculate potential for each solution: objective diversity and slack capacity\n    potentials = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        slack = capacity - total_weight\n        diversity = v1 + v2  # Simple proxy for diversity\n        potential = diversity * slack\n        potentials.append(potential)\n\n    # Select top 3 solutions with highest potential\n    top_indices = np.argsort(potentials)[-min(3, len(archive)):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate marginal value-to-weight ratios for both objectives\n    included = new_solution == 1\n    excluded = new_solution == 0\n\n    # For included items, calculate marginal value-to-weight ratios\n    if np.any(included):\n        marginal_v1_in = value1_lst[included] / weight_lst[included]\n        marginal_v2_in = value2_lst[included] / weight_lst[included]\n\n        # For excluded items, calculate marginal value-to-weight ratios\n    if np.any(excluded):\n        marginal_v1_out = value1_lst[excluded] / weight_lst[excluded]\n        marginal_v2_out = value2_lst[excluded] / weight_lst[excluded]\n\n    # Step 2.1: Flip items with high marginal ratios\n    flip_candidates = []\n    if np.any(included):\n        # Consider removing items with low marginal value\n        low_v1_in = np.where(marginal_v1_in < np.percentile(marginal_v1_in, 30))[0]\n        low_v2_in = np.where(marginal_v2_in < np.percentile(marginal_v2_in, 30))[0]\n        flip_candidates.extend(np.where(included)[0][np.intersect1d(low_v1_in, low_v2_in)])\n\n    if np.any(excluded):\n        # Consider adding items with high marginal value\n        high_v1_out = np.where(marginal_v1_out > np.percentile(marginal_v1_out, 70))[0]\n        high_v2_out = np.where(marginal_v2_out > np.percentile(marginal_v2_out, 70))[0]\n        flip_candidates.extend(np.where(excluded)[0][np.intersect1d(high_v1_out, high_v2_out)])\n\n    # Apply flips while maintaining feasibility\n    random.shuffle(flip_candidates)\n    current_weight = np.sum(weight_lst * new_solution)\n    for idx in flip_candidates:\n        if new_solution[idx] == 1:\n            # Trying to remove item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Trying to add item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2.2: Random walk to escape local optima\n    # Flip a small number of random items (1-3) to introduce diversity\n    num_flips = random.randint(1, 3)\n    for _ in range(num_flips):\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
        "score": [
            -0.3677253735822246,
            5.794322639703751
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution\n    # Calculate potential for each solution: objective diversity and slack capacity\n    potentials = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        slack = capacity - total_weight\n        diversity = v1 + v2  # Simple proxy for diversity\n        potential = diversity * slack\n        potentials.append(potential)\n\n    # Select top 3 solutions with highest potential\n    top_indices = np.argsort(potentials)[-min(3, len(archive)):]\n    selected_idx = random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n\n    # Calculate marginal value-to-weight ratios for both objectives\n    included = new_solution == 1\n    excluded = new_solution == 0\n\n    # For included items, calculate marginal value-to-weight ratios\n    if np.any(included):\n        marginal_v1_in = value1_lst[included] / weight_lst[included]\n        marginal_v2_in = value2_lst[included] / weight_lst[included]\n\n        # For excluded items, calculate marginal value-to-weight ratios\n    if np.any(excluded):\n        marginal_v1_out = value1_lst[excluded] / weight_lst[excluded]\n        marginal_v2_out = value2_lst[excluded] / weight_lst[excluded]\n\n    # Step 2.1: Flip items with high marginal ratios\n    flip_candidates = []\n    if np.any(included):\n        # Consider removing items with low marginal value\n        low_v1_in = np.where(marginal_v1_in < np.percentile(marginal_v1_in, 30))[0]\n        low_v2_in = np.where(marginal_v2_in < np.percentile(marginal_v2_in, 30))[0]\n        flip_candidates.extend(np.where(included)[0][np.intersect1d(low_v1_in, low_v2_in)])\n\n    if np.any(excluded):\n        # Consider adding items with high marginal value\n        high_v1_out = np.where(marginal_v1_out > np.percentile(marginal_v1_out, 70))[0]\n        high_v2_out = np.where(marginal_v2_out > np.percentile(marginal_v2_out, 70))[0]\n        flip_candidates.extend(np.where(excluded)[0][np.intersect1d(high_v1_out, high_v2_out)])\n\n    # Apply flips while maintaining feasibility\n    random.shuffle(flip_candidates)\n    current_weight = np.sum(weight_lst * new_solution)\n    for idx in flip_candidates:\n        if new_solution[idx] == 1:\n            # Trying to remove item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Trying to add item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2.2: Random walk to escape local optima\n    # Flip a small number of random items (1-3) to introduce diversity\n    num_flips = random.randint(1, 3)\n    for _ in range(num_flips):\n        idx = random.randint(0, n_items - 1)\n        if new_solution[idx] == 1:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    return new_solution\n\n"
    }
]